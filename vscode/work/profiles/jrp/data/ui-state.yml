42Crunch.vscode-openapi: '{"openapiVersion":"4.37.2"}'
amazonwebservices.aws-toolkit-vscode: '{"telemetryClientId":"3eb36e65-667b-422d-85e7-49022cd4aa5b","isExtensionFirstUse":false,"lastOsStartTime":1752927119896,"globalsMostRecentVersion":"3.69.0","aws.notifications":{"startUp":{"payload":{"schemaVersion":"1.x","notifications":[]},"eTag":"\"5bdb28c6f8572180bd1bd2a343fe05d8\""},"emergency":{"payload":{"schemaVersion":"1.x","notifications":[]},"eTag":"\"5bdb28c6f8572180bd1bd2a343fe05d8\""},"dismissed":[],"newlyReceived":[]},"devfileSchemaVersion":"v2.3.0","aws.toolkit.amazonqInstall.dismissed":true,"lastExtensionVersion":"3.69.0","samAndCfnSchemaVersion":"W/\"4b3c5c4611ca66293f4fd95cd3817e52c1f75c878cfe64da364bf9d593bb093a\"","telemetryId":"[[\"us-east-1:820fd6d1-95c0-4ca4-bffb-3f01d32da842\",\"us-east-1:622b0cc5-147d-c403-1f8c-ce645f0d680a\"]]","awsTelemetryNoticeVersionAck":2,"auth.profiles":{"profile:AWSAdministratorAccess-904906761843":{"type":"iam","subtype":"unknown","name":"AWSAdministratorAccess-904906761843","metadata":{"connectionState":"unauthenticated"}}}}'
atlassian.atlascode: '{"rulingPid":7768,"pmfStats":{"lastSurveyed":"2024-08-23","snoozeUntil":"2025-02-23[1740361568439]19:46:08-06:00","activityByDay":{"2025-07-07":1,"2025-07-12":1}},"atlascodeVersion":"3.8.6","configurationTarget":"user","jiraSites":[{"avatarUrl":"https://site-admin-avatar-cdn.prod.public.atl-paas.net/avatars/240/star.png","baseApiUrl":"https://api.atlassian.com/ex/jira/83e543b3-ccb7-46d9-8395-c9f7673e0b1b/rest","baseLinkUrl":"https://jasperridge.atlassian.net","host":"jasperridge.atlassian.net","id":"83e543b3-ccb7-46d9-8395-c9f7673e0b1b","name":"jasperridge","product":{"name":"Jira","key":"jira"},"isCloud":true,"userId":"63cee469a05386069cda1536","credentialId":"5f3911b9f10aa9a9f47ebb46b4a5aeeb"}],"userReadNotifications":[]}'
ckolkman.vscode-postgres: '{"postgresql.connections":{"1800f3d0-f37a-11ef-9c77-ef70b72e73b6":{"label":"Local
  Entity
  Mgmt","host":"127.0.0.1","user":"entity_mgmt_admin","port":5432,"ssl":false,"database":"entity_mgmt_db","hasPassword":true}}}'
figma.figma-vscode-extension: '{"loggedIn.prod":false,"selectedOrgId.prod":null,"featureFlags.prod":{"dt_code_connect_vscode_assistant":false}}'
GitHub.copilot: '{"installedVersion":"1.344.0"}'
GitHub.vscode-pull-request-github: '{"VSCode.ABExp.FeatureData":{"features":["chat.defaultLanguageModel","chat.defaultMode","config.chat.editRequests","config.chat.setup.signInDialogVariant","config.github.copilot.chat.advanced.enableApplyPatchTool","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow","config.workbench.secondarySideBar.defaultVisibility","copilotchat.claudeReplaceStringExclusively","copilotchat.enableNesInSettings","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","test-ai-12cf","testaa123cf","validate_micf","vscode.nothing5","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;binariesv615:30325510;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;9d2cg352:31346308;usemarketplace:31343026;nesew2to5:31336538;agentclaude:31335814;nes-diff-11:31337487;replacestringexc:31350595;nes-set-on:31340697;testaa123cf:31335227;6abeh943:31336334;yijiwantestdri0626-c:31336931;0927b901:31350571;4gdec884:31348710;7g84e740:31350607;1c1c4419-mono:31350621;","configs":[{"Id":"vscode","Parameters":{"chat.defaultLanguageModel":"github.copilot-chat/claude-sonnet-4","chat.defaultMode":"agent","config.chat.editRequests":"inline","config.chat.setup.signInDialogVariant":"alternate-monochrome","config.github.copilot.chat.advanced.enableApplyPatchTool":true,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove":2,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow":5,"config.workbench.secondarySideBar.defaultVisibility":"visibleInWorkspace","copilotchat.claudeReplaceStringExclusively":true,"copilotchat.enableNesInSettings":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"test-ai-12":false,"testaa123":false,"validate_mi":false,"vscode.nothing5":"
  ","workspace.embeddingIndex.automaticReindexingDelay":100000000}}]},"hasMigratedQueries":true,"hasMigratedDefaultQueries4":true,"githubPullRequest.lastUsedScopes":["read:user","user:email","repo","workflow"],"githubPullRequest.lastUsedScopesEnterprise":["read:user","user:email","repo","workflow"]}'
hediet.vscode-drawio: '{"hediet.vscode-drawio.local-storage":{".drawio-config":"{\"language\":\"\",\"customFonts\":[],\"libraries\":\"general;er\",\"customLibraries\":[\"L.scratchpad\"],\"plugins\":[],\"recentColors\":[],\"formatWidth\":\"240\",\"createTarget\":false,\"pageFormat\":{\"x\":0,\"y\":0,\"width\":850,\"height\":1100},\"search\":true,\"showStartScreen\":true,\"gridColor\":\"#d0d0d0\",\"darkGridColor\":\"#424242\",\"autosave\":true,\"openCounter\":0,\"version\":18,\"unit\":1,\"isRulerOn\":false,\"ui\":\"\"}"}}'
innoverio.vscode-dbt-power-user: '{"showSetupWalkthrough":false}'
ms-azuretools.vscode-docker: '{"isRegistryMigrated":true,"vscode-docker.activity.overallnoedit":{"lastSession":1747750291080,"currentMonthSessions":1,"totalSessions":3},"vscode-docker.activity.overall":{"lastSession":1747750291088,"currentMonthSessions":1,"totalSessions":3},"VSCode.ABExp.FeatureData":{"features":["config.chat.experimental.statusIndicator.enabled","config.chat.setupFromDialog","config.window.experimentalTitleBarStyle","copilot_ci","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","portForwardingServiceEnabled-development","portForwardingServiceEnabled-production","portForwardingServiceEnabled-staging","shouldUseGrpcService","validate_micf","vscode-docker.aatestcf","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;vscode-docker_aaflightcf:30153984;vspor879:30202332;vspor708:30202333;vspor363:30204092;binariesv615:30325510;c4g48928:30535728;6074i472:31201624;customenabled:31248079;9064b325:31222308;copilot_t_ci:31222730;4gafe986:31271826;usemplatestapi:31297334;7bj51361:31289155;aj953862:31281341;","configs":[{"Id":"vscode","Parameters":{"config.chat.experimental.statusIndicator.enabled":true,"config.chat.setupFromDialog":true,"config.window.experimentalTitleBarStyle":"custom","copilot_ci":true,"extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"portForwardingServiceEnabled-development":true,"portForwardingServiceEnabled-production":true,"portForwardingServiceEnabled-staging":true,"shouldUseGrpcService":true,"validate_mi":false,"vscode-docker.aatest":false,"workspace.embeddingIndex.automaticReindexingDelay":100000000}}]},"vscode-docker.migrateToContainerTools.lastShown":1747750291080}'
ms-dotnettools.csdevkit: '{"VSCode.ABExp.FeatureData":{"features":["chat.defaultLanguageModel","chat.defaultMode","config.chat.editRequests","config.chat.setup.signInDialogVariant","config.github.copilot.chat.advanced.enableApplyPatchTool","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow","config.workbench.secondarySideBar.defaultVisibility","copilotchat.claudeReplaceStringExclusively","copilotchat.enableNesInSettings","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","test-ai-12cf","testaa123cf","validate_micf","vscode.nothing5","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;binariesv615:30325510;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;9d2cg352:31346308;usemarketplace:31343026;nesew2to5:31336538;agentclaude:31335814;nes-diff-11:31337487;replacestringexc:31350595;nes-set-on:31340697;testaa123cf:31335227;6abeh943:31336334;yijiwantestdri0626-c:31336931;0927b901:31350571;4gdec884:31348710;7g84e740:31350607;1c1c4419-mono:31350621;","configs":[{"Id":"vscode","Parameters":{"chat.defaultLanguageModel":"github.copilot-chat/claude-sonnet-4","chat.defaultMode":"agent","config.chat.editRequests":"inline","config.chat.setup.signInDialogVariant":"alternate-monochrome","config.github.copilot.chat.advanced.enableApplyPatchTool":true,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove":2,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow":5,"config.workbench.secondarySideBar.defaultVisibility":"visibleInWorkspace","copilotchat.claudeReplaceStringExclusively":true,"copilotchat.enableNesInSettings":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"test-ai-12":false,"testaa123":false,"validate_mi":false,"vscode.nothing5":"
  ","workspace.embeddingIndex.automaticReindexingDelay":100000000}}]}}'
ms-dotnettools.vscode-dotnet-runtime: '{"installed":[{"dotnetInstall":{"installId":"8.0.13~arm64~aspnetcore","version":"8.0.13","architecture":"arm64","isGlobal":false,"installMode":"aspnetcore"},"installingExtensions":["ms-dotnettools.csdevkit"]},{"dotnetInstall":{"installId":"8.0.13~arm64","version":"8.0.13","architecture":"arm64","isGlobal":false,"installMode":"runtime"},"installingExtensions":["ms-dotnettools.csharp"]},{"dotnetInstall":{"installId":"8.0.16~arm64~aspnetcore","version":"8.0.16","architecture":"arm64","isGlobal":false,"installMode":"aspnetcore"},"installingExtensions":["ms-dotnettools.csdevkit"]},{"dotnetInstall":{"installId":"8.0.16~arm64","version":"8.0.16","architecture":"arm64","isGlobal":false,"installMode":"runtime"},"installingExtensions":["ms-dotnettools.csharp"]},{"dotnetInstall":{"installId":"8.0.17~arm64~aspnetcore","version":"8.0.17","architecture":"arm64","isGlobal":false,"installMode":"aspnetcore"},"installingExtensions":["ms-dotnettools.csdevkit"]},{"dotnetInstall":{"installId":"8.0.17~arm64","version":"8.0.17","architecture":"arm64","isGlobal":false,"installMode":"runtime"},"installingExtensions":["ms-dotnettools.csharp"]},{"dotnetInstall":{"installId":"8.0.18~arm64~aspnetcore","version":"8.0.18","architecture":"arm64","isGlobal":false,"installMode":"aspnetcore"},"installingExtensions":["ms-dotnettools.csdevkit"]},{"dotnetInstall":{"installId":"8.0.18~arm64","version":"8.0.18","architecture":"arm64","isGlobal":false,"installMode":"runtime"},"installingExtensions":["ms-dotnettools.csharp"]},{"dotnetInstall":{"installId":"9.0.7~arm64","version":"9.0.7","architecture":"arm64","isGlobal":false,"installMode":"runtime"},"installingExtensions":["ms-dotnettools.csharp","muhammad-sammy.csharp"]},{"dotnetInstall":{"installId":"9.0.7~arm64~aspnetcore","version":"9.0.7","architecture":"arm64","isGlobal":false,"installMode":"aspnetcore"},"installingExtensions":["ms-dotnettools.csharp","ms-dotnettools.csdevkit"]}],"installing":[],"installPathsGraveyard":{}}'
ms-python.debugpy: '{"PYTHON_GLOBAL_STORAGE_KEYS":[{"key":"PYTHON_EXTENSION_GLOBAL_STORAGE_KEYS","defaultValue":[]}]}'
ms-python.vscode-pylance: '{"VSCode.ABExp.FeatureData":{"features":["chat.defaultLanguageModel","chat.defaultMode","config.chat.editRequests","config.chat.setup.signInDialogVariant","config.github.copilot.chat.advanced.enableApplyPatchTool","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow","config.notebook.experimental.generate","config.python.analysis.enableEditableInstalls","config.python.analysis.usePullDiagnostics","config.python.locator","config.workbench.secondarySideBar.defaultVisibility","copilotchat.claudeReplaceStringExclusively","copilotchat.enableNesInSettings","copilotchat.ruffDiagnosticsCookbook","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","pylanceConvertFormatString","pylanceGenerateSymbol","pythonTerminalEnvVarActivation","test-ai-12cf","testaa123cf","validate_micf","vscode.nothing5","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;binariesv615:30325510;962ge761:31350689;nativeloc1:31344060;5fd0e150:31155592;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;pythoneinst12:31285622;pythonpulldiag:31343502;pythonrdcb7:31342333;usemplatestapi:31297334;aj953862:31281341;generatesymbolt:31295002;convertfstringf:31295003;9d2cg352:31346308;usemarketplace:31343026;nesew2to5:31336538;agentclaude:31335814;nes-diff-11:31337487;replacestringexc:31350595;nes-set-on:31340697;testaa123cf:31335227;6abeh943:31336334;yijiwantestdri0626-c:31336931;0927b901:31350571;4gdec884:31348710;7g84e740:31350607;1c1c4419-mono:31350621;","configs":[{"Id":"vscode","Parameters":{"chat.defaultLanguageModel":"github.copilot-chat/claude-sonnet-4","chat.defaultMode":"agent","config.chat.editRequests":"inline","config.chat.setup.signInDialogVariant":"alternate-monochrome","config.github.copilot.chat.advanced.enableApplyPatchTool":true,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove":2,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow":5,"config.notebook.experimental.generate":true,"config.python.analysis.enableEditableInstalls":true,"config.python.analysis.usePullDiagnostics":true,"config.python.locator":"native","config.workbench.secondarySideBar.defaultVisibility":"visibleInWorkspace","copilotchat.claudeReplaceStringExclusively":true,"copilotchat.enableNesInSettings":true,"copilotchat.ruffDiagnosticsCookbook":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"pylanceConvertFormatString":true,"pylanceGenerateSymbol":true,"pythonTerminalEnvVarActivation":true,"test-ai-12":false,"testaa123":false,"validate_mi":false,"vscode.nothing5":"
  ","workspace.embeddingIndex.automaticReindexingDelay":100000000}}]}}'
ms-toolsai.datawrangler: '{"VSCode.ABExp.FeatureData":{"features":["config.chat.editRequests","config.dataWrangler.experiments.copilot.enabled","config.dataWrangler.experiments.useJupyterProposedAPIcf","config.dataWrangler.outputRenderer.enabled","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","portForwardingServiceEnabled-development","portForwardingServiceEnabled-production","portForwardingServiceEnabled-staging","shouldUseGrpcService","test-ai-12cf","validate_micf","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;vspor879:30202332;vspor708:30202333;vspor363:30204092;binariesv615:30325510;c4g48928:30535728;dwnewjupytercf:31046870;dwcopilot:31170013;6074i472:31201624;dwoutputs:31242946;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;usemarketplace:31343026;nes-diff-11:31337487;6abeh943:31336334;yijiwantestdri0626-t:31336930;ji9b5146:31342393;","configs":[{"Id":"vscode","Parameters":{"config.chat.editRequests":"hover","config.dataWrangler.experiments.copilot.enabled":true,"config.dataWrangler.experiments.useJupyterProposedAPI":false,"config.dataWrangler.outputRenderer.enabled":true,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"portForwardingServiceEnabled-development":true,"portForwardingServiceEnabled-production":true,"portForwardingServiceEnabled-staging":true,"shouldUseGrpcService":true,"test-ai-12":false,"validate_mi":false,"workspace.embeddingIndex.automaticReindexingDelay":100000000}}]},"feedbackInteractionCount_preview":1}'
ms-toolsai.jupyter: '{"VSCode.ABExp.FeatureData":{"features":["config.chat.editRequests","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","config.notebook.experimental.generate","config.python.analysis.enableEditableInstalls","config.python.analysis.enableTroubleshootMissingImportscf","config.python.analysis.usePullDiagnostics","config.python.locator","copilotchat.ruffDiagnosticsCookbook","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","portForwardingServiceEnabled-development","portForwardingServiceEnabled-production","portForwardingServiceEnabled-staging","pylanceConvertFormatString","pylanceConvertLambdaToNamedFunction","pylanceGenerateSymbol","pythonTerminalEnvVarActivation","shouldUseGrpcService","test-ai-12cf","validate_micf","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;vspor879:30202332;vspor708:30202333;vspor363:30204092;binariesv615:30325510;c4g48928:30535728;962ge761:30959799;nativeloc1:31344060;5fd0e150:31155592;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;pythoneinst12:31285622;pythonpulldiag:31343502;pythonrdcb7:31342333;usemplatestapi:31297334;aj953862:31281341;generatesymbolt:31295002;convertfstringf:31295003;pylancequickfixf:31329273;convertlamdat:31329272;usemarketplace:31343026;nes-diff-11:31337487;6abeh943:31336334;yijiwantestdri0626-t:31336930;ji9b5146:31342393;","configs":[{"Id":"vscode","Parameters":{"config.chat.editRequests":"hover","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"config.notebook.experimental.generate":true,"config.python.analysis.enableEditableInstalls":true,"config.python.analysis.enableTroubleshootMissingImports":false,"config.python.analysis.usePullDiagnostics":true,"config.python.locator":"native","copilotchat.ruffDiagnosticsCookbook":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"portForwardingServiceEnabled-development":true,"portForwardingServiceEnabled-production":true,"portForwardingServiceEnabled-staging":true,"pylanceConvertFormatString":true,"pylanceConvertLambdaToNamedFunction":true,"pylanceGenerateSymbol":true,"pythonTerminalEnvVarActivation":true,"shouldUseGrpcService":true,"test-ai-12":false,"validate_mi":false,"workspace.embeddingIndex.automaticReindexingDelay":100000000}}]},"INTERPRETER_PATH_WAS_SELECTED_FOR_JUPYTER_SERVER":true}'
ms-vscode-remote.remote-containers: '{"localExtensions":["42Crunch.vscode-openapi","aaron-bond.better-comments","adpyke.vscode-sql-formatter","altimateai.vscode-altimate-mcp-server","amazonwebservices.aws-toolkit-vscode","Anthropic.claude-code","anysphere.csharp","anysphere.cursorpyright","anysphere.pyright","asciidoctor.asciidoctor-vscode","atlassian.atlascode","austenc.tailwind-docs","bradlc.vscode-tailwindcss","Catppuccin.catppuccin-vsc","Catppuccin.catppuccin-vsc-icons","christian-kohler.path-intellisense","ckolkman.vscode-postgres","Dart-Code.dart-code","Dart-Code.flutter","DavidAnson.vscode-markdownlint","dbaeumer.vscode-eslint","dbtLabsInc.dbt","donjayamanne.githistory","eamodio.gitlens","esbenp.prettier-vscode","figma.figma-vscode-extension","github.copilot-workspace","github.vscode-github-actions","GitHub.vscode-pull-request-github","golang.go","Gruntfuggly.todo-tree","hashicorp.terraform","hediet.vscode-drawio","hoovercj.vscode-power-mode","humao.rest-client","innoverio.vscode-dbt-power-user","Ionide.Ionide-fsharp","janisdd.vscode-edit-csv","Jetify.devbox","jkjustjoshing.vscode-text-pastry","johnpapa.vscode-peacock","kahole.magit","leanprover.lean4","malloydata.malloy-vscode","marp-team.marp-vscode","mechatroner.rainbow-csv","mikestead.dotenv","ms-azuretools.vscode-docker","ms-dotnettools.vscode-dotnet-runtime","ms-edgedevtools.vscode-edge-devtools","ms-python.black-formatter","ms-python.debugpy","ms-python.isort","ms-python.python","ms-python.vscode-pylance","ms-toolsai.datawrangler","ms-toolsai.jupyter","ms-toolsai.jupyter-renderers","ms-toolsai.vscode-jupyter-cell-tags","ms-toolsai.vscode-jupyter-slideshow","ms-vscode-remote.remote-containers","ms-vscode-remote.remote-ssh","ms-vscode-remote.remote-ssh-edit","ms-vscode.powershell","ms-vscode.remote-explorer","muhammad-sammy.csharp","nrwl.angular-console","oderwat.indent-rainbow","PrismaCloud.prisma-cloud","quicktype.quicktype","redhat.vscode-yaml","RooVeterinaryInc.roo-cline","samuelcolvin.jinjahtml","saoudrizwan.claude-dev","shd101wyy.markdown-preview-enhanced","snowflake.snowflake-vsc","stagewise.stagewise-vscode-extension","sumneko.lua","tamasfe.even-better-toml","TheNuProjectContributors.vscode-nushell-lang","tilt-dev.tiltfile","tomoki1207.pdf","VisualStudioExptTeam.intellicode-api-usage-examples","VisualStudioExptTeam.vscodeintellicode","WakaTime.vscode-wakatime","WizCloud.wiz-vscode","yassun7010.vscode-shandy-sqlfmt","YoavBls.pretty-ts-errors","zokugun.cron-tasks","zokugun.sync-settings"],"VSCode.ABExp.FeatureData":{"features":["chat.defaultLanguageModel","chat.defaultMode","config.chat.editRequests","config.chat.setup.signInDialogVariant","config.github.copilot.chat.advanced.enableApplyPatchTool","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow","config.workbench.secondarySideBar.defaultVisibility","copilotchat.claudeReplaceStringExclusively","copilotchat.enableNesInSettings","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","test-ai-12cf","testaa123cf","validate_micf","vscode.nothing5","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;binariesv615:30325510;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;9d2cg352:31346308;usemarketplace:31343026;nesew2to5:31336538;agentclaude:31335814;nes-diff-11:31337487;replacestringexc:31350595;nes-set-on:31340697;testaa123cf:31335227;6abeh943:31336334;yijiwantestdri0626-c:31336931;0927b901:31350571;4gdec884:31348710;7g84e740:31350607;1c1c4419-mono:31350621;","configs":[{"Id":"vscode","Parameters":{"chat.defaultLanguageModel":"github.copilot-chat/claude-sonnet-4","chat.defaultMode":"agent","config.chat.editRequests":"inline","config.chat.setup.signInDialogVariant":"alternate-monochrome","config.github.copilot.chat.advanced.enableApplyPatchTool":true,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesAbove":2,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.nLinesBelow":5,"config.workbench.secondarySideBar.defaultVisibility":"visibleInWorkspace","copilotchat.claudeReplaceStringExclusively":true,"copilotchat.enableNesInSettings":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"test-ai-12":false,"testaa123":false,"validate_mi":false,"vscode.nothing5":"
  ","workspace.embeddingIndex.automaticReindexingDelay":100000000}}]}}'
PrismaCloud.prisma-cloud: '{"installationId":"e30775e4-5cab-4d59-aa68-fbcdadc5a3fe","customerModules":{"sastEnabled":false},"configurationMigrated":true}'
RooVeterinaryInc.roo-cline: '{"allowedCommands":["npm test","npm
  install","tsc","git log","git diff","git
  show"],"mcpHubInstanceId":"1753011559332","codebaseIndexModels":{"openai":{"text-embedding-3-small":{"dimension":1536,"scoreThreshold":0.4},"text-embedding-3-large":{"dimension":3072,"scoreThreshold":0.4},"text-embedding-ada-002":{"dimension":1536,"scoreThreshold":0.4}},"ollama":{"nomic-embed-text":{"dimension":768,"scoreThreshold":0.4},"nomic-embed-code":{"dimension":3584,"scoreThreshold":0.15,"queryPrefix":"Represent
  this query for searching relevant code:
  "},"mxbai-embed-large":{"dimension":1024,"scoreThreshold":0.4},"all-minilm":{"dimension":384,"scoreThreshold":0.4}},"openai-compatible":{"text-embedding-3-small":{"dimension":1536,"scoreThreshold":0.4},"text-embedding-3-large":{"dimension":3072,"scoreThreshold":0.4},"text-embedding-ada-002":{"dimension":1536,"scoreThreshold":0.4},"nomic-embed-code":{"dimension":3584,"scoreThreshold":0.15,"queryPrefix":"Represent
  this query for searching relevant code:
  "}},"gemini":{"text-embedding-004":{"dimension":768},"gemini-embedding-001":{"dimension":3072,"scoreThreshold":0.4}}}}'
saoudrizwan.claude-dev: "{\"clineVersion\":\"3.19.7\",\"clineLastPopupNotificat\
  ionVersion\":\"3.19.7\",\"planActSeparateModelsSetting\":false,\"lastShownAnn\
  ouncementId\":\"june-25-2025_16:11:00\",\"mcpMarketplaceCatalog\":{\"items\":\
  [{\"mcpId\":\"github.com/graphlit/graphlit-mcp-server\",\"githubUrl\":\"https\
  ://github.com/graphlit/graphlit-mcp-server\",\"name\":\"Graphlit\",\"author\":\
  \"graphlit\",\"description\":\"Create a personalized knowledge base from tools
  like Linear, GitHub, Jira, and Discord, and empower AI Agents to retrieve
  associated content with built-in reranking for enhanced
  relevance.\",\"codiconIcon\":\"library\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/graphlit.png\",\"category\":\"knowledge-memory\",\
  \"tags\":[\"content-management\",\"data-ingestion\",\"document-processing\",\
  \"search-retrieval\",\"multi-platform\"],\"requiresApiKey\":false,\"readmeCon\
  tent\":\"[![npm
  version](https://badge.fury.io/js/graphlit-mcp-server.svg)](https://badge.fur\
  y.io/js/graphlit-mcp-server)\\n[![smithery
  badge](https://smithery.ai/badge/@graphlit/graphlit-mcp-server)](https://smit\
  hery.ai/server/@graphlit/graphlit-mcp-server)\\n\\n# Model Context Protocol
  (MCP) Server for Graphlit Platform\\n\\n## Overview\\n\\nThe Model Context
  Protocol (MCP) Server enables integration between MCP clients and the Graphlit
  service. This document outlines the setup process and provides a basic example
  of using the client.\\n\\nIngest anything from Slack, Discord, websites,
  Google Drive, email, Jira, Linear or GitHub into a Graphlit project - and then
  search and retrieve relevant knowledge within an MCP client like Cursor,
  Windsurf, Goose or Cline.\\n\\nYour Graphlit project acts as a searchable, and
  RAG-ready knowledge base across all your developer and product management
  tools.\\n\\nDocuments (PDF, DOCX, PPTX, etc.) and HTML web pages will be
  extracted to Markdown upon ingestion. Audio and video files will be
  transcribed upon ingestion.\\n\\nWeb crawling and web search are built-in as
  MCP tools, with no need to integrate other tools like Firecrawl, Exa, etc.
  separately.\\n\\nYou can read more about the MCP Server use cases and features
  on our [blog](https://www.graphlit.com/blog/graphlit-mcp-server).\\n\\nWatch
  our latest [YouTube video](https://www.youtube.com/watch?v=Or-QqonvcAs&t=4s)
  on using the Graphlit MCP Server with the Goose MCP client.\\n\\nFor any
  questions on using the MCP Server, please join our
  [Discord](https://discord.gg/ygFmfjy3Qx) community and post on the #mcp
  channel.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/fscrivteod\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/fscrivteod/badge\\\"
  alt=\\\"graphlit-mcp-server MCP server\\\" />\\n</a>\\n\\n## Tools\\n\\n###
  Retrieval\\n\\n- Query Contents\\n- Query Collections\\n- Query Feeds\\n-
  Query Conversations\\n- Retrieve Relevant Sources\\n- Retrieve Similar
  Images\\n- Visually Describe Image\\n\\n### RAG\\n\\n- Prompt LLM
  Conversation\\n\\n### Extraction\\n\\n- Extract Structured JSON from
  Text\\n\\n### Publishing\\n\\n- Publish as Audio (ElevenLabs Audio)\\n-
  Publish as Image (OpenAI Image Generation)\\n\\n### Ingestion\\n\\n- Files\\n-
  Web Pages\\n- Messages\\n- Posts\\n- Emails\\n- Issues\\n- Text\\n- Memory
  (Short-Term)\\n\\n### Data Connectors\\n\\n- Microsoft Outlook email\\n-
  Google Mail\\n- Notion\\n- Reddit\\n- Linear\\n- Jira\\n- GitHub Issues\\n-
  Google Drive\\n- OneDrive\\n- SharePoint\\n- Dropbox\\n- Box\\n- GitHub\\n-
  Slack\\n- Microsoft Teams\\n- Discord\\n- Twitter/X\\n- Podcasts
  (RSS)\\n\\n### Web\\n\\n- Web Crawling\\n- Web Search (including Podcast
  Search)\\n- Web Mapping\\n- Screenshot Page\\n\\n### Notifications\\n\\n-
  Slack\\n- Email\\n- Webhook\\n- Twitter/X\\n\\n### Operations\\n\\n- Configure
  Project\\n- Create Collection\\n- Add Contents to Collection\\n- Remove
  Contents from Collection\\n- Delete Collection(s)\\n- Delete Feed(s)\\n-
  Delete Content(s)\\n- Delete Conversation(s)\\n- Is Feed Done?\\n- Is Content
  Done?\\n\\n### Enumerations\\n\\n- List Slack Channels\\n- List Microsoft
  Teams Teams\\n- List Microsoft Teams Channels\\n- List SharePoint
  Libraries\\n- List SharePoint Folders\\n- List Linear Projects\\n- List Notion
  Databases\\n\\n## Resources\\n\\n- Project\\n- Contents\\n- Feeds\\n-
  Collections (of Content)\\n- Workflows\\n- Conversations\\n-
  Specifications\\n\\n## Prerequisites\\n\\nBefore you begin, ensure you have
  the following:\\n\\n- Node.js installed on your system (recommended version
  18.x or higher).\\n- An active account on the [Graphlit
  Platform](https://portal.graphlit.dev) with access to the API settings
  dashboard.\\n\\n## Configuration\\n\\nThe Graphlit MCP Server supports
  environment variables to be set for authentication and configuration:\\n\\n-
  `GRAPHLIT_ENVIRONMENT_ID`: Your environment ID.\\n-
  `GRAPHLIT_ORGANIZATION_ID`: Your organization ID.\\n- `GRAPHLIT_JWT_SECRET`:
  Your JWT secret for signing the JWT token.\\n\\nYou can find these values in
  the API settings dashboard on the [Graphlit
  Platform](https://portal.graphlit.dev).\\n\\n## Installation\\n\\n###
  Installing via VS Code\\n\\nFor quick installation, use one of the one-click
  install buttons below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=graphlit&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%\
  3A%22organization_id%22%2C%22description%22%3A%22Graphlit%20Organization%20ID\
  %22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%2\
  2%3A%22environment_id%22%2C%22description%22%3A%22Graphlit%20Environment%20ID\
  %22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%2\
  2%3A%22jwt_secret%22%2C%22description%22%3A%22Graphlit%20JWT%20Secret%22%2C%2\
  2password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A\
  %5B%22-y%22%2C%22graphlit-mcp-server%22%5D%2C%22env%22%3A%7B%22GRAPHLIT_ORGAN\
  IZATION_ID%22%3A%22%24%7Binput%3Aorganization_id%7D%22%2C%22GRAPHLIT_ENVIRONM\
  ENT_ID%22%3A%22%24%7Binput%3Aenvironment_id%7D%22%2C%22GRAPHLIT_JWT_SECRET%22\
  %3A%22%24%7Binput%3Ajwt_secret%7D%22%7D%7D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=graphlit&inputs=%5B%7B%22type%22%3A%22promptString%2\
  2%2C%22id%22%3A%22organization_id%22%2C%22description%22%3A%22Graphlit%20Orga\
  nization%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString\
  %22%2C%22id%22%3A%22environment_id%22%2C%22description%22%3A%22Graphlit%20Env\
  ironment%20ID%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString\
  %22%2C%22id%22%3A%22jwt_secret%22%2C%22description%22%3A%22Graphlit%20JWT%20S\
  ecret%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C\
  %22args%22%3A%5B%22-y%22%2C%22graphlit-mcp-server%22%5D%2C%22env%22%3A%7B%22G\
  RAPHLIT_ORGANIZATION_ID%22%3A%22%24%7Binput%3Aorganization_id%7D%22%2C%22GRAP\
  HLIT_ENVIRONMENT_ID%22%3A%22%24%7Binput%3Aenvironment_id%7D%22%2C%22GRAPHLIT_\
  JWT_SECRET%22%3A%22%24%7Binput%3Ajwt_secret%7D%22%7D%7D&quality=insiders)\\n\
  \\nFor manual installation, add the following JSON block to your User Settings
  (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and
  typing `Preferences: Open User Settings (JSON)`.\\n\\nOptionally, you can add
  it to a file called `.vscode/mcp.json` in your workspace. This will allow you
  to share the configuration with others.\\n\\n> Note that the `mcp` key is not
  needed in the `.vscode/mcp.json` file.\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"inputs\\\": [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"organization_id\\\",\\n        \\\"description\\\": \\\"Graphlit
  Organization ID\\\",\\n        \\\"password\\\":
  true\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"environment_id\\\",\\n        \\\"description\\\": \\\"Graphlit
  Environment ID\\\",\\n        \\\"password\\\":
  true\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"jwt_secret\\\",\\n        \\\"description\\\": \\\"Graphlit JWT
  Secret\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"graphlit\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"graphlit-mcp-server\\\"],\\n        \\\"env\\\":
  {\\n          \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"${input:organization_id}\\\",\\n          \\\"GRAPHLIT_ENVIRONMENT_ID\\\":
  \\\"${input:environment_id}\\\",\\n          \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"${input:jwt_secret}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\
  \\n### Installing via Windsurf\\n\\nTo install graphlit-mcp-server in Windsurf
  IDE application, Cline should use NPX:\\n\\n```bash\\nnpx -y
  graphlit-mcp-server\\n```\\n\\nYour mcp_config.json file should be configured
  similar to:\\n\\n```\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"graphlit-mcp-server\\\": {\\n            \\\"command\\\":
  \\\"npx\\\",\\n            \\\"args\\\":
  [\\n                \\\"-y\\\",\\n                \\\"graphlit-mcp-server\\\"\
  \\n            ],\\n            \\\"env\\\":
  {\\n                \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"your-organization-id\\\",\\n                \\\"GRAPHLIT_ENVIRONMENT_ID\\\
  \":
  \\\"your-environment-id\\\",\\n                \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"your-jwt-secret\\\",\\n            }\\n        }\\n    }\\n}\\n```\\n\\n#\
  ## Installing via Cline\\n\\nTo install graphlit-mcp-server in Cline IDE
  application, Cline should use NPX:\\n\\n```bash\\nnpx -y
  graphlit-mcp-server\\n```\\n\\nYour cline_mcp_settings.json file should be
  configured similar to:\\n\\n```\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"graphlit-mcp-server\\\": {\\n            \\\"command\\\":
  \\\"npx\\\",\\n            \\\"args\\\":
  [\\n                \\\"-y\\\",\\n                \\\"graphlit-mcp-server\\\"\
  \\n            ],\\n            \\\"env\\\":
  {\\n                \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"your-organization-id\\\",\\n                \\\"GRAPHLIT_ENVIRONMENT_ID\\\
  \":
  \\\"your-environment-id\\\",\\n                \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"your-jwt-secret\\\",\\n            }\\n        }\\n    }\\n}\\n```\\n\\n#\
  ## Installing via Cursor\\n\\nTo install graphlit-mcp-server in Cursor IDE
  application, Cursor should use NPX:\\n\\n```bash\\nnpx -y
  graphlit-mcp-server\\n```\\n\\nYour mcp.json file should be configured similar
  to:\\n\\n```\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"graphlit-mcp-server\\\": {\\n            \\\"command\\\":
  \\\"npx\\\",\\n            \\\"args\\\":
  [\\n                \\\"-y\\\",\\n                \\\"graphlit-mcp-server\\\"\
  \\n            ],\\n            \\\"env\\\":
  {\\n                \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"your-organization-id\\\",\\n                \\\"GRAPHLIT_ENVIRONMENT_ID\\\
  \":
  \\\"your-environment-id\\\",\\n                \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"your-jwt-secret\\\",\\n            }\\n        }\\n    }\\n}\\n```\\n\\n#\
  ## Installing via Smithery\\n\\nTo install graphlit-mcp-server for Claude
  Desktop automatically via
  [Smithery](https://smithery.ai/server/@graphlit/graphlit-mcp-server):\\n\\n``\
  `bash\\nnpx -y @smithery/cli install @graphlit/graphlit-mcp-server --client
  claude\\n```\\n\\n### Installing manually\\n\\nTo use the Graphlit MCP Server
  in any MCP client application, use:\\n\\n```\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"graphlit-mcp-server\\\": {\\n            \\\"command\\\":
  \\\"npx\\\",\\n            \\\"args\\\":
  [\\n                \\\"-y\\\",\\n                \\\"graphlit-mcp-server\\\"\
  \\n            ],\\n            \\\"env\\\":
  {\\n                \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"your-organization-id\\\",\\n                \\\"GRAPHLIT_ENVIRONMENT_ID\\\
  \":
  \\\"your-environment-id\\\",\\n                \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"your-jwt-secret\\\",\\n            }\\n        }\\n    }\\n}\\n```\\n\\nO\
  ptionally, you can configure the credentials for data connectors, such as
  Slack, Google Email and Notion.\\nOnly GRAPHLIT_ORGANIZATION_ID,
  GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET are
  required.\\n\\n```\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"graphlit-mcp-server\\\": {\\n            \\\"command\\\":
  \\\"npx\\\",\\n            \\\"args\\\":
  [\\n                \\\"-y\\\",\\n                \\\"graphlit-mcp-server\\\"\
  \\n            ],\\n            \\\"env\\\":
  {\\n                \\\"GRAPHLIT_ORGANIZATION_ID\\\":
  \\\"your-organization-id\\\",\\n                \\\"GRAPHLIT_ENVIRONMENT_ID\\\
  \":
  \\\"your-environment-id\\\",\\n                \\\"GRAPHLIT_JWT_SECRET\\\":
  \\\"your-jwt-secret\\\",\\n                \\\"SLACK_BOT_TOKEN\\\":
  \\\"your-slack-bot-token\\\",\\n                \\\"DISCORD_BOT_TOKEN\\\":
  \\\"your-discord-bot-token\\\",\\n                \\\"TWITTER_TOKEN\\\":
  \\\"your-twitter-token\\\",\\n                \\\"GOOGLE_EMAIL_REFRESH_TOKEN\\\
  \":
  \\\"your-google-refresh-token\\\",\\n                \\\"GOOGLE_EMAIL_CLIENT_\
  ID\\\":
  \\\"your-google-client-id\\\",\\n                \\\"GOOGLE_EMAIL_CLIENT_SECR\
  ET\\\":
  \\\"your-google-client-secret\\\",\\n                \\\"LINEAR_API_KEY\\\":
  \\\"your-linear-api-key\\\",\\n                \\\"GITHUB_PERSONAL_ACCESS_TOK\
  EN\\\": \\\"your-github-pat\\\",\\n                \\\"JIRA_EMAIL\\\":
  \\\"your-jira-email\\\",\\n                \\\"JIRA_TOKEN\\\":
  \\\"your-jira-token\\\",\\n                \\\"NOTION_API_KEY\\\":
  \\\"your-notion-api-key\\\"\\n            }\\n        }\\n    }\\n}\\n```\\n\
  \\nNOTE: when running 'npx' on Windows, you may need to explicitly call npx
  via the command prompt.\\n\\n```\\n\\\"command\\\":
  \\\"C:\\\\\\\\Windows\\\\\\\\System32\\\\\\\\cmd.exe /c npx\\\"\\n```\\n\\n##
  Support\\n\\nPlease refer to the [Graphlit API
  Documentation](https://docs.graphlit.dev/).\\n\\nFor support with the Graphlit
  MCP Server, please submit a [GitHub
  Issue](https://github.com/graphlit/graphlit-mcp-server/issues).\\n\\nFor
  further support with the Graphlit Platform, please join our
  [Discord](https://discord.gg/ygFmfjy3Qx)
  community.\\n\",\"isRecommended\":false,\"githubStars\":325,\"downloadCount\"\
  :1734,\"createdAt\":\"2025-03-03T19:20:12.867689Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T21:48:48.601558Z\"},{\"m\
  cpId\":\"github.com/modelcontextprotocol/servers/tree/main/src/memory\",\"git\
  hubUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/memo\
  ry\",\"name\":\"Knowledge Graph
  Memory\",\"author\":\"modelcontextprotocol\",\"description\":\"A persistent
  memory system using a local knowledge graph that enables AI assistants to
  remember information about users across conversations through entities,
  relations, and
  observations.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/knowledge-graph-memory.png\",\"category\":\"\
  knowledge-memory\",\"tags\":[\"knowledge-graph\",\"persistent-memory\",\"enti\
  ty-management\",\"graph-database\",\"memory-storage\"],\"requiresApiKey\":fal\
  se,\"readmeContent\":\"# Knowledge Graph Memory Server\\n\\nA basic
  implementation of persistent memory using a local knowledge graph. This lets
  Claude remember information about the user across chats.\\n\\n## Core
  Concepts\\n\\n### Entities\\nEntities are the primary nodes in the knowledge
  graph. Each entity has:\\n- A unique name (identifier)\\n- An entity type
  (e.g., \\\"person\\\", \\\"organization\\\", \\\"event\\\")\\n- A list of
  observations\\n\\nExample:\\n```json\\n{\\n  \\\"name\\\":
  \\\"John_Smith\\\",\\n  \\\"entityType\\\":
  \\\"person\\\",\\n  \\\"observations\\\": [\\\"Speaks fluent
  Spanish\\\"]\\n}\\n```\\n\\n### Relations\\nRelations define directed
  connections between entities. They are always stored in active voice and
  describe how entities interact or relate to each
  other.\\n\\nExample:\\n```json\\n{\\n  \\\"from\\\":
  \\\"John_Smith\\\",\\n  \\\"to\\\":
  \\\"Anthropic\\\",\\n  \\\"relationType\\\": \\\"works_at\\\"\\n}\\n```\\n###
  Observations\\nObservations are discrete pieces of information about an
  entity. They are:\\n\\n- Stored as strings\\n- Attached to specific
  entities\\n- Can be added or removed independently\\n- Should be atomic (one
  fact per observation)\\n\\nExample:\\n```json\\n{\\n  \\\"entityName\\\":
  \\\"John_Smith\\\",\\n  \\\"observations\\\": [\\n    \\\"Speaks fluent
  Spanish\\\",\\n    \\\"Graduated in 2019\\\",\\n    \\\"Prefers morning
  meetings\\\"\\n  ]\\n}\\n```\\n\\n## API\\n\\n### Tools\\n-
  **create_entities**\\n  - Create multiple new entities in the knowledge
  graph\\n  - Input: `entities` (array of objects)\\n    - Each object
  contains:\\n      - `name` (string): Entity identifier\\n      - `entityType`
  (string): Type classification\\n      - `observations` (string[]): Associated
  observations\\n  - Ignores entities with existing names\\n\\n-
  **create_relations**\\n  - Create multiple new relations between
  entities\\n  - Input: `relations` (array of objects)\\n    - Each object
  contains:\\n      - `from` (string): Source entity name\\n      - `to`
  (string): Target entity name\\n      - `relationType` (string): Relationship
  type in active voice\\n  - Skips duplicate relations\\n\\n-
  **add_observations**\\n  - Add new observations to existing entities\\n  -
  Input: `observations` (array of objects)\\n    - Each object
  contains:\\n      - `entityName` (string): Target entity\\n      - `contents`
  (string[]): New observations to add\\n  - Returns added observations per
  entity\\n  - Fails if entity doesn't exist\\n\\n- **delete_entities**\\n  -
  Remove entities and their relations\\n  - Input: `entityNames`
  (string[])\\n  - Cascading deletion of associated relations\\n  - Silent
  operation if entity doesn't exist\\n\\n- **delete_observations**\\n  - Remove
  specific observations from entities\\n  - Input: `deletions` (array of
  objects)\\n    - Each object contains:\\n      - `entityName` (string): Target
  entity\\n      - `observations` (string[]): Observations to remove\\n  -
  Silent operation if observation doesn't exist\\n\\n-
  **delete_relations**\\n  - Remove specific relations from the graph\\n  -
  Input: `relations` (array of objects)\\n    - Each object contains:\\n      -
  `from` (string): Source entity name\\n      - `to` (string): Target entity
  name\\n      - `relationType` (string): Relationship type\\n  - Silent
  operation if relation doesn't exist\\n\\n- **read_graph**\\n  - Read the
  entire knowledge graph\\n  - No input required\\n  - Returns complete graph
  structure with all entities and relations\\n\\n- **search_nodes**\\n  - Search
  for nodes based on query\\n  - Input: `query` (string)\\n  - Searches
  across:\\n    - Entity names\\n    - Entity types\\n    - Observation
  content\\n  - Returns matching entities and their relations\\n\\n-
  **open_nodes**\\n  - Retrieve specific nodes by name\\n  - Input: `names`
  (string[])\\n  - Returns:\\n    - Requested entities\\n    - Relations between
  requested entities\\n  - Silently skips non-existent nodes\\n\\n# Usage with
  Claude Desktop\\n\\n### Setup\\n\\nAdd this to your
  claude_desktop_config.json:\\n\\n####
  Docker\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"memory\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\": [\\\"run\\\",
  \\\"-i\\\", \\\"-v\\\", \\\"claude-memory:/app/dist\\\", \\\"--rm\\\",
  \\\"mcp/memory\\\"]\\n    }\\n  }\\n}\\n```\\n\\n####
  NPX\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"memory\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@modelcontextprotocol/server-memory\\\"\
  \\n      ]\\n    }\\n  }\\n}\\n```\\n\\n#### NPX with custom setting\\n\\nThe
  server can be configured using the following environment
  variables:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"memory\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@modelcontextprotocol/server-memory\\\"\
  \\n      ],\\n      \\\"env\\\": {\\n        \\\"MEMORY_FILE_PATH\\\":
  \\\"/path/to/custom/memory.json\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n-
  `MEMORY_FILE_PATH`: Path to the memory storage JSON file (default:
  `memory.json` in the server directory)\\n\\n# VS Code Installation
  Instructions\\n\\nFor quick installation, use one of the one-click
  installation buttons below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=memory&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-\
  y%22%2C%22%40modelcontextprotocol%2Fserver-memory%22%5D%7D) [![Install with
  NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=memory&config=%7B%22command%22%3A%22npx%22%2C%22args\
  %22%3A%5B%22-y%22%2C%22%40modelcontextprotocol%2Fserver-memory%22%5D%7D&quali\
  ty=insiders)\\n\\n[![Install with Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=memory&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%\
  5B%22run%22%2C%22-i%22%2C%22-v%22%2C%22claude-memory%3A%2Fapp%2Fdist%22%2C%22\
  --rm%22%2C%22mcp%2Fmemory%22%5D%7D) [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=memory&config=%7B%22command%22%3A%22docker%22%2C%\
  22args%22%3A%5B%22run%22%2C%22-i%22%2C%22-v%22%2C%22claude-memory%3A%2Fapp%2F\
  dist%22%2C%22--rm%22%2C%22mcp%2Fmemory%22%5D%7D&quality=insiders)\\n\\nFor
  manual installation, add the following JSON block to your User Settings (JSON)
  file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing
  `Preferences: Open Settings (JSON)`.\\n\\nOptionally, you can add it to a file
  called `.vscode/mcp.json` in your workspace. This will allow you to share the
  configuration with others. \\n\\n> Note that the `mcp` key is not needed in
  the `.vscode/mcp.json` file.\\n\\n#### NPX\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"memory\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\":
  [\\n          \\\"-y\\\",\\n          \\\"@modelcontextprotocol/server-memory\
  \\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n####
  Docker\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"memory\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"-i\\\",\\n          \\\"-v\\\",\\n          \
  \\\"claude-memory:/app/dist\\\",\\n          \\\"--rm\\\",\\n          \\\"mc\
  p/memory\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### System
  Prompt\\n\\nThe prompt for utilizing memory depends on the use case. Changing
  the prompt will help the model determine the frequency and types of memories
  created.\\n\\nHere is an example prompt for chat personalization. You could
  use this prompt in the \\\"Custom Instructions\\\" field of a [Claude.ai
  Project](https://www.anthropic.com/news/projects). \\n\\n```\\nFollow these
  steps for each interaction:\\n\\n1. User Identification:\\n   - You should
  assume that you are interacting with default_user\\n   - If you have not
  identified default_user, proactively try to do so.\\n\\n2. Memory
  Retrieval:\\n   - Always begin your chat by saying only \\\"Remembering...\\\"
  and retrieve all relevant information from your knowledge graph\\n   - Always
  refer to your knowledge graph as your \\\"memory\\\"\\n\\n3. Memory\\n   -
  While conversing with the user, be attentive to any new information that falls
  into these categories:\\n     a) Basic Identity (age, gender, location, job
  title, education level, etc.)\\n     b) Behaviors (interests, habits,
  etc.)\\n     c) Preferences (communication style, preferred language,
  etc.)\\n     d) Goals (goals, targets, aspirations, etc.)\\n     e)
  Relationships (personal and professional relationships up to 3 degrees of
  separation)\\n\\n4. Memory Update:\\n   - If any new information was gathered
  during the interaction, update your memory as follows:\\n     a) Create
  entities for recurring organizations, people, and significant events\\n     b)
  Connect them to the current entities using relations\\n     b) Store facts
  about them as observations\\n```\\n\\n##
  Building\\n\\nDocker:\\n\\n```sh\\ndocker build -t mcp/memory -f
  src/memory/Dockerfile . \\n```\\n\\n## License\\n\\nThis MCP server is
  licensed under the MIT License. This means you are free to use, modify, and
  distribute the software, subject to the terms and conditions of the MIT
  License. For more details, please see the LICENSE file in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":56949,\"downloadCount\
  \":11996,\"createdAt\":\"2025-02-17T22:22:24.982087Z\",\"updatedAt\":\"2025-0\
  7-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T04:34:15.14996Z\"},{\
  \"mcpId\":\"github.com/pashpashpash/mcp-atlassian\",\"githubUrl\":\"https://g\
  ithub.com/pashpashpash/mcp-atlassian\",\"name\":\"Atlassian\",\"author\":\"pa\
  shpashpash\",\"description\":\"Integrates with Atlassian Cloud products
  (Confluence and Jira) to enable searching, accessing, and managing pages,
  spaces, issues, and projects via their respective
  APIs.\",\"codiconIcon\":\"organization\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/atlassian.png\",\"category\":\"developer-tools\",\
  \"tags\":[\"atlassian\",\"confluence\",\"jira\",\"project-management\",\"docu\
  mentation\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP
  Atlassian\\n\\nModel Context Protocol (MCP) server for Atlassian Cloud
  products (Confluence and Jira). This integration is designed specifically for
  Atlassian Cloud instances and does not support Atlassian Server or Data Center
  deployments.\\n\\n### Feature
  Demo\\n![Demo](https://github.com/user-attachments/assets/995d96a8-4cf3-4a03-\
  abe1-a9f6aea27ac0)\\n\\n### Resources\\n\\n- `confluence://{space_key}`:
  Access Confluence spaces and pages\\n-
  `confluence://{space_key}/pages/{title}`: Access specific Confluence pages\\n-
  `jira://{project_key}`: Access Jira project and its issues\\n-
  `jira://{project_key}/issues/{issue_key}`: Access specific Jira
  issues\\n\\n### Tools\\n\\n#### Confluence Tools\\n\\n1.
  `confluence_search`\\n   - Search Confluence content using CQL\\n   -
  Inputs:\\n     - `query` (string): CQL query string\\n     - `limit` (number,
  optional): Results limit (1-50, default: 10)\\n   - Returns: Array of search
  results with page_id, title, space, url, last_modified, type, and
  excerpt\\n\\n2. `confluence_get_page`\\n   - Get content of a specific
  Confluence page\\n   - Inputs:\\n     - `page_id` (string): Confluence page
  ID\\n     - `include_metadata` (boolean, optional): Include page metadata
  (default: true)\\n   - Returns: Page content and optional metadata\\n\\n3.
  `confluence_get_comments`\\n   - Get comments for a specific Confluence
  page\\n   - Input: \\n     - `page_id` (string): Confluence page ID\\n   -
  Returns: Array of comments with author, creation date, and content\\n\\n####
  Jira Tools\\n\\n1. `jira_get_issue`\\n   - Get details of a specific Jira
  issue\\n   - Inputs:\\n     - `issue_key` (string): Jira issue key (e.g.,
  'PROJ-123')\\n     - `expand` (string, optional): Fields to expand\\n   -
  Returns: Issue details including content and metadata\\n\\n2.
  `jira_search`\\n   - Search Jira issues using JQL\\n   - Inputs:\\n     -
  `jql` (string): JQL query string\\n     - `fields` (string, optional):
  Comma-separated fields (default: \\\"*all\\\")\\n     - `limit` (number,
  optional): Results limit (1-50, default: 10)\\n   - Returns: Array of matching
  issues with metadata\\n\\n3. `jira_get_project_issues`\\n   - Get all issues
  for a specific Jira project\\n   - Inputs:\\n     - `project_key` (string):
  Project key\\n     - `limit` (number, optional): Results limit (1-50, default:
  10)\\n   - Returns: Array of project issues with metadata\\n\\n##
  Installation\\n\\n1. **Clone the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-atlassian.git\\n   cd
  mcp-atlassian\\n   ```\\n\\n2. **Install Dependencies**:\\n   ```bash\\n   npm
  install\\n   ```\\n\\n3. **Build the Project**:\\n   ```bash\\n   npm run
  build\\n   ```\\n\\n## Configuration\\n\\nThe MCP Atlassian integration
  supports using either Confluence, Jira, or both services. You only need to
  provide the environment variables for the service(s) you want to use.\\n\\n###
  Usage with Claude Desktop\\n\\n1. Get API tokens from:
  https://id.atlassian.com/manage-profile/security/api-tokens\\n\\n2. Add to
  your `claude_desktop_config.json` with only the services you need:\\n\\nFor
  Confluence only:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-atlassian\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"CONFLUENCE_URL\\\":
  \\\"https://your-domain.atlassian.net/wiki\\\",\\n        \\\"CONFLUENCE_USER\
  NAME\\\":
  \\\"your.email@domain.com\\\",\\n        \\\"CONFLUENCE_API_TOKEN\\\":
  \\\"your_api_token\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor Jira
  only:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-atlassian\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"JIRA_URL\\\":
  \\\"https://your-domain.atlassian.net\\\",\\n        \\\"JIRA_USERNAME\\\":
  \\\"your.email@domain.com\\\",\\n        \\\"JIRA_API_TOKEN\\\":
  \\\"your_api_token\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor both
  services:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-atlassian\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"CONFLUENCE_URL\\\":
  \\\"https://your-domain.atlassian.net/wiki\\\",\\n        \\\"CONFLUENCE_USER\
  NAME\\\":
  \\\"your.email@domain.com\\\",\\n        \\\"CONFLUENCE_API_TOKEN\\\":
  \\\"your_api_token\\\",\\n        \\\"JIRA_URL\\\":
  \\\"https://your-domain.atlassian.net\\\",\\n        \\\"JIRA_USERNAME\\\":
  \\\"your.email@domain.com\\\",\\n        \\\"JIRA_API_TOKEN\\\":
  \\\"your_api_token\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n##
  Debugging\\n\\nYou can use the MCP inspector to debug the
  server:\\n\\n```bash\\ncd path/to/mcp-atlassian\\nnpx
  @modelcontextprotocol/inspector node build/index.js\\n```\\n\\nView logs
  with:\\n```bash\\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\\n```\\n\\n##
  Security\\n\\n- Never share API tokens\\n- Keep .env files secure and
  private\\n- See [SECURITY.md](SECURITY.md) for best practices\\n\\n##
  License\\n\\nLicensed under MIT - see [LICENSE](LICENSE) file. This is not an
  official Atlassian product.\\n\\n---\\nNote: This is a fork of the [original
  mcp-atlassian
  repository](https://github.com/sooperset/mcp-atlassian).\\n\",\"isRecommended\
  \":false,\"githubStars\":9,\"downloadCount\":7802,\"createdAt\":\"2025-02-18T\
  23:04:29.548307Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithub\
  Sync\":\"2025-07-02T05:31:47.446675Z\"},{\"mcpId\":\"github.com/jean-technolo\
  gies/mcp-writer-substack\",\"githubUrl\":\"https://github.com/jean-technologi\
  es/mcp-writer-substack\",\"name\":\"Substack
  Writer\",\"author\":\"jean-technologies\",\"description\":\"Connect to your
  Substack/Medium blogs, allowing Cline to become an expert writer tailored to
  your writing
  style.\",\"codiconIcon\":\"notebook\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/writer-context.png\",\"category\":\"knowledge-memory\
  \",\"tags\":[\"content-analysis\",\"writing\",\"semantic-search\",\"blog-inte\
  gration\",\"embeddings\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Writer Context Tool for
  Claude\\n\\n![image](https://github.com/user-attachments/assets/e9a90109-5cbe\
  -454d-b9f9-43f61a2544e5)\\n\\nOpen-Sourced Model Context Protocol (MCP)
  implementation that connects Claude to your Substack and Medium
  writing.\\n\\n## What is this?\\n\\nWriter Context Tool is an MCP server that
  allows Claude to access and analyze your writing from platforms like Substack
  and Medium. With this tool, Claude can understand the context of your
  published content, providing more personalized assistance with your
  writing.\\n\\n## Features\\n\\n-  Retrieves and permanently caches your blog
  posts from Substack and Medium\\n-  Uses embeddings to find the most
  relevant essays based on your queries\\n-  Makes individual essays available
  as separate resources for Claude\\n-  Performs semantic searches across your
  writing\\n-  Preloads all content and generates embeddings at startup\\n\\n##
  How It Works\\n\\nThe tool connects to your Substack/Medium blogs via their
  RSS feeds, fetches your posts, and permanently caches them locally. It also
  generates embeddings for each post, enabling semantic search to find the most
  relevant essays based on your queries.\\n\\nWhen you ask Claude about your
  writing, it can use these individual essay resources to provide insights or
  help you develop new ideas based on your existing content.\\n\\n## Setup
  Instructions (Step by Step)\\n\\n### Prerequisites\\n\\n- Python 3.10 or
  higher\\n- Claude Desktop (latest version)\\n- A Substack or Medium account
  with published content\\n\\n### 1. Clone this Repository\\n\\n```bash\\ngit
  clone https://github.com/yourusername/writer-context-tool.git\\ncd
  writer-context-tool\\n```\\n\\n### 2. Set up Python Environment\\n\\nUsing uv
  (recommended):\\n\\n```bash\\n# Install uv if you don't have it\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n\\n# Create virtual environment and
  install dependencies\\nuv venv\\nsource .venv/bin/activate  # On Windows:
  .venv\\\\Scripts\\\\activate\\nuv pip install -r
  requirements.txt\\n```\\n\\nOr using standard pip:\\n\\n```bash\\npython -m
  venv .venv\\nsource .venv/bin/activate  # On Windows:
  .venv\\\\Scripts\\\\activate\\npip install -r requirements.txt\\n```\\n\\n###
  3. Configure Your Blogs\\n\\n1. Copy the example configuration
  file:\\n   ```bash\\n   cp config.example.json config.json\\n   ```\\n\\n2.
  Edit `config.json` with your Substack/Medium
  URLs:\\n   ```json\\n   {\\n     \\\"platforms\\\":
  [\\n       {\\n         \\\"type\\\":
  \\\"substack\\\",\\n         \\\"url\\\":
  \\\"https://yourusername.substack.com\\\",\\n         \\\"name\\\": \\\"My
  Substack Blog\\\"\\n       },\\n       {\\n         \\\"type\\\":
  \\\"medium\\\",\\n         \\\"url\\\":
  \\\"https://medium.com/@yourusername\\\",\\n         \\\"name\\\": \\\"My
  Medium Blog\\\"\\n       }\\n     ],\\n     \\\"max_posts\\\":
  100,\\n     \\\"cache_duration_minutes\\\":
  10080,\\n     \\\"similar_posts_count\\\": 10\\n   }\\n   ```\\n   \\n   -
  `max_posts`: Maximum number of posts to fetch from each platform (default:
  100)\\n   - `cache_duration_minutes`: How long to cache content before
  refreshing (default: 1 week or 10080 minutes)\\n   - `similar_posts_count`:
  Number of most relevant posts to return when searching (default: 10)\\n\\n###
  4. Connect with Claude Desktop\\n\\n1. Create the Claude Desktop configuration
  directory:\\n   ```bash\\n   # On macOS\\n   mkdir -p
  ~/Library/Application\\\\ Support/Claude/\\n   ```\\n\\n2. Create the
  configuration file:\\n   ```bash\\n   # Get the absolute path to your uv
  command\\n   UV_PATH=$(which uv)\\n   \\n   # Create the
  configuration\\n   cat > ~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json <<
  EOF\\n   {\\n     \\\"mcpServers\\\": {\\n       \\\"writer-tool\\\":
  {\\n         \\\"command\\\": \\\"${UV_PATH}\\\",\\n         \\\"args\\\":
  [\\n           \\\"--directory\\\",\\n           \\\"$(pwd)\\\",\\n           \
  \\\"run\\\",\\n           \\\"writer_tool.py\\\"\\n         ]\\n       }\\n     \
  }\\n   }\\n   EOF\\n   ```\\n   \\n   > **Note:** If you experience issues
  with the `uv` command, you can use the included shell script
  alternative:\\n   > 1. Make the script executable: `chmod +x
  run_writer_tool.sh`\\n   > 2. Update your Claude Desktop config to use the
  script:\\n   > ```json\\n   > {\\n   >   \\\"mcpServers\\\":
  {\\n   >     \\\"writer-tool\\\": {\\n   >       \\\"command\\\":
  \\\"/absolute/path/to/run_writer_tool.sh\\\",\\n   >       \\\"args\\\":
  []\\n   >     }\\n   >   }\\n   > }\\n   > ```\\n\\n3. Restart Claude
  Desktop\\n\\n## Using the Tool with Claude\\n\\nOnce set up, you'll see
  individual essays available as resources in Claude Desktop. You can:\\n\\n1.
  **Search across your writing**: Ask Claude to find relevant content\\n   -
  \\\"Find essays where I discuss [specific topic]\\\"\\n   - \\\"What have I
  written about [subject]?\\\"\\n\\n2. **Reference specific essays**: Access
  individual essays by clicking on them when listed in search results\\n   -
  \\\"Show me the full text of [essay title]\\\"\\n\\n3. **Refresh content**:
  Force a refresh of your content\\n   - \\\"Refresh my writing
  content\\\"\\n\\n## Available Tools and Resources\\n\\nThe Writer Context Tool
  provides:\\n\\n1. **Individual Essay Resources**: Each of your essays becomes
  a selectable resource\\n2. **search_writing**: A semantic search tool that
  finds the most relevant essays using embeddings\\n3. **refresh_content**:
  Refreshes and recaches your content from all configured platforms\\n\\n## How
  Caching Works\\n\\nThe tool implements permanent caching with these
  features:\\n\\n1. **Disk Caching**: All content is stored on disk, so it
  persists between sessions\\n2. **Embeddings**: Each essay is converted to
  embeddings for semantic search\\n3. **Selective Refresh**: The tool only
  refreshes content when needed according to your cache settings\\n4.
  **Preloading**: All content is automatically refreshed and embeddings
  generated at startup\\n\\n## Troubleshooting\\n\\nIf you encounter
  issues:\\n\\n1. **Tool doesn't appear in Claude Desktop:**\\n   - Check that
  your Claude Desktop configuration file is correct\\n   - Verify that all paths
  in the configuration are absolute \\n   - Make sure your Python environment
  has all required packages\\n   - Restart Claude Desktop\\n\\n2. **No content
  appears:**\\n   - Verify your Substack/Medium URLs in config.json\\n   - Try
  using the \\\"refresh_content\\\" tool\\n   - Check that your blogs are public
  and have published posts\\n\\n3. **Error with uv command:**\\n   - Try using
  the shell script approach instead\\n   - Verify the uv command is installed
  and in your PATH\\n\\n4. **Embedding issues:**\\n   - If you see errors about
  the embedding model, make sure you have enough disk space\\n   - Consider
  rerunning with a fresh installation if embeddings aren't working
  properly\\n\\n## License\\n\\nThis project is available under the MIT License.
  \\n\",\"isRecommended\":false,\"githubStars\":11,\"downloadCount\":129,\"crea\
  tedAt\":\"2025-04-24T06:36:53.326393Z\",\"updatedAt\":\"2025-07-08T01:10:48.3\
  98933Z\",\"lastGithubSync\":\"2025-07-01T16:07:23.275443Z\"},{\"mcpId\":\"git\
  hub.com/planetscale/cli\",\"githubUrl\":\"https://github.com/planetscale/cli\
  \",\"name\":\"PlanetScale\",\"author\":\"planetscale\",\"description\":\"Enab\
  les AI tools to interact with PlanetScale databases, providing capabilities
  for managing organizations, databases, branches, and executing SQL queries
  with proper
  authentication.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.\
  googleapis.com/cline_public_images/planetscale.png\",\"category\":\"databases\
  \",\"tags\":[\"mysql\",\"database-management\",\"sql\",\"branching\",\"planet\
  scale-api\"],\"requiresApiKey\":false,\"readmeContent\":\"# PlanetScale CLI
  [![Build
  status](https://badge.buildkite.com/cf225eb6ccc163b365267fd8172a6e5bd9baa7c8f\
  cdd10c77c.svg?branch=main)](https://buildkite.com/planetscale/cli)\\n\\nPlane\
  tScale is more than a database and our CLI is more than a jumble of commands.
  The `pscale` command line tool brings branches, deploy requests, and other
  PlanetScale concepts to your fingertips.\\n\\n![PlanetScale
  CLI](https://user-images.githubusercontent.com/6104/191803574-be63da54-d255-4\
  f5a-ab2d-2b49cdf7eb12.png)\\n\\n\\n## Installation\\n\\n####
  macOS\\n\\n`pscale` is available via a Homebrew Tap, and as downloadable
  binary from the [releases](https://github.com/planetscale/cli/releases/latest)
  page:\\n\\n```\\nbrew install planetscale/tap/pscale\\n```\\nOptional:
  `pscale` requires a MySQL 8 Client in your PATH for certain commands. You can
  install it by running:\\n\\n```\\nbrew install mysql-client@8.4\\n```\\n\\nTo
  upgrade to the latest version:\\n\\n```\\nbrew upgrade pscale\\n```\\n\\n####
  Linux\\n\\n`pscale` is available as downloadable binaries from the
  [releases](https://github.com/planetscale/cli/releases/latest) page. Download
  the .deb or .rpm from the
  [releases](https://github.com/planetscale/cli/releases/latest) page and
  install with `sudo dpkg -i` and `sudo rpm -i` respectively.\\n\\nArch:
  [`pscale-cli-bin`](https://aur.archlinux.org/packages/pscale-cli-bin)\\n\\n##\
  ## Windows\\n\\n`pscale` is available via [scoop](https://scoop.sh/), and as a
  downloadable binary from the
  [releases](https://github.com/planetscale/cli/releases/latest)
  page:\\n\\n```\\nscoop bucket add pscale
  https://github.com/planetscale/scoop-bucket.git\\nscoop install pscale
  mysql\\n```\\n\\nTo upgrade to the latest version:\\n\\n```\\nscoop update
  pscale\\n```\\n\\n#### Manually\\n\\nDownload the pre-compiled binaries from
  the [releases](https://github.com/planetscale/cli/releases/latest) page and
  copy to the desired location.\\n\\nAlternatively, you can install
  [bin](https://github.com/marcosnils/bin) which works on all `macOS`,
  `Windows`, and `Linux` platforms:\\n\\n```\\nbin install
  https://github.com/planetscale/cli\\n```\\n\\nTo upgrade to the latest
  version\\n\\n```\\nbin upgrade pscale\\n```\\n\\n#### Container images\\n\\nWe
  provide ready to use Docker container images.  To pull the latest
  image:\\n\\n```\\ndocker pull planetscale/pscale:latest\\n```\\n\\nTo pull a
  specific version:\\n\\n```\\ndocker pull
  planetscale/pscale:v0.63.0\\n```\\n\\nIf you like to have a shell alias that
  runs the latest version of pscale from docker whenever you type
  `pscale`:\\n\\n```\\nmkdir -p $HOME/.config/planetscale\\nalias
  pscale=\\\"docker run -e HOME=/tmp -v
  $HOME/.config/planetscale:/tmp/.config/planetscale --user $(id -u):$(id -g)
  --rm -it -p 3306:3306/tcp planetscale/pscale:latest\\\"\\n```\\n\\nIf you need
  a more advanced example that works with service tokens and differentiates
  between commands that need a pseudo terminal or non-interactive mode, [have a
  look at this shell
  function](https://github.com/jonico/pscale-cli-helper-scripts/blob/main/.psca\
  le/cli-helper-scripts/use-pscale-docker-image.sh).\\n\\n## MCP Server
  Integration\\n\\nThe PlanetScale CLI includes a Model Context Protocol (MCP)
  server that provides AI tools direct access to your PlanetScale databases.
  This allows AI assistants to list organizations, databases, branches, and run
  SQL queries with proper authentication.\\n\\n### Setting up MCP in AI
  tools\\n\\n#### Claude Desktop\\n\\nTo enable the PlanetScale MCP server in
  Claude Desktop:\\n\\n```\\npscale mcp install --target claude\\n```\\n\\n####
  Cursor Editor\\n\\nTo enable the PlanetScale MCP server in
  Cursor:\\n\\n```\\npscale mcp install --target cursor\\n```\\n\\n#### Manual
  Setup for Other AI Tools\\n\\nFor AI tools that support custom MCP servers but
  don't have automated installation through the CLI, you can manually configure
  them:\\n\\n1. Find your tool's MCP configuration file\\n2. Add the following
  configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"planetscale\\\": {\\n      \\\"command\\\":
  \\\"pscale\\\",\\n      \\\"args\\\": [\\\"mcp\\\",
  \\\"server\\\"]\\n    }\\n  }\\n}\\n```\\n\\n3. Restart your AI tool to apply
  the changes\\n\\nVerify the tool recognizes the PlanetScale MCP server by
  asking it to list your databases or perform other PlanetScale
  operations.\\n\\nOnce configured, these AI tools will be able to use
  PlanetScale-specific context to help you work with your databases. The MCP
  server provides the following capabilities:\\n- List organizations\\n- List
  databases\\n- List branches\\n- List keyspaces\\n- List tables\\n- Get table
  schemas\\n- Run read-only SQL queries\\n\\n## GitHub Actions Usage\\nUse the
  [setup-pscale-action](https://github.com/planetscale/setup-pscale-action) to
  install and use `pscale` in GitHub Actions.\\n\\n```yaml\\n- name: Setup
  pscale\\n  uses: planetscale/setup-pscale-action@v1\\n- name: Use
  pscale\\n  env:\\n    PLANETSCALE_SERVICE_TOKEN_ID: ${{
  secrets.PLANETSCALE_SERVICE_TOKEN_ID }}\\n    PLANETSCALE_SERVICE_TOKEN: ${{
  secrets.PLANETSCALE_SERVICE_TOKEN }}\\n  run: |\\n    pscale deploy-request
  list my-db --org my-org\\n```\\n\\n## Local Development\\n\\nTo run a
  command:\\n```\\ngo run cmd/pscale/main.go <command>\\n```\\n\\nAlternatively,
  you can build `pscale`:\\n```\\ngo build cmd/pscale/main.go\\n```\\n\\nAnd
  then use the `pscale` binary built in `cmd/pscale/` for
  testing:\\n```\\n./cmd/pscale/pscale <command>\\n```\\n\\n##
  Documentation\\n\\nPlease checkout our Documentation page:
  [planetscale.com/docs](https://planetscale.com/docs/reference/planetscale-cli)\
  \\n\",\"isRecommended\":false,\"githubStars\":620,\"downloadCount\":878,\"cre\
  atedAt\":\"2025-04-12T20:26:22.45373Z\",\"updatedAt\":\"2025-07-08T01:10:48.3\
  98933Z\",\"lastGithubSync\":\"2025-07-04T02:46:20.894724Z\"},{\"mcpId\":\"git\
  hub.com/auth0/auth0-mcp-server\",\"githubUrl\":\"https://github.com/auth0/aut\
  h0-mcp-server\",\"name\":\"Auth0\",\"author\":\"auth0\",\"description\":\"All\
  ows AI assistants to manage Auth0 resources through natural language,
  including applications, resource servers, actions, forms, and logs management
  via the Auth0 Management
  API.\",\"codiconIcon\":\"shield\",\"logoUrl\":\"https://storage.googleapis.co\
  m/cline_public_images/auth0.png\",\"category\":\"security\",\"tags\":[\"authe\
  ntication\",\"authorization\",\"identity-management\",\"oauth\",\"access-cont\
  rol\"],\"requiresApiKey\":false,\"readmeContent\":\"![MCP server for
  Auth0](https://cdn.auth0.com/website/mcp/assets/mcp-banner-light.png)\\n\\n<d\
  iv align=\\\"center\\\">\\n\\n[![License:
  MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource\
  .org/licenses/MIT)\\n[![Node.js
  Version](https://img.shields.io/badge/node-%3E%3D18.0.0-brightgreen.svg)](htt\
  ps://nodejs.org/)\\n[![NPM
  Downloads](https://img.shields.io/npm/dw/%40auth0%2Fauth0-mcp-server)](https:\
  //www.npmjs.com/package/@auth0/auth0-mcp-server)\\n[![NPM
  Version](https://img.shields.io/npm/v/@auth0/auth0-mcp-server)](https://www.n\
  pmjs.com/package/@auth0/auth0-mcp-server)\\n[<img
  src=\\\"https://devin.ai/assets/deepwiki-badge.png\\\" alt=\\\"Ask questions
  about auth0-mcp-server on DeepWiki\\\"
  height=\\\"20\\\"/>](https://deepwiki.com/auth0/auth0-mcp-server)\\n\\n</div>\
  \\n\\n<div align=\\\"center\\\">\\n\\n
  [Documentation](https://auth0.com/docs/get-started/mcp)   [Getting
  Started](#-getting-started)   [Supported Tools](#%EF%B8%8F-supported-tools)
    [Feedback](#-feedback-and-contributing)\\n\\n</div>\\n\\n[MCP (Model
  Context Protocol)](https://modelcontextprotocol.io/introduction) is an open
  protocol introduced by Anthropic that standardizes how large language models
  communicate with external tools, resources or remote services.\\n\\n>
  [!CAUTION]\\n> **Beta Software Notice: This software is currently in beta and
  is provided AS IS without any warranties.**\\n>\\n> - Features, APIs, and
  functionality may change at any time without notice\\n> - Not recommended for
  production use or critical workloads\\n> - Support during the beta period is
  limited\\n> - Issues and feedback can be reported through the [GitHub issue
  tracker](https://github.com/auth0/auth0-mcp-server/issues)\\n>\\n> By using
  this beta software, you acknowledge and accept these conditions.\\n\\nThe
  Auth0 MCP Server integrates with LLMs and AI agents, allowing you to perform
  various Auth0 management operations using natural language. For instance, you
  could simply ask Claude Desktop to perform Auth0 management operations:\\n\\n-
  > Create a new Auth0 app and get the domain and client ID\\n- > Create and
  deploy a new Auth0 action to generate a JWT token\\n- > Could you check Auth0
  logs for logins from 192.108.92.3 IP address?\\n\\n<br/>\\n\\n<div
  align=\\\"center\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/auth0-mcp-example-demo.gif\\\
  \" alt=\\\"Auth0 MCP Server Demo\\\" width=\\\"800\\\">\\n</div>\\n\\n## 
  Getting Started\\n\\n**Prerequisites:**\\n\\n- [Node.js v18 or
  higher](https://nodejs.org/en/download)\\n- [Claude
  Desktop](https://claude.ai/download) or any other [MCP
  Client](https://modelcontextprotocol.io/clients)\\n-
  [Auth0](https://auth0.com/) account with appropriate
  permissions\\n\\n<br/>\\n\\n### Install the Auth0 MCP Server\\n\\nInstall
  Auth0 MCP Server and configure it to work with your preferred MCP Client. The
  `--tools` parameter specifies which tools should be available (defaults to `*`
  if not provided).\\n\\n**Claude Desktop with all tools**\\n\\n```bash\\nnpx
  @auth0/auth0-mcp-server init\\n```\\n\\n**Claude Desktop with read-only
  tools**\\n\\n```bash\\nnpx @auth0/auth0-mcp-server init
  --read-only\\n```\\n\\nYou can also explicitly select read-only
  tools:\\n\\n```bash\\nnpx @auth0/auth0-mcp-server init --tools
  'auth0_list_*,auth0_get_*'\\n```\\n\\n**Windsurf**\\n\\n```bash\\nnpx
  @auth0/auth0-mcp-server init --client
  windsurf\\n```\\n\\n**Cursor**\\n\\n```bash\\nnpx @auth0/auth0-mcp-server init
  --client cursor\\n```\\n\\n**With limited tools access**\\n\\n```bash\\nnpx
  @auth0/auth0-mcp-server init --client cursor --tools
  'auth0_list_applications,auth0_get_application'\\n```\\n\\n**Other MCP
  Clients**\\n\\nTo use Auth0 MCP Server with any other MCP Client, you can
  manually add this configuration to the client and restart for changes to take
  effect:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"auth0\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@auth0/auth0-mcp-server\\\", \\\"run\\\"],\\n      \\\"capabilities\\\":
  [\\\"tools\\\"],\\n      \\\"env\\\": {\\n        \\\"DEBUG\\\":
  \\\"auth0-mcp\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nYou can add `--tools
  '<pattern>'` to the args array to control which tools are available. See
  [Security Best Practices](#-security-best-practices-for-tool-access) for
  recommended patterns.\\n\\n### Authorize with Auth0\\n\\nYour browser will
  automatically open to initiate the OAuth 2.0 device authorization flow. Log
  into your Auth0 account and grant the requested permissions.\\n\\n>
  [!NOTE]\\n> Credentials are securely stored in your system's keychain. You can
  optionally verify storage through your keychain management tool. Check out
  [Authentication](#-authentication) for more info.\\n\\n### Verify your
  integration\\n\\nRestart your MCP Client (Claude Desktop, Windsurf, Cursor,
  etc.) and ask it to help you manage your Auth0 tenant\\n\\n<div
  align=\\\"left\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/help-image-01.png\\\"
  alt=\\\"Claude Desktop help screen showing successful integration\\\"
  width=\\\"300\\\">\\n</div>\\n\\n##  Supported Tools\\n\\nThe Auth0 MCP
  Server provides the following tools for Claude to interact with your Auth0
  tenant:\\n\\n<div align=\\\"center\\\" style=\\\"display: flex;
  justify-content: center; gap: 20px;\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/help-image-02.png\\\"
  alt=\\\"Supported Tools img\\\" width=\\\"400\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/help-image-03.png\\\"
  alt=\\\"Supported Tools img\\\" width=\\\"400\\\">\\n</div>\\n\\n###
  Applications\\n\\n| Tool                       |
  Description                                                 | Usage
  Examples                                                                                                                                                                                                                           \
  |\\n| -------------------------- |
  ----------------------------------------------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  ------------------------------------------------------------------------------
  |\\n| `auth0_list_applications`  | List all applications in the Auth0 tenant
  or search by name | - `Show me all my Auth0 applications` <br> - `Find
  applications with 'api' in their name` <br> - `What applications do I have in
  my Auth0
  tenant?`                                                                                       \
  |\\n| `auth0_get_application`    | Get details about a specific Auth0
  application              | - `Show me details for the application called
  'Customer Portal'` <br> - `Get information about my application with client ID
  abc123` <br> - `What are the callback URLs for my 'Mobile
  App'?`                                            |\\n|
  `auth0_create_application` | Create a new Auth0
  application                              | - `Create a new single-page
  application called 'Analytics Dashboard'` <br> - `Set up a new native mobile
  app called 'iOS Client'` <br> - `Create a machine-to-machine application for
  our background service`                            |\\n|
  `auth0_update_application` | Update an existing Auth0
  application                        | - `Update the callback URLs for my 'Web
  App' to include https://staging.example.com/callback` <br> - `Change the
  logout URL for the 'Customer Portal'` <br> - `Add development environment
  metadata to my 'Admin Dashboard' application` |\\n\\n### Resource
  Servers\\n\\n| Tool                           |
  Description                                          | Usage
  Examples                                                                                                                                                                                            \
  |\\n| ------------------------------ |
  ---------------------------------------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  ----------------------------------------------- |\\n|
  `auth0_list_resource_servers`  | List all resource servers (APIs) in the Auth0
  tenant | - `Show me all the APIs in my Auth0 tenant` <br> - `List my resource
  servers` <br> - `What APIs have I configured in
  Auth0?`                                                                              \
  |\\n| `auth0_get_resource_server`    | Get details about a specific Auth0
  resource server   | - `Show me details for the 'User API'` <br> - `What scopes
  are defined for my 'Payment API'?` <br> - `Get information about the resource
  server with identifier https://api.example.com\\\"`                 |\\n|
  `auth0_create_resource_server` | Create a new Auth0 resource server
  (API)             | - `Create a new API called 'Inventory API' with read and
  write scopes` <br> - `Set up a resource server for our customer data API` <br>
  - `Create an API with the identifier https://orders.example.com\\\"` |\\n|
  `auth0_update_resource_server` | Update an existing Auth0 resource
  server             | - `Add an 'admin' scope to the 'User API'` <br> - `Update
  the token lifetime for my 'Payment API' to 1 hour` <br> - `Change the signing
  algorithm for my API to RS256`                                    |\\n\\n###
  Actions\\n\\n| Tool                  |
  Description                               | Usage
  Examples                                                                                                                                                                            \
  |\\n| --------------------- | ----------------------------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  ------------------------------- |\\n| `auth0_list_actions`  | List all actions
  in the Auth0 tenant      | - `Show me all my Auth0 actions` <br> - `What
  actions do I have configured?` <br> - `List the actions in my
  tenant`                                                                       \
  |\\n| `auth0_get_action`    | Get details about a specific Auth0 action | -
  `Show me the code for my 'Enrich User Profile' action` <br> - `Get details
  about my login flow action` <br> - `What does my 'Add Custom Claims' action
  do?`                             |\\n| `auth0_create_action` | Create a new
  Auth0 action                 | - `Create an action that adds user roles to
  tokens` <br> - `Set up an action to log failed login attempts` <br> - `Create
  a post-login action that checks user location`                  |\\n|
  `auth0_update_action` | Update an existing Auth0 action           | - `Update
  my 'Add Custom Claims' action to include department information` <br> -
  `Modify the IP filtering logic in my security action` <br> - `Fix the bug in
  my user enrichment action` |\\n| `auth0_deploy_action` | Deploy an Auth0
  action                    | - `Deploy my 'Add Custom Claims' action to
  production` <br> - `Make my new security action live` <br> - `Deploy the
  updated user enrichment
  action`                                       |\\n\\n### Logs\\n\\n|
  Tool              | Description                     | Usage
  Examples                                                                                                                                                                                    \
  |\\n| ----------------- | ------------------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  --------------------------------------- |\\n| `auth0_list_logs` | List logs
  from the Auth0 tenant | - `Show me recent login attempts` <br> - `Find failed
  logins from the past 24 hours` <br> - `Get authentication logs from yesterday`
  <br> - `Show me successful logins for user john@example.com` |\\n|
  `auth0_get_log`   | Get a specific log entry by ID  | - `Show me details for
  log entry abc123` <br> - `Get more information about this failed login
  attempt` <br> - `What caused this authentication
  error?`                                            |\\n\\n### Forms\\n\\n|
  Tool                 | Description                             | Usage
  Examples                                                                                                                                                                      \
  |\\n| -------------------- | --------------------------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  ------------------------- |\\n| `auth0_list_forms`   | List all forms in the
  Auth0 tenant      | - `Show me all my Auth0 forms` <br> - `What login forms do
  I have configured?` <br> - `List the custom forms in my
  tenant`                                                          |\\n|
  `auth0_get_form`     | Get details about a specific Auth0 form | - `Show me
  the details of my 'Corporate Login' form` <br> - `What does my password reset
  form look like?` <br> - `Get the configuration for my signup
  form`                         |\\n| `auth0_create_form`  | Create a new Auth0
  form                 | - `Create a new login form with our company branding`
  <br> - `Set up a custom signup form that collects department information` <br>
  - `Create a password reset form with our logo` |\\n| `auth0_update_form`  |
  Update an existing Auth0 form           | - `Update the colors on our login
  form to match our new brand guidelines` <br> - `Add a privacy policy link to
  our signup form` <br> - `Change the logo on our password reset form` |\\n|
  `auth0_publish_form` | Publish an Auth0 form                   | - `Publish my
  updated login form` <br> - `Make the new signup form live` <br> - `Deploy the
  password reset form to
  production`                                                      |\\n\\n### 
  Security Best Practices for Tool Access\\n\\nWhen configuring the Auth0 MCP
  Server, it's important to follow security best practices by limiting tool
  access based on your specific needs. The server provides flexible
  configuration options that let you control which tools AI assistants can
  access.\\n\\nYou can easily restrict tool access using the `--tools` and
  `--read-only` flags when starting the server:\\n\\n```bash\\n# Enable only
  read-only operations\\nnpx @auth0/auth0-mcp-server run --read-only\\n\\n#
  Alternative way to enable only read-only operations\\nnpx
  @auth0/auth0-mcp-server run --tools 'auth0_list_*,auth0_get_*'\\n\\n# Limit to
  just application-related tools\\nnpx @auth0/auth0-mcp-server run --tools
  'auth0_*_application*'\\n\\n# Limit to read-only application-related tools\\n#
  Note: --read-only takes priority when used with --tools\\nnpx
  @auth0/auth0-mcp-server run --tools 'auth0_*_application*' --read-only\\n\\n#
  Restrict to only log viewing capabilities\\nnpx @auth0/auth0-mcp-server run
  --tools 'auth0_list_logs,auth0_get_log'\\n\\n# Run the server with all tools
  enabled\\nnpx @auth0/auth0-mcp-server run --tools '*'\\n```\\n\\n>
  [!IMPORTANT]\\n> When both `--read-only` and `--tools` flags are used
  together, the `--read-only` flag takes priority for security. This means even
  if your `--tools` pattern matches non-read-only tools, only read-only
  operations will be available. This ensures you can rely on the `--read-only`
  flag as a security guardrail.\\n\\nThis approach offers several important
  benefits:\\n\\n1. **Enhanced Security**: By limiting available tools to only
  what's needed, you reduce the potential attack surface and prevent unintended
  modifications to your Auth0 tenant.\\n\\n2. **Better Performance**: Providing
  fewer tools to AI assistants actually improves performance. When models have
  access to many tools, they use more of their context window to reason about
  which tools to use. With a focused set of tools, you'll get faster and more
  relevant responses.\\n\\n3. **Resource-Based Access Control**: You can
  configure different instances of the MCP server with different tool sets based
  on specific needs - development environments might need full access, while
  production environments could be limited to read operations only.\\n\\n4.
  **Simplified Auditing**: With limited tools, it's easier to track which
  operations were performed through the AI assistant.\\n\\nFor most use cases,
  start with the minimum set of tools needed and add more only when required.
  This follows the principle of least privilege - a fundamental security best
  practice.\\n\\n###  Security Scanning\\n\\nWe recommend regularly scanning
  this server, and any other MCP-compatible servers you deploy, with community
  tools built to surface protocol-level risks and misconfigurations.\\n\\nThese
  scanners help identify issues across key vulnerability classes including:
  server implementation bugs, tool definition and lifecycle risks, interaction
  and data flow weaknesses, and configuration or environment gaps.\\n\\nUseful
  tools include:\\n\\n- **[mcpscan.ai](https://mcpscan.ai)**  \\n  Web-based
  scanner that inspects live MCP endpoints for exposed tools, schema enforcement
  gaps, and other issues.\\n\\n-
  **[mcp-scan](https://github.com/invariantlabs-ai/mcp-scan)**  \\n  CLI tool
  that simulates attack paths and evaluates server behavior from a client
  perspective.\\n\\nThese tools are not a substitute for a full audit, but they
  offer meaningful guardrails and early warnings. We suggest including them in
  your regular security review process.\\n\\nIf you discover a vulnerability,
  please follow our [responsible disclosure
  process](https://auth0.com/whitehat).\\n\\n##  Architecture\\n\\nThe Auth0
  MCP Server implements the Model Context Protocol, allowing Claude to:\\n\\n1.
  Request a list of available Auth0 tools\\n2. Call specific tools with
  parameters\\n3. Receive structured responses from the Auth0 Management
  API\\n\\nThe server handles authentication, request validation, and secure
  communication with the Auth0 Management API.\\n\\n<div
  align=\\\"center\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/auth0-mcp-server-hld.png\\\"
  alt=\\\"Auth0 MCP Server HLD\\\" width=\\\"800\\\">\\n</div>\\n\\n>
  [!NOTE]\\n> The server operates as a local process that connects to Claude
  Desktop, enabling secure communication without exposing your Auth0
  credentials.\\n\\n##  Authentication\\n\\nThe Auth0 MCP Server uses the
  Auth0 Management API and requires authentication to access your Auth0
  tenant.\\n\\n### Initial Setup\\n\\nTo authenticate the MCP
  Server:\\n\\n```bash\\nnpx @auth0/auth0-mcp-server init\\n```\\n\\nThis will
  start the device authorization flow, allowing you to log in to your Auth0
  account and select the tenant you want to use.\\n\\n> [!IMPORTANT]\\n> The
  `init` command needs to be run whenever:\\n>\\n> - You're setting up the MCP
  Server for the first time\\n> - You've logged out from a previous session\\n>
  - You want to switch to a different tenant\\n> - Your token has
  expired\\n>\\n> The `run` command will automatically check for token validity
  before starting the server and will provide helpful error messages if
  authentication is needed.\\n\\n### Session Management\\n\\nTo see information
  about your current authentication session:\\n\\n```bash\\nnpx
  @auth0/auth0-mcp-server session\\n```\\n\\n### Logging Out\\n\\nFor security
  best practices, always use the logout command when you're done with a
  session:\\n\\n```bash\\nnpx @auth0/auth0-mcp-server logout\\n```\\n\\nThis
  ensures your authentication tokens are properly removed from the system
  keychain.\\n\\n### Authentication Flow\\n\\nThe server uses OAuth 2.0 device
  authorization flow for secure authentication with Auth0. Your credentials are
  stored securely in your system's keychain and are never exposed in plain
  text.\\n\\n<div align=\\\"center\\\">\\n  <img
  src=\\\"https://cdn.auth0.com/website/mcp/assets/mcp-server-auth.png\\\"
  alt=\\\"Authentication Sequence Diagram\\\"
  width=\\\"800\\\">\\n</div>\\n\\n##  Troubleshooting\\n\\nWhen encountering
  issues with the Auth0 MCP Server, several troubleshooting options are
  available to help diagnose and resolve problems.\\n\\nStart troubleshooting by
  exploring all available commands and options:\\n\\n```bash\\nnpx
  @auth0/auth0-mcp-server help\\n```\\n\\n###  Operation Modes\\n\\n#### 
  Debug Mode\\n\\n- More detailed logging\\n- Enable by setting environment
  variable: `export DEBUG=auth0-mcp`\\n\\n> [!TIP]\\n> Debug mode is
  particularly useful when troubleshooting connection or authentication
  issues.\\n\\n####  Scope Selection\\n\\nThe server provides an interactive
  scope selection interface during initialization:\\n\\n- **Interactive
  Selection**: Navigate with arrow keys and toggle selections with spacebar\\n-
  **No Default Scopes**: By default, no scopes are selected for maximum
  security\\n- **Glob Pattern Support**: Quickly select multiple related scopes
  with patterns:\\n\\n  ```bash\\n  # Select all read scopes\\n  npx
  @auth0/auth0-mcp-server init --scopes 'read:*'\\n\\n  # Select multiple scope
  patterns (comma-separated)\\n  npx @auth0/auth0-mcp-server init --scopes
  'read:*,create:clients,update:actions'\\n  ```\\n\\n> [!NOTE]\\n> Selected
  scopes determine what operations the MCP server can perform on your Auth0
  tenant.\\n\\n###  Configuration\\n\\n#### Other MCP Clients:\\n\\nTo use
  Auth0 MCP Server with any other MCP Client, you can add this configuration to
  the client and restart for changes to take
  effect:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"auth0\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@auth0/auth0-mcp-server\\\", \\\"run\\\"],\\n      \\\"capabilities\\\":
  [\\\"tools\\\"],\\n      \\\"env\\\": {\\n        \\\"DEBUG\\\":
  \\\"auth0-mcp\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n> [!NOTE]  \\n> You
  can manually update if needed or if any unexpected errors occur during the npx
  init command.\\n\\n###  Common Issues\\n\\n1. **Authentication
  Failures**\\n\\n   - Ensure you have the correct permissions in your Auth0
  tenant\\n   - Try re-initializing with `npx @auth0/auth0-mcp-server
  init`\\n\\n2. **Claude Desktop Can't Connect to the Server**\\n\\n   - Restart
  Claude Desktop after installation\\n   - Check that the server is running with
  `ps aux | grep auth0-mcp`\\n\\n3. **API Errors or Permission
  Issues**\\n\\n   - Enable debug mode with `export DEBUG=auth0-mcp`\\n   -
  Check your Auth0 token status: `npx @auth0/auth0-mcp-server session`\\n   -
  Reinitialize with specific scopes: `npx @auth0/auth0-mcp-server init --scopes
  'read:*,update:*,create:*'`\\n   - If a specific operation fails, you may be
  missing the required scope\\n\\n4. **Invalid Auth0 Configuration
  Error**\\n\\n   - This typically happens when your authorization token is
  missing or expired\\n   - Run `npx @auth0/auth0-mcp-server session` to check
  your token status\\n   - If expired or missing, run `npx
  @auth0/auth0-mcp-server init` to authenticate\\n\\n> [!TIP]\\n> Most
  connection issues can be resolved by restarting both the server and Claude
  Desktop.\\n\\n##  Debug logs\\n\\nEnable debug mode to view detailed
  logs:\\n\\n```sh\\nexport DEBUG=auth0-mcp\\n```\\n\\nGet detailed MCP Client
  logs from Claude Desktop:\\n\\n```sh\\n# Follow logs in real-time\\ntail -n 20
  -F ~/Library/Logs/Claude/mcp*.log\\n```\\n\\nFor advanced troubleshooting, use
  the MCP Inspector:\\n\\n```sh\\nnpx @modelcontextprotocol/inspector -e
  DEBUG='auth0-mcp' @auth0/auth0-mcp-server run\\n```\\n\\nFor detailed MCP
  Server logs, run the server in debug mode:\\n\\n```bash\\nDEBUG=auth0-mcp npx
  @auth0/auth0-mcp-server run\\n```\\n\\n##  Development\\n\\n### Building
  from Source\\n\\n```bash\\n# Clone the repository\\ngit clone
  https://github.com/auth0/auth0-mcp-server.git\\ncd auth0-mcp-server\\n\\n#
  Install dependencies\\nnpm install\\n\\n# Build the project\\nnpm run
  build\\n\\n# Initiate device auth flow\\nnpx . init\\n\\n# Configure your MCP
  Client (e.g. Claude Desktop) with MCP server path\\nnpm run
  setup\\n```\\n\\n### Development Scripts\\n\\n```bash\\n# Run directly with
  TypeScript (no build needed)\\nnpm run dev\\n\\n# Run with debug logs
  enabled\\nnpm run dev:debug\\n\\n# Run with MCP inspector for debugging\\nnpm
  run dev:inspect\\n\\n# Run the compiled JavaScript version\\nnpm run
  start\\n```\\n\\n> [!NOTE]\\n> This server requires [Node.js v18 or
  higher](https://nodejs.org/en/download).\\n\\n##  Security\\n\\nThe Auth0
  MCP Server prioritizes security:\\n\\n- Credentials are stored in the system's
  secure keychain\\n- No sensitive information is stored in plain text\\n-
  Authentication uses OAuth 2.0 device authorization flow\\n- No permissions
  (scopes) are requested by default\\n- Interactive scope selection allows you
  to choose exactly which permissions to grant\\n- Support for glob patterns to
  quickly select related scopes (e.g., `read:*`)\\n- Easy token removal via
  `logout` command when no longer needed\\n\\n> [!IMPORTANT]\\n> For security
  best practices, always use `npx @auth0/auth0-mcp-server logout` when you're
  done with a session or switching between tenants. This ensures your
  authentication tokens are properly removed from the system keychain.\\n\\n>
  [!CAUTION]\\n> Always review the permissions requested during the
  authentication process to ensure they align with your security
  requirements.\\n\\n## Anonymized Analytics Disclosure\\n\\nAnonymized data
  points are collected during the use of this MCP server. This data includes the
  MCP version, operating system, timestamp, and other technical details that do
  not personally identify you.\\n\\nAuth0 uses this data to better understand
  the usage of this tool to prioritize the features, enhancements and fixes that
  matter most to our users.\\n\\nTo **opt-out** of this collection, set the
  `AUTH0_MCP_ANALYTICS` environment variable to `false`.\\n\\n##  Feedback and
  Contributing\\n\\nWe appreciate feedback and contributions to this project!
  Before you get started, please see:\\n\\n- [Auth0's general contribution
  guidelines](https://github.com/auth0/open-source-template/blob/master/GENERAL\
  -CONTRIBUTING.md)\\n- [Auth0's code of conduct
  guidelines](https://github.com/auth0/open-source-template/blob/master/CODE-OF\
  -CONDUCT.md)\\n\\n### Reporting Issues\\n\\nTo provide feedback or report a
  bug, please [raise an issue on our issue
  tracker](https://github.com/auth0/auth0-mcp-server/issues).\\n\\n###
  Vulnerability Reporting\\n\\nPlease do not report security vulnerabilities on
  the public GitHub issue tracker. The [Responsible Disclosure
  Program](https://auth0.com/whitehat) details the procedure for disclosing
  security issues.\\n\\n##  License\\n\\nThis project is licensed under the
  MIT license. See the [LICENSE](LICENSE) file for more info.\\n\\n## What is
  Auth0?\\n\\n<p align=\\\"center\\\">\\n  <picture>\\n    <source
  media=\\\"(prefers-color-scheme: dark)\\\"
  srcset=\\\"https://cdn.auth0.com/website/auth0-logos/2023-branding/favicon/au\
  th0-icon-ondark.svg\\\" width=\\\"150\\\" height=\\\"75\\\">\\n    <source
  media=\\\"(prefers-color-scheme: light)\\\"
  srcset=\\\"https://cdn.auth0.com/website/auth0-logos/2023-branding/favicon/au\
  th0-icon-onlight.svg\\\" width=\\\"150\\\" height=\\\"75\\\">\\n    <img
  alt=\\\"Auth0 Logo\\\"
  src=\\\"https://cdn.auth0.com/website/sdks/logos/auth0_light_mode.png\\\"
  width=\\\"150\\\">\\n  </picture>\\n</p>\\n<p align=\\\"center\\\">\\n  Auth0
  is an easy to implement, adaptable authentication and authorization platform.
  To learn more checkout <a href=\\\"https://auth0.com/why-auth0\\\">Why
  Auth0?</a>\\n</p>\\n\",\"isRecommended\":false,\"githubStars\":61,\"downloadC\
  ount\":495,\"createdAt\":\"2025-04-17T21:21:56.331236Z\",\"updatedAt\":\"2025\
  -07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T21:14:43.424913Z\"}\
  ,{\"mcpId\":\"github.com/21st-dev/magic-mcp\",\"githubUrl\":\"https://github.\
  com/21st-dev/magic-mcp\",\"name\":\"Magic
  UI\",\"author\":\"21st-dev\",\"description\":\"Create modern UI components
  instantly through natural language descriptions, with IDE integrations and
  access to a vast library of pre-built, customizable
  components.\",\"codiconIcon\":\"layout\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/ui-component-generator.png\",\"category\":\"deve\
  loper-tools\",\"tags\":[\"ui-generation\",\"component-library\",\"ide-integra\
  tion\",\"typescript\",\"react\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"# 21st.dev Magic AI Agent\\n\\n![MCP
  Banner](https://21st.dev/magic-agent-og-image.png)\\n\\nMagic Component
  Platform (MCP) is a powerful AI-driven tool that helps developers create
  beautiful, modern UI components instantly through natural language
  descriptions. It integrates seamlessly with popular IDEs and provides a
  streamlined workflow for UI development.\\n\\n##  Features\\n\\n-
  **AI-Powered UI Generation**: Create UI components by describing them in
  natural language\\n- **Multi-IDE Support**:\\n  - [Cursor](https://cursor.com)
  IDE integration\\n  - [Windsurf](https://windsurf.ai) support\\n  -
  [VSCode](https://code.visualstudio.com/) support\\n  - [VSCode +
  Cline](https://cline.bot) integration (Beta)\\n- **Modern Component Library**:
  Access to a vast collection of pre-built, customizable components inspired by
  [21st.dev](https://21st.dev)\\n- **Real-time Preview**: Instantly see your
  components as you create them\\n- **TypeScript Support**: Full TypeScript
  support for type-safe development\\n- **SVGL Integration**: Access to a vast
  collection of professional brand assets and logos\\n- **Component
  Enhancement**: Improve existing components with advanced features and
  animations (Coming Soon)\\n\\n##  How It Works\\n\\n1. **Tell Agent What You
  Need**\\n\\n   - In your AI Agent's chat, just type `/ui` and describe the
  component you're looking for\\n   - Example: `/ui create a modern navigation
  bar with responsive design`\\n\\n2. **Let Magic Create It**\\n\\n   - Your IDE
  prompts you to use Magic\\n   - Magic instantly builds a polished UI
  component\\n   - Components are inspired by 21st.dev's library\\n\\n3.
  **Seamless Integration**\\n   - Components are automatically added to your
  project\\n   - Start using your new UI components right away\\n   - All
  components are fully customizable\\n\\n##  Getting Started\\n\\n###
  Prerequisites\\n\\n- Node.js (Latest LTS version recommended)\\n- One of the
  supported IDEs:\\n  - Cursor\\n  - Windsurf\\n  - VSCode (with Cline
  extension)\\n\\n### Installation\\n\\n1. **Generate API Key**\\n\\n   - Visit
  [21st.dev Magic Console](https://21st.dev/magic/console)\\n   - Generate a new
  API key\\n\\n2. **Choose Installation Method**\\n\\n#### Method 1: CLI
  Installation (Recommended)\\n\\nOne command to install and configure MCP for
  your IDE:\\n\\n```bash\\nnpx @21st-dev/cli@latest install <client> --api-key
  <key>\\n```\\n\\nSupported clients: cursor, windsurf, cline, claude\\n\\n####
  Method 2: Manual Configuration\\n\\nIf you prefer manual setup, add this to
  your IDE's MCP config file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"@21st-dev/magic\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@21st-dev/magic@latest\\\",
  \\\"API_KEY=\\\\\\\"your-api-key\\\\\\\"\\\"]\\n    }\\n  }\\n}\\n```\\n\\nCo\
  nfig file locations:\\n\\n- Cursor: `~/.cursor/mcp.json`\\n- Windsurf:
  `~/.codeium/windsurf/mcp_config.json`\\n- Cline:
  `~/.cline/mcp_config.json`\\n- Claude: `~/.claude/mcp_config.json`\\n\\n####
  Method 3: VS Code Installation\\n\\nFor one-click installation, click one of
  the install buttons below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=%4021st-dev%2Fmagic&config=%7B%22command%22%3A%22npx%22%2C%22args\
  %22%3A%5B%22-y%22%2C%22%4021st-dev%2Fmagic%40latest%22%5D%2C%22env%22%3A%7B%2\
  2API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%\
  22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%2221st.dev\
  +Magic+API+Key%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in VS
  Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=%4021st-dev%2Fmagic&config=%7B%22command%22%3A%22npx\
  %22%2C%22args%22%3A%5B%22-y%22%2C%22%4021st-dev%2Fmagic%40latest%22%5D%2C%22e\
  nv%22%3A%7B%22API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&inputs=%5B%7B%\
  22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%\
  3A%2221st.dev+Magic+API+Key%22%2C%22password%22%3Atrue%7D%5D&quality=insiders)\
  \\n\\n##### Manual VS Code Setup\\n\\nFirst, check the install buttons above
  for one-click installation. For manual setup:\\n\\nAdd the following JSON
  block to your User Settings (JSON) file in VS Code. You can do this by
  pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings
  (JSON)`:\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"apiKey\\\",\\n        \\\"description\\\": \\\"21st.dev Magic API
  Key\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\":
  {\\n      \\\"@21st-dev/magic\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"@21st-dev/magic@latest\\\"],\\n        \\\"env\\\":
  {\\n          \\\"API_KEY\\\":
  \\\"${input:apiKey}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nOp\
  tionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace:\\n\\n```json\\n{\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"apiKey\\\",\\n      \\\"description\\\": \\\"21st.dev Magic API
  Key\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\":
  {\\n    \\\"@21st-dev/magic\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@21st-dev/magic@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"API_KEY\\\":
  \\\"${input:apiKey}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## 
  FAQ\\n\\n### How does Magic AI Agent handle my codebase?\\n\\nMagic AI Agent
  only writes or modifies files related to the components it generates. It
  follows your project's code style and structure, and integrates seamlessly
  with your existing codebase without affecting other parts of your
  application.\\n\\n### Can I customize the generated components?\\n\\nYes! All
  generated components are fully editable and come with well-structured code.
  You can modify the styling, functionality, and behavior just like any other
  React component in your codebase.\\n\\n### What happens if I run out of
  generations?\\n\\nIf you exceed your monthly generation limit, you'll be
  prompted to upgrade your plan. You can upgrade at any time to continue
  generating components. Your existing components will remain fully
  functional.\\n\\n### How soon do new components get added to 21st.dev's
  library?\\n\\nAuthors can publish components to 21st.dev at any time, and
  Magic Agent will have immediate access to them. This means you'll always have
  access to the latest components and design patterns from the
  community.\\n\\n### Is there a limit to component complexity?\\n\\nMagic AI
  Agent can handle components of varying complexity, from simple buttons to
  complex interactive forms. However, for best results, we recommend breaking
  down very complex UIs into smaller, manageable components.\\n\\n## 
  Development\\n\\n### Project Structure\\n\\n```\\nmcp/\\n app/\\n   
  components/     # Core UI components\\n types/             # TypeScript
  type definitions\\n lib/              # Utility functions\\n
  public/           # Static assets\\n```\\n\\n### Key Components\\n\\n-
  `IdeInstructions`: Setup instructions for different IDEs\\n- `ApiKeySection`:
  API key management interface\\n- `WelcomeOnboarding`: Onboarding flow for new
  users\\n\\n##  Contributing\\n\\nWe welcome contributions! Please join our
  [Discord community](https://discord.gg/Qx4rFunHfm) and provide feedback to
  help improve Magic Agent. The source code is available on
  [GitHub](https://github.com/serafimcloud/21st).\\n\\n##  Community &
  Support\\n\\n- [Discord Community](https://discord.gg/Qx4rFunHfm) - Join our
  active community\\n- [Twitter](https://x.com/serafimcloud) - Follow us for
  updates\\n\\n##  Beta Notice\\n\\nMagic Agent is currently in beta. All
  features are free during this period. We appreciate your feedback and patience
  as we continue to improve the platform.\\n\\n##  License\\n\\nMIT
  License\\n\\n##  Acknowledgments\\n\\n- Thanks to our beta testers and
  community members\\n- Special thanks to the Cursor, Windsurf, and Cline teams
  for their collaboration\\n- Integration with [21st.dev](https://21st.dev) for
  component inspiration\\n- [SVGL](https://svgl.app) for logo and brand asset
  integration\\n\\n---\\n\\nFor more information, join our [Discord
  community](https://discord.gg/Qx4rFunHfm) or visit
  [21st.dev/magic](https://21st.dev/magic).\\n\",\"llmsInstallationContent\":\"#
  Magic MCP Server Installation Guide\\n\\nThis guide is specifically designed
  for AI agents like Cline to install and configure the Magic MCP
  server.\\n\\n## Prerequisites\\n\\n1. Node.js (Latest LTS version)\\n2. A
  valid TWENTY_FIRST_API_KEY from
  [21st.dev/magic](https://21st.dev/magic)\\n\\n## Installation Steps\\n\\n###
  1. Configuration Setup\\n\\nThe Magic MCP server requires configuration based
  on the client type. Below are the setup instructions for each supported
  client:\\n\\n#### For Windsurf\\n\\n1. Create or modify the configuration file
  at
  `~/.codeium/windsurf/mcp_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\
  \": {\\n    \\\"magic\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@smithery/cli@latest\\\",\\n        \\\
  \"install\\\",\\n        \\\"@21st-dev/magic-mcp\\\",\\n        \\\"--client\\\
  \",\\n        \\\"windsurf\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"TWENTY_FIRST_API_KEY\\\":
  \\\"<API_KEY>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n2. Replace
  `<API_KEY>` with the actual TWENTY_FIRST_API_KEY value.\\n\\n#### For
  Cline\\n\\n1. Create or modify the MCP configuration
  file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"@21st-dev-magic-mcp\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@smithery/cli@latest\\\",\\n        \\\
  \"run\\\",\\n        \\\"@21st-dev/magic-mcp\\\",\\n        \\\"--config\\\",\
  \\n        \\\"\\\\\\\"{\\\\\\\\\\\\\\\"TWENTY_FIRST_API_KEY\\\\\\\\\\\\\\\":\
  \\\\\\\\\\\\\\\"<API_KEY>\\\\\\\\\\\\\\\"}\\\\\\\"\\\"\\n      ]\\n    }\\n  }\
  \\n}\\n```\\n\\n2. Replace `<API_KEY>` with the actual TWENTY_FIRST_API_KEY
  value.\\n\\n### 2. Verification\\n\\nTo verify the installation:\\n\\n1. The
  MCP server should appear in the list of available servers\\n2. Test the
  connection by sending a simple command:\\n   ```\\n   /ui create a basic
  button\\n   ```\\n\\n## Troubleshooting\\n\\nCommon issues and
  solutions:\\n\\n1. If the server fails to start:\\n\\n   - Verify the API key
  is valid\\n   - Check Node.js version (should be LTS)\\n   - Ensure all
  dependencies are installed\\n\\n2. If components fail to generate:\\n   -
  Verify network connectivity\\n   - Check API key permissions\\n   - Ensure the
  command format is correct\\n\\n## Environment Variables\\n\\nRequired
  environment variables:\\n\\n- `TWENTY_FIRST_API_KEY`: Your Magic API key from
  21st.dev\\n\\n## Additional Notes\\n\\n- The server automatically handles
  TypeScript and React components\\n- No additional configuration is needed for
  basic usage\\n- The server supports hot reloading for development\\n\\n##
  Support\\n\\nIf you encounter any issues:\\n\\n1. Check the [FAQ
  section](https://21st.dev/magic/docs/faq)\\n2. Join our [Discord
  community](https://discord.gg/Qx4rFunHfm)\\n3. Submit an issue on
  [GitHub](https://github.com/serafimcloud/21st)\\n\\n---\\n\\nThis installation
  guide is maintained by the Magic team. For updates and more information, visit
  [21st.dev/magic](https://21st.dev/magic).\\n\",\"isRecommended\":false,\"gith\
  ubStars\":2834,\"downloadCount\":13755,\"createdAt\":\"2025-03-03T06:37:07.50\
  4691Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"20\
  25-07-07T16:16:49.206078Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/sr\
  c/syntheticdata-mcp-server\",\"githubUrl\":\"https://github.com/awslabs/mcp/t\
  ree/main/src/syntheticdata-mcp-server\",\"name\":\"Synthetic
  Data\",\"author\":\"awslabs\",\"description\":\"Generates, validates, and
  manages synthetic data with features for business-driven generation, safe
  pandas code execution, data validation, and integration with storage systems
  like
  S3.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis.c\
  om/cline_public_images/aws.png\",\"category\":\"developer-tools\",\"tags\":[\
  \"data-generation\",\"validation\",\"pandas\",\"synthetic-data\",\"aws-integr\
  ation\"],\"requiresApiKey\":false,\"readmeContent\":\"# Synthetic Data MCP
  Server\\n\\nA Model Context Protocol (MCP) server for generating, validating,
  and managing synthetic data.\\n\\n## Overview\\n\\nThis MCP server provides
  tools for generating synthetic data based on business descriptions, executing
  pandas code safely, validating data structures, and loading data to storage
  systems like S3.\\n\\n## Features\\n\\n- **Business-Driven Generation**:
  Generate synthetic data instructions based on business descriptions\\n- **Data
  Generation Instructions**: Generate structured data generation instructions
  from business descriptions\\n- **Safe Pandas Code Execution**: Run pandas code
  in a restricted environment with automatic DataFrame detection\\n- **JSON
  Lines Validation**: Validate and convert JSON Lines data to CSV format\\n-
  **Data Validation**: Validate data structure, referential integrity, and save
  as CSV files\\n- **Referential Integrity Checking**: Validate relationships
  between tables\\n- **Data Quality Assessment**: Identify potential issues in
  data models (3NF validation)\\n- **Storage Integration**: Load data to various
  storage targets (S3) with support for:\\n  - Multiple file formats (CSV, JSON,
  Parquet)\\n  - Partitioning options\\n  - Storage class configuration\\n  -
  Encryption settings\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS services\\n   - You need an AWS account with appropriate
  permissions\\n   - Configure AWS credentials with `aws configure` or
  environment variables\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.syntheticdata-mcp-server&config=eyJjb21tYW5kIjoidX\
  Z4IGF3c2xhYnMuc3ludGhldGljZGF0YS1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0x\
  FVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9O\
  IjoidXMtZWFzdC0xIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D)\\n\
  \\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.syntheticdata-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.syntheticdata-mcp-server\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      },\\n      \\\"autoApprove\\\":
  [],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\nNOTE: Your
  credentials will need to be kept refreshed from your host\\n\\n### AWS
  Authentication\\n\\nThe MCP server uses the AWS profile specified in the
  `AWS_PROFILE` environment variable. If not provided, it defaults to the
  \\\"default\\\" profile in your AWS configuration
  file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n}\\n```\\n\\n## Usage\\n\\n### Getting Data
  Generation Instructions\\n\\n```python\\nresponse = await
  server.get_data_gen_instructions(\\n    business_description=\\\"An e-commerce
  platform with customers, orders, and products\\\"\\n)\\n```\\n\\n### Executing
  Pandas Code\\n\\n```python\\nresponse = await
  server.execute_pandas_code(\\n    code=\\\"your_pandas_code_here\\\",\\n    w\
  orkspace_dir=\\\"/path/to/workspace\\\",\\n    output_dir=\\\"data\\\"\\n)\\n\
  ```\\n\\n### Validating and Saving Data\\n\\n```python\\nresponse = await
  server.validate_and_save_data(\\n    data={\\n        \\\"customers\\\":
  [{\\\"id\\\": 1, \\\"name\\\": \\\"John\\\"}],\\n        \\\"orders\\\":
  [{\\\"id\\\": 101, \\\"customer_id\\\":
  1}]\\n    },\\n    workspace_dir=\\\"/path/to/workspace\\\",\\n    output_dir=\
  \\\"data\\\"\\n)\\n```\\n\\n### Loading to Storage\\n\\n```python\\nresponse =
  await server.load_to_storage(\\n    data={\\n        \\\"customers\\\":
  [{\\\"id\\\": 1, \\\"name\\\":
  \\\"John\\\"}]\\n    },\\n    targets=[{\\n        \\\"type\\\":
  \\\"s3\\\",\\n        \\\"config\\\": {\\n            \\\"bucket\\\":
  \\\"my-bucket\\\",\\n            \\\"prefix\\\":
  \\\"data/\\\",\\n            \\\"format\\\":
  \\\"parquet\\\"\\n        }\\n    }]\\n)\\n```\\n\",\"isRecommended\":false,\
  \"githubStars\":4269,\"downloadCount\":30,\"createdAt\":\"2025-06-21T01:36:32\
  .944387Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\
  \"2025-06-30T03:46:16.274629Z\"},{\"mcpId\":\"github.com/e2b-dev/mcp-server\",\
  \"githubUrl\":\"https://github.com/e2b-dev/mcp-server\",\"name\":\"Code
  Interpreter\",\"author\":\"e2b-dev\",\"description\":\"Adds secure code
  execution capabilities to Claude Desktop using E2B Sandbox, supporting both
  JavaScript and Python
  environments.\",\"codiconIcon\":\"terminal\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/e2b.jpeg\",\"category\":\"developer-tools\",\
  \"tags\":[\"code-execution\",\"sandbox\",\"javascript\",\"python\",\"claude-i\
  ntegration\"],\"requiresApiKey\":false,\"readmeContent\":\"![E2B MCP Server
  Preview Light](/readme-assets/mcp-server-light.png#gh-light-mode-only)\\n![E2B
  MCP Server Preview
  Dark](/readme-assets/mcp-server-dark.png#gh-dark-mode-only)\\n\\n# E2B MCP
  Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/e2b)](https://smithery.ai/server/e2b)\\n\\nT\
  his repository contains the source code for the [E2B](https://e2b.dev) MCP
  server.\\n\\nThe E2B MCP server allows you to add [code interpreting
  capabilities](https://github.com/e2b-dev/code-interpreter) to your Claude
  Desktop app via the E2B Sandbox. See demo
  [here](https://x.com/mishushakov/status/1863286108433317958).\\n\\n\\nAvailab\
  le in two editions:\\n\\n- [JavaScript](packages/js/README.md)\\n\\n-
  [Python](packages/python/README.md)\\n\\n\\n### Installing via
  Smithery\\n\\nYou can also install E2B for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/e2b):\\n\\n```bash\\nnpx @smithery/cli
  install e2b --client
  claude\\n```\\n\",\"isRecommended\":true,\"githubStars\":281,\"downloadCount\
  \":1210,\"createdAt\":\"2025-02-18T05:45:58.533295Z\",\"updatedAt\":\"2025-07\
  -08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T02:03:04.449654Z\"},{\
  \"mcpId\":\"github.com/cline/linear-mcp\",\"githubUrl\":\"https://github.com/\
  cline/linear-mcp\",\"name\":\"Linear\",\"author\":\"cline\",\"description\":\
  \"Facilitates project management with the Linear API, enabling issue tracking,
  project organization, and team management through comprehensive tools for
  creating, updating, and managing work
  items.\",\"codiconIcon\":\"project\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/linear.jpg\",\"category\":\"developer-tools\",\"tags\
  \":[\"project-management\",\"issue-tracking\",\"team-collaboration\",\"linear\
  -api\",\"workflow\"],\"requiresApiKey\":false,\"readmeContent\":\"# Linear MCP
  Server\\n\\nAn MCP server for interacting with Linear's API. This server
  provides a set of tools for managing Linear issues, projects, and teams
  through Cline.\\n\\n## Setup Guide\\n\\n### 1. Environment Setup\\n\\n1. Clone
  the repository\\n2. Install dependencies:\\n   ```bash\\n   npm
  install\\n   ```\\n3. Copy `.env.example` to `.env`:\\n   ```bash\\n   cp
  .env.example .env\\n   ```\\n\\n### 2. Authentication\\n\\nThe server supports
  two authentication methods:\\n\\n#### API Key (Recommended)\\n\\n1. Go to
  Linear Settings\\n2. Navigate to the \\\"Security & access\\\" section\\n3.
  Find the \\\"Personal API keys\\\" section\\n4. Click \\\"New API key\\\"\\n5.
  Give the key a descriptive label (e.g. \\\"Cline MCP\\\")\\n6. Copy the
  generated token immediately\\n7. Add the token to your `.env`
  file:\\n   ```\\n   LINEAR_API_KEY=your_api_key\\n   ```\\n\\n#### OAuth Flow
  (Alternative) ***NOT IMPLEMENTED***\\n\\n1. Create an OAuth application at
  https://linear.app/settings/api/applications\\n2. Configure OAuth environment
  variables in
  `.env`:\\n   ```\\n   LINEAR_CLIENT_ID=your_oauth_client_id\\n   LINEAR_CLIEN\
  T_SECRET=your_oauth_client_secret\\n   LINEAR_REDIRECT_URI=http://localhost:3\
  000/callback\\n   ```\\n\\n### 3. Running the Server\\n\\n1. Build the
  server:\\n   ```bash\\n   npm run build\\n   ```\\n2. Start the
  server:\\n   ```bash\\n   npm start\\n   ```\\n\\n### 4. Cline
  Integration\\n\\n1. Open your Cline MCP settings file:\\n   - macOS:
  `~/Library/Application
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json`\\n   - Windows:
  `%APPDATA%/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_\
  settings.json`\\n   - Linux:
  `~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_\
  settings.json`\\n\\n2. Add the Linear MCP server
  configuration:\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"linear\\\": {\\n         \\\"command\\\":
  \\\"node\\\",\\n         \\\"args\\\":
  [\\\"/path/to/linear-mcp/build/index.js\\\"],\\n         \\\"env\\\":
  {\\n           \\\"LINEAR_API_KEY\\\":
  \\\"your_personal_access_token\\\"\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n## Available Actions\\n\\nThe
  server currently supports the following operations:\\n\\n### Issue
  Management\\n-  Create issues with full field support (title, description,
  team, project, etc.)\\n-  Update existing issues (priority, description,
  etc.)\\n-  Delete issues (single or bulk deletion)\\n-  Search issues with
  filtering\\n-  Associate issues with projects\\n-  Create parent/child issue
  relationships\\n\\n### Project Management\\n-  Create projects with
  associated issues\\n-  Get project information\\n-  Associate issues with
  projects\\n\\n### Team Management\\n-  Get team information (with states and
  workflow details)\\n-  Access team states and labels\\n\\n###
  Authentication\\n-  API Key authentication\\n-  Secure token
  storage\\n\\n### Batch Operations\\n-  Bulk issue creation\\n-  Bulk issue
  deletion\\n\\n### Bulk Updates (In Testing)\\n-  Bulk issue updates
  (parallel processing implemented, needs testing)\\n\\n## Features in
  Development\\n\\nThe following features are currently being worked
  on:\\n\\n### Issue Management\\n-  Comment functionality (add/edit comments,
  threading)\\n-  Complex search filters\\n-  Pagination support for large
  result sets\\n\\n### Metadata Operations\\n-  Label management
  (create/update/assign)\\n-  Cycle/milestone management\\n\\n### Project
  Management\\n-  Project template support\\n-  Advanced project
  operations\\n\\n### Authentication\\n-  OAuth flow with automatic token
  refresh\\n\\n### Performance & Security\\n-  Rate limiting\\n-  Detailed
  logging\\n-  Load testing and optimization\\n\\n##
  Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n# Run
  tests\\nnpm test\\n\\n# Run integration tests (requires LINEAR_API_KEY)\\nnpm
  run test:integration\\n\\n# Build the server\\nnpm run build\\n\\n# Start the
  server\\nnpm start\\n```\\n\\n## Integration Testing\\n\\nIntegration tests
  verify that authentication and API calls work correctly:\\n\\n1. Set up
  authentication (API Key recommended for testing)\\n2. Run integration
  tests:\\n   ```bash\\n   npm run test:integration\\n   ```\\n\\nFor OAuth
  testing:\\n1. Configure OAuth credentials in `.env`\\n2. Remove `.skip` from
  OAuth tests in `src/__tests__/auth.integration.test.ts`\\n3. Run integration
  tests\",\"isRecommended\":true,\"githubStars\":80,\"downloadCount\":1124,\"cr\
  eatedAt\":\"2025-02-18T06:10:46.800194Z\",\"updatedAt\":\"2025-07-08T01:10:48\
  .398933Z\",\"lastGithubSync\":\"2025-07-02T14:50:01.973002Z\"},{\"mcpId\":\"g\
  ithub.com/apify/actors-mcp-server\",\"githubUrl\":\"https://github.com/apify/\
  actors-mcp-server\",\"name\":\"Apify
  Actors\",\"author\":\"apify\",\"description\":\"Enables AI assistants to
  interact with Apify's web scraping and automation actors, providing access to
  tools for data extraction, web searching, social media analysis, and
  more.\",\"codiconIcon\":\"server-process\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/apify.jpg\",\"category\":\"search\",\"tags\":[\
  \"web-scraping\",\"data-extraction\",\"automation\",\"actor-management\",\"ap\
  ify-platform\"],\"requiresApiKey\":false,\"readmeContent\":\"# Apify Model
  Context Protocol (MCP) Server\\n\\n[![Actors MCP
  Server](https://apify.com/actor-badge?actor=apify/actors-mcp-server)](https:/\
  /apify.com/apify/actors-mcp-server)\\n\\nImplementation of an MCP server for
  all [Apify Actors](https://apify.com/store).\\nThis server enables interaction
  with one or more Apify Actors that can be defined in the MCP Server
  configuration.\\n\\nThe server can be used in two ways:\\n- ** [MCP Server
  Actor](https://apify.com/apify/actors-mcp-server)**  HTTP server accessible
  via Server-Sent Events (SSE), see [guide](#-mcp-server-actor)\\n- ** MCP
  Server Stdio**  Local server available via standard input/output (stdio), see
  [guide](#-mcp-server-at-a-local-host)\\n\\nYou can also interact with the MCP
  server using a chat-like UI with  [Tester MCP
  Client](https://apify.com/jiri.spilka/tester-mcp-client)\\n\\n#  What does
  Apify MCP server do?\\n\\nThe MCP Server Actor allows an AI assistant to use
  any [Apify Actor](https://apify.com/store) as a tool to perform a specific
  task.\\nFor example, it can:\\n- Use [Facebook Posts
  Scraper](https://apify.com/apify/facebook-posts-scraper) to extract data from
  Facebook posts from multiple pages/profiles\\n- Use [Google Maps Email
  Extractor](https://apify.com/lukaskrivka/google-maps-with-contact-details) to
  extract Google Maps contact details\\n- Use [Google Search Results
  Scraper](https://apify.com/apify/google-search-scraper) to scrape Google
  Search Engine Results Pages (SERPs)\\n- Use [Instagram
  Scraper](https://apify.com/apify/instagram-scraper) to scrape Instagram posts,
  profiles, places, photos, and comments\\n- Use [RAG Web
  Browser](https://apify.com/apify/web-scraper) to search the web, scrape the
  top N URLs, and return their content\\n\\n# MCP Clients\\n\\nTo interact with
  the Apify MCP server, you can use MCP clients such as:\\n- [Claude
  Desktop](https://claude.ai/download) (only Stdio support)\\n- [Visual Studio
  Code](https://code.visualstudio.com/) (Stdio and SSE support)\\n-
  [LibreChat](https://www.librechat.ai/) (Stdio and SSE support, yet without
  Authorization header)\\n- [Apify Tester MCP
  Client](https://apify.com/jiri.spilka/tester-mcp-client) (SSE support with
  Authorization headers)\\n- Other clients at
  [https://modelcontextprotocol.io/clients](https://modelcontextprotocol.io/cli\
  ents)\\n- More clients at
  [https://glama.ai/mcp/clients](https://glama.ai/mcp/clients)\\n\\nWhen you
  have Actors integrated with the MCP server, you can ask:\\n- \\\"Search the
  web and summarize recent trends about AI Agents\\\"\\n- \\\"Find the top 10
  best Italian restaurants in San Francisco\\\"\\n- \\\"Find and analyze the
  Instagram profile of The Rock\\\"\\n- \\\"Provide a step-by-step guide on
  using the Model Context Protocol with source URLs\\\"\\n- \\\"What Apify
  Actors can I use?\\\"\\n\\nThe following image shows how the Apify MCP server
  interacts with the Apify platform and AI
  clients:\\n\\n![Actors-MCP-server](https://raw.githubusercontent.com/apify/ac\
  tors-mcp-server/refs/heads/master/docs/actors-mcp-server.png)\\n\\nWith the
  MCP Tester client you can load Actors dynamically but this is not yet
  supported by other MCP clients.\\nWe also plan to add more features, see
  [Roadmap](#-roadmap-march-2025) for more details.\\n\\n#  What is the Model
  Context Protocol?\\n\\nThe Model Context Protocol (MCP) allows AI applications
  (and AI agents), such as Claude Desktop, to connect to external tools and data
  sources.\\nMCP is an open protocol that enables secure, controlled
  interactions between AI applications, AI Agents, and local or remote
  resources.\\n\\nFor more information, see the [Model Context
  Protocol](https://modelcontextprotocol.org/) website or the blog post [What is
  MCP and why does it
  matter?](https://blog.apify.com/what-is-model-context-protocol/).\\n\\n\\n# 
  How is MCP Server related to AI Agents?\\n\\nThe Apify MCP Server exposes
  Apify's Actors through the MCP protocol, allowing AI Agents or frameworks that
  implement the MCP protocol to access all Apify Actors as tools for data
  extraction, web searching, and other tasks.\\n\\nTo learn more about AI
  Agents, explore our blog post: [What are AI
  Agents?](https://blog.apify.com/what-are-ai-agents/) and browse Apify's
  curated [AI Agent
  collection](https://apify.com/store/collections/ai_agents).\\nInterested in
  building and monetizing your own AI agent on Apify? Check out our
  [step-by-step guide](https://blog.apify.com/how-to-build-an-ai-agent/) for
  creating, publishing, and monetizing AI agents on the Apify platform.\\n\\n#
   Components\\n\\n## Tools\\n\\n### Actors\\n\\nAny [Apify
  Actor](https://apify.com/store) can be used as a tool.\\nBy default, the
  server is pre-configured with the Actors specified below, but this can be
  overridden by providing Actor
  input.\\n\\n```text\\n'apify/rag-web-browser'\\n```\\nThe MCP server loads the
  Actor input schema and creates MCP tools corresponding to the Actors.\\nSee
  this example of input schema for the [RAG Web
  Browser](https://apify.com/apify/rag-web-browser/input-schema).\\n\\nThe tool
  name must always be the full Actor name, such as
  `apify/rag-web-browser`.\\nThe arguments for an MCP tool represent the input
  parameters of the Actor.\\nFor example, for the `apify/rag-web-browser` Actor,
  the arguments are:\\n\\n```json\\n{\\n  \\\"query\\\": \\\"restaurants in San
  Francisco\\\",\\n  \\\"maxResults\\\": 3\\n}\\n```\\nYou don't need to specify
  the input parameters or which Actor to call; everything is managed by an
  LLM.\\nWhen a tool is called, the arguments are automatically passed to the
  Actor by the LLM.\\nYou can refer to the specific Actor's documentation for a
  list of available arguments.\\n\\n### Helper tools\\nOne of the powerful
  features of MCP with Apify is dynamic actor tooling  the ability for an AI
  agent to find new tools (Actors) as needed and incorporate them. Here are some
  special MCP operations and how Apify MCP Server supports them:\\n\\n- Actor
  discovery and management: Search for Actors (`search-actors`), view details
  (`get-actor-details`), and dynamically add or remove tools (`add-actor`,
  `remove-actor`).\\n- Actor execution and monitoring: Start Actor runs, fetch
  run results (`get-actor-run`), logs (`get-actor-log`), and abort runs
  (`abort-actor-run`).\\n- Dataset access: List datasets, retrieve dataset info
  and items (`get-dataset`, `get-dataset-list`, `get-dataset-items`).\\n-
  Key-value store access: List key-value stores, view keys, and retrieve records
  (`get-key-value-store-list`, `get-key-value-store`,
  `get-key-value-store-keys`, `get-key-value-store-record`).\\n- Built-in help
  tool: A static helper (`apify-actor-help-tool`) that returns usage info for
  the Apify MCP Server.\\n\\n## Prompt & Resources\\n\\nThe server does not
  provide any resources and prompts.\\nWe plan to add [Apify's
  dataset](https://docs.apify.com/platform/storage/dataset) and [key-value
  store](https://docs.apify.com/platform/storage/key-value-store) as resources
  in the future.\\n\\n#  Usage\\n\\nThe Apify MCP Server can be used in two
  ways: **as an Apify Actor** running on the Apify platform\\nor as a **local
  server** running on your machine.\\n\\n##  MCP Server Actor\\n\\n### Standby
  web server\\n\\nThe Actor runs in [**Standby
  mode**](https://docs.apify.com/platform/actors/running/standby) with an HTTP
  web server that receives and processes requests.\\n\\nTo start the server with
  default Actors, send an HTTP GET request with your [Apify API
  token](https://console.apify.com/settings/integrations) to the following
  URL:\\n```\\nhttps://actors-mcp-server.apify.actor?token=<APIFY_TOKEN>\\n```\
  \\nIt is also possible to start the MCP server with a different set of
  Actors.\\nTo do this, create a
  [task](https://docs.apify.com/platform/actors/running/tasks) and specify the
  list of Actors you want to use.\\n\\nThen, run the task in Standby mode with
  the selected
  Actors:\\n```shell\\nhttps://USERNAME--actors-mcp-server-task.apify.actor?tok\
  en=<APIFY_TOKEN>\\n```\\n\\nYou can find a list of all available Actors in the
  [Apify Store](https://apify.com/store).\\n\\n####  Interact with the MCP
  Server over SSE\\n\\nOnce the server is running, you can interact with
  Server-Sent Events (SSE) to send messages to the server and receive
  responses.\\nThe easiest way is to use [Tester MCP
  Client](https://apify.com/jiri.spilka/tester-mcp-client) on
  Apify.\\n\\n[Claude Desktop](https://claude.ai/download) currently lacks SSE
  support, but you can use it with Stdio transport; see [MCP Server at a local
  host](#-mcp-server-at-a-local-host) for more details.\\nNote: The free version
  of Claude Desktop may experience intermittent connection issues with the
  server.\\n\\nIn the client settings, you need to provide server
  configuration:\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"apify\\\": {\\n            \\\"type\\\":
  \\\"sse\\\",\\n            \\\"url\\\":
  \\\"https://actors-mcp-server.apify.actor/sse\\\",\\n            \\\"env\\\":
  {\\n                \\\"APIFY_TOKEN\\\":
  \\\"your-apify-token\\\"\\n            }\\n        }\\n    }\\n}\\n```\\n\\n##
   MCP Server at a local host\\n\\nYou can run the Apify MCP Server on your
  local machine by configuring it with Claude Desktop or any other [MCP
  client](https://modelcontextprotocol.io/clients).\\nYou can also use
  [Smithery](https://smithery.ai/server/@apify/actors-mcp-server) to install the
  server automatically.\\n\\n### Prerequisites\\n\\n- MacOS or Windows\\n- The
  latest version of Claude Desktop must be installed (or another MCP client)\\n-
  [Node.js](https://nodejs.org/en) (v18 or higher)\\n- [Apify API
  Token](https://docs.apify.com/platform/integrations/api#api-token)
  (`APIFY_TOKEN`)\\n\\nMake sure you have the `node` and `npx` installed
  properly:\\n```bash\\nnode -v\\nnpx -v\\n```\\nIf not, follow this guide to
  install Node.js: [Downloading and installing Node.js and
  npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\\n\\\
  n#### Claude Desktop\\n\\nTo configure Claude Desktop to work with the MCP
  server, follow these steps. For a detailed guide, refer to the [Claude Desktop
  Users Guide](https://modelcontextprotocol.io/quickstart/user) or watch the
  [video tutorial](https://youtu.be/gf5WXeqydUU?t=440).\\n\\n1. Download Claude
  for desktop\\n   - Available for Windows and macOS.\\n   - For Linux users,
  you can build a Debian package using this [unofficial build
  script](https://github.com/aaddrick/claude-desktop-debian).\\n2. Open the
  Claude Desktop app and enable **Developer Mode** from the top-left menu
  bar.\\n3. Once enabled, open **Settings** (also from the top-left menu bar)
  and navigate to the **Developer Option**, where you'll find the **Edit
  Config** button.\\n4. Open the configuration file and edit the following
  file:\\n\\n    - On macOS: `~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json`\\n    - On Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n    - On Linux:
  `~/.config/Claude/claude_desktop_config.json`\\n\\n    ```json\\n    {\\n     \
  \\\"mcpServers\\\": {\\n       \\\"actors-mcp-server\\\":
  {\\n         \\\"command\\\": \\\"npx\\\",\\n         \\\"args\\\":
  [\\\"-y\\\", \\\"@apify/actors-mcp-server\\\"],\\n         \\\"env\\\":
  {\\n            \\\"APIFY_TOKEN\\\":
  \\\"your-apify-token\\\"\\n         }\\n       }\\n     }\\n    }\\n    ```\\\
  n    Alternatively, you can use the `actors` argument to select one or more
  Apify Actors:\\n    ```json\\n   {\\n    \\\"mcpServers\\\":
  {\\n      \\\"actors-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\n          \\\"-y\\\",
  \\\"@apify/actors-mcp-server\\\",\\n          \\\"--actors\\\",
  \\\"lukaskrivka/google-maps-with-contact-details,apify/instagram-scraper\\\"\
  \\n        ],\\n        \\\"env\\\": {\\n           \\\"APIFY_TOKEN\\\":
  \\\"your-apify-token\\\"\\n        }\\n      }\\n    }\\n   }\\n    ```\\n5.
  Restart Claude Desktop\\n\\n    - Fully quit Claude Desktop (ensure it's not
  just minimized or closed).\\n    - Restart Claude Desktop.\\n    - Look for
  the  icon to confirm that the Actors MCP server is connected.\\n\\n6. Open
  the Claude Desktop chat and ask \\\"What Apify Actors can I
  use?\\\"\\n\\n   ![Claude-desktop-with-Actors-MCP-server](https://raw.githubu\
  sercontent.com/apify/actors-mcp-server/refs/heads/master/docs/claude-desktop.\
  png)\\n\\n7. Examples\\n\\n   You can ask Claude to perform tasks, such
  as:\\n    ```text\\n    Find and analyze recent research papers about
  LLMs.\\n    Find the top 10 best Italian restaurants in San
  Francisco.\\n    Find and analyze the Instagram profile of The
  Rock.\\n    ```\\n\\nTo understand how to set up and run the MCP server on
  Claude, you can watch this short video tutorial  on YouTube:\\n\\n[Apify MCP
  Server Tutorial: Integrate 5,000+ Apify Actors and Agents Into
  Claude](https://www.youtube.com/watch?v=UOkJm9pTgMw)\\n\\n#### VS
  Code\\n\\nFor one-click installation, click one of the install buttons
  below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=actors-mcp-server&config=%7B%22command%22%3A%22npx%22%2C%22args%2\
  2%3A%5B%22-y%22%2C%22%40apify%2Factors-mcp-server%22%5D%2C%22env%22%3A%7B%22A\
  PIFY_TOKEN%22%3A%22%24%7Binput%3Aapify_token%7D%22%7D%7D&inputs=%5B%7B%22type\
  %22%3A%22promptString%22%2C%22id%22%3A%22apify_token%22%2C%22description%22%3\
  A%22Apify+API+Token%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in
  VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=actors-mcp-server&config=%7B%22command%22%3A%22npx%2\
  2%2C%22args%22%3A%5B%22-y%22%2C%22%40apify%2Factors-mcp-server%22%5D%2C%22env\
  %22%3A%7B%22APIFY_TOKEN%22%3A%22%24%7Binput%3Aapify_token%7D%22%7D%7D&inputs=\
  %5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apify_token%22%2C%22des\
  cription%22%3A%22Apify+API+Token%22%2C%22password%22%3Atrue%7D%5D&quality=ins\
  iders)\\n\\n##### Manual installation\\n\\nYou can manually install the Apify
  MCP Server in VS Code. First, click one of the install buttons at the top of
  this section for a one-click installation.\\n\\nAlternatively, add the
  following JSON block to your User Settings (JSON) file in VS Code. You can do
  this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User
  Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"apify_token\\\",\\n        \\\"description\\\": \\\"Apify API
  Token\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\":
  {\\n      \\\"actors-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"@apify/actors-mcp-server\\\"],\\n        \\\"env\\\":
  {\\n          \\\"APIFY_TOKEN\\\":
  \\\"${input:apify_token}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\
  \\nOptionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace - just omit the top-level `mcp {}` key. This will allow you to share
  the configuration with others.\\n\\nIf you want to specify which Actors to
  load, you can add the `--actors`
  argument:\\n\\n```json\\n{\\n  \\\"servers\\\":
  {\\n    \\\"actors-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\n        \\\"-y\\\",
  \\\"@apify/actors-mcp-server\\\",\\n        \\\"--actors\\\",
  \\\"lukaskrivka/google-maps-with-contact-details,apify/instagram-scraper\\\"\
  \\n      ],\\n      \\\"env\\\": {\\n        \\\"APIFY_TOKEN\\\":
  \\\"${input:apify_token}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n#### VS
  Code\\n\\nFor one-click installation, click one of the install buttons
  below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=actors-mcp-server&config=%7B%22command%22%3A%22npx%22%2C%22args%2\
  2%3A%5B%22-y%22%2C%22%40apify%2Factors-mcp-server%22%5D%2C%22env%22%3A%7B%22A\
  PIFY_TOKEN%22%3A%22%24%7Binput%3Aapify_token%7D%22%7D%7D&inputs=%5B%7B%22type\
  %22%3A%22promptString%22%2C%22id%22%3A%22apify_token%22%2C%22description%22%3\
  A%22Apify+API+Token%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in
  VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=actors-mcp-server&config=%7B%22command%22%3A%22npx%2\
  2%2C%22args%22%3A%5B%22-y%22%2C%22%40apify%2Factors-mcp-server%22%5D%2C%22env\
  %22%3A%7B%22APIFY_TOKEN%22%3A%22%24%7Binput%3Aapify_token%7D%22%7D%7D&inputs=\
  %5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apify_token%22%2C%22des\
  cription%22%3A%22Apify+API+Token%22%2C%22password%22%3Atrue%7D%5D&quality=ins\
  iders)\\n\\n##### Manual installation\\n\\nYou can manually install the Apify
  MCP Server in VS Code. First, click one of the install buttons at the top of
  this section for a one-click installation.\\n\\nAlternatively, add the
  following JSON block to your User Settings (JSON) file in VS Code. You can do
  this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User
  Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"apify_token\\\",\\n        \\\"description\\\": \\\"Apify API
  Token\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\":
  {\\n      \\\"actors-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"@apify/actors-mcp-server\\\"],\\n        \\\"env\\\":
  {\\n          \\\"APIFY_TOKEN\\\":
  \\\"${input:apify_token}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\
  \\nOptionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace - just omit the top-level `mcp {}` key. This will allow you to share
  the configuration with others.\\n\\nIf you want to specify which Actors to
  load, you can add the `--actors`
  argument:\\n\\n```json\\n{\\n  \\\"servers\\\":
  {\\n    \\\"actors-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\n        \\\"-y\\\",
  \\\"@apify/actors-mcp-server\\\",\\n        \\\"--actors\\\",
  \\\"lukaskrivka/google-maps-with-contact-details,apify/instagram-scraper\\\"\
  \\n      ],\\n      \\\"env\\\": {\\n        \\\"APIFY_TOKEN\\\":
  \\\"${input:apify_token}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n####
  Debugging NPM package @apify/actors-mcp-server with
  @modelcontextprotocol/inspector\\n\\nTo debug the server, use the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector)
  tool:\\n\\n```shell\\nexport APIFY_TOKEN=your-apify-token\\nnpx
  @modelcontextprotocol/inspector npx -y @apify/actors-mcp-server\\n```\\n\\n#
   Development\\n\\n## Prerequisites\\n\\n- [Node.js](https://nodejs.org/en)
  (v18 or higher)\\n- Python 3.9 or higher\\n\\nCreate an environment file
  `.env` with the following
  content:\\n```text\\nAPIFY_TOKEN=your-apify-token\\n```\\n\\nBuild the
  actor-mcp-server package:\\n\\n```bash\\nnpm run build\\n```\\n\\n## Local
  client (SSE)\\n\\nTo test the server with the SSE transport, you can use the
  script `examples/clientSse.ts`:\\nCurrently, the Node.js client does not
  support establishing a connection to a remote server with custom
  headers.\\nYou need to change the URL to your local server URL in the
  script.\\n\\n```bash\\nnode dist/examples/clientSse.js\\n```\\n\\n##
  Debugging\\n\\nSince MCP servers operate over standard input/output (stdio),
  debugging can be challenging.\\nFor the best debugging experience, use the
  [MCP Inspector](https://github.com/modelcontextprotocol/inspector).\\n\\nYou
  can launch the MCP Inspector via
  [`npm`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)
  with this command:\\n\\n```bash\\nexport APIFY_TOKEN=your-apify-token\\nnpx
  @modelcontextprotocol/inspector node ./dist/stdio.js\\n```\\n\\nUpon
  launching, the Inspector will display a URL that you can access in your
  browser to begin debugging.\\n\\n##  Limitations and feedback\\n\\nThe Actor
  input schema is processed to be compatible with most MCP clients while
  adhering to [JSON Schema](https://json-schema.org/) standards. The processing
  includes:\\n- **Descriptions** are truncated to 500 characters (as defined in
  `MAX_DESCRIPTION_LENGTH`).\\n- **Enum fields** are truncated to a maximum
  combined length of 200 characters for all elements (as defined in
  `ACTOR_ENUM_MAX_LENGTH`).\\n- **Required fields** are explicitly marked with a
  \\\"REQUIRED\\\" prefix in their descriptions for compatibility with
  frameworks that may not handle JSON schema properly.\\n- **Nested properties**
  are built for special cases like proxy configuration and request list sources
  to ensure correct input structure.\\n- **Array item types** are inferred when
  not explicitly defined in the schema, using a priority order: explicit type in
  items > prefill type > default value type > editor type.\\n- **Enum values and
  examples** are added to property descriptions to ensure visibility even if the
  client doesn't fully support JSON schema.\\n\\nMemory for each Actor is
  limited to 4GB.\\nFree users have an 8GB limit, 128MB needs to be allocated
  for running `Actors-MCP-Server`.\\n\\nIf you need other features or have any
  feedback, [submit an
  issue](https://console.apify.com/actors/1lSvMAaRcadrM1Vgv/issues) in Apify
  Console to let us know.\\n\\n#  Roadmap (March 2025)\\n\\n- Add Apify's
  dataset and key-value store as resources.\\n- Add tools such as Actor logs and
  Actor runs for debugging.\\n\\n#  Troubleshooting\\n\\n- Make sure you have
  the `node` installed by running `node -v`\\n- Make sure you have the
  `APIFY_TOKEN` environment variable set\\n- Always use the latest version of
  the MCP server by setting `@apify/actors-mcp-server@latest`\\n\\n#  Learn
  more\\n\\n- [Model Context Protocol](https://modelcontextprotocol.org/)\\n-
  [What are AI Agents?](https://blog.apify.com/what-are-ai-agents/)\\n- [What is
  MCP and why does it
  matter?](https://blog.apify.com/what-is-model-context-protocol/)\\n- [How to
  use MCP with Apify Actors](https://blog.apify.com/how-to-use-mcp/)\\n- [Tester
  MCP Client](https://apify.com/jiri.spilka/tester-mcp-client)\\n- [AI agent
  workflow: building an agent to query Apify
  datasets](https://blog.apify.com/ai-agent-workflow/)\\n- [MCP Client
  development
  guide](https://github.com/cyanheads/model-context-protocol-resources/blob/mai\
  n/guides/mcp-client-development-guide.md)\\n- [How to build and monetize an AI
  agent on
  Apify](https://blog.apify.com/how-to-build-an-ai-agent/)\\n\",\"isRecommended\
  \":true,\"githubStars\":242,\"downloadCount\":537,\"createdAt\":\"2025-02-18T\
  05:45:40.818024Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithub\
  Sync\":\"2025-06-30T09:05:37.809176Z\"},{\"mcpId\":\"github.com/axiomhq/mcp-s\
  erver-axiom\",\"githubUrl\":\"https://github.com/axiomhq/mcp-server-axiom\",\
  \"name\":\"Axiom\",\"author\":\"axiomhq\",\"description\":\"Query and analyze
  data using Axiom Processing Language (APL), enabling AI agents to interact
  with Axiom datasets through natural
  language.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/axiom-query.png\",\"category\":\"databases\",\"t\
  ags\":[\"data-query\",\"log-analysis\",\"apl\",\"datasets\",\"analytics\"],\"\
  requiresApiKey\":false,\"readmeContent\":\"# mcp-server-axiom\\n\\nA [Model
  Context Protocol](https://modelcontextprotocol.io/) server implementation for
  [Axiom](https://axiom.co) that enables AI agents to query your data using
  Axiom Processing Language (APL).\\n\\n## Status\\n\\nWorks with Claude desktop
  app. Implements two MCP
  [tools](https://modelcontextprotocol.io/docs/concepts/tools):\\n\\n- queryApl:
  Execute APL queries against Axiom datasets\\n- listDatasets: List available
  Axiom datasets\\n\\nNo support for MCP
  [resources](https://modelcontextprotocol.io/docs/concepts/resources) or
  [prompts](https://modelcontextprotocol.io/docs/concepts/prompts) yet.\\n\\n##
  Installation\\n\\n### Releases\\n\\nDownload the latest built binary from the
  [releases page](https://github.com/axiomhq/axiom-mcp/releases).\\n\\n###
  Source\\n\\n```bash\\ngo install
  github.com/axiomhq/axiom-mcp@latest\\n```\\n\\n## Configuration\\n\\nConfigure
  using one of these methods:\\n\\n### Config File Example
  (config.txt):\\n```txt\\ntoken xaat-your-token\\nurl
  https://api.axiom.co\\nquery-rate 1\\nquery-burst 1\\ndatasets-rate
  1\\ndatasets-burst 1\\n```\\n\\n### Command Line Flags:\\n```bash\\naxiom-mcp
  \\\\\\n  -token xaat-your-token \\\\\\n  -url https://api.axiom.co
  \\\\\\n  -query-rate 1 \\\\\\n  -query-burst 1 \\\\\\n  -datasets-rate 1
  \\\\\\n  -datasets-burst 1\\n```\\n\\n### Environment
  Variables:\\n```bash\\nexport AXIOM_TOKEN=xaat-your-token\\nexport
  AXIOM_URL=https://api.axiom.co\\nexport AXIOM_ORG_ID=your-org-id\\nexport
  AXIOM_QUERY_RATE=1\\nexport AXIOM_QUERY_BURST=1\\nexport
  AXIOM_DATASETS_RATE=1\\nexport AXIOM_DATASETS_BURST=1\\n```\\n\\n##
  Usage\\n\\n1. Create a config file:\\n```bash\\necho \\\"token
  xaat-your-token\\\" > config.txt\\n```\\n\\n2. Configure the Claude app to use
  the MCP server:\\n\\n```bash\\ncode ~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json\\n```\\n\\n```json\\n{\\n  \\\"mcpS\
  ervers\\\": {\\n    \\\"axiom\\\": {\\n      \\\"command\\\":
  \\\"/path/to/your/axiom-mcp-binary\\\",\\n      \\\"args\\\" :
  [\\\"--config\\\", \\\"/path/to/your/config.txt\\\"],\\n      \\\"env\\\": {
  // Alternatively, you can set the environment variables
  here\\n        \\\"AXIOM_TOKEN\\\":
  \\\"xaat-your-token\\\",\\n        \\\"AXIOM_URL\\\":
  \\\"https://api.axiom.co\\\",\\n        \\\"AXIOM_ORG_ID\\\":
  \\\"your-org-id\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## License\\n\\nMIT
  License - see LICENSE
  file\\n\",\"isRecommended\":true,\"githubStars\":49,\"downloadCount\":83,\"cr\
  eatedAt\":\"2025-02-18T05:45:45.629989Z\",\"updatedAt\":\"2025-07-08T01:10:48\
  .398933Z\",\"lastGithubSync\":\"2025-06-30T11:20:55.71495Z\"},{\"mcpId\":\"gi\
  thub.com/modelcontextprotocol/servers/tree/main/src/sentry\",\"githubUrl\":\"\
  https://github.com/modelcontextprotocol/servers/tree/main/src/sentry\",\"name\
  \":\"Sentry\",\"author\":\"modelcontextprotocol\",\"description\":\"Retrieves
  and analyzes error reports, stacktraces, and debugging information from
  Sentry.io, enabling AI assistants to inspect and understand application
  issues.\",\"codiconIcon\":\"bug\",\"logoUrl\":\"https://storage.googleapis.co\
  m/cline_public_images/sentry.png\",\"category\":\"monitoring\",\"tags\":[\"er\
  ror-tracking\",\"debugging\",\"stacktraces\",\"issue-monitoring\",\"applicati\
  on-monitoring\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\
  \":57529,\"downloadCount\":9565,\"createdAt\":\"2025-02-19T02:22:38.723905Z\",\
  \"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03\
  T20:28:39.154078Z\"},{\"mcpId\":\"github.com/modelcontextprotocol/servers/tre\
  e/main/src/brave-search\",\"githubUrl\":\"https://github.com/modelcontextprot\
  ocol/servers/tree/main/src/brave-search\",\"name\":\"Brave
  Search\",\"author\":\"modelcontextprotocol\",\"description\":\"Integrates
  Brave Search API to provide comprehensive web and local search capabilities
  with smart filtering, pagination, and automatic
  fallbacks.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/brave-search.png\",\"category\":\"search\",\"tags\
  \":[\"search-engine\",\"local-search\",\"web-search\",\"brave-api\",\"content\
  -discovery\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\"\
  :56925,\"downloadCount\":23222,\"createdAt\":\"2025-02-17T22:22:18.563691Z\",\
  \"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01\
  T02:40:12.2031Z\"},{\"mcpId\":\"github.com/pashpashpash/iterm-mcp\",\"githubU\
  rl\":\"https://github.com/pashpashpash/iterm-mcp\",\"name\":\"iTerm\",\"author\
  \":\"pashpashpash\",\"description\":\"Provides direct access to iTerm terminal
  sessions, enabling command execution, REPL interaction, and terminal output
  inspection with efficient token usage and control character
  support.\",\"codiconIcon\":\"terminal\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/iterm.png\",\"category\":\"os-automation\",\"tags\
  \":[\"terminal\",\"iterm\",\"command-execution\",\"repl\",\"automation\"],\"r\
  equiresApiKey\":false,\"readmeContent\":\"# iterm-mcp \\n\\nA Model Context
  Protocol server that provides access to your iTerm session.\\n\\n![Main
  Image](.github/images/demo.gif)\\n\\n### Features\\n\\n**Efficient Token
  Use:** iterm-mcp gives the model the ability to inspect only the output that
  the model is interested in. The model typically only wants to see the last few
  lines of output even for long running commands. \\n\\n**Natural Integration:**
  You share iTerm with the model. You can ask questions about what's on the
  screen, or delegate a task to the model and watch as it performs each
  step.\\n\\n**Full Terminal Control and REPL support:** The model can start and
  interact with REPL's as well as send control characters like ctrl-c, ctrl-z,
  etc.\\n\\n**Easy on the Dependencies:** iterm-mcp is built with minimal
  dependencies and is designed to be easy to add to Claude Desktop and other MCP
  clients. It should just work.\\n\\n## Safety Considerations\\n\\n* The user is
  responsible for using the tool safely.\\n* No built-in restrictions: iterm-mcp
  makes no attempt to evaluate the safety of commands that are executed.\\n*
  Models can behave in unexpected ways. The user is expected to monitor activity
  and abort when appropriate.\\n* For multi-step tasks, you may need to
  interrupt the model if it goes off track. Start with smaller, focused tasks
  until you're familiar with how the model behaves. \\n\\n### Tools\\n\\n-
  `write_to_terminal` - Writes to the active iTerm terminal, often used to run a
  command. Returns the number of lines of output produced by the command.\\n-
  `read_terminal_output` - Reads the requested number of lines from the active
  iTerm terminal.\\n- `send_control_character` - Sends a control character to
  the active iTerm terminal.\\n\\n### Requirements\\n\\n* iTerm2 must be
  running\\n* Node version 18 or greater\\n\\n## Installation\\n\\n1. **Clone
  the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/iterm-mcp.git\\n   cd
  iterm-mcp\\n   ```\\n\\n2. **Install Dependencies**:\\n   ```bash\\n   yarn
  install\\n   ```\\n\\n3. **Build the Project**:\\n   ```bash\\n   yarn run
  build\\n   ```\\n\\n4. **Configure Claude Desktop**:\\n\\nAdd the server
  config to:\\n- On macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n- On Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"iterm-mcp\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/build/index.js\\\"]\\n    }\\n  }\\n}\\n```\\n\\nNote: Replace
  \\\"path/to/build/index.js\\\" with the actual path to your built index.js
  file.\\n\\n## Development\\n\\nFor development with
  auto-rebuild:\\n```bash\\nyarn run watch\\n```\\n\\n### Debugging\\n\\nSince
  MCP servers communicate over stdio, debugging can be challenging. We recommend
  using the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector):\\n\\n```bash\\\
  ncd path/to/iterm-mcp\\nyarn run inspector\\nyarn debug
  <command>\\n```\\n\\nThe Inspector will provide a URL to access debugging
  tools in your browser.\\n\\nView logs with:\\n```bash\\ntail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n```\\n\\n## License\\n\\nLicensed under MIT -
  see [LICENSE](LICENSE) file.\\n\\n---\\nNote: This is a fork of the [original
  iterm-mcp
  repository](https://github.com/ferrislucas/iterm-mcp).\\n\",\"isRecommended\"\
  :false,\"githubStars\":14,\"downloadCount\":2465,\"createdAt\":\"2025-02-18T2\
  3:04:41.146991Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubS\
  ync\":\"2025-07-03T02:39:05.425232Z\"},{\"mcpId\":\"github.com/MindscapeHQ/mc\
  p-server-raygun\",\"githubUrl\":\"https://github.com/MindscapeHQ/mcp-server-r\
  aygun\",\"name\":\"Raygun\",\"author\":\"MindscapeHQ\",\"description\":\"Prov\
  ides comprehensive access to Raygun's error tracking, crash reporting, and
  real user monitoring features through API integration, enabling management of
  applications, errors, deployments, and performance
  metrics.\",\"codiconIcon\":\"bug\",\"logoUrl\":\"https://storage.googleapis.c\
  om/cline_public_images/raygun.png\",\"category\":\"monitoring\",\"tags\":[\"e\
  rror-tracking\",\"crash-reporting\",\"performance-monitoring\",\"debugging\",\
  \"application-monitoring\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Raygun MCP Server\\n\\nMCP Server for Raygun's API V3 endpoints for
  interacting with your Crash Reporting and Real User Monitoring applications.
  This server provides comprehensive access to Raygun's API features through the
  Model Context Protocol.\\n\\n## Features\\n\\n### Tools\\n\\n####
  Applications\\n- `list_applications` - List all applications under your
  account\\n- `get_application` - Get application details by identifier\\n-
  `get_application_by_api_key` - Get application details by API key\\n-
  `regenerate_application_api_key` - Generate a new API key for an
  application\\n\\n#### Error Management\\n- `list_error_groups` - List error
  groups for an application\\n- `get_error_group` - Get detailed information
  about an error group\\n- `resolve_error_group` - Set error group status to
  resolved\\n- `activate_error_group` - Set error group status to active\\n-
  `ignore_error_group` - Set error group status to ignored\\n-
  `permanently_ignore_error_group` - Set error group status to permanently
  ignored\\n\\n#### Deployment Management\\n- `list_deployments` - List
  deployments for an application\\n- `get_deployment` - Get deployment details
  by identifier\\n- `delete_deployment` - Remove a deployment\\n-
  `update_deployment` - Update deployment information\\n-
  `reprocess_deployment_commits` - Reprocess deployment commit data\\n\\n####
  User & Session Management\\n- `list_customers` - List customers for an
  application\\n- `list_sessions` - List user sessions for an application\\n-
  `get_session` - Get detailed session information\\n\\n#### Performance
  Monitoring\\n- `list_pages` - List monitored pages for an application\\n-
  `get_page_metrics_time_series` - Get time-series performance metrics\\n-
  `get_page_metrics_histogram` - Get histogram of performance metrics\\n-
  `get_error_metrics_time_series` - Get time-series error metrics\\n\\n####
  Source Maps\\n- `list_source_maps` - List source maps for an application\\n-
  `get_source_map` - Get source map details\\n- `update_source_map` - Update
  source map information\\n- `delete_source_map` - Remove a source map\\n-
  `upload_source_map` - Upload a new source map\\n- `delete_all_source_maps` -
  Remove all source maps\\n\\n#### Team Management\\n- `list_invitations` - List
  pending team invitations\\n- `send_invitation` - Send a new team
  invitation\\n- `get_invitation` - Get invitation details\\n-
  `revoke_invitation` - Revoke a pending invitation\\n\\n##
  Configuration\\n\\nThe server requires the following environment
  variables:\\n\\n- `RAYGUN_PAT_TOKEN` (required): Your [Raygun PAT
  token](https://raygun.com/documentation/product-guides/raygun-api/)\\n-
  `SOURCEMAP_ALLOWED_DIRS` (optional): Comma-separated list of directories
  allowed for source map operations\\n\\n## Usage with Claude Desktop\\n\\nAdd
  to your `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"raygun\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@raygun.io/mcp-server-raygun\\\"],\\n      \\\"env\\\":
  {\\n        \\\"RAYGUN_PAT_TOKEN\\\":
  \\\"your-pat-token-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n##
  Development\\n\\nInstall dependencies:\\n```bash\\nnpm
  install\\n```\\n\\nBuild the server:\\n```bash\\nnpm run build\\n```\\n\\nFor
  development with auto-rebuild:\\n```bash\\nnpm run watch\\n```\\n\\n##
  Installation\\n\\nTo use with Claude Desktop, add the server config:\\n\\nOn
  MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\\nOn
  Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"raygun\\\": {\\n      \\\"command\\\":
  \\\"/path/to/server-raygun/build/index.js\\\",\\n      \\\"env\\\":
  {\\n        \\\"RAYGUN_PAT_TOKEN\\\":
  \\\"your-pat-token-ken\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n###
  Debugging\\n\\nSince MCP servers communicate over stdio, debugging can be
  challenging. We recommend using the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector), which is
  available as a package script:\\n\\n```bash\\nnpm run inspector\\n```\\n\\nThe
  Inspector will provide a URL to access debugging tools in your
  browser.\\n\",\"isRecommended\":true,\"githubStars\":13,\"downloadCount\":51,\
  \"createdAt\":\"2025-02-18T06:28:29.20344Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-06-30T15:49:12.946088Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/cdk-mcp-server\",\"githubUrl\":\"https\
  ://github.com/awslabs/mcp/tree/main/src/cdk-mcp-server\",\"name\":\"AWS CDK
  Assistant\",\"author\":\"awslabs\",\"description\":\"Provides guidance on AWS
  CDK best practices, infrastructure patterns, and security compliance through
  CDK Nag integration and AWS Solutions
  Constructs.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\
  \":[\"aws-cdk\",\"infrastructure-as-code\",\"security-compliance\",\"cloud-ar\
  chitecture\",\"aws\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS CDK
  MCP Server\\n\\nMCP server for AWS Cloud Development Kit (CDK) best practices,
  infrastructure as code patterns, and security compliance with CDK Nag.\\n\\n##
  Features\\n\\n### CDK General Guidance\\n\\n- Prescriptive patterns with AWS
  Solutions Constructs and GenAI CDK libraries\\n- Structured decision flow for
  choosing appropriate implementation approaches\\n- Security automation through
  CDK Nag integration and Lambda Powertools\\n\\n### CDK Nag Integration\\n\\n-
  Work with CDK Nag rules for security and compliance\\n- Explain specific CDK
  Nag rules with AWS Well-Architected guidance\\n- Check if CDK code contains
  Nag suppressions that require human review\\n\\n### AWS Solutions
  Constructs\\n\\n- Search and discover AWS Solutions Constructs patterns\\n-
  Find recommended patterns for common architecture needs\\n- Get detailed
  documentation on Solutions Constructs\\n\\n### Generative AI CDK
  Constructs\\n\\n- Search for GenAI CDK constructs by name or type\\n- Discover
  specialized constructs for AI/ML workloads\\n- Get implementation guidance for
  generative AI applications\\n\\n### Lambda Layer Documentation Provider\\n\\n-
  Access comprehensive documentation for AWS Lambda layers\\n- Get code examples
  for generic Lambda layers and Python-specific layers\\n- Retrieve directory
  structure information and implementation best practices\\n- Seamless
  integration with AWS Documentation MCP Server for detailed
  documentation\\n\\n### Amazon Bedrock Agent Schema Generation\\n\\n- Use this
  tool when creating Bedrock Agents with Action Groups that use Lambda
  functions\\n- Streamline the creation of Bedrock Agent schemas\\n- Convert
  code files to compatible OpenAPI specifications\\n\\n#### Developer
  Notes\\n\\n- **Requirements**: Your Lambda function must use
  `BedrockAgentResolver` from AWS Lambda Powertools\\n- **Lambda Dependencies**:
  If schema generation fails, a fallback script will be generated. If you see
  error messages about missing dependencies, install them and then run the
  script again.\\n- **Integration**: Use the generated schema with
  `bedrock.ApiSchema.fromLocalAsset()` in your CDK code\\n\\n## CDK
  Implementation Workflow\\n\\nThis diagram provides a comprehensive view of the
  recommended CDK implementation workflow:\\n\\n```mermaid\\ngraph
  TD\\n    Start([Start]) --> A[\\\"CDKGeneralGuidance\\\"]\\n    A -->
  Init[\\\"cdk init app\\\"]\\n\\n    Init --> B{Choose Approach}\\n    B
  -->|\\\"Common Patterns\\\"|
  C1[\\\"GetAwsSolutionsConstructPattern\\\"]\\n    B -->|\\\"GenAI
  Features\\\"| C2[\\\"SearchGenAICDKConstructs\\\"]\\n    B -->|\\\"Custom
  Needs\\\"| C3[\\\"Custom CDK Code\\\"]\\n\\n    C1 --> D1[\\\"Implement
  Solutions Construct\\\"]\\n    C2 --> D2[\\\"Implement GenAI
  Constructs\\\"]\\n    C3 --> D3[\\\"Implement Custom
  Resources\\\"]\\n\\n    %% Bedrock Agent with Action Groups specific
  flow\\n    D2 -->|\\\"For Bedrock Agents<br/>with Action Groups\\\"|
  BA[\\\"Create Lambda with<br/>BedrockAgentResolver\\\"]\\n\\n    %% Schema
  generation flow\\n    BA --> BS[\\\"GenerateBedrockAgentSchema\\\"]\\n    BS
  -->|\\\"Success\\\"| JSON[\\\"openapi.json created\\\"]\\n    BS
  -->|\\\"Import Errors\\\"| BSF[\\\"Tool
  generates<br/>generate_schema.py\\\"]\\n    BSF -->|\\\"Missing
  dependencies?\\\"| InstallDeps[\\\"Install dependencies\\\"]\\n    InstallDeps
  --> BSR[\\\"Run script manually:<br/>python generate_schema.py\\\"]\\n    BSR
  --> JSON[\\\"openapi.json created\\\"]\\n\\n    %% Use schema in Agent
  CDK\\n    JSON --> AgentCDK[\\\"Use schema in<br/>Agent CDK
  code\\\"]\\n    AgentCDK --> D2\\n\\n    %% Conditional Lambda Powertools
  implementation\\n    D1 & D2 & D3 --> HasLambda{\\\"Using
  Lambda<br/>Functions?\\\"}\\n    HasLambda --> UseLayer{\\\"Using
  Lambda<br/>Layers?\\\"}\\n    UseLayer -->|\\\"Yes\\\"|
  LLDP[\\\"LambdaLayerDocumentationProvider\\\"]\\n\\n    HasLambda
  -->|\\\"No\\\"| SkipL[\\\"Skip\\\"]\\n\\n    %% Rest of
  workflow\\n    LLDP[\\\"LambdaLayerDocumentationProvider\\\"] -->
  Synth[\\\"cdk synth\\\"]\\n    SkipL --> Synth\\n\\n    Synth --> Nag{\\\"CDK
  Nag<br/>warnings?\\\"}\\n    Nag -->|Yes|
  E[\\\"ExplainCDKNagRule\\\"]\\n    Nag -->|No| Deploy[\\\"cdk
  deploy\\\"]\\n\\n    E --> Fix[\\\"Fix or Add Suppressions\\\"]\\n    Fix -->
  CN[\\\"CheckCDKNagSuppressions\\\"]\\n    CN --> Synth\\n\\n    %% Styling
  with darker colors\\n    classDef default
  fill:#424242,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n    classDef cmd
  fill:#4a148c,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n    classDef
  tool
  fill:#01579b,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n    classDef
  note
  fill:#1b5e20,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n    classDef
  output
  fill:#006064,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n    classDef
  decision
  fill:#5d4037,stroke:#ffffff,stroke-width:1px,color:#ffffff;\\n\\n    class
  Init,Synth,Deploy,BSR cmd;\\n    class A,C1,C2,BS,E,CN,LLDP tool;\\n    class
  JSON output;\\n    class HasLambda,UseLayer,Nag decision;\\n```\\n\\n##
  Available MCP Tools\\n\\n- **CDKGeneralGuidance**: Get prescriptive advice for
  building AWS applications with CDK\\n- **GetAwsSolutionsConstructPattern**:
  Find vetted architecture patterns combining AWS services\\n-
  **SearchGenAICDKConstructs**: Discover GenAI CDK constructs by name or
  features\\n- **GenerateBedrockAgentSchema**: Create OpenAPI schemas for
  Bedrock Agent action groups\\n- **LambdaLayerDocumentationProvider**: Access
  documentation for Lambda layers implementation\\n- **ExplainCDKNagRule**: Get
  detailed guidance on CDK Nag security rules\\n- **CheckCDKNagSuppressions**:
  Validate CDK Nag suppressions in your code\\n\\n## Available MCP
  Resources\\n\\n- **CDK Nag Rules**: Access rule packs via
  `cdk-nag://rules/{rule_pack}`\\n- **AWS Solutions Constructs**: Access
  patterns via `aws-solutions-constructs://{pattern_name}`\\n- **GenAI CDK
  Constructs**: Access documentation via
  `genai-cdk-constructs://{construct_type}/{construct_name}`\\n- **Lambda
  Powertools**: Get guidance on Lambda Powertools via
  `lambda-powertools://{topic}`\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Install AWS CDK CLI using `npm
  install -g aws-cdk` (Note: The MCP server itself doesn't use the CDK CLI
  directly, but it guides users through CDK application development that
  requires the CLI)\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.cdk-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xh\
  YnMuY2RrLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST\
  1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nConfigure the MCP
  server in your MCP client configuration (e.g., for Amazon Q Developer CLI,
  edit `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cdk-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.cdk-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/cdk-mcp-server
  .`:\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.cdk-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"awslabs/cdk-mcp-server:latest\\\"\\n        ],\\n        \
  \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n\\n##
  Security Considerations\\n\\nWhen using this MCP server, you should
  consider:\\n\\n- Reviewing all CDK Nag warnings and errors manually\\n- Fixing
  security issues rather than suppressing them whenever possible\\n- Documenting
  clear justifications for any necessary suppressions\\n- Using the
  CheckCDKNagSuppressions tool to verify no unauthorized suppressions
  exist\\n\\nBefore applying CDK NAG Suppressions, you should consider
  conducting your own independent assessment to ensure that your use would
  comply with your own specific security and quality control practices and
  standards, as well as the local laws, rules, and regulations that govern you
  and your
  content.\\n\",\"isRecommended\":false,\"githubStars\":4366,\"downloadCount\":\
  4901,\"createdAt\":\"2025-04-04T01:24:58.958958Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T09:27:29.920361Z\"},{\"mc\
  pId\":\"github.com/modelcontextprotocol/servers/tree/main/src/redis\",\"githu\
  bUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/redis\
  \",\"name\":\"Redis\",\"author\":\"modelcontextprotocol\",\"description\":\"P\
  rovides access to Redis key-value stores, enabling operations like setting,
  getting, deleting, and listing keys with optional expiration time
  support.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/redis.png\",\"category\":\"databases\",\"tags\":[\
  \"redis\",\"key-value-store\",\"caching\",\"data-storage\",\"database-operati\
  ons\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\":57346,\
  \"downloadCount\":4033,\"createdAt\":\"2025-02-18T05:45:15.150896Z\",\"update\
  dAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T02:20:2\
  5.927242Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/lambda-tool-mc\
  p-server\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/lambd\
  a-tool-mcp-server\",\"name\":\"Lambda
  Bridge\",\"author\":\"awslabs\",\"description\":\"Enables secure access to AWS
  Lambda functions as MCP tools, allowing AI models to interact with private
  resources, AWS services, and networks without direct access
  credentials.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\
  \":[\"aws-lambda\",\"serverless\",\"security\",\"aws-integration\",\"function\
  -management\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Lambda Tool
  MCP Server\\n\\nA Model Context Protocol (MCP) server for AWS Lambda to select
  and run Lambda function as MCP tools without code changes.\\n\\n##
  Features\\n\\nThis MCP server acts as a **bridge** between MCP clients and AWS
  Lambda functions, allowing generative AI models to access and run Lambda
  functions as tools. This is useful, for example, to access private resources
  such as internal applications and databases without the need to provide public
  network access. This approach allows the model to use other AWS services,
  private networks, and the public internet.\\n\\n```mermaid\\ngraph
  LR\\n    A[Model] <--> B[MCP Client]\\n    B <--> C[\\\"MCP2Lambda<br>(MCP
  Server)\\\"]\\n    C <--> D[Lambda Function]\\n    D <--> E[Other AWS
  Services]\\n    D <--> F[Internet]\\n    D <--> G[VPC]\\n\\n    style A
  fill:#f9f,stroke:#333,stroke-width:2px\\n    style B
  fill:#bbf,stroke:#333,stroke-width:2px\\n    style C
  fill:#bfb,stroke:#333,stroke-width:4px\\n    style D
  fill:#fbb,stroke:#333,stroke-width:2px\\n    style E
  fill:#fbf,stroke:#333,stroke-width:2px\\n    style F
  fill:#dff,stroke:#333,stroke-width:2px\\n    style G
  fill:#ffd,stroke:#333,stroke-width:2px\\n```\\n\\nFrom a **security**
  perspective, this approach implements segregation of duties by allowing the
  model to invoke the Lambda functions but not to access the other AWS services
  directly. The client only needs AWS credentials to invoke the Lambda
  functions. The Lambda functions can then interact with other AWS services
  (using the function role) and access public or private networks.\\n\\n##
  Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.lambda-tool-mcp-server&config=eyJjb21tYW5kIjoidXZ4\
  IGF3c2xhYnMubGFtYmRhLXRvb2wtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJT\
  EUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZVTkNUSU9OX1\
  BSRUZJWCI6InlvdXItZnVuY3Rpb24tcHJlZml4IiwiRlVOQ1RJT05fTElTVCI6InlvdXItZmlyc3Q\
  tZnVuY3Rpb24sIHlvdXItc2Vjb25kLWZ1bmN0aW9uIiwiRlVOQ1RJT05fVEFHX0tFWSI6InlvdXIt\
  dGFnLWtleSIsIkZVTkNUSU9OX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiRlVOQ1RJT05fS\
  U5QVVRfU0NIRU1BX0FSTl9UQUdfS0VZIjoieW91ci1mdW5jdGlvbi10YWctZm9yLWlucHV0LXNjaG\
  VtYSJ9fQ%3D%3D)\\n\\nConfigure the MCP server in your MCP client configuration
  (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.lambda-tool-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.lambda-tool-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FUNCTION_PREFIX\\\":
  \\\"your-function-prefix\\\",\\n        \\\"FUNCTION_LIST\\\":
  \\\"your-first-function,
  your-second-function\\\",\\n        \\\"FUNCTION_TAG_KEY\\\":
  \\\"your-tag-key\\\",\\n        \\\"FUNCTION_TAG_VALUE\\\":
  \\\"your-tag-value\\\",\\n        \\\"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\\\":
  \\\"your-function-tag-for-input-schema\\\"\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nor docker after a successful `docker build -t
  awslabs/bedrock-kb-retrieval-mcp-server .`:\\n\\n```file\\n# fictitious `.env`
  file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\": {\\n      \\\"awslabs.lambda-tool-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"AWS_REGION=us-east-1\\\
  \",\\n          \\\"--env\\\",\\n          \\\"FUNCTION_PREFIX=your-function-\
  prefix\\\",\\n          \\\"--env\\\",\\n          \\\"FUNCTION_LIST=your-fir\
  st-function,your-second-function\\\",\\n          \\\"--env\\\",\\n          \
  \\\"FUNCTION_TAG_KEY=your-tag-key\\\",\\n          \\\"--env\\\",\\n          \
  \\\"FUNCTION_TAG_VALUE=your-tag-value\\\",\\n          \\\"--env\\\",\\n          \
  \\\"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY=your-function-tag-for-input-schema\\\",\
  \\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file/above/.env\
  \\\",\\n          \\\"awslabs/lambda-tool-mcp-server:latest\\\"\\n        ],\
  \\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\nThe `AWS_PROFILE` and the `AWS_REGION` are
  optional, their default values are `default` and `us-east-1`.\\n\\nYou can
  specify `FUNCTION_PREFIX`, `FUNCTION_LIST`, or both. If both are empty, all
  functions pass the name check.\\nAfter the name check, if both
  `FUNCTION_TAG_KEY` and `FUNCTION_TAG_VALUE` are set, functions are further
  filtered by tag (with key=value).\\nIf only one of `FUNCTION_TAG_KEY` and
  `FUNCTION_TAG_VALUE`, then no function is selected and a warning is
  displayed.\\n\\n**IMPORTANT**: The function name is used as MCP tool name. The
  function description in AWS Lambda is used as MCP tool description. The
  function description should clarify when to use the function (what it
  provides) and how (which parameters). For example, a function that gives
  access to an internal Customer Relationship Management (CRM) system can use
  this description:\\n```plaintext\\nRetrieve customer status on the CRM system
  based on { 'customerId' } or { 'customerEmail' }\\n```\\n\\nThe lambda
  function parameters can also be provided through the EventBridge Schema
  Registry, which provides formal JSON Schema. See [Schema
  Support](#schema-support) below.\\n\\nSample functions that can be deployed
  via AWS SAM are provided in the `examples` folder.\\n\\n## Schema
  Support\\n\\nThe Lambda MCP Server supports input schema through AWS
  EventBridge Schema Registry. This provides formal JSON Schema documentation
  for your Lambda function inputs.\\n\\n### Configuration\\n\\nTo use schema
  validation:\\n\\n1. Create your schema in EventBridge Schema Registry\\n2. Tag
  your Lambda function with the schema ARN:\\n   ```plaintext\\n   Key:
  FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY (configurable)\\n   Value:
  arn:aws:schemas:region:account:schema/registry-name/schema-name\\n   ```\\n3.
  Configure the MCP server with the tag
  key:\\n   ```json\\n   {\\n     \\\"env\\\":
  {\\n       \\\"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\\\":
  \\\"your-schema-arn-tag-key\\\"\\n     }\\n   }\\n   ```\\n\\nWhen a Lambda
  function has a schema tag, the MCP server will:\\n1. Fetch the schema from
  EventBridge Schema Registry\\n2. Add the schema to the tool's
  documentation\\n\\nThis provides better documentation compared to describing
  parameters in the function description.\\n\\n## Best practices\\n\\n- Use the
  `FUNCTION_LIST` to specify the functions that are available as MCP tools.\\n-
  Use the `FUNCTION_PREFIX` to specify the prefix of the functions that are
  available as MCP tools.\\n- Use the `FUNCTION_TAG_KEY` and
  `FUNCTION_TAG_VALUE` to specify the tag key and value of the functions that
  are available as MCP tools.\\n- AWS Lambda `Description` property: the
  description of the function is used as MCP tool description, so it should be
  very detailed to help the model understand when and how to use the
  function\\n- Use EventBridge Schema Registry to provide formal input
  validation:\\n  - Create JSON Schema definitions for your function
  inputs\\n  - Tag functions with their schema ARNs\\n  - Configure
  `FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY` in the MCP server\\n\\n## Security
  Considerations\\n\\nWhen using this MCP server, you should consider:\\n\\n-
  Only Lambda functions that are in the provided list or with a name starting
  with the prefix are imported as MCP tools.\\n- The MCP server needs
  permissions to invoke the Lambda functions.\\n- Each Lambda function has its
  own permissions to optionally access other AWS
  resources.\\n\",\"isRecommended\":false,\"githubStars\":4413,\"downloadCount\
  \":44,\"createdAt\":\"2025-06-21T01:43:01.398984Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T08:39:15.599695Z\"},{\"m\
  cpId\":\"github.com/lharries/whatsapp-mcp\",\"githubUrl\":\"https://github.co\
  m/lharries/whatsapp-mcp\",\"name\":\"WhatsApp\",\"author\":\"lharries\",\"des\
  cription\":\"Enables searching personal WhatsApp messages, managing contacts,
  and sending messages to individuals or groups through WhatsApp Web's
  multidevice API with local message
  storage.\",\"codiconIcon\":\"comment\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/whatsapp.png\",\"category\":\"communication\",\"ta\
  gs\":[\"messaging\",\"chat-history\",\"contacts\",\"whatsapp\",\"message-sear\
  ch\"],\"requiresApiKey\":false,\"readmeContent\":\"# WhatsApp MCP
  Server\\n\\nThis is a Model Context Protocol (MCP) server for
  WhatsApp.\\n\\nWith this you can search and read your personal Whatsapp
  messages (including images, videos, documents, and audio messages), search
  your contacts and send messages to either individuals or groups. You can also
  send media files including images, videos, documents, and audio
  messages.\\n\\nIt connects to your **personal WhatsApp account** directly via
  the Whatsapp web multidevice API (using the
  [whatsmeow](https://github.com/tulir/whatsmeow) library). All your messages
  are stored locally in a SQLite database and only sent to an LLM (such as
  Claude) when the agent accesses them through tools (which you
  control).\\n\\nHere's an example of what you can do when it's connected to
  Claude.\\n\\n![WhatsApp MCP](./example-use.png)\\n\\n> To get updates on this
  and other projects I work on [enter your email
  here](https://docs.google.com/forms/d/1rTF9wMBTN0vPfzWuQa2BjfGKdKIpTbyeKxhPMc\
  EzgyI/preview)\\n\\n## Installation\\n\\n### Prerequisites\\n\\n- Go\\n-
  Python 3.6+\\n- Anthropic Claude Desktop app (or Cursor)\\n- UV (Python
  package manager), install with `curl -LsSf https://astral.sh/uv/install.sh |
  sh`\\n- FFmpeg (_optional_) - Only needed for audio messages. If you want to
  send audio files as playable WhatsApp voice messages, they must be in `.ogg`
  Opus format. With FFmpeg installed, the MCP server will automatically convert
  non-Opus audio files. Without FFmpeg, you can still send raw audio files using
  the `send_file` tool.\\n\\n### Steps\\n\\n1. **Clone this
  repository**\\n\\n   ```bash\\n   git clone
  https://github.com/lharries/whatsapp-mcp.git\\n   cd
  whatsapp-mcp\\n   ```\\n\\n2. **Run the WhatsApp bridge**\\n\\n   Navigate to
  the whatsapp-bridge directory and run the Go
  application:\\n\\n   ```bash\\n   cd whatsapp-bridge\\n   go run
  main.go\\n   ```\\n\\n   The first time you run it, you will be prompted to
  scan a QR code. Scan the QR code with your WhatsApp mobile app to
  authenticate.\\n\\n   After approximately 20 days, you will might need to
  re-authenticate.\\n\\n3. **Connect to the MCP server**\\n\\n   Copy the below
  json with the appropriate {{PATH}}
  values:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"whatsapp\\\": {\\n         \\\"command\\\":
  \\\"{{PATH_TO_UV}}\\\", // Run `which uv` and place the output
  here\\n         \\\"args\\\":
  [\\n           \\\"--directory\\\",\\n           \\\"{{PATH_TO_SRC}}/whatsapp\
  -mcp/whatsapp-mcp-server\\\", // cd into the repo, run `pwd` and enter the
  output here +
  \\\"/whatsapp-mcp-server\\\"\\n           \\\"run\\\",\\n           \\\"main.\
  py\\\"\\n         ]\\n       }\\n     }\\n   }\\n   ```\\n\\n   For
  **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop
  configuration directory at:\\n\\n   ```\\n   ~/Library/Application
  Support/Claude/claude_desktop_config.json\\n   ```\\n\\n   For **Cursor**,
  save this as `mcp.json` in your Cursor configuration directory
  at:\\n\\n   ```\\n   ~/.cursor/mcp.json\\n   ```\\n\\n4. **Restart Claude
  Desktop / Cursor**\\n\\n   Open Claude Desktop and you should now see WhatsApp
  as an available integration.\\n\\n   Or restart Cursor.\\n\\n### Windows
  Compatibility\\n\\nIf you're running this project on Windows, be aware that
  `go-sqlite3` requires **CGO to be enabled** in order to compile and work
  properly. By default, **CGO is disabled on Windows**, so you need to
  explicitly enable it and have a C compiler installed.\\n\\n#### Steps to get
  it working:\\n\\n1. **Install a C compiler**  \\n   We recommend using
  [MSYS2](https://www.msys2.org/) to install a C compiler for Windows. After
  installing MSYS2, make sure to add the `ucrt64\\\\bin` folder to your
  `PATH`.  \\n    A step-by-step guide is available
  [here](https://code.visualstudio.com/docs/cpp/config-mingw).\\n\\n2. **Enable
  CGO and run the app**\\n\\n   ```bash\\n   cd whatsapp-bridge\\n   go env -w
  CGO_ENABLED=1\\n   go run main.go\\n   ```\\n\\nWithout this setup, you'll
  likely run into errors like:\\n\\n> `Binary was compiled with 'CGO_ENABLED=0',
  go-sqlite3 requires cgo to work.`\\n\\n## Architecture Overview\\n\\nThis
  application consists of two main components:\\n\\n1. **Go WhatsApp Bridge**
  (`whatsapp-bridge/`): A Go application that connects to WhatsApp's web API,
  handles authentication via QR code, and stores message history in SQLite. It
  serves as the bridge between WhatsApp and the MCP server.\\n\\n2. **Python MCP
  Server** (`whatsapp-mcp-server/`): A Python server implementing the Model
  Context Protocol (MCP), which provides standardized tools for Claude to
  interact with WhatsApp data and send/receive messages.\\n\\n### Data
  Storage\\n\\n- All message history is stored in a SQLite database within the
  `whatsapp-bridge/store/` directory\\n- The database maintains tables for chats
  and messages\\n- Messages are indexed for efficient searching and
  retrieval\\n\\n## Usage\\n\\nOnce connected, you can interact with your
  WhatsApp contacts through Claude, leveraging Claude's AI capabilities in your
  WhatsApp conversations.\\n\\n### MCP Tools\\n\\nClaude can access the
  following tools to interact with WhatsApp:\\n\\n- **search_contacts**: Search
  for contacts by name or phone number\\n- **list_messages**: Retrieve messages
  with optional filters and context\\n- **list_chats**: List available chats
  with metadata\\n- **get_chat**: Get information about a specific chat\\n-
  **get_direct_chat_by_contact**: Find a direct chat with a specific contact\\n-
  **get_contact_chats**: List all chats involving a specific contact\\n-
  **get_last_interaction**: Get the most recent message with a contact\\n-
  **get_message_context**: Retrieve context around a specific message\\n-
  **send_message**: Send a WhatsApp message to a specified phone number or group
  JID\\n- **send_file**: Send a file (image, video, raw audio, document) to a
  specified recipient\\n- **send_audio_message**: Send an audio file as a
  WhatsApp voice message (requires the file to be an .ogg opus file or ffmpeg
  must be installed)\\n- **download_media**: Download media from a WhatsApp
  message and get the local file path\\n\\n### Media Handling Features\\n\\nThe
  MCP server supports both sending and receiving various media types:\\n\\n####
  Media Sending\\n\\nYou can send various media types to your WhatsApp
  contacts:\\n\\n- **Images, Videos, Documents**: Use the `send_file` tool to
  share any supported media type.\\n- **Voice Messages**: Use the
  `send_audio_message` tool to send audio files as playable WhatsApp voice
  messages.\\n  - For optimal compatibility, audio files should be in `.ogg`
  Opus format.\\n  - With FFmpeg installed, the system will automatically
  convert other audio formats (MP3, WAV, etc.) to the required format.\\n  -
  Without FFmpeg, you can still send raw audio files using the `send_file` tool,
  but they won't appear as playable voice messages.\\n\\n#### Media
  Downloading\\n\\nBy default, just the metadata of the media is stored in the
  local database. The message will indicate that media was sent. To access this
  media you need to use the download_media tool which takes the `message_id` and
  `chat_jid` (which are shown when printing messages containing the meda), this
  downloads the media and then returns the file path which can be then opened or
  passed to another tool.\\n\\n## Technical Details\\n\\n1. Claude sends
  requests to the Python MCP server\\n2. The MCP server queries the Go bridge
  for WhatsApp data or directly to the SQLite database\\n3. The Go accesses the
  WhatsApp API and keeps the SQLite database up to date\\n4. Data flows back
  through the chain to Claude\\n5. When sending messages, the request flows from
  Claude through the MCP server to the Go bridge and to WhatsApp\\n\\n##
  Troubleshooting\\n\\n- If you encounter permission issues when running uv, you
  may need to add it to your PATH or use the full path to the executable.\\n-
  Make sure both the Go application and the Python server are running for the
  integration to work properly.\\n\\n### Authentication Issues\\n\\n- **QR Code
  Not Displaying**: If the QR code doesn't appear, try restarting the
  authentication script. If issues persist, check if your terminal supports
  displaying QR codes.\\n- **WhatsApp Already Logged In**: If your session is
  already active, the Go bridge will automatically reconnect without showing a
  QR code.\\n- **Device Limit Reached**: WhatsApp limits the number of linked
  devices. If you reach this limit, you'll need to remove an existing device
  from WhatsApp on your phone (Settings > Linked Devices).\\n- **No Messages
  Loading**: After initial authentication, it can take several minutes for your
  message history to load, especially if you have many chats.\\n- **WhatsApp Out
  of Sync**: If your WhatsApp messages get out of sync with the bridge, delete
  both database files (`whatsapp-bridge/store/messages.db` and
  `whatsapp-bridge/store/whatsapp.db`) and restart the bridge to
  re-authenticate.\\n\\nFor additional Claude Desktop integration
  troubleshooting, see the [MCP
  documentation](https://modelcontextprotocol.io/quickstart/server#claude-for-d\
  esktop-integration-issues). The documentation includes helpful tips for
  checking logs and resolving common
  issues.\\n\",\"isRecommended\":false,\"githubStars\":4293,\"downloadCount\":2\
  943,\"createdAt\":\"2025-03-31T18:44:25.818276Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T02:02:51.406636Z\"},{\"mcp\
  Id\":\"github.com/pashpashpash/mcp-taskmanager\",\"githubUrl\":\"https://gith\
  ub.com/pashpashpash/mcp-taskmanager\",\"name\":\"Task
  Manager\",\"author\":\"pashpashpash\",\"description\":\"A queue-based task
  management system that enables planning, execution, and tracking of tasks with
  support for task lists, execution plans, and completion
  feedback.\",\"codiconIcon\":\"tasklist\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/task-manager.png\",\"category\":\"developer-tools\
  \",\"tags\":[\"task-management\",\"queue-system\",\"workflow\",\"task-tracking\
  \",\"automation\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP
  TaskManager\\n\\nModel Context Protocol server for Task Management. This
  allows Claude Desktop (or any MCP client) to manage and execute tasks in a
  queue-based system.\\n\\n## Prerequisites\\n\\n- Node.js 18+ (install via
  `brew install node`)\\n- Claude Desktop (install from
  https://claude.ai/desktop)\\n- tsx (install via `npm install -g tsx`)\\n\\n##
  Installation\\n\\n1. **Clone the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-taskmanager.git\\n   cd
  mcp-taskmanager\\n   ```\\n\\n2. **Install
  Dependencies**:\\n   ```bash\\n   npm install\\n   ```\\n\\n3. **Build the
  Project**:\\n   ```bash\\n   npm run build\\n   ```\\n\\n4. **Configure Claude
  Desktop**:\\n\\nLocate your Claude Desktop configuration file at:\\n- macOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\nYou can also find this
  through the Claude Desktop menu:\\n1. Open Claude Desktop\\n2. Click Claude on
  the Mac menu bar\\n3. Click \\\"Settings\\\"\\n4. Click
  \\\"Developer\\\"\\n\\nAdd the following to your
  configuration:\\n```json\\n{\\n  \\\"tools\\\": {\\n    \\\"taskmanager\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/mcp-taskmanager/dist/index.js\\\"]\\n    }\\n  }\\n}\\n```\\nNot\
  e: Replace \\\"path/to/mcp-taskmanager\\\" with the actual path to your cloned
  repository.\\n\\n## Development Setup\\n\\n1. **Install tsx globally** (if not
  already installed):\\n   ```bash\\n   npm install -g tsx\\n   ```\\n\\n2.
  **Development Configuration**:\\n   \\n   For development with the TypeScript
  source, modify your Claude Desktop
  config:\\n   ```json\\n   {\\n     \\\"tools\\\":
  {\\n       \\\"taskmanager\\\": {\\n         \\\"command\\\":
  \\\"tsx\\\",\\n         \\\"args\\\":
  [\\\"path/to/mcp-taskmanager/index.ts\\\"]\\n       }\\n     }\\n   }\\n   ```\
  \\n\\n## Available Operations\\n\\nThe TaskManager supports two main phases of
  operation:\\n\\n### Planning Phase\\n- Accepts a task list (array of strings)
  from the user\\n- Stores tasks internally as a queue\\n- Returns an execution
  plan (task overview, task ID, current queue status)\\n\\n### Execution
  Phase\\n- Returns the next task from the queue when requested\\n- Provides
  feedback mechanism for task completion\\n- Removes completed tasks from the
  queue\\n- Prepares the next task for execution\\n\\n### Parameters\\n-
  `action`: \\\"plan\\\" | \\\"execute\\\" | \\\"complete\\\"\\n- `tasks`: Array
  of task strings (required for \\\"plan\\\" action)\\n- `taskId`: Task
  identifier (required for \\\"complete\\\" action)\\n- `getNext`: Boolean flag
  to request next task (for \\\"execute\\\" action)\\n\\n## Example
  Usage\\n\\n```typescript\\n// Planning phase\\n{\\n  action:
  \\\"plan\\\",\\n  tasks: [\\\"Task 1\\\", \\\"Task 2\\\", \\\"Task
  3\\\"]\\n}\\n\\n// Execution phase\\n{\\n  action:
  \\\"execute\\\",\\n  getNext: true\\n}\\n\\n// Complete task\\n{\\n  action:
  \\\"complete\\\",\\n  taskId: \\\"task-123\\\"\\n}\\n```\\n\\n##
  Debugging\\n\\nIf you run into issues, check Claude Desktop's MCP
  logs:\\n```bash\\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\\n```\\n\\n##
  Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n# Build
  the project\\nnpm run build\\n\\n# Development with auto-rebuild\\nnpm run
  watch\\n```\\n\\n## License\\n\\nMIT\\n\\n---\\nNote: This is a fork of the
  [original mcp-taskmanager
  repository](https://github.com/kazuph/mcp-taskmanager).\\n\",\"isRecommended\
  \":false,\"githubStars\":24,\"downloadCount\":3064,\"createdAt\":\"2025-02-18\
  T23:06:16.564387Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithu\
  bSync\":\"2025-07-02T16:59:14.877216Z\"},{\"mcpId\":\"github.com/awslabs/mcp/\
  tree/main/src/postgres-mcp-server\",\"githubUrl\":\"https://github.com/awslab\
  s/mcp/tree/main/src/postgres-mcp-server\",\"name\":\"Aurora
  Postgres\",\"author\":\"awslabs\",\"description\":\"Enables natural language
  interactions with Aurora Postgres databases through AWS RDS Data API,
  supporting SQL query generation and execution with configurable read/write
  permissions.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\"\
  :[\"postgres\",\"aurora\",\"aws\",\"sql\",\"database-management\"],\"requires\
  ApiKey\":false,\"readmeContent\":\"# AWS Labs postgres MCP Server\\n\\nAn AWS
  Labs Model Context Protocol (MCP) server for Aurora Postgres\\n\\n##
  Features\\n\\n### Natural language to Postgres SQL query\\n\\n- Converting
  human-readable questions and commands into structured Postgres-compatible SQL
  queries and executing them against the configured Aurora Postgres
  database.\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Aurora Postgres Cluster with
  Postgres username and password stored in AWS Secrets Manager\\n4. Enable RDS
  Data API for your Aurora Postgres Cluster, see [instructions
  here](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.h\
  tml)\\n5. This MCP server can only be run locally on the same host as your LLM
  client.\\n6. Docker runtime\\n7. Set up AWS credentials with access to AWS
  services\\n   - You need an AWS account with appropriate permissions\\n   -
  Configure AWS credentials with `aws configure` or environment
  variables\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.postgres-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF\
  3c2xhYnMucG9zdGdyZXMtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0\
  YV0gLS1zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb\
  24gW3lvdXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci\
  1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI\
  6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nConfi\
  gure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.postgres-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.postgres-mcp-server@latest\\\",\\n        \\\"--resou\
  rce_arn\\\", \\\"[your data]\\\",\\n        \\\"--secret_arn\\\", \\\"[your
  data]\\\",\\n        \\\"--database\\\", \\\"[your
  data]\\\",\\n        \\\"--region\\\", \\\"[your
  data]\\\",\\n        \\\"--readonly\\\",
  \\\"True\\\"\\n      ],\\n      \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n### Build
  and install docker image locally on the same host of your LLM client\\n\\n1.
  'git clone https://github.com/awslabs/mcp.git'\\n2. Go to sub-directory
  'src/postgres-mcp-server/'\\n3. Run 'docker build -t
  awslabs/postgres-mcp-server:latest .'\\n\\n### Add or update your LLM client's
  config with following:\\n<pre><code>\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.postgres-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"-e\\\", \\\"AWS_ACCESS_KEY_ID=[your data]\\\",\\n        \\\"-e\\\",
  \\\"AWS_SECRET_ACCESS_KEY=[your data]\\\",\\n        \\\"-e\\\",
  \\\"AWS_REGION=[your
  data]\\\",\\n        \\\"awslabs/postgres-mcp-server:latest\\\",\\n        \\\
  \"--resource_arn\\\", \\\"[your data]\\\",\\n        \\\"--secret_arn\\\",
  \\\"[your data]\\\",\\n        \\\"--database\\\", \\\"[your
  data]\\\",\\n        \\\"--region\\\", \\\"[your
  data]\\\",\\n        \\\"--readonly\\\",
  \\\"True\\\"\\n      ]\\n    }\\n  }\\n}\\n</code></pre>\\n\\nNOTE: By
  default, only read-only queries are allowed and it is controlled by --readonly
  parameter above. Set it to False if you also want to allow writable DML or
  DDL.\\n\\n### AWS Authentication\\n\\nThe MCP server uses the AWS profile
  specified in the `AWS_PROFILE` environment variable. If not provided, it
  defaults to the \\\"default\\\" profile in your AWS configuration
  file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n}\\n```\\n\\nMake sure the AWS profile has
  permissions to access the [RDS data
  API](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.ht\
  ml#data-api.access), and the secret from AWS Secrets Manager. The MCP server
  creates a boto3 session using the specified profile to authenticate with AWS
  services. Your AWS IAM credentials remain on your local machine and are
  strictly used for accessing AWS
  services.\\n\",\"isRecommended\":false,\"githubStars\":4408,\"downloadCount\"\
  :51,\"createdAt\":\"2025-06-21T01:38:11.728617Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T05:40:48.283165Z\"},{\"mcp\
  Id\":\"github.com/upstash/context7-mcp\",\"githubUrl\":\"https://github.com/u\
  pstash/context7-mcp\",\"name\":\"Context7\",\"author\":\"upstash\",\"descript\
  ion\":\"Provides up-to-date library documentation and code examples directly
  in LLM prompts, ensuring accurate and current programming
  assistance.\",\"codiconIcon\":\"library\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/upstash.jpg\",\"category\":\"developer-tools\",\
  \"tags\":[\"documentation\",\"code-examples\",\"api-reference\",\"library-docs\
  \",\"programming-help\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Context7 MCP - Up-to-date Code Docs For Any
  Prompt\\n\\n[![Website](https://img.shields.io/badge/Website-context7.com-blu\
  e)](https://context7.com) [![smithery
  badge](https://smithery.ai/badge/@upstash/context7-mcp)](https://smithery.ai/\
  server/@upstash/context7-mcp) [<img alt=\\\"Install in VS Code (npx)\\\"
  src=\\\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=\
  Install%20Context7%20MCP&color=0098FF\\\">](https://insiders.vscode.dev/redir\
  ect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%\
  22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40la\
  test%22%5D%7D)\\n\\n[![](https://img.shields.io/badge/docs--yellow)](\
  ./docs/README.zh-TW.md)
  [![](https://img.shields.io/badge/docs--yellow)](./docs/README.zh-CN.\
  md)
  [![](https://img.shields.io/badge/docs--b7003a)](./docs/README.ja.md)
  [![ ](https://img.shields.io/badge/docs--green)](./docs/README.ko.md)
  [![Documentacin en
  Espaol](https://img.shields.io/badge/docs-Espaol-orange)](./docs/README.es.\
  md) [![Documentation en
  Franais](https://img.shields.io/badge/docs-Franais-blue)](./docs/README.fr.\
  md) [![Documentao em Portugus
  (Brasil)](<https://img.shields.io/badge/docs-Portugus%20(Brasil)-purple>)](.\
  /docs/README.pt-BR.md) [![Documentazione in
  italiano](https://img.shields.io/badge/docs-Italian-red)](./docs/README.it.md)
  [![Dokumentasi Bahasa
  Indonesia](https://img.shields.io/badge/docs-Bahasa%20Indonesia-pink)](./docs\
  /README.id-ID.md) [![Dokumentation auf
  Deutsch](https://img.shields.io/badge/docs-Deutsch-darkgreen)](./docs/README.\
  de.md) [![  
  ](https://img.shields.io/badge/docs--darkblue)](./docs/README.ru.\
  md) [![Trke
  Dokman](https://img.shields.io/badge/docs-Trke-blue)](./docs/README.tr.md)
  [![Arabic
  Documentation](https://img.shields.io/badge/docs-Arabic-white)](./docs/README\
  .ar.md)\\n\\n##  Without Context7\\n\\nLLMs rely on outdated or generic
  information about the libraries you use. You get:\\n\\n-  Code examples are
  outdated and based on year-old training data\\n-  Hallucinated APIs don't
  even exist\\n-  Generic answers for old package versions\\n\\n##  With
  Context7\\n\\nContext7 MCP pulls up-to-date, version-specific documentation
  and code examples straight from the source  and places them directly into
  your prompt.\\n\\nAdd `use context7` to your prompt in
  Cursor:\\n\\n```txt\\nCreate a Next.js middleware that checks for a valid JWT
  in cookies and redirects unauthenticated users to `/login`. use
  context7\\n```\\n\\n```txt\\nConfigure a Cloudflare Worker script to cache
  JSON API responses for five minutes. use context7\\n```\\n\\nContext7 fetches
  up-to-date code examples and documentation right into your LLM's
  context.\\n\\n- 1 Write your prompt naturally\\n- 2 Tell the LLM to `use
  context7`\\n- 3 Get working code answers\\n\\nNo tab-switching, no
  hallucinated APIs that don't exist, no outdated code generations.\\n\\n## 
  Adding Projects\\n\\nCheck out our [project addition
  guide](./docs/adding-projects.md) to learn how to add (or update) your
  favorite libraries to Context7.\\n\\n##  Installation\\n\\n###
  Requirements\\n\\n- Node.js >= v18.0.0\\n- Cursor, Windsurf, Claude Desktop or
  another MCP Client\\n\\n<details>\\n<summary><b>Installing via
  Smithery</b></summary>\\n\\nTo install Context7 MCP Server for any client
  automatically via
  [Smithery](https://smithery.ai/server/@upstash/context7-mcp):\\n\\n```bash\\n\
  npx -y @smithery/cli@latest install @upstash/context7-mcp --client
  <CLIENT_NAME> --key <YOUR_SMITHERY_KEY>\\n```\\n\\nYou can find your Smithery
  key in the [Smithery.ai
  webpage](https://smithery.ai/server/@upstash/context7-mcp).\\n\\n</details>\\n\
  \\n<details>\\n<summary><b>Install in Cursor</b></summary>\\n\\nGo to:
  `Settings` -> `Cursor Settings` -> `MCP` -> `Add new global MCP
  server`\\n\\nPasting the following configuration into your Cursor
  `~/.cursor/mcp.json` file is the recommended approach. You may also install in
  a specific project by creating `.cursor/mcp.json` in your project folder. See
  [Cursor MCP docs](https://docs.cursor.com/context/model-context-protocol) for
  more info.\\n\\n> Since Cursor 1.0, you can click the install button below for
  instant one-click installation.\\n\\n#### Cursor Remote Server
  Connection\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=context7&config=eyJ1cmwiOiJodHRwczovL21jcC5jb250ZXh0Ny5jb20\
  vbWNwIn0%3D)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n    }\\n  }\\n}\\n```\\n\\n#### Cursor
  Local Server Connection\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=context7&config=eyJjb21tYW5kIjoibnB4IC15IEB1cHN0YXNoL2NvbnR\
  leHQ3LW1jcCJ9)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n<details>\\n<summ\
  ary>Alternative: Use Bun</summary>\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=context7&config=eyJjb21tYW5kIjoiYnVueCAteSBAdXBzdGFzaC9jb25\
  0ZXh0Ny1tY3AifQ%3D%3D)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"bunx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary>Alternative: Use Deno</summary>\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=context7&config=eyJjb21tYW5kIjoiZGVubyBydW4gLS1hbGxvdy1lbnY\
  gLS1hbGxvdy1uZXQgbnBtOkB1cHN0YXNoL2NvbnRleHQ3LW1jcCJ9)\\n\\n```json\\n{\\n  \\\
  \"mcpServers\\\": {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"deno\\\",\\n      \\\"args\\\": [\\\"run\\\",
  \\\"--allow-env=NO_DEPRECATION,TRACE_DEPRECATION\\\", \\\"--allow-net\\\",
  \\\"npm:@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\
  \\n</details>\\n\\n<details>\\n<summary><b>Install in
  Windsurf</b></summary>\\n\\nAdd this to your Windsurf MCP config file. See
  [Windsurf MCP docs](https://docs.windsurf.com/windsurf/mcp) for more
  info.\\n\\n#### Windsurf Remote Server
  Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"serverUrl\\\":
  \\\"https://mcp.context7.com/sse\\\"\\n    }\\n  }\\n}\\n```\\n\\n####
  Windsurf Local Server Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary><b>Install in Trae</b></summary>\\n\\nUse the Add manually
  feature and fill in the JSON configuration information for that MCP
  server.\\nFor more details, visit the [Trae
  documentation](https://docs.trae.ai/ide/model-context-protocol?_lang=en).\\n\
  \\n#### Trae Remote Server Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n    }\\n  }\\n}\\n```\\n\\n#### Trae
  Local Server Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@upstash/context7-mcp\\\"\\n      ]\\n    \
  }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in VS
  Code</b></summary>\\n\\n[<img alt=\\\"Install in VS Code (npx)\\\"
  src=\\\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=\
  Install%20Context7%20MCP&color=0098FF\\\">](https://insiders.vscode.dev/redir\
  ect?url=vscode%3Amcp%2Finstall%3F%7B%22name%22%3A%22context7%22%2C%22command%\
  22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40upstash%2Fcontext7-mcp%40la\
  test%22%5D%7D)\\n[<img alt=\\\"Install in VS Code Insiders (npx)\\\"
  src=\\\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=\
  flat-square&label=Install%20Context7%20MCP&color=24bfa5\\\">](https://insider\
  s.vscode.dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%7B%22name%22%3A%\
  22context7%22%2C%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22%40\
  upstash%2Fcontext7-mcp%40latest%22%5D%7D)\\n\\nAdd this to your VS Code MCP
  config file. See [VS Code MCP
  docs](https://code.visualstudio.com/docs/copilot/chat/mcp-servers) for more
  info.\\n\\n#### VS Code Remote Server Connection\\n\\n```json\\n\\\"mcp\\\":
  {\\n  \\\"servers\\\": {\\n    \\\"context7\\\": {\\n      \\\"type\\\":
  \\\"http\\\",\\n      \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n    }\\n  }\\n}\\n```\\n\\n#### VS Code
  Local Server Connection\\n\\n```json\\n\\\"mcp\\\": {\\n  \\\"servers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"type\\\":
  \\\"stdio\\\",\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary><b>Install in Visual Studio 2022</b></summary>\\n\\nYou
  can configure Context7 MCP in Visual Studio 2022 by following the [Visual
  Studio MCP Servers
  documentation](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=\
  vs-2022).\\n\\nAdd this to your Visual Studio MCP config file (see the [Visual
  Studio
  docs](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=vs-2022)
  for details):\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"context7\\\": {\\n        \\\"type\\\":
  \\\"http\\\",\\n        \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nO\
  r, for a local server:\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"context7\\\": {\\n        \\\"type\\\":
  \\\"stdio\\\",\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\":
  [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor more
  information and troubleshooting, refer to the [Visual Studio MCP Servers
  documentation](https://learn.microsoft.com/visualstudio/ide/mcp-servers?view=\
  vs-2022).\\n</details>\\n\\n<details>\\n<summary><b>Install in
  Zed</b></summary>\\n\\nIt can be installed via [Zed
  Extensions](https://zed.dev/extensions?query=Context7) or you can add this to
  your Zed `settings.json`. See [Zed Context Server
  docs](https://zed.dev/docs/assistant/context-servers) for more
  info.\\n\\n```json\\n{\\n  \\\"context_servers\\\": {\\n    \\\"Context7\\\":
  {\\n      \\\"command\\\": {\\n        \\\"path\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n      },\\n      \\\"settings\\\":
  {}\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<details>\\n<summary><b>Insta\
  ll in Gemini CLI</b></summary>\\n\\nSee [Gemini CLI
  Configuration](https://github.com/google-gemini/gemini-cli/blob/main/docs/cli\
  /configuration.md) for details.\\n\\n1.  Open the Gemini CLI settings file.
  The location is `~/.gemini/settings.json` (where `~` is your home
  directory).\\n2.  Add the following to the `mcpServers` object in your
  `settings.json` file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\nIf the
  `mcpServers` object does not exist, create
  it.\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in Claude
  Code</b></summary>\\n\\nRun this command. See [Claude Code MCP
  docs](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutoria\
  ls#set-up-model-context-protocol-mcp) for more info.\\n\\n#### Claude Code
  Remote Server Connection\\n\\n```sh\\nclaude mcp add --transport http context7
  https://mcp.context7.com/mcp\\n```\\n\\nOr using SSE
  transport:\\n\\n```sh\\nclaude mcp add --transport sse context7
  https://mcp.context7.com/sse\\n```\\n\\n#### Claude Code Local Server
  Connection\\n\\n```sh\\nclaude mcp add context7 -- npx -y
  @upstash/context7-mcp\\n```\\n\\n</details>\\n\\n<details>\\n<summary><b>Inst\
  all in Claude Desktop</b></summary>\\n\\nAdd this to your Claude Desktop
  `claude_desktop_config.json` file. See [Claude Desktop MCP
  docs](https://modelcontextprotocol.io/quickstart/user) for more
  info.\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary>\\n<b>Install in Cline</b>\\n</summary>\\n\\nYou can
  easily install Context7 through the [Cline MCP Server
  Marketplace](https://cline.bot/mcp-marketplace) by following these
  instructions:\\n\\n1. Open **Cline**.\\n1. Click the hamburger menu icon ()
  to enter the **MCP Servers** section.\\n2. Use the search bar within the
  **Marketplace** tab to find *Context7*.\\n3. Click the **Install**
  button.\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in
  BoltAI</b></summary>\\n\\nOpen the \\\"Settings\\\" page of the app, navigate
  to \\\"Plugins,\\\" and enter the following
  JSON:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\nOnce saved, enter
  in the chat `get-library-docs` followed by your Context7 documentation ID
  (e.g., `get-library-docs /nuxt/ui`). More information is available on
  [BoltAI's Documentation
  site](https://docs.boltai.com/docs/plugins/mcp-servers). For BoltAI on iOS,
  [see this
  guide](https://docs.boltai.com/docs/boltai-mobile/mcp-servers).\\n\\n</detail\
  s>\\n\\n<details>\\n<summary><b>Using Docker</b></summary>\\n\\nIf you prefer
  to run the MCP server in a Docker container:\\n\\n1. **Build the Docker
  Image:**\\n\\n   First, create a `Dockerfile` in the project root (or anywhere
  you prefer):\\n\\n   <details>\\n   <summary>Click to see Dockerfile
  content</summary>\\n\\n   ```Dockerfile\\n   FROM
  node:18-alpine\\n\\n   WORKDIR /app\\n\\n   # Install the latest version
  globally\\n   RUN npm install -g @upstash/context7-mcp\\n\\n   # Expose
  default port if needed (optional, depends on MCP client interaction)\\n   #
  EXPOSE 3000\\n\\n   # Default command to run the server\\n   CMD
  [\\\"context7-mcp\\\"]\\n   ```\\n\\n   </details>\\n\\n   Then, build the
  image using a tag (e.g., `context7-mcp`). **Make sure Docker Desktop (or the
  Docker daemon) is running.** Run the following command in the same directory
  where you saved the `Dockerfile`:\\n\\n   ```bash\\n   docker build -t
  context7-mcp .\\n   ```\\n\\n2. **Configure Your MCP Client:**\\n\\n   Update
  your MCP client's configuration to use the Docker command.\\n\\n   _Example
  for a
  cline_mcp_settings.json:_\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"ontext7\\\": {\\n         \\\"autoApprove\\\":
  [],\\n         \\\"disabled\\\": false,\\n         \\\"timeout\\\":
  60,\\n         \\\"command\\\": \\\"docker\\\",\\n         \\\"args\\\":
  [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\",
  \\\"context7-mcp\\\"],\\n         \\\"transportType\\\":
  \\\"stdio\\\"\\n       }\\n     }\\n   }\\n   ```\\n\\n   _Note: This is an
  example configuration. Please refer to the specific examples for your MCP
  client (like Cursor, VS Code, etc.) earlier in this README to adapt the
  structure (e.g., `mcpServers` vs `servers`). Also, ensure the image name in
  `args` matches the tag used during the `docker build`
  command._\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in
  Windows</b></summary>\\n\\nThe configuration on Windows is slightly different
  compared to Linux or macOS (_`Cline` is used in the example_). The same
  principle applies to other editors; refer to the configuration of `command`
  and `args`.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"github.com/upstash/context7-mcp\\\": {\\n      \\\"command\\\":
  \\\"cmd\\\",\\n      \\\"args\\\": [\\\"/c\\\", \\\"npx\\\", \\\"-y\\\",
  \\\"@upstash/context7-mcp@latest\\\"],\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<details>\\n<summary><b>Insta\
  ll in Augment Code</b></summary>\\n\\nTo configure Context7 MCP in Augment
  Code, you can use either the graphical interface or manual
  configuration.\\n\\n### **A. Using the Augment Code UI**\\n\\n1. Click the
  hamburger menu.\\n2. Select **Settings**.\\n3. Navigate to the **Tools**
  section.\\n4. Click the **+ Add MCP** button.\\n5. Enter the following
  command:\\n\\n   ```\\n   npx -y @upstash/context7-mcp@latest\\n   ```\\n\\n6.
  Name the MCP: **Context7**.\\n7. Click the **Add** button.\\n\\nOnce the MCP
  server is added, you can start using Context7's up-to-date code documentation
  features directly within Augment Code.\\n\\n---\\n\\n### **B. Manual
  Configuration**\\n\\n1. Press Cmd/Ctrl Shift P or go to the hamburger menu in
  the Augment panel\\n2. Select Edit Settings\\n3. Under Advanced, click Edit in
  settings.json\\n4. Add the server configuration to the `mcpServers` array in
  the `augment.advanced` object\\n\\n\\\"augment.advanced\\\":
  {\\n\\\"mcpServers\\\": [\\n{\\n\\\"name\\\":
  \\\"context7\\\",\\n\\\"command\\\": \\\"npx\\\",\\n\\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n}\\n]\\n}\\n\\nOnce the MCP server is added,
  restart your editor. If you receive any errors, check the syntax to make sure
  closing brackets or commas are not
  missing.\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in Roo
  Code</b></summary>\\n\\nAdd this to your Roo Code MCP configuration file. See
  [Roo Code MCP docs](https://docs.roocode.com/features/mcp/using-mcp-in-roo)
  for more info.\\n\\n#### Roo Code Remote Server
  Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"type\\\": \\\"streamable-http\\\",\\n      \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n    }\\n  }\\n}\\n```\\n\\n#### Roo
  Code Local Server Connection\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary><b>Install in Zencoder</b></summary>\\n\\nTo configure
  Context7 MCP in Zencoder, follow these steps:\\n\\n1. Go to the Zencoder menu
  (...)\\n2. From the dropdown menu, select Agent tools\\n3. Click on the Add
  custom MCP\\n4. Add the name and server configuration from below, and make
  sure to hit the Install button\\n\\n```json\\n{\\n    \\\"command\\\":
  \\\"npx\\\",\\n    \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@upstash/context7-mcp@latest\\\"\\n    ]\
  \\n}\\n```\\n\\nOnce the MCP server is added, you can easily continue using
  it.\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in Amazon Q Developer
  CLI</b></summary>\\n\\nAdd this to your Amazon Q Developer CLI configuration
  file. See [Amazon Q Developer CLI
  docs](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-m\
  cp-configuration.html) for more
  details.\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp@latest\\\"]\\n    }\\n  }\\n}\\n```\\n</details>\\n\
  \\n<details>\\n<summary><b>Install in Qodo Gen</b></summary>\\n\\nSee [Qodo
  Gen
  docs](https://docs.qodo.ai/qodo-documentation/qodo-gen/qodo-gen-chat/agentic-\
  mode/agentic-tools-mcps) for more details.\\n\\n1. Open Qodo Gen chat panel in
  VSCode or IntelliJ.\\n2. Click Connect more tools.\\n3. Click + Add new
  MCP.\\n4. Add the following
  configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"url\\\":
  \\\"https://mcp.context7.com/mcp\\\"\\n    }\\n  }\\n}\\n```\\n</details>\\n\
  \\n<details>\\n<summary><b>Install in JetBrains AI
  Assistant</b></summary>\\n\\nSee [JetBrains AI Assistant
  Documentation](https://www.jetbrains.com/help/ai-assistant/configure-an-mcp-s\
  erver.html) for more details.\\n\\n1. In JetBrains IDEs go to `Settings` ->
  `Tools` -> `AI Assistant` -> `Model Context Protocol (MCP)`\\n2. Click `+
  Add`.\\n3. Click on `Command` in the top-left corner of the dialog and select
  the As JSON option from the list\\n4. Add this configuration and click
  `OK`\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n5. Click `Apply`
  to save changes.\\n\\n</details>\\n\\n<details>\\n<summary><b>Install in
  Warp</b></summary>\\n\\nSee [Warp Model Context Protocol
  Documentation](https://docs.warp.dev/knowledge-and-collaboration/mcp#adding-a\
  n-mcp-server) for details.\\n\\n1. Navigate `Settings` > `AI` > `Manage MCP
  servers`.\\n2. Add a new MCP server by clicking the `+ Add` button.\\n3. Paste
  the configuration given below:\\n\\n```json\\n{\\n  \\\"Context7\\\":
  {\\n    \\\"command\\\": \\\"npx\\\",\\n    \\\"args\\\":
  [\\n      \\\"-y\\\",\\n      \\\"@upstash/context7-mcp\\\"\\n    ],\\n    \\\
  \"env\\\": {},\\n    \\\"working_directory\\\":
  null,\\n    \\\"start_on_launch\\\": true\\n  }\\n}\\n```\\n\\n4. Click `Save`
  to apply the changes.\\n\\n</details>\\n\\n##  Available Tools\\n\\nContext7
  MCP provides the following tools that LLMs can use:\\n\\n-
  `resolve-library-id`: Resolves a general library name into a
  Context7-compatible library ID.\\n\\n  - `libraryName` (required): The name of
  the library to search for\\n\\n- `get-library-docs`: Fetches documentation for
  a library using a Context7-compatible library ID.\\n  -
  `context7CompatibleLibraryID` (required): Exact Context7-compatible library ID
  (e.g., `/mongodb/docs`, `/vercel/next.js`)\\n  - `topic` (optional): Focus the
  docs on a specific topic (e.g., \\\"routing\\\", \\\"hooks\\\")\\n  - `tokens`
  (optional, default 10000): Max number of tokens to return. Values less than
  the default value of 10000 are automatically increased to 10000.\\n\\n## 
  Tips\\n\\n### Add a Rule\\n> If you dont want to add `use context7` to every
  prompt, you can define a simple rule in your `.windsurfrules` file in Windsurf
  or from `Cursor Settings > Rules` section in Cursor (or the equivalent in your
  MCP client) to auto-invoke Context7 on any code question:\\n> ```toml\\n>
  [[calls]]\\n> match = \\\"when the user requests code examples, setup or
  configuration steps, or library/API documentation\\\"\\n> tool  =
  \\\"context7\\\"\\n> ```\\n> From then on youll get Context7s docs in any
  related conversation without typing anything extra. You can add your use cases
  to the match part.\\n\\n### Use Library Id\\n> If you already know exactly
  which library you want to use, add its Context7 ID to your prompt. That way,
  Context7 MCP server can skip the library-matching step and directly continue
  with retrieving docs.\\n> ```txt\\n> implement basic authentication with
  supabase. use library /supabase/supabase for api and docs\\n> ```\\n> The
  slash syntax tells the MCP tool exactly which library to load docs
  for.\\n\\n\\n\\n##  Development\\n\\nClone the project and install
  dependencies:\\n\\n```bash\\nbun i\\n```\\n\\nBuild:\\n\\n```bash\\nbun run
  build\\n```\\n\\nRun the server:\\n\\n```bash\\nbun run
  dist/index.js\\n```\\n\\n### CLI Arguments\\n\\n`context7-mcp` accepts the
  following CLI flags:\\n\\n- `--transport <stdio|http|sse>`  Transport to use
  (`stdio` by default).\\n- `--port <number>`  Port to listen on when using
  `http` or `sse` transport (default `3000`).\\n\\nExample with http transport
  and port 8080:\\n\\n```bash\\nbun run dist/index.js --transport http --port
  8080\\n```\\n\\n<details>\\n<summary><b>Local Configuration
  Example</b></summary>\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"tsx\\\",
  \\\"/path/to/folder/context7-mcp/src/index.ts\\\"]\\n    }\\n  }\\n}\\n```\\n\
  \\n</details>\\n\\n<details>\\n<summary><b>Testing with MCP
  Inspector</b></summary>\\n\\n```bash\\nnpx -y @modelcontextprotocol/inspector
  npx @upstash/context7-mcp\\n```\\n\\n</details>\\n\\n## 
  Troubleshooting\\n\\n<details>\\n<summary><b>Module Not Found
  Errors</b></summary>\\n\\nIf you encounter `ERR_MODULE_NOT_FOUND`, try using
  `bunx` instead of `npx`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"context7\\\": {\\n      \\\"command\\\":
  \\\"bunx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\nThis often
  resolves module resolution issues in environments where `npx` doesn't properly
  install or resolve packages.\\n\\n</details>\\n\\n<details>\\n<summary><b>ESM
  Resolution Issues</b></summary>\\n\\nFor errors like `Error: Cannot find
  module 'uriTemplate.js'`, try the `--experimental-vm-modules`
  flag:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"--node-options=--experimental-vm-modules\\\",
  \\\"@upstash/context7-mcp@1.0.6\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\
  \\n\\n<details>\\n<summary><b>TLS/Certificate Issues</b></summary>\\n\\nUse
  the `--experimental-fetch` flag to bypass TLS-related
  problems:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"context7\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"--node-options=--experimental-fetch\\\",
  \\\"@upstash/context7-mcp\\\"]\\n    }\\n  }\\n}\\n```\\n\\n</details>\\n\\n<\
  details>\\n<summary><b>General MCP Client Errors</b></summary>\\n\\n1. Try
  adding `@latest` to the package name\\n2. Use `bunx` as an alternative to
  `npx`\\n3. Consider using `deno` as another alternative\\n4. Ensure you're
  using Node.js v18 or higher for native fetch support\\n\\n</details>\\n\\n##
   Disclaimer\\n\\nContext7 projects are community-contributed and while we
  strive to maintain high quality, we cannot guarantee the accuracy,
  completeness, or security of all library documentation. Projects listed in
  Context7 are developed and maintained by their respective owners, not by
  Context7. If you encounter any suspicious, inappropriate, or potentially
  harmful content, please use the \\\"Report\\\" button on the project page to
  notify us immediately. We take all reports seriously and will review flagged
  content promptly to maintain the integrity and safety of our platform. By
  using Context7, you acknowledge that you do so at your own discretion and
  risk.\\n\\n##  Connect with Us\\n\\nStay updated and join our
  community:\\n\\n-  Follow us on [X](https://x.com/contextai) for the latest
  news and updates\\n-  Visit our [Website](https://context7.com)\\n-  Join
  our [Discord Community](https://upstash.com/discord)\\n\\n##  Context7 In
  Media\\n\\n- [Better Stack: \\\"Free Tool Makes Cursor 10x
  Smarter\\\"](https://youtu.be/52FC3qObp9E)\\n- [Cole Medin: \\\"This is Hands
  Down the BEST MCP Server for AI Coding
  Assistants\\\"](https://www.youtube.com/watch?v=G7gK8H6u7Rs)\\n- [Income
  Stream Surfers: \\\"Context7 + SequentialThinking MCPs: Is This
  AGI?\\\"](https://www.youtube.com/watch?v=-ggvzyLpK6o)\\n- [Julian Goldie SEO:
  \\\"Context7: New MCP AI Agent
  Update\\\"](https://www.youtube.com/watch?v=CTZm6fBYisc)\\n- [JeredBlu:
  \\\"Context 7 MCP: Get Documentation Instantly + VS Code
  Setup\\\"](https://www.youtube.com/watch?v=-ls0D-rtET4)\\n- [Income Stream
  Surfers: \\\"Context7: The New MCP Server That Will CHANGE AI
  Coding\\\"](https://www.youtube.com/watch?v=PS-2Azb-C3M)\\n- [AICodeKing:
  \\\"Context7 + Cline & RooCode: This MCP Server Makes CLINE 100X MORE
  EFFECTIVE!\\\"](https://www.youtube.com/watch?v=qZfENAPMnyo)\\n- [Sean Kochel:
  \\\"5 MCP Servers For Vibe Coding Glory (Just Plug-In &
  Go)\\\"](https://www.youtube.com/watch?v=LqTQi8qexJM)\\n\\n##  Star
  History\\n\\n[![Star History
  Chart](https://api.star-history.com/svg?repos=upstash/context7&type=Date)](ht\
  tps://www.star-history.com/#upstash/context7&Date)\\n\\n## 
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":17631,\"downloa\
  dCount\":55067,\"createdAt\":\"2025-04-18T21:16:05.668719Z\",\"updatedAt\":\"\
  2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T21:43:30.072074Z\
  \"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/cost-analysis-mcp-server\
  \",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/cost-analysis\
  -mcp-server\",\"name\":\"Cost
  Analysis\",\"author\":\"awslabs\",\"description\":\"Analyzes AWS service costs
  and generates cost reports with natural language querying capabilities and
  visualization tools for cost
  optimization.\",\"codiconIcon\":\"graph\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/aws.png\",\"category\":\"monitoring\",\"tags\":[\
  \"aws-costs\",\"cost-optimization\",\"cloud-pricing\",\"reporting\",\"analyti\
  cs\"],\"requiresApiKey\":false,\"readmeContent\":\"# Cost Analysis MCP
  Server\\n\\nMCP server for generating upfront AWS service cost estimates and
  providing cost insights\\n\\n**Important Note**: This server provides
  estimated pricing based on AWS pricing APIs and web pages. These estimates are
  for pre-deployment planning purposes and do not reflect the actual expenses of
  deployed cloud services.\\n\\n## Features\\n\\n### Analyze and visualize AWS
  costs\\n\\n- Get detailed breakdown of your AWS costs by service, region and
  tier\\n- Understand how costs are distributed across various services\\n-
  Provide pre-deployment cost estimates for infrastructure planning\\n- Support
  for analyzing both CDK and Terraform projects to identify AWS
  services\\n\\n### Query cost data with natural language\\n\\n- Ask questions
  about your AWS costs in plain English, no complex query languages required\\n-
  Get instant answers fetched from pricing webpage and AWS Pricing API, for
  questions related to AWS services\\n- Retrieve estimated pricing information
  before actual cloud service deployment\\n\\n### Generate cost reports and
  insights\\n\\n- Generate comprehensive cost estimates based on your IaC
  implementation\\n- Get cost optimization recommendations for potential cloud
  infrastructure\\n- Provide upfront pricing analysis to support informed
  decision-making\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS services\\n   - You need an AWS account with appropriate
  permissions\\n   - Configure AWS credentials with `aws configure` or
  environment variables\\n   - Ensure your IAM role/user has permissions to
  access AWS Pricing API\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.cost-analysis-mcp-server&config=eyJjb21tYW5kIjoidX\
  Z4IGF3c2xhYnMuY29zdC1hbmFseXNpcy1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJGQVNUTUN\
  QX0xPR19MRVZFTCI6IkVSUk9SIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIn0sImRp\
  c2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nConfigure the MCP
  server in your MCP client configuration (e.g., for Amazon Q Developer CLI,
  edit `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cost-analysis-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.cost-analysis-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/cost-analysis-mcp-server
  .`:\\n\\n```file\\n# fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\": {\\n      \\\"awslabs.cost-analysis-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file/abov\
  e/.env\\\",\\n          \\\"awslabs/cost-analysis-mcp-server:latest\\\"\\n        \
  ],\\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\n### AWS Authentication\\n\\nThe MCP server
  uses the AWS profile specified in the `AWS_PROFILE` environment variable. If
  not provided, it defaults to the \\\"default\\\" profile in your AWS
  configuration file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n}\\n```\\n\\nMake sure the AWS profile has
  permissions to access the AWS Pricing API. The MCP server creates a boto3
  session using the specified profile to authenticate with AWS services. Your
  AWS IAM credentials remain on your local machine and are strictly used for
  accessing AWS
  services.\\n\",\"isRecommended\":false,\"githubStars\":4282,\"downloadCount\"\
  :1322,\"createdAt\":\"2025-04-04T01:26:17.400469Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06-30T16:51:52.125568Z\"},{\"m\
  cpId\":\"github.com/canvrno/ProxmoxMCP\",\"githubUrl\":\"https://github.com/c\
  anvrno/ProxmoxMCP\",\"name\":\"Proxmox
  Manager\",\"author\":\"canvrno\",\"description\":\"A server for managing
  Proxmox hypervisors, providing tools to control nodes, VMs, containers,
  storage, and execute console commands in virtual
  machines.\",\"codiconIcon\":\"server\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/proxmox-manager.png\",\"category\":\"virtualization\
  \",\"tags\":[\"proxmox\",\"virtualization\",\"vm-management\",\"server-manage\
  ment\",\"infrastructure\"],\"requiresApiKey\":false,\"readmeContent\":\"# 
  Proxmox Manager - Proxmox MCP
  Server\\n\\n![ProxmoxMCP](https://github.com/user-attachments/assets/e32ab79f\
  -be8a-420c-ab2d-475612150534)\\n\\nA Python-based Model Context Protocol (MCP)
  server for interacting with Proxmox hypervisors, providing a clean interface
  for managing nodes, VMs, and containers.\\n\\n##  Built With\\n\\n-
  [Cline](https://github.com/cline/cline) - Autonomous coding agent - Go faster
  with Cline.\\n- [Proxmoxer](https://github.com/proxmoxer/proxmoxer) - Python
  wrapper for Proxmox API\\n- [MCP
  SDK](https://github.com/modelcontextprotocol/sdk) - Model Context Protocol
  SDK\\n- [Pydantic](https://docs.pydantic.dev/) - Data validation using Python
  type annotations\\n\\n##  Features\\n\\n-  Full integration with Cline\\n-
   Built with the official MCP SDK\\n-  Secure token-based authentication
  with Proxmox\\n-  Tools for managing nodes and VMs\\n-  VM console
  command execution\\n-  Configurable logging system\\n-  Type-safe
  implementation with Pydantic\\n-  Rich output formatting with customizable
  themes\\n\\n\\n\\nhttps://github.com/user-attachments/assets/1b5f42f7-85d5-49\
  18-aca4-d38413b0e82b\\n\\n\\n\\n##  Installation\\n\\n### Prerequisites\\n-
  UV package manager (recommended)\\n- Python 3.10 or higher\\n- Git\\n- Access
  to a Proxmox server with API token credentials\\n\\nBefore starting, ensure
  you have:\\n- [ ] Proxmox server hostname or IP\\n- [ ] Proxmox API token (see
  [API Token Setup](#proxmox-api-token-setup))\\n- [ ] UV installed (`pip
  install uv`)\\n\\n### Option 1: Quick Install (Recommended)\\n\\n1. Clone and
  set up environment:\\n   ```bash\\n   # Clone repository\\n   cd
  ~/Documents/Cline/MCP  # For Cline users\\n   # OR\\n   cd
  your/preferred/directory  # For manual installation\\n   \\n   git clone
  https://github.com/canvrno/ProxmoxMCP.git\\n   cd ProxmoxMCP\\n\\n   # Create
  and activate virtual environment\\n   uv venv\\n   source
  .venv/bin/activate  # Linux/macOS\\n   #
  OR\\n   .\\\\.venv\\\\Scripts\\\\Activate.ps1  # Windows\\n   ```\\n\\n2.
  Install dependencies:\\n   ```bash\\n   # Install with development
  dependencies\\n   uv pip install -e \\\".[dev]\\\"\\n   ```\\n\\n3. Create
  configuration:\\n   ```bash\\n   # Create config directory and copy
  template\\n   mkdir -p proxmox-config\\n   cp config/config.example.json
  proxmox-config/config.json\\n   ```\\n\\n4. Edit
  `proxmox-config/config.json`:\\n   ```json\\n   {\\n       \\\"proxmox\\\":
  {\\n           \\\"host\\\": \\\"PROXMOX_HOST\\\",        # Required: Your
  Proxmox server address\\n           \\\"port\\\": 8006,                  #
  Optional: Default is 8006\\n           \\\"verify_ssl\\\": false,           #
  Optional: Set false for self-signed certs\\n           \\\"service\\\":
  \\\"PVE\\\"               # Optional: Default is
  PVE\\n       },\\n       \\\"auth\\\": {\\n           \\\"user\\\":
  \\\"USER@pve\\\",            # Required: Your Proxmox
  username\\n           \\\"token_name\\\": \\\"TOKEN_NAME\\\",    # Required:
  API token ID\\n           \\\"token_value\\\": \\\"TOKEN_VALUE\\\"   #
  Required: API token value\\n       },\\n       \\\"logging\\\":
  {\\n           \\\"level\\\": \\\"INFO\\\",               # Optional: DEBUG
  for more detail\\n           \\\"format\\\": \\\"%(asctime)s - %(name)s -
  %(levelname)s - %(message)s\\\",\\n           \\\"file\\\":
  \\\"proxmox_mcp.log\\\"      # Optional: Log to
  file\\n       }\\n   }\\n   ```\\n\\n### Verifying Installation\\n\\n1. Check
  Python environment:\\n   ```bash\\n   python -c \\\"import proxmox_mcp;
  print('Installation OK')\\\"\\n   ```\\n\\n2. Run the
  tests:\\n   ```bash\\n   pytest\\n   ```\\n\\n3. Verify
  configuration:\\n   ```bash\\n   #
  Linux/macOS\\n   PROXMOX_MCP_CONFIG=\\\"proxmox-config/config.json\\\" python
  -m proxmox_mcp.server\\n\\n   # Windows
  (PowerShell)\\n   $env:PROXMOX_MCP_CONFIG=\\\"proxmox-config\\\\config.json\\\
  \"; python -m proxmox_mcp.server\\n   ```\\n\\n   You should see
  either:\\n   - A successful connection to your Proxmox server\\n   - Or a
  connection error (if Proxmox details are incorrect)\\n\\n## 
  Configuration\\n\\n### Proxmox API Token Setup\\n1. Log into your Proxmox web
  interface\\n2. Navigate to Datacenter -> Permissions -> API Tokens\\n3. Create
  a new API token:\\n   - Select a user (e.g., root@pam)\\n   - Enter a token ID
  (e.g., \\\"mcp-token\\\")\\n   - Uncheck \\\"Privilege Separation\\\" if you
  want full access\\n   - Save and copy both the token ID and secret\\n\\n\\n##
   Running the Server\\n\\n### Development Mode\\nFor testing and
  development:\\n```bash\\n# Activate virtual environment first\\nsource
  .venv/bin/activate  # Linux/macOS\\n#
  OR\\n.\\\\.venv\\\\Scripts\\\\Activate.ps1  # Windows\\n\\n# Run the
  server\\npython -m proxmox_mcp.server\\n```\\n\\n### Cline Desktop
  Integration\\n\\nFor Cline users, add this configuration to your MCP settings
  file (typically at
  `~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_\
  settings.json`):\\n\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"github.com/canvrno/ProxmoxMCP\\\":
  {\\n            \\\"command\\\":
  \\\"/absolute/path/to/ProxmoxMCP/.venv/bin/python\\\",\\n            \\\"args\
  \\\": [\\\"-m\\\", \\\"proxmox_mcp.server\\\"],\\n            \\\"cwd\\\":
  \\\"/absolute/path/to/ProxmoxMCP\\\",\\n            \\\"env\\\":
  {\\n                \\\"PYTHONPATH\\\":
  \\\"/absolute/path/to/ProxmoxMCP/src\\\",\\n                \\\"PROXMOX_MCP_C\
  ONFIG\\\":
  \\\"/absolute/path/to/ProxmoxMCP/proxmox-config/config.json\\\",\\n                \
  \\\"PROXMOX_HOST\\\":
  \\\"your-proxmox-host\\\",\\n                \\\"PROXMOX_USER\\\":
  \\\"username@pve\\\",\\n                \\\"PROXMOX_TOKEN_NAME\\\":
  \\\"token-name\\\",\\n                \\\"PROXMOX_TOKEN_VALUE\\\":
  \\\"token-value\\\",\\n                \\\"PROXMOX_PORT\\\":
  \\\"8006\\\",\\n                \\\"PROXMOX_VERIFY_SSL\\\":
  \\\"false\\\",\\n                \\\"PROXMOX_SERVICE\\\":
  \\\"PVE\\\",\\n                \\\"LOG_LEVEL\\\":
  \\\"DEBUG\\\"\\n            },\\n            \\\"disabled\\\":
  false,\\n            \\\"autoApprove\\\":
  []\\n        }\\n    }\\n}\\n```\\n\\nTo help generate the correct paths, you
  can use this command:\\n```bash\\n# This will print the MCP settings with your
  absolute paths filled in\\npython -c \\\"import os;
  print(f'''{{\\n    \\\\\\\"mcpServers\\\\\\\":
  {{\\n        \\\\\\\"github.com/canvrno/ProxmoxMCP\\\\\\\":
  {{\\n            \\\\\\\"command\\\\\\\":
  \\\\\\\"{os.path.abspath('.venv/bin/python')}\\\\\\\",\\n            \\\\\\\"\
  args\\\\\\\": [\\\\\\\"-m\\\\\\\",
  \\\\\\\"proxmox_mcp.server\\\\\\\"],\\n            \\\\\\\"cwd\\\\\\\":
  \\\\\\\"{os.getcwd()}\\\\\\\",\\n            \\\\\\\"env\\\\\\\":
  {{\\n                \\\\\\\"PYTHONPATH\\\\\\\":
  \\\\\\\"{os.path.abspath('src')}\\\\\\\",\\n                \\\\\\\"PROXMOX_M\
  CP_CONFIG\\\\\\\":
  \\\\\\\"{os.path.abspath('proxmox-config/config.json')}\\\\\\\",\\n                \
  ...\\n            }}\\n        }}\\n    }}\\n}}''')\\\"\\n```\\n\\nImportant:\
  \\n- All paths must be absolute\\n- The Python interpreter must be from your
  virtual environment\\n- The PYTHONPATH must point to the src directory\\n-
  Restart VSCode after updating MCP settings\\n\\n#  Available Tools\\n\\nThe
  server provides the following MCP tools for interacting with Proxmox:\\n\\n###
  get_nodes\\nLists all nodes in the Proxmox cluster.\\n\\n- Parameters:
  None\\n- Example Response:\\n  ```\\n   Proxmox Nodes\\n\\n  
  pve-compute-01\\n     Status: ONLINE\\n     Uptime:  156d 12h\\n     CPU
  Cores: 64\\n     Memory: 186.5 GB / 512.0 GB (36.4%)\\n\\n  
  pve-compute-02\\n     Status: ONLINE\\n     Uptime:  156d 11h\\n     CPU
  Cores: 64\\n     Memory: 201.3 GB / 512.0 GB (39.3%)\\n  ```\\n\\n###
  get_node_status\\nGet detailed status of a specific node.\\n\\n-
  Parameters:\\n  - `node` (string, required): Name of the node\\n- Example
  Response:\\n  ```\\n   Node: pve-compute-01\\n     Status: ONLINE\\n    
  Uptime:  156d 12h\\n     CPU Usage: 42.3%\\n     CPU Cores: 64 (AMD EPYC
  7763)\\n     Memory: 186.5 GB / 512.0 GB (36.4%)\\n     Network:  12.8
  GB/s  9.2 GB/s\\n     Temperature: 38C\\n  ```\\n\\n### get_vms\\nList all
  VMs across the cluster.\\n\\n- Parameters: None\\n- Example
  Response:\\n  ```\\n   Virtual Machines\\n\\n   prod-db-master (ID:
  100)\\n     Status: RUNNING\\n     Node: pve-compute-01\\n     CPU Cores:
  16\\n     Memory: 92.3 GB / 128.0 GB (72.1%)\\n\\n   prod-web-01 (ID:
  102)\\n     Status: RUNNING\\n     Node: pve-compute-01\\n     CPU Cores:
  8\\n     Memory: 12.8 GB / 32.0 GB (40.0%)\\n  ```\\n\\n###
  get_storage\\nList available storage.\\n\\n- Parameters: None\\n- Example
  Response:\\n  ```\\n   Storage Pools\\n\\n   ceph-prod\\n     Status:
  ONLINE\\n     Type: rbd\\n     Usage: 12.8 TB / 20.0 TB (64.0%)\\n    
  IOPS:  15.2k  12.8k\\n\\n   local-zfs\\n     Status: ONLINE\\n    
  Type: zfspool\\n     Usage: 3.2 TB / 8.0 TB (40.0%)\\n     IOPS:  42.8k 
  35.6k\\n  ```\\n\\n### get_cluster_status\\nGet overall cluster status.\\n\\n-
  Parameters: None\\n- Example Response:\\n  ```\\n   Proxmox
  Cluster\\n\\n     Name: enterprise-cloud\\n     Status: HEALTHY\\n    
  Quorum: OK\\n     Nodes: 4 ONLINE\\n     Version: 8.1.3\\n     HA Status:
  ACTIVE\\n     Resources:\\n      - Total CPU Cores: 192\\n      - Total
  Memory: 1536 GB\\n      - Total Storage: 70 TB\\n     Workload:\\n      -
  Running VMs: 7\\n      - Total VMs: 8\\n      - Average CPU Usage:
  38.6%\\n      - Average Memory Usage: 42.8%\\n  ```\\n\\n###
  execute_vm_command\\nExecute a command in a VM's console using QEMU Guest
  Agent.\\n\\n- Parameters:\\n  - `node` (string, required): Name of the node
  where VM is running\\n  - `vmid` (string, required): ID of the VM\\n  -
  `command` (string, required): Command to execute\\n- Example
  Response:\\n  ```\\n   Console Command Result\\n     Status:
  SUCCESS\\n     Command: systemctl status nginx\\n     Node:
  pve-compute-01\\n     VM: prod-web-01 (ID: 102)\\n\\n  Output:\\n  
  nginx.service - A high performance web server and a reverse proxy
  server\\n     Loaded: loaded (/lib/systemd/system/nginx.service; enabled;
  vendor preset: enabled)\\n     Active: active (running) since Tue 2025-02-18
  15:23:45 UTC; 2 months 3 days ago\\n  ```\\n- Requirements:\\n  - VM must be
  running\\n  - QEMU Guest Agent must be installed and running in the VM\\n  -
  Command execution permissions must be enabled in the Guest Agent\\n- Error
  Handling:\\n  - Returns error if VM is not running\\n  - Returns error if VM
  is not found\\n  - Returns error if command execution fails\\n  - Includes
  command output even if command returns non-zero exit code\\n\\n## 
  Development\\n\\nAfter activating your virtual environment:\\n\\n- Run tests:
  `pytest`\\n- Format code: `black .`\\n- Type checking: `mypy .`\\n- Lint:
  `ruff .`\\n\\n##  Project Structure\\n\\n```\\nproxmox-mcp/\\n
  src/\\n    proxmox_mcp/\\n        server.py          # Main MCP server
  implementation\\n        config/            # Configuration
  handling\\n        core/              # Core functionality\\n       
  formatting/        # Output formatting and themes\\n       
  tools/             # Tool implementations\\n           console/       #
  VM console operations\\n        utils/             # Utilities (auth,
  logging)\\n tests/                     # Test suite\\n
  proxmox-config/\\n    config.example.json    # Configuration
  template\\n pyproject.toml            # Project metadata and
  dependencies\\n LICENSE                   # MIT License\\n```\\n\\n## 
  License\\n\\nMIT
  License\\n\",\"isRecommended\":false,\"githubStars\":127,\"downloadCount\":13\
  39,\"createdAt\":\"2025-02-19T07:28:09.637633Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T14:49:57.435176Z\"},{\"mcpId\
  \":\"github.com/Garoth/wolframalpha-llm-mcp\",\"githubUrl\":\"https://github.\
  com/Garoth/wolframalpha-llm-mcp\",\"name\":\"WolframAlpha\",\"author\":\"Garo\
  th\",\"description\":\"Provides access to WolframAlpha's LLM API for answering
  complex mathematical, scientific, and general knowledge questions with
  structured
  responses.\",\"codiconIcon\":\"symbol-numeric\",\"logoUrl\":\"https://storage\
  .googleapis.com/cline_public_images/wolframalpha.png\",\"category\":\"researc\
  h-data\",\"tags\":[\"mathematics\",\"scientific-computing\",\"knowledge-base\
  \",\"wolfram-api\",\"computation\"],\"requiresApiKey\":false,\"readmeContent\
  \":\"# WolframAlpha LLM MCP Server\\n\\n<img
  src=\\\"assets/wolfram-llm-logo.png\\\" width=\\\"256\\\" alt=\\\"WolframAlpha
  LLM MCP Logo\\\" />\\n\\nA Model Context Protocol (MCP) server that provides
  access to WolframAlpha's LLM API.
  https://products.wolframalpha.com/llm-api/documentation\\n\\n<div>\\n  <img
  src=\\\"assets/readme-screen-1.png\\\" width=\\\"609\\\" alt=\\\"WolframAlpha
  MCP Server Example 1\\\" /><br/><br/>\\n  <img
  src=\\\"assets/readme-screen-2.png\\\" width=\\\"609\\\" alt=\\\"WolframAlpha
  MCP Server Example 2\\\" />\\n</div>\\n\\n## Features\\n\\n- Query
  WolframAlpha's LLM API with natural language questions\\n- Answer complicated
  mathematical questions\\n- Query facts about science, physics, history,
  geography, and more\\n- Get structured responses optimized for LLM
  consumption\\n- Support for simplified answers and detailed responses with
  sections\\n\\n## Available Tools\\n\\n- `ask_llm`: Ask WolframAlpha a question
  and get a structured llm-friendly response\\n- `get_simple_answer`: Get a
  simplified answer\\n- `validate_key`: Validate the WolframAlpha API
  key\\n\\n## Installation\\n\\n```bash\\ngit clone
  https://github.com/Garoth/wolframalpha-llm-mcp.git\\nnpm install\\n```\\n\\n##
  Configuration\\n\\n1. Get your WolframAlpha API key from
  [developer.wolframalpha.com](https://developer.wolframalpha.com/)\\n\\n2. Add
  it to your Cline MCP settings file inside VSCode's settings (ex.
  ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_s\
  ettings.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"wolframalpha\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/wolframalpha-mcp-server/build/index.js\\\"],\\n      \\\"env\\\
  \": {\\n        \\\"WOLFRAM_LLM_APP_ID\\\":
  \\\"your-api-key-here\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\":
  [\\n        \\\"ask_llm\\\",\\n        \\\"get_simple_answer\\\",\\n        \\\
  \"validate_key\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n##
  Development\\n\\n### Setting Up Tests\\n\\nThe tests use real API calls to
  ensure accurate responses. To run the tests:\\n\\n1. Copy the example
  environment file:\\n   ```bash\\n   cp .env.example .env\\n   ```\\n\\n2. Edit
  `.env` and add your WolframAlpha API
  key:\\n   ```\\n   WOLFRAM_LLM_APP_ID=your-api-key-here\\n   ```\\n   Note:
  The `.env` file is gitignored to prevent committing sensitive
  information.\\n\\n3. Run the tests:\\n   ```bash\\n   npm
  test\\n   ```\\n\\n### Building\\n\\n```bash\\nnpm run build\\n```\\n\\n##
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":34,\"downloadCo\
  unt\":2025,\"createdAt\":\"2025-02-20T23:51:50.467973Z\",\"updatedAt\":\"2025\
  -07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T01:52:08.228334Z\"}\
  ,{\"mcpId\":\"github.com/sendaifun/solana-mcp\",\"githubUrl\":\"https://githu\
  b.com/sendaifun/solana-mcp\",\"name\":\"Solana Agent
  Kit\",\"author\":\"sendaifun\",\"description\":\"Provides tools for
  interacting with the Solana blockchain, enabling operations like token
  management, NFT minting, trading, and wallet interactions through a
  standardized
  interface.\",\"codiconIcon\":\"link\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/sendai.jpg\",\"category\":\"finance\",\"tags\":[\"b\
  lockchain\",\"solana\",\"cryptocurrency\",\"web3\",\"tokens\"],\"requiresApiK\
  ey\":false,\"readmeContent\":\"# Solana Agent Kit MCP Server\\n\\n[![npm
  version](https://badge.fury.io/js/solana-mcp.svg)](https://www.npmjs.com/pack\
  age/solana-mcp)\\n[![License:
  ISC](https://img.shields.io/badge/License-ISC-blue.svg)](https://opensource.o\
  rg/licenses/ISC)\\n<a
  href=\\\"https://cloud.phala.network/features/mcp-hosting/solana-mcp-by-senda\
  i-and-dark\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"
  style=\\\"display:inline-flex;align-items:center;text-decoration:none;backgro\
  und:#fff;border:1px solid #e5e7eb;border-radius:6px;padding:2px
  8px;font-size:16px;font-family:sans-serif;\\\">\\n  <img
  src=\\\"https://raw.githubusercontent.com/Phala-Network/mcp-hosting/refs/head\
  s/main/assets/logs/phala.png\\\" alt=\\\"Phala Logo\\\" height=\\\"24\\\"
  style=\\\"vertical-align:middle;margin-right:8px;\\\"/>\\n  <span
  style=\\\"color:#222;font-weight:600;\\\">Check on Phala</span>\\n</a>\\n\\nA
  Model Context Protocol (MCP) server that provides onchain tools for Claude AI,
  allowing it to interact with the Solana blockchain through a standardized
  interface. This implementation is based on the Solana Agent Kit and enables AI
  agents to perform blockchain operations seamlessly.\\n\\n\\n\\n\\n##
  Overview\\n\\nThis MCP server extends Claude's capabilities by providing tools
  to:\\n\\n* Interact with Solana blockchain\\n* Execute transactions\\n* Query
  account information\\n* Manage Solana wallets\\n\\nThe server implements the
  Model Context Protocol specification to standardize blockchain interactions
  for AI agents.\\n\\n## Prerequisites\\n\\n* Node.js (v16 or higher)\\n* pnpm
  (recommended), npm, or yarn\\n* Solana wallet with private key\\n* Solana RPC
  URL (mainnet, testnet, or devnet)\\n\\n## Installation\\n\\n### Option 1:
  Quick Install (Recommended)\\n\\n```bash\\n# Download the installation
  script\\ncurl -fsSL
  https://raw.githubusercontent.com/sendaifun/solana-mcp/main/scripts/install.sh
  -o solana-mcp-install.sh\\n\\n# Make it executable and run\\nchmod +x
  solana-mcp-install.sh && ./solana-mcp-install.sh --backup\\n```\\n\\nThis will
  start an interactive installation process that will guide you through:\\n-
  Setting up Node.js if needed\\n- Configuring your Solana RPC URL and private
  key\\n- Setting up the Claude Desktop integration\\n\\n### Option 2: Install
  from npm ( recommend for clients like Cursor/Cline)\\n\\n```bash\\n# Install
  globally\\nnpm install -g solana-mcp\\n\\n# Or install locally in your
  project\\nnpm install solana-mcp\\n```\\n\\n### Option 3: Build from
  Source\\n\\n1. Clone this repository:\\n```bash\\ngit clone
  https://github.com/sendaifun/solana-mcp\\ncd solana-mcp\\n```\\n\\n2. Install
  dependencies:\\n```bash\\npnpm install\\n```\\n\\n3. Build the
  project:\\n```bash\\npnpm run build\\n```\\n\\n## Configuration\\n\\n###
  Environment Setup\\n\\nCreate a `.env` file with your
  credentials:\\n\\n```env\\n# Solana
  Configuration\\nSOLANA_PRIVATE_KEY=your_private_key_here\\nRPC_URL=your_solan\
  a_rpc_url_here\\nOPENAI_API_KEY=your_openai_api_key # OPTIONAL\\n```\\n\\n###
  Integration with Claude Desktop\\n\\nTo add this MCP server to Claude Desktop,
  follow these steps:\\n\\n1. **Locate the Claude Desktop Configuration
  File**\\n   - macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n   - Windows:
  `%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\\n   - Linux:
  `~/.config/Claude/claude_desktop_config.json`\\n\\n2. **Add the
  Configuration**\\n   Create or edit the configuration file and add the
  following JSON:\\n\\n   If you installed via npm (Option
  1):\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"solana-mcp\\\": {\\n         \\\"command\\\":
  \\\"npx\\\",\\n         \\\"args\\\":
  [\\\"solana-mcp\\\"],\\n         \\\"env\\\": {\\n           \\\"RPC_URL\\\":
  \\\"your_solana_rpc_url_here\\\",\\n           \\\"SOLANA_PRIVATE_KEY\\\":
  \\\"your_private_key_here\\\",\\n           \\\"OPENAI_API_KEY\\\":
  \\\"your_openai_api_key\\\"  //
  OPTIONAL\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n   If you built from source
  (Option 2):\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"solana-mcp\\\": {\\n         \\\"command\\\":
  \\\"node\\\",\\n         \\\"args\\\":
  [\\\"/path/to/solana-mcp/build/index.js\\\"],\\n         \\\"env\\\":
  {\\n           \\\"RPC_URL\\\":
  \\\"your_solana_rpc_url_here\\\",\\n           \\\"SOLANA_PRIVATE_KEY\\\":
  \\\"your_private_key_here\\\",\\n           \\\"OPENAI_API_KEY\\\":
  \\\"your_openai_api_key\\\"  //
  OPTIONAL\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n3. **Restart Claude
  Desktop**\\n   After making these changes, restart Claude Desktop for the
  configuration to take effect.\\n\\n## Project
  Structure\\n\\n```\\nsolana-agent-kit-mcp/\\n src/\\n   
  index.ts          # Main entry point\\n package.json\\n
  tsconfig.json\\n```\\n\\n## Available Tools\\n\\nThe MCP server provides the
  following Solana blockchain tools:\\n\\n* `GET_ASSET` - Retrieve information
  about a Solana asset/token\\n* `DEPLOY_TOKEN` - Deploy a new token on
  Solana\\n* `GET_PRICE` - Fetch price information for tokens\\n*
  `WALLET_ADDRESS` - Get the wallet address\\n* `BALANCE` - Check wallet
  balance\\n* `TRANSFER` - Transfer tokens between wallets\\n* `MINT_NFT` -
  Create and mint new NFTs\\n* `TRADE` - Execute token trades\\n*
  `REQUEST_FUNDS` - Request funds (useful for testing/development)\\n*
  `RESOLVE_DOMAIN` - Resolve Solana domain names\\n* `GET_TPS` - Get current
  transactions per second on Solana\\n\\n## Security Considerations\\n\\n* Keep
  your private key secure and never share it\\n* Use environment variables for
  sensitive information\\n* Consider using a dedicated wallet for AI agent
  operations\\n* Regularly monitor and audit AI agent activities\\n* Test
  operations on devnet/testnet before mainnet\\n\\n## Troubleshooting\\n\\nIf
  you encounter issues:\\n\\n1. Verify your Solana private key is correct\\n2.
  Check your RPC URL is accessible\\n3. Ensure you're on the intended network
  (mainnet, testnet, or devnet)\\n4. Check Claude Desktop logs for error
  messages\\n5. Verify the build was successful\\n\\n## Dependencies\\n\\nKey
  dependencies include:\\n*
  [@solana/web3.js](https://github.com/solana-labs/solana-web3.js)\\n*
  [@modelcontextprotocol/sdk](https://github.com/modelcontextprotocol/typescrip\
  t-sdk)\\n*
  [solana-agent-kit](https://github.com/sendaifun/solana-agent-kit)\\n\\n##
  Contributing\\n\\nContributions are welcome! Please feel free to submit a Pull
  Request.\\n\\n1. Fork the repository\\n2. Create your feature branch (`git
  checkout -b feature/amazing-feature`)\\n3. Commit your changes (`git commit -m
  'Add some amazing feature'`)\\n4. Push to the branch (`git push origin
  feature/amazing-feature`)\\n5. Open a Pull Request\\n\\n## License\\n\\nThis
  project is licensed under the MIT
  License.\\n\",\"isRecommended\":false,\"githubStars\":96,\"downloadCount\":94\
  3,\"createdAt\":\"2025-03-10T20:11:10.747447Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T06:15:03.55117Z\"},{\"mcpId\
  \":\"github.com/awslabs/mcp/tree/main/src/mysql-mcp-server\",\"githubUrl\":\"\
  https://github.com/awslabs/mcp/tree/main/src/mysql-mcp-server\",\"name\":\"Au\
  rora MySQL\",\"author\":\"awslabs\",\"description\":\"Enables natural language
  to SQL query conversion and execution for Aurora MySQL databases through AWS
  RDS Data API, with configurable read-only mode and secure credential
  management.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\
  \"aurora\",\"mysql\",\"aws\",\"sql\",\"data-api\"],\"requiresApiKey\":false,\
  \"readmeContent\":\"# AWS Labs MySQL MCP Server\\n\\nAn AWS Labs Model Context
  Protocol (MCP) server for Aurora MySQL\\n\\n## Features\\n\\n### Natural
  language to MySQL SQL query\\n\\n- Converting human-readable questions and
  commands into structured MySQL-compatible SQL queries and executing them
  against the configured Aurora MySQL database.\\n\\n## Prerequisites\\n\\n1.
  Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Aurora MySQL Cluster with MySQL
  username and password stored in AWS Secrets Manager\\n4. Enable RDS Data API
  for your Aurora MySQL Cluster, see [instructions
  here](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.h\
  tml)\\n5. This MCP server can only be run locally on the same host as your LLM
  client.\\n6. Docker runtime\\n7. Set up AWS credentials with access to AWS
  services\\n   - You need an AWS account with appropriate permissions\\n   -
  Configure AWS credentials with `aws configure` or environment
  variables\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.mysql-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2\
  xhYnMubXlzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1yZXNvdXJjZV9hcm4gW3lvdXIgZGF0YV0gLS1\
  zZWNyZXRfYXJuIFt5b3VyIGRhdGFdIC0tZGF0YWJhc2UgW3lvdXIgZGF0YV0gLS1yZWdpb24gW3lv\
  dXIgZGF0YV0gLS1yZWFkb25seSBUcnVlIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3Mtc\
  HJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk\
  9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nConfigure the
  MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI,
  edit `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.mysql-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.mysql-mcp-server@latest\\\",\\n        \\\"--resource\
  _arn\\\", \\\"[your data]\\\",\\n        \\\"--secret_arn\\\", \\\"[your
  data]\\\",\\n        \\\"--database\\\", \\\"[your
  data]\\\",\\n        \\\"--region\\\", \\\"[your
  data]\\\",\\n        \\\"--readonly\\\",
  \\\"True\\\"\\n      ],\\n      \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n### Build
  and install docker image locally on the same host of your LLM client\\n\\n1.
  'git clone https://github.com/awslabs/mcp.git'\\n2. Go to sub-directory
  'src/mysql-mcp-server/'\\n3. Run 'docker build -t
  awslabs/mysql-mcp-server:latest .'\\n\\n### Add or update your LLM client's
  config with following:\\n<pre><code>\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.mysql-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"-e\\\", \\\"AWS_ACCESS_KEY_ID=[your data]\\\",\\n        \\\"-e\\\",
  \\\"AWS_SECRET_ACCESS_KEY=[your data]\\\",\\n        \\\"-e\\\",
  \\\"AWS_REGION=[your
  data]\\\",\\n        \\\"awslabs/mysql-mcp-server:latest\\\",\\n        \\\"-\
  -resource_arn\\\", \\\"[your data]\\\",\\n        \\\"--secret_arn\\\",
  \\\"[your data]\\\",\\n        \\\"--database\\\", \\\"[your
  data]\\\",\\n        \\\"--region\\\", \\\"[your
  data]\\\",\\n        \\\"--readonly\\\",
  \\\"True\\\"\\n      ]\\n    }\\n  }\\n}\\n</code></pre>\\n\\nNOTE: By
  default, only read-only queries are allowed and it is controlled by --readonly
  parameter above. Set it to False if you also want to allow writable DML or
  DDL.\\n\\n### AWS Authentication\\n\\nThe MCP server uses the AWS profile
  specified in the `AWS_PROFILE` environment variable. If not provided, it
  defaults to the \\\"default\\\" profile in your AWS configuration
  file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n}\\n```\\n\\nMake sure the AWS profile has
  permissions to access the [RDS data
  API](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.ht\
  ml#data-api.access), and the secret from AWS Secrets Manager. The MCP server
  creates a boto3 session using the specified profile to authenticate with AWS
  services. Your AWS IAM credentials remain on your local machine and are
  strictly used for accessing AWS
  services.\\n\",\"isRecommended\":false,\"githubStars\":4382,\"downloadCount\"\
  :216,\"createdAt\":\"2025-06-21T01:41:24.750847Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T09:32:49.219239Z\"},{\"mc\
  pId\":\"github.com/zcaceres/markdownify-mcp\",\"githubUrl\":\"https://github.\
  com/zcaceres/markdownify-mcp\",\"name\":\"Markdownify\",\"author\":\"zcaceres\
  \",\"description\":\"Converts various file types and web content (PDFs,
  images, audio, Office documents, web pages) into standardized Markdown format
  for easy reading and
  sharing.\",\"codiconIcon\":\"markdown\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/markdownify.png\",\"category\":\"file-systems\",\
  \"tags\":[\"file-conversion\",\"markdown\",\"document-processing\",\"content-\
  transformation\",\"format-conversion\"],\"requiresApiKey\":false,\"readmeCont\
  ent\":\"# Markdownify MCP Server\\n\\n> Help! I need someone with a Windows
  computer to help me add support for Markdownify-MCP on Windows. PRs exist but
  I cannot test them. Post
  [here](https://github.com/zcaceres/markdownify-mcp/issues/18) if
  interested.\\n\\n![markdownify mcp logo](logo.jpg)\\n\\nMarkdownify is a Model
  Context Protocol (MCP) server that converts various file types and web content
  to Markdown format. It provides a set of tools to transform PDFs, images,
  audio files, web pages, and more into easily readable and shareable Markdown
  text.\\n\\n<a href=\\\"https://glama.ai/mcp/servers/bn5q4b0ett\\\"><img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/bn5q4b0ett/badge\\\" alt=\\\"Markdownify
  Server MCP server\\\" /></a>\\n\\n## Features\\n\\n- Convert multiple file
  types to Markdown:\\n  - PDF\\n  - Images\\n  - Audio (with
  transcription)\\n  - DOCX\\n  - XLSX\\n  - PPTX\\n- Convert web content to
  Markdown:\\n  - YouTube video transcripts\\n  - Bing search results\\n  -
  General web pages\\n- Retrieve existing Markdown files\\n\\n## Getting
  Started\\n\\n1. Clone this repository\\n2. Install
  dependencies:\\n   ```\\n   pnpm install\\n   ```\\n\\nNote: this will also
  install `uv` and related Python depdencies.\\n\\n3. Build the
  project:\\n   ```\\n   pnpm run build\\n   ```\\n4. Start the
  server:\\n   ```\\n   pnpm start\\n   ```\\n\\n## Development\\n\\n- Use `pnpm
  run dev` to start the TypeScript compiler in watch mode\\n- Modify
  `src/server.ts` to customize server behavior\\n- Add or modify tools in
  `src/tools.ts`\\n\\n## Usage with Desktop App\\n\\nTo integrate this server
  with a desktop app, add the following to your app's server
  configuration:\\n\\n```js\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"markdownify\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\": [\\n        \\\"{ABSOLUTE PATH TO FILE
  HERE}/dist/index.js\\\"\\n      ],\\n      \\\"env\\\": {\\n        // By
  default, the server will use the default install location of
  `uv`\\n        \\\"UV_PATH\\\":
  \\\"/path/to/uv\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Available
  Tools\\n\\n- `youtube-to-markdown`: Convert YouTube videos to Markdown\\n-
  `pdf-to-markdown`: Convert PDF files to Markdown\\n-
  `bing-search-to-markdown`: Convert Bing search results to Markdown\\n-
  `webpage-to-markdown`: Convert web pages to Markdown\\n- `image-to-markdown`:
  Convert images to Markdown with metadata\\n- `audio-to-markdown`: Convert
  audio files to Markdown with transcription\\n- `docx-to-markdown`: Convert
  DOCX files to Markdown\\n- `xlsx-to-markdown`: Convert XLSX files to
  Markdown\\n- `pptx-to-markdown`: Convert PPTX files to Markdown\\n-
  `get-markdown-file`: Retrieve an existing Markdown file. File extension must
  end with: *.md, *.markdown.\\n  \\n  OPTIONAL: set `MD_SHARE_DIR` env var to
  restrict the directory from which files can be retrieved, e.g.
  `MD_SHARE_DIR=[SOME_PATH] pnpm run start` \\n\\n##
  Contributing\\n\\nContributions are welcome! Please feel free to submit a Pull
  Request.\\n\\n## License\\n\\nThis project is licensed under the MIT License -
  see the [LICENSE](LICENSE) file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":1851,\"downloadCount\":\
  8238,\"createdAt\":\"2025-02-19T00:55:54.241944Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T09:19:24.756159Z\"},{\"mc\
  pId\":\"github.com/modelcontextprotocol/servers/tree/main/src/git\",\"githubU\
  rl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/git\",\"\
  name\":\"Git
  Tools\",\"author\":\"modelcontextprotocol\",\"description\":\"Provides Git
  repository interaction and automation tools for reading, searching, and
  manipulating Git repositories through commands like status, diff, commit,
  branch management, and
  more.\",\"codiconIcon\":\"git-merge\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/git-tools.png\",\"category\":\"version-control\",\"\
  tags\":[\"git\",\"version-control\",\"repository-management\",\"source-control\
  \",\"development\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  mcp-server-git: A git MCP server\\n\\n## Overview\\n\\nA Model Context
  Protocol server for Git repository interaction and automation. This server
  provides tools to read, search, and manipulate Git repositories via Large
  Language Models.\\n\\nPlease note that mcp-server-git is currently in early
  development. The functionality and available tools are subject to change and
  expansion as we continue to develop and improve the server.\\n\\n###
  Tools\\n\\n1. `git_status`\\n   - Shows the working tree status\\n   -
  Input:\\n     - `repo_path` (string): Path to Git repository\\n   - Returns:
  Current status of working directory as text output\\n\\n2.
  `git_diff_unstaged`\\n   - Shows changes in working directory not yet
  staged\\n   - Inputs:\\n     - `repo_path` (string): Path to Git
  repository\\n     - `context_lines` (number, optional): Number of context
  lines to show (default: 3)\\n   - Returns: Diff output of unstaged
  changes\\n\\n3. `git_diff_staged`\\n   - Shows changes that are staged for
  commit\\n   - Inputs:\\n     - `repo_path` (string): Path to Git
  repository\\n     - `context_lines` (number, optional): Number of context
  lines to show (default: 3)\\n   - Returns: Diff output of staged
  changes\\n\\n4. `git_diff`\\n   - Shows differences between branches or
  commits\\n   - Inputs:\\n     - `repo_path` (string): Path to Git
  repository\\n     - `target` (string): Target branch or commit to compare
  with\\n     - `context_lines` (number, optional): Number of context lines to
  show (default: 3)\\n   - Returns: Diff output comparing current state with
  target\\n\\n5. `git_commit`\\n   - Records changes to the repository\\n   -
  Inputs:\\n     - `repo_path` (string): Path to Git repository\\n     -
  `message` (string): Commit message\\n   - Returns: Confirmation with new
  commit hash\\n\\n6. `git_add`\\n   - Adds file contents to the staging
  area\\n   - Inputs:\\n     - `repo_path` (string): Path to Git
  repository\\n     - `files` (string[]): Array of file paths to stage\\n   -
  Returns: Confirmation of staged files\\n\\n7. `git_reset`\\n   - Unstages all
  staged changes\\n   - Input:\\n     - `repo_path` (string): Path to Git
  repository\\n   - Returns: Confirmation of reset operation\\n\\n8.
  `git_log`\\n   - Shows the commit logs\\n   - Inputs:\\n     - `repo_path`
  (string): Path to Git repository\\n     - `max_count` (number, optional):
  Maximum number of commits to show (default: 10)\\n   - Returns: Array of
  commit entries with hash, author, date, and message\\n\\n9.
  `git_create_branch`\\n   - Creates a new branch\\n   - Inputs:\\n     -
  `repo_path` (string): Path to Git repository\\n     - `branch_name` (string):
  Name of the new branch\\n     - `start_point` (string, optional): Starting
  point for the new branch\\n   - Returns: Confirmation of branch creation\\n10.
  `git_checkout`\\n   - Switches branches\\n   - Inputs:\\n     - `repo_path`
  (string): Path to Git repository\\n     - `branch_name` (string): Name of
  branch to checkout\\n   - Returns: Confirmation of branch switch\\n11.
  `git_show`\\n   - Shows the contents of a commit\\n   - Inputs:\\n     -
  `repo_path` (string): Path to Git repository\\n     - `revision` (string): The
  revision (commit hash, branch name, tag) to show\\n   - Returns: Contents of
  the specified commit\\n12. `git_init`\\n   - Initializes a Git
  repository\\n   - Inputs:\\n     - `repo_path` (string): Path to directory to
  initialize git repo\\n   - Returns: Confirmation of repository
  initialization\\n\\n13. `git_branch`\\n   - List Git branches\\n   -
  Inputs:\\n     - `repo_path` (string): Path to the Git repository.\\n     -
  `branch_type` (string): Whether to list local branches ('local'), remote
  branches ('remote') or all branches('all').\\n     - `contains` (string,
  optional): The commit sha that branch should contain. Do not pass anything to
  this param if no commit sha is specified\\n     - `not_contains` (string,
  optional): The commit sha that branch should NOT contain. Do not pass anything
  to this param if no commit sha is specified\\n   - Returns: List of
  branches\\n\\n## Installation\\n\\n### Using uv (recommended)\\n\\nWhen using
  [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We
  will\\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run
  *mcp-server-git*.\\n\\n### Using PIP\\n\\nAlternatively you can install
  `mcp-server-git` via pip:\\n\\n```\\npip install
  mcp-server-git\\n```\\n\\nAfter installation, you can run it as a script
  using:\\n\\n```\\npython -m mcp_server_git\\n```\\n\\n##
  Configuration\\n\\n### Usage with Claude Desktop\\n\\nAdd this to your
  `claude_desktop_config.json`:\\n\\n<details>\\n<summary>Using
  uvx</summary>\\n\\n```json\\n\\\"mcpServers\\\": {\\n  \\\"git\\\":
  {\\n    \\\"command\\\": \\\"uvx\\\",\\n    \\\"args\\\":
  [\\\"mcp-server-git\\\", \\\"--repository\\\",
  \\\"path/to/git/repo\\\"]\\n  }\\n}\\n```\\n</details>\\n\\n<details>\\n<summ\
  ary>Using docker</summary>\\n\\n* Note: replace '/Users/username' with the a
  path that you want to be accessible by this
  tool\\n\\n```json\\n\\\"mcpServers\\\": {\\n  \\\"git\\\":
  {\\n    \\\"command\\\": \\\"docker\\\",\\n    \\\"args\\\": [\\\"run\\\",
  \\\"--rm\\\", \\\"-i\\\", \\\"--mount\\\",
  \\\"type=bind,src=/Users/username,dst=/Users/username\\\",
  \\\"mcp/git\\\"]\\n  }\\n}\\n```\\n</details>\\n\\n<details>\\n<summary>Using
  pip installation</summary>\\n\\n```json\\n\\\"mcpServers\\\":
  {\\n  \\\"git\\\": {\\n    \\\"command\\\":
  \\\"python\\\",\\n    \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_git\\\",
  \\\"--repository\\\",
  \\\"path/to/git/repo\\\"]\\n  }\\n}\\n```\\n</details>\\n\\n### Usage with VS
  Code\\n\\nFor quick installation, use one of the one-click install buttons
  below...\\n\\n[![Install with UV in VS
  Code](https://img.shields.io/badge/VS_Code-UV-0098FF?style=flat-square&logo=v\
  isualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/in\
  stall?name=git&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22mcp-s\
  erver-git%22%5D%7D) [![Install with UV in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-UV-24bfa5?style=flat-\
  square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/re\
  direct/mcp/install?name=git&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%\
  3A%5B%22mcp-server-git%22%5D%7D&quality=insiders)\\n\\n[![Install with Docker
  in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=git&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%\
  22run%22%2C%22--rm%22%2C%22-i%22%2C%22--mount%22%2C%22type%3Dbind%2Csrc%3D%24\
  %7BworkspaceFolder%7D%2Cdst%3D%2Fworkspace%22%2C%22mcp%2Fgit%22%5D%7D)
  [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=git&config=%7B%22command%22%3A%22docker%22%2C%22a\
  rgs%22%3A%5B%22run%22%2C%22--rm%22%2C%22-i%22%2C%22--mount%22%2C%22type%3Dbin\
  d%2Csrc%3D%24%7BworkspaceFolder%7D%2Cdst%3D%2Fworkspace%22%2C%22mcp%2Fgit%22%\
  5D%7D&quality=insiders)\\n\\nFor manual installation, add the following JSON
  block to your User Settings (JSON) file in VS Code. You can do this by
  pressing `Ctrl + Shift + P` and typing `Preferences: Open Settings
  (JSON)`.\\n\\nOptionally, you can add it to a file called `.vscode/mcp.json`
  in your workspace. This will allow you to share the configuration with others.
  \\n\\n> Note that the `mcp` key is not needed in the `.vscode/mcp.json`
  file.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"git\\\": {\\n        \\\"command\\\":
  \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"mcp-server-git\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor Docker
  installation:\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"git\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"-i\\\",\
  \\n          \\\"--mount\\\",
  \\\"type=bind,src=${workspaceFolder},dst=/workspace\\\",\\n          \\\"mcp/\
  git\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Usage with
  [Zed](https://github.com/zed-industries/zed)\\n\\nAdd to your Zed
  settings.json:\\n\\n<details>\\n<summary>Using
  uvx</summary>\\n\\n```json\\n\\\"context_servers\\\":
  [\\n  \\\"mcp-server-git\\\": {\\n    \\\"command\\\": {\\n      \\\"path\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-git\\\"]\\n    }\\n  }\\n],\\n```\\n</details>\\n\\n<details>\
  \\n<summary>Using pip
  installation</summary>\\n\\n```json\\n\\\"context_servers\\\":
  {\\n  \\\"mcp-server-git\\\": {\\n    \\\"command\\\": {\\n      \\\"path\\\":
  \\\"python\\\",\\n      \\\"args\\\": [\\\"-m\\\",
  \\\"mcp_server_git\\\"]\\n    }\\n  }\\n},\\n```\\n</details>\\n\\n##
  Debugging\\n\\nYou can use the MCP inspector to debug the server. For uvx
  installations:\\n\\n```\\nnpx @modelcontextprotocol/inspector uvx
  mcp-server-git\\n```\\n\\nOr if you've installed the package in a specific
  directory or are developing on it:\\n\\n```\\ncd path/to/servers/src/git\\nnpx
  @modelcontextprotocol/inspector uv run mcp-server-git\\n```\\n\\nRunning `tail
  -n 20 -f ~/Library/Logs/Claude/mcp*.log` will show the logs from the server
  and may\\nhelp you debug any issues.\\n\\n## Development\\n\\nIf you are doing
  local development, there are two ways to test your changes:\\n\\n1. Run the
  MCP inspector to test your changes. See [Debugging](#debugging) for run
  instructions.\\n\\n2. Test using the Claude desktop app. Add the following to
  your `claude_desktop_config.json`:\\n\\n###
  Docker\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"git\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"-i\\\",\\n        \
  \\\"--mount\\\",
  \\\"type=bind,src=/Users/username/Desktop,dst=/projects/Desktop\\\",\\n        \
  \\\"--mount\\\",
  \\\"type=bind,src=/path/to/other/allowed/dir,dst=/projects/other/allowed/dir,\
  ro\\\",\\n        \\\"--mount\\\",
  \\\"type=bind,src=/path/to/file.txt,dst=/projects/path/to/file.txt\\\",\\n        \
  \\\"mcp/git\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n###
  UVX\\n```json\\n{\\n\\\"mcpServers\\\": {\\n  \\\"git\\\":
  {\\n    \\\"command\\\": \\\"uv\\\",\\n    \\\"args\\\":
  [\\n      \\\"--directory\\\",\\n      \\\"/<path to
  mcp-servers>/mcp-servers/src/git\\\",\\n      \\\"run\\\",\\n      \\\"mcp-se\
  rver-git\\\"\\n    ]\\n    }\\n  }\\n}\\n```\\n\\n## Build\\n\\nDocker
  build:\\n\\n```bash\\ncd src/git\\ndocker build -t mcp/git .\\n```\\n\\n##
  License\\n\\nThis MCP server is licensed under the MIT License. This means you
  are free to use, modify, and distribute the software, subject to the terms and
  conditions of the MIT License. For more details, please see the LICENSE file
  in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":57154,\"downloadCount\
  \":42197,\"createdAt\":\"2025-02-19T02:22:25.91666Z\",\"updatedAt\":\"2025-07\
  -08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T05:09:06.741295Z\"},{\
  \"mcpId\":\"github.com/pashpashpash/perplexity-mcp\",\"githubUrl\":\"https://\
  github.com/pashpashpash/perplexity-mcp\",\"name\":\"Perplexity
  Research\",\"author\":\"pashpashpash\",\"description\":\"Leverages
  Perplexity's Sonar Pro API to provide comprehensive research capabilities,
  including documentation search, API discovery, and code deprecation analysis
  with chain-of-thought
  reasoning.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/perplexity-ai-icon.png\",\"category\":\"research-\
  data\",\"tags\":[\"research\",\"documentation\",\"api-discovery\",\"code-anal\
  ysis\",\"perplexity\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  MCP-researcher Server\\n\\nYour own research assistant inside of Claude!
  Utilizes Perplexity's Sonar Pro API to get documentation, create up-to-date
  API routes, and check deprecated code. Includes Chain of Thought Reasoning and
  local chat history through SQLite.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/g1i6ilg8sl\\\"><img width=\\\"380\\\"
  height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/g1i6ilg8sl/badge\\\"
  alt=\\\"MCP-researcher Server MCP server\\\" /></a>\\n\\n## Features\\n\\n###
  1. Search\\nPerforms general search queries to get comprehensive information
  on any topic. Supports different detail levels (brief, normal, detailed) to
  get tailored responses.\\n\\n### 2. Get Documentation\\nRetrieves
  documentation and usage examples for specific technologies, libraries, or
  APIs. Get comprehensive documentation including best practices and common
  pitfalls.\\n\\n### 3. Find APIs\\nDiscovers and evaluates APIs that could be
  integrated into a project. Get detailed analysis of features, pricing, and
  integration complexity.\\n\\n### 4. Check Deprecated Code\\nAnalyzes code for
  deprecated features or patterns, providing migration guidance. Helps modernize
  code by suggesting current best practices.\\n\\n## Prerequisites\\n\\n1.
  **System Requirements**:\\n   - Node.js (install from
  [nodejs.org](https://nodejs.org))\\n   - Python with distutils (required for
  some npm dependencies)\\n     ```bash\\n     # On macOS with
  Homebrew:\\n     brew install python-setuptools\\n     ```\\n\\n2. **API
  Key**:\\n   - Get your Perplexity API key from
  [perplexity.ai/settings/api](https://www.perplexity.ai/settings/api)\\n\\n##
  Installation\\n\\n1. **Create Project Directory**:\\n   ```bash\\n   mkdir -p
  ~/Documents/Claude/MCP\\n   cd ~/Documents/Claude/MCP\\n   ```\\n\\n2. **Clone
  the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/perplexity-mcp.git\\n   cd
  perplexity-mcp\\n   ```\\n\\n3. **Install
  Dependencies**:\\n   ```bash\\n   npm install\\n   ```\\n   Note: If you see
  Python distutils errors, make sure you've installed python-setuptools as
  mentioned in prerequisites.\\n\\n4. **Build the
  Project**:\\n   ```bash\\n   npm run build\\n   ```\\n   This will create the
  build directory with the compiled server code.\\n\\n## Configuration\\n\\n1.
  **Configure Claude Desktop**:\\n\\nAdd this to your
  claude_desktop_config.json:\\n- macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"perplexity-server\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/perplexity-mcp/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"PERPLEXITY_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      },\\n      \\\"autoApprove\\\":
  [\\n        \\\"search\\\",\\n        \\\"get_documentation\\\",\\n        \\\
  \"find_apis\\\",\\n        \\\"check_deprecated_code\\\"\\n      ]\\n    }\\n  \
  }\\n}\\n```\\nNote: \\n- Replace \\\"path/to/perplexity-mcp\\\" with the
  absolute path to your cloned repository\\n- Replace \\\"your-api-key-here\\\"
  with your Perplexity API key\\n- Make sure to use \\\"/build/index.js\\\" (not
  \\\"/dist/index.js\\\")\\n\\n## Starting the Server\\n\\n1. **Manual
  Start**:\\n   ```bash\\n   cd
  path/to/perplexity-mcp\\n   PERPLEXITY_API_KEY=\\\"your-api-key-here\\\" node
  build/index.js\\n   ```\\n\\n2. **Verify Server**:\\n   The server should
  start without any errors. Keep this terminal window open while using the
  server.\\n\\n## Example Usage\\n\\n### Search\\n```json\\n{\\n  \\\"query\\\":
  \\\"What are the best practices for React
  hooks?\\\",\\n  \\\"detail_level\\\": \\\"detailed\\\"\\n}\\n```\\n\\n### Get
  Documentation\\n```json\\n{\\n  \\\"technology\\\":
  \\\"React\\\",\\n  \\\"topic\\\": \\\"useEffect
  hook\\\",\\n  \\\"include_examples\\\": true\\n}\\n```\\n\\n### Find
  APIs\\n```json\\n{\\n  \\\"category\\\": \\\"payment
  processing\\\",\\n  \\\"requirements\\\": [\\\"recurring billing\\\",
  \\\"international support\\\"]\\n}\\n```\\n\\n### Check Deprecated
  Code\\n```json\\n{\\n  \\\"code\\\": \\\"class MyComponent extends
  React.Component {...}\\\",\\n  \\\"framework\\\":
  \\\"React\\\",\\n  \\\"version\\\": \\\"18\\\"\\n}\\n```\\n\\n##
  Troubleshooting\\n\\n1. **Build Directory Issues**:\\n   - Make sure you're
  using the correct path in Claude Desktop config\\n   - Verify the build
  directory exists after running `npm run build`\\n   - Check that the path is
  using `/build/index.js`, not `/dist/index.js`\\n\\n2. **Server Connection
  Issues**:\\n   - Ensure the server is running in a separate terminal\\n   -
  Verify the API key is properly set in the environment\\n   - Check Claude
  Desktop's MCP logs:\\n     ```bash\\n     tail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n     ```\\n\\n3. **Python
  Dependencies**:\\n   - If you see Python distutils errors during npm
  install:\\n     ```bash\\n     brew install
  python-setuptools\\n     ```\\n   - Then retry `npm install`\\n\\n##
  Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n# Build
  the project\\nnpm run build\\n\\n# Development with auto-rebuild\\nnpm run
  watch\\n\\n# Start server with debug output\\nDEBUG=* node
  build/index.js\\n```\\n\\n## Documentation\\n\\nFor detailed examples and
  usage guides, see:\\n- [Search
  Examples](https://github.com/DaInfernalCoder/perplexity-mcp/blob/main/example\
  s/search.md)\\n- [API Documentation
  Examples](https://github.com/DaInfernalCoder/perplexity-mcp/blob/main/example\
  s/find-apis.md)\\n- [Deprecated Code
  Examples](https://github.com/DaInfernalCoder/perplexity-mcp/blob/main/example\
  s/check-deprecated-code.md)\\n\\n## License\\n\\nMIT\\n\\n---\\nNote: This is
  a fork of the [original perplexity-mcp
  repository](https://github.com/DaInfernalCoder/perplexity-mcp).\\n\",\"isReco\
  mmended\":false,\"githubStars\":30,\"downloadCount\":15268,\"createdAt\":\"20\
  25-02-19T00:44:43.25332Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"la\
  stGithubSync\":\"2025-07-02T05:05:10.134982Z\"},{\"mcpId\":\"github.com/zcace\
  res/fetch-mcp\",\"githubUrl\":\"https://github.com/zcaceres/fetch-mcp\",\"name\
  \":\"Fetch\",\"author\":\"zcaceres\",\"description\":\"Provides functionality
  to fetch web content in various formats, including HTML, JSON, plain text, and
  Markdown, with support for custom headers and content
  transformation.\",\"codiconIcon\":\"cloud-download\",\"logoUrl\":\"https://st\
  orage.googleapis.com/cline_public_images/fetch.png\",\"category\":\"search\",\
  \"tags\":[\"web-fetching\",\"html\",\"json\",\"markdown\",\"content-extraction\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Fetch MCP
  Server\\n\\n![fetch mcp logo](logo.jpg)\\n\\nThis MCP server provides
  functionality to fetch web content in various formats, including HTML, JSON,
  plain text, and Markdown.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/nu09wf23ao\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/nu09wf23ao/badge\\\" alt=\\\"Fetch Server
  MCP server\\\" />\\n</a>\\n\\n## Components\\n\\n### Tools\\n\\n-
  **fetch_html**\\n  - Fetch a website and return the content as HTML\\n  -
  Input:\\n    - `url` (string, required): URL of the website to fetch\\n    -
  `headers` (object, optional): Custom headers to include in the request\\n  -
  Returns the raw HTML content of the webpage\\n\\n- **fetch_json**\\n  - Fetch
  a JSON file from a URL\\n  - Input:\\n    - `url` (string, required): URL of
  the JSON to fetch\\n    - `headers` (object, optional): Custom headers to
  include in the request\\n  - Returns the parsed JSON content\\n\\n-
  **fetch_txt**\\n  - Fetch a website and return the content as plain text (no
  HTML)\\n  - Input:\\n    - `url` (string, required): URL of the website to
  fetch\\n    - `headers` (object, optional): Custom headers to include in the
  request\\n  - Returns the text content of the webpage with HTML tags, scripts,
  and styles removed\\n\\n- **fetch_markdown**\\n  - Fetch a website and return
  the content as Markdown\\n  - Input:\\n    - `url` (string, required): URL of
  the website to fetch\\n    - `headers` (object, optional): Custom headers to
  include in the request\\n  - Returns the content of the webpage converted to
  Markdown format\\n\\n### Resources\\n\\nThis server does not provide any
  persistent resources. It's designed to fetch and transform web content on
  demand.\\n\\n## Getting started\\n\\n1. Clone the repository\\n2. Install
  dependencies: `npm install`\\n3. Build the server: `npm run build`\\n\\n###
  Usage\\n\\nTo use the server, you can run it directly:\\n\\n```bash\\nnpm
  start\\n```\\n\\nThis will start the Fetch MCP Server running on
  stdio.\\n\\n### Usage with Desktop App\\n\\nTo integrate this server with a
  desktop app, add the following to your app's server
  configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"fetch\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"{ABSOLUTE PATH TO FILE
  HERE}/dist/index.js\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n##
  Features\\n\\n- Fetches web content using modern fetch API\\n- Supports custom
  headers for requests\\n- Provides content in multiple formats: HTML, JSON,
  plain text, and Markdown\\n- Uses JSDOM for HTML parsing and text
  extraction\\n- Uses TurndownService for HTML to Markdown conversion\\n\\n##
  Development\\n\\n- Run `npm run dev` to start the TypeScript compiler in watch
  mode\\n- Use `npm test` to run the test suite\\n\\n## License\\n\\nThis
  project is licensed under the MIT
  License.\",\"isRecommended\":false,\"githubStars\":470,\"downloadCount\":3508\
  2,\"createdAt\":\"2025-02-19T00:55:59.104097Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T02:31:26.566015Z\"},{\"mcpId\
  \":\"github.com/domdomegg/airtable-mcp-server\",\"githubUrl\":\"https://githu\
  b.com/domdomegg/airtable-mcp-server\",\"name\":\"Airtable\",\"author\":\"domd\
  omegg\",\"description\":\"Provides read and write access to Airtable
  databases, enabling schema inspection, record management, and table operations
  through comprehensive API
  integration.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/airtable.png\",\"category\":\"databases\",\"t\
  ags\":[\"airtable\",\"database-management\",\"records\",\"schemas\",\"crud\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"#
  airtable-mcp-server\\n\\n[![smithery
  badge](https://smithery.ai/badge/airtable-mcp-server)](https://smithery.ai/se\
  rver/airtable-mcp-server)\\n\\nA Model Context Protocol server that provides
  read and write access to Airtable databases. This server enables LLMs to
  inspect database schemas, then read and write
  records.\\n\\nhttps://github.com/user-attachments/assets/c8285e76-d0ed-4018-9\
  4c7-20535db6c944\\n\\n## Usage\\n\\nTo use this server with the Claude Desktop
  app, add the following configuration to the \\\"mcpServers\\\" section of your
  `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"airtable\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"airtable-mcp-server\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"AIRTABLE_API_KEY\\\":
  \\\"pat123.abc123\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nReplace
  `pat123.abc123` with your [Airtable personal access
  token](https://airtable.com/create/tokens). Your token should have at least
  `schema.bases:read` and `data.records:read`, and optionally the corresponding
  write permissions.\\n\\n## Components\\n\\n### Tools\\n\\n-
  **list_records**\\n  - Lists records from a specified Airtable table\\n  -
  Input parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table to
  query\\n    - `maxRecords` (number, optional): Maximum number of records to
  return. Defaults to 100.\\n    - `filterByFormula` (string, optional):
  Airtable formula to filter records\\n\\n- **search_records**\\n  - Search for
  records containing specific text\\n  - Input parameters:\\n    - `baseId`
  (string, required): The ID of the Airtable base\\n    - `tableId` (string,
  required): The ID of the table to query\\n    - `searchTerm` (string,
  required): Text to search for in records\\n    - `fieldIds` (array, optional):
  Specific field IDs to search in. If not provided, searches all text-based
  fields.\\n    - `maxRecords` (number, optional): Maximum number of records to
  return. Defaults to 100.\\n\\n- **list_bases**\\n  - Lists all accessible
  Airtable bases\\n  - No input parameters required\\n  - Returns base ID, name,
  and permission level\\n\\n- **list_tables**\\n  - Lists all tables in a
  specific base\\n  - Input parameters:\\n    - `baseId` (string, required): The
  ID of the Airtable base\\n    - `detailLevel` (string, optional): The amount
  of detail to get about the tables (`tableIdentifiersOnly`, `identifiersOnly`,
  or `full`)\\n  - Returns table ID, name, description, fields, and views (to
  the given `detailLevel`)\\n\\n- **describe_table**\\n  - Gets detailed
  information about a specific table\\n  - Input parameters:\\n    - `baseId`
  (string, required): The ID of the Airtable base\\n    - `tableId` (string,
  required): The ID of the table to describe\\n    - `detailLevel` (string,
  optional): The amount of detail to get about the table
  (`tableIdentifiersOnly`, `identifiersOnly`, or `full`)\\n  - Returns the same
  format as list_tables but for a single table\\n  - Useful for getting details
  about a specific table without fetching information about all tables in the
  base\\n\\n- **get_record**\\n  - Gets a specific record by ID\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table\\n    -
  `recordId` (string, required): The ID of the record to retrieve\\n\\n-
  **create_record**\\n  - Creates a new record in a table\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table\\n    -
  `fields` (object, required): The fields and values for the new record\\n\\n-
  **update_records**\\n  - Updates one or more records in a table\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table\\n    -
  `records` (array, required): Array of objects containing record ID and fields
  to update\\n\\n- **delete_records**\\n  - Deletes one or more records from a
  table\\n  - Input parameters:\\n    - `baseId` (string, required): The ID of
  the Airtable base\\n    - `tableId` (string, required): The ID of the
  table\\n    - `recordIds` (array, required): Array of record IDs to
  delete\\n\\n- **create_table**\\n  - Creates a new table in a base\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `name` (string, required): Name of the new table\\n    -
  `description` (string, optional): Description of the table\\n    - `fields`
  (array, required): Array of field definitions (name, type, description,
  options)\\n\\n- **update_table**\\n  - Updates a table's name or
  description\\n  - Input parameters:\\n    - `baseId` (string, required): The
  ID of the Airtable base\\n    - `tableId` (string, required): The ID of the
  table\\n    - `name` (string, optional): New name for the table\\n    -
  `description` (string, optional): New description for the table\\n\\n-
  **create_field**\\n  - Creates a new field in a table\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table\\n    - `name`
  (string, required): Name of the new field\\n    - `type` (string, required):
  Type of the field\\n    - `description` (string, optional): Description of the
  field\\n    - `options` (object, optional): Field-specific options\\n\\n-
  **update_field**\\n  - Updates a field's name or description\\n  - Input
  parameters:\\n    - `baseId` (string, required): The ID of the Airtable
  base\\n    - `tableId` (string, required): The ID of the table\\n    -
  `fieldId` (string, required): The ID of the field\\n    - `name` (string,
  optional): New name for the field\\n    - `description` (string, optional):
  New description for the field\\n\\n### Resources\\n\\nThe server provides
  schema information for Airtable bases and tables:\\n\\n- **Table Schemas**
  (`airtable://<baseId>/<tableId>/schema`)\\n  - JSON schema information for
  each table\\n  - Includes:\\n    - Base id and table id\\n    - Table name and
  description\\n    - Primary field ID\\n    - Field definitions (ID, name,
  type, description, options)\\n    - View definitions (ID, name, type)\\n  -
  Automatically discovered from Airtable's metadata API\\n\\n##
  Contributing\\n\\nPull requests are welcomed on GitHub! To get
  started:\\n\\n1. Install Git and Node.js\\n2. Clone the repository\\n3.
  Install dependencies with `npm install`\\n4. Run `npm run test` to run
  tests\\n5. Build with `npm run build`\\n  - You can use `npm run build:watch`
  to automatically build after editing [`src/index.ts`](./src/index.ts). This
  means you can hit save, reload Claude Desktop (with Ctrl/Cmd+R), and the
  changes apply.\\n\\n## Releases\\n\\nVersions follow the [semantic versioning
  spec](https://semver.org/).\\n\\nTo release:\\n\\n1. Use `npm version <major |
  minor | patch>` to bump the version\\n2. Run `git push --follow-tags` to push
  with tags\\n3. Wait for GitHub Actions to publish to the NPM
  registry.\\n\",\"isRecommended\":false,\"githubStars\":183,\"downloadCount\":\
  1105,\"createdAt\":\"2025-02-19T02:22:31.761899Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06-30T17:26:46.172276Z\"},{\"mc\
  pId\":\"github.com/smithery-ai/mcp-obsidian\",\"githubUrl\":\"https://github.\
  com/smithery-ai/mcp-obsidian\",\"name\":\"Obsidian\",\"author\":\"smithery-ai\
  \",\"description\":\"Enables reading and searching of Markdown notes
  directories (like Obsidian vaults), allowing AI assistants to access and query
  local knowledge
  bases.\",\"codiconIcon\":\"notebook\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/obsidian.png\",\"category\":\"note-taking\",\"tags\
  \":[\"markdown\",\"knowledge-base\",\"notes\",\"search\",\"obsidian\"],\"requ\
  iresApiKey\":false,\"readmeContent\":\"# Obsidian Model Context
  Protocol\\n\\n[![smithery
  badge](https://smithery.ai/badge/mcp-obsidian)](https://smithery.ai/protocol/\
  mcp-obsidian)\\n\\nThis is a connector to allow Claude Desktop (or any MCP
  client) to read and search any directory containing Markdown notes (such as an
  Obsidian vault).\\n\\n## Installation\\n\\nMake sure Claude Desktop and `npm`
  is installed.\\n\\n### Installing via Smithery\\n\\nTo install Obsidian Model
  Context Protocol for Claude Desktop automatically via
  [Smithery](https://smithery.ai/protocol/mcp-obsidian):\\n\\n```bash\\nnpx
  @smithery/cli install mcp-obsidian --client claude\\n```\\n\\nThen, restart
  Claude Desktop and you should see the following MCP tools
  listed:\\n\\n![image](./images/mcp-tools.png)\\n\\n### Usage with VS
  Code\\n\\nFor quick installation, use one of the one-click install buttons
  below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=obsidian&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%\
  3A%22vaultPath%22%2C%22description%22%3A%22Path%20to%20Obsidian%20vault%22%7D\
  %5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22mcp-o\
  bsidian%22%2C%22%24%7Binput%3AvaultPath%7D%22%5D%7D) [![Install with NPX in VS
  Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=obsidian&inputs=%5B%7B%22type%22%3A%22promptString%2\
  2%2C%22id%22%3A%22vaultPath%22%2C%22description%22%3A%22Path%20to%20Obsidian%\
  20vault%22%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%\
  22%2C%22mcp-obsidian%22%2C%22%24%7Binput%3AvaultPath%7D%22%5D%7D&quality=insi\
  ders)\\n\\nFor manual installation, add the following JSON block to your User
  Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift +
  P` and typing `Preferences: Open User Settings (JSON)`.\\n\\nOptionally, you
  can add it to a file called `.vscode/mcp.json` in your workspace. This will
  allow you to share the configuration with others.\\n\\n> Note that the `mcp`
  key is not needed in the `.vscode/mcp.json`
  file.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"vaultPath\\\",\\n        \\\"description\\\": \\\"Path to Obsidian
  vault\\\"\\n      }\\n    ],\\n    \\\"servers\\\":
  {\\n      \\\"obsidian\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\", \\\"mcp-obsidian\\\",
  \\\"${input:vaultPath}\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n\",\"isRecomm\
  ended\":false,\"githubStars\":967,\"downloadCount\":7525,\"createdAt\":\"2025\
  -02-17T22:22:13.239338Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"las\
  tGithubSync\":\"2025-07-01T14:22:07.480107Z\"},{\"mcpId\":\"github.com/ahujas\
  id/blender-mcp\",\"githubUrl\":\"https://github.com/ahujasid/blender-mcp\",\"\
  name\":\"Blender\",\"author\":\"ahujasid\",\"description\":\"Enables AI
  assistants to control Blender for 3D modeling, scene creation, and asset
  management through socket-based communication, with support for Poly Haven
  assets and Hyper3D Rodin
  models.\",\"codiconIcon\":\"symbol-cube\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/blender-control.png\",\"category\":\"image-vide\
  o-processing\",\"tags\":[\"3d-modeling\",\"blender\",\"asset-management\",\"s\
  cene-creation\",\"visualization\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"\\n\\n# BlenderMCP - Blender Model Context Protocol
  Integration\\n\\nBlenderMCP connects Blender to Claude AI through the Model
  Context Protocol (MCP), allowing Claude to directly interact with and control
  Blender. This integration enables prompt assisted 3D modeling, scene creation,
  and manipulation.\\n\\n[Full
  tutorial](https://www.youtube.com/watch?v=lCyQ717DuzQ)\\n\\n### Join the
  Community\\n\\nGive feedback, get inspired, and build on top of the MCP:
  [Discord](https://discord.gg/z5apgR8TFU)\\n\\n### Supporters\\n\\n<div
  align=\\\"center\\\" markdown=\\\"1\\\">\\n   <sup>Special thanks
  to:</sup>\\n   <br>\\n   <br>\\n   <a
  href=\\\"https://www.warp.dev/blender-mcp\\\">\\n      <img alt=\\\"Warp
  sponsorship\\\" width=\\\"400\\\"
  src=\\\"https://github.com/user-attachments/assets/c21102f7-bab9-4344-a731-0c\
  f6b341cab2\\\">\\n   </a>\\n\\n### [Warp, the intelligent terminal for
  developers](https://www.warp.dev/blender-mcp)\\n[Available for MacOS, Linux, &
  Windows](https://www.warp.dev/blender-mcp)<br>\\n\\n</div>\\n<hr>\\n\\n**Other
  supporters:**\\n\\n[CodeRabbit](https://www.coderabbit.ai/)\\n\\n**All
  supporters:**\\n\\n[Support this
  project](https://github.com/sponsors/ahujasid)\\n\\n## Release notes
  (1.2.0)\\n- View screenshots for Blender viewport to better understand the
  scene\\n- Search and download Sketchfab models\\n\\n\\n### Previously added
  features:\\n- Support for Poly Haven assets through their API\\n- Support to
  generate 3D models using Hyper3D Rodin\\n- For newcomers, you can go straight
  to Installation. For existing users, see the points below\\n- Download the
  latest addon.py file and replace the older one, then add it to Blender\\n-
  Delete the MCP server from Claude and add it back again, and you should be
  good to go!\\n\\n## Features\\n\\n- **Two-way communication**: Connect Claude
  AI to Blender through a socket-based server\\n- **Object manipulation**:
  Create, modify, and delete 3D objects in Blender\\n- **Material control**:
  Apply and modify materials and colors\\n- **Scene inspection**: Get detailed
  information about the current Blender scene\\n- **Code execution**: Run
  arbitrary Python code in Blender from Claude\\n\\n## Components\\n\\nThe
  system consists of two main components:\\n\\n1. **Blender Addon
  (`addon.py`)**: A Blender addon that creates a socket server within Blender to
  receive and execute commands\\n2. **MCP Server
  (`src/blender_mcp/server.py`)**: A Python server that implements the Model
  Context Protocol and connects to the Blender addon\\n\\n##
  Installation\\n\\n\\n### Prerequisites\\n\\n- Blender 3.0 or newer\\n- Python
  3.10 or newer\\n- uv package manager: \\n\\n**If you're on Mac, please install
  uv as**\\n```bash\\nbrew install uv\\n```\\n**On
  Windows**\\n```bash\\npowershell -c \\\"irm https://astral.sh/uv/install.ps1 |
  iex\\\" \\n```\\nand then\\n```bash\\nset
  Path=C:\\\\Users\\\\nntra\\\\.local\\\\bin;%Path%\\n```\\n\\nOtherwise
  installation instructions are on their website: [Install
  uv](https://docs.astral.sh/uv/getting-started/installation/)\\n\\n** Do not
  proceed before installing UV**\\n\\n\\n### Claude for Desktop
  Integration\\n\\n[Watch the setup instruction
  video](https://www.youtube.com/watch?v=neoK_WMq92g) (Assuming you have already
  installed uv)\\n\\nGo to Claude > Settings > Developer > Edit Config >
  claude_desktop_config.json to include the
  following:\\n\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"blender\\\": {\\n            \\\"command\\\":
  \\\"uvx\\\",\\n            \\\"args\\\":
  [\\n                \\\"blender-mcp\\\"\\n            ]\\n        }\\n    }\\\
  n}\\n```\\n\\n### Cursor integration\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=blender&config=eyJjb21tYW5kIjoidXZ4IGJsZW5kZXItbWNwIn0%3D)\
  \\n\\nFor Mac users, go to Settings > MCP and paste the following \\n\\n- To
  use as a global server, use \\\"add new global MCP server\\\" button and
  paste\\n- To use as a project specific server, create `.cursor/mcp.json` in
  the root of the project and
  paste\\n\\n\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"blender\\\": {\\n            \\\"command\\\":
  \\\"uvx\\\",\\n            \\\"args\\\":
  [\\n                \\\"blender-mcp\\\"\\n            ]\\n        }\\n    }\\\
  n}\\n```\\n\\nFor Windows users, go to Settings > MCP > Add Server, add a new
  server with the following settings:\\n\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"blender\\\": {\\n            \\\"command\\\":
  \\\"cmd\\\",\\n            \\\"args\\\":
  [\\n                \\\"/c\\\",\\n                \\\"uvx\\\",\\n                \
  \\\"blender-mcp\\\"\\n            ]\\n        }\\n    }\\n}\\n```\\n\\n[Cursor
  setup video](https://www.youtube.com/watch?v=wgWsJshecac)\\n\\n** Only run
  one instance of the MCP server (either on Cursor or Claude Desktop), not
  both**\\n\\n### Installing the Blender Addon\\n\\n1. Download the `addon.py`
  file from this repo\\n1. Open Blender\\n2. Go to Edit > Preferences >
  Add-ons\\n3. Click \\\"Install...\\\" and select the `addon.py` file\\n4.
  Enable the addon by checking the box next to \\\"Interface: Blender
  MCP\\\"\\n\\n\\n## Usage\\n\\n### Starting the Connection\\n![BlenderMCP in
  the sidebar](assets/addon-instructions.png)\\n\\n1. In Blender, go to the 3D
  View sidebar (press N if not visible)\\n2. Find the \\\"BlenderMCP\\\"
  tab\\n3. Turn on the Poly Haven checkbox if you want assets from their API
  (optional)\\n4. Click \\\"Connect to Claude\\\"\\n5. Make sure the MCP server
  is running in your terminal\\n\\n### Using with Claude\\n\\nOnce the config
  file has been set on Claude, and the addon is running on Blender, you will see
  a hammer icon with tools for the Blender MCP.\\n\\n![BlenderMCP in the
  sidebar](assets/hammer-icon.png)\\n\\n#### Capabilities\\n\\n- Get scene and
  object information \\n- Create, delete and modify shapes\\n- Apply or create
  materials for objects\\n- Execute any Python code in Blender\\n- Download the
  right models, assets and HDRIs through [Poly
  Haven](https://polyhaven.com/)\\n- AI generated 3D models through [Hyper3D
  Rodin](https://hyper3d.ai/)\\n\\n\\n### Example Commands\\n\\nHere are some
  examples of what you can ask Claude to do:\\n\\n- \\\"Create a low poly scene
  in a dungeon, with a dragon guarding a pot of gold\\\"
  [Demo](https://www.youtube.com/watch?v=DqgKuLYUv00)\\n- \\\"Create a beach
  vibe using HDRIs, textures, and models like rocks and vegetation from Poly
  Haven\\\" [Demo](https://www.youtube.com/watch?v=I29rn92gkC4)\\n- Give a
  reference image, and create a Blender scene out of it
  [Demo](https://www.youtube.com/watch?v=FDRb03XPiRo)\\n- \\\"Generate a 3D
  model of a garden gnome through Hyper3D\\\"\\n- \\\"Get information about the
  current scene, and make a threejs sketch from it\\\"
  [Demo](https://www.youtube.com/watch?v=jxbNI5L7AH8)\\n- \\\"Make this car red
  and metallic\\\" \\n- \\\"Create a sphere and place it above the cube\\\"\\n-
  \\\"Make the lighting like a studio\\\"\\n- \\\"Point the camera at the scene,
  and make it isometric\\\"\\n\\n## Hyper3D integration\\n\\nHyper3D's free
  trial key allows you to generate a limited number of models per day. If the
  daily limit is reached, you can wait for the next day's reset or obtain your
  own key from hyper3d.ai and fal.ai.\\n\\n## Troubleshooting\\n\\n-
  **Connection issues**: Make sure the Blender addon server is running, and the
  MCP server is configured on Claude, DO NOT run the uvx command in the
  terminal. Sometimes, the first command won't go through but after that it
  starts working.\\n- **Timeout errors**: Try simplifying your requests or
  breaking them into smaller steps\\n- **Poly Haven integration**: Claude is
  sometimes erratic with its behaviour\\n- **Have you tried turning it off and
  on again?**: If you're still having connection errors, try restarting both
  Claude and the Blender server\\n\\n\\n## Technical Details\\n\\n###
  Communication Protocol\\n\\nThe system uses a simple JSON-based protocol over
  TCP sockets:\\n\\n- **Commands** are sent as JSON objects with a `type` and
  optional `params`\\n- **Responses** are JSON objects with a `status` and
  `result` or `message`\\n\\n## Limitations & Security Considerations\\n\\n- The
  `execute_blender_code` tool allows running arbitrary Python code in Blender,
  which can be powerful but potentially dangerous. Use with caution in
  production environments. ALWAYS save your work before using it.\\n- Poly Haven
  requires downloading models, textures, and HDRI images. If you do not want to
  use it, please turn it off in the checkbox in Blender. \\n- Complex operations
  might need to be broken down into smaller steps\\n\\n\\n##
  Contributing\\n\\nContributions are welcome! Please feel free to submit a Pull
  Request.\\n\\n## Disclaimer\\n\\nThis is a third-party integration and not
  made by Blender. Made by
  [Siddharth](https://x.com/sidahuj)\\n\",\"isRecommended\":false,\"githubStars\
  \":12122,\"downloadCount\":13790,\"createdAt\":\"2025-03-17T01:52:54.102355Z\
  \",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06\
  -30T23:31:38.591276Z\"},{\"mcpId\":\"github.com/Garoth/echo-mcp\",\"githubUrl\
  \":\"https://github.com/Garoth/echo-mcp\",\"name\":\"Echo\",\"author\":\"Garo\
  th\",\"description\":\"A simple testing utility that echoes back any message
  it receives, useful for validating MCP functionality and
  connections.\",\"codiconIcon\":\"reply\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/echo.png\",\"category\":\"developer-tools\",\"ta\
  gs\":[\"testing\",\"debugging\",\"validation\",\"echo\",\"development\"],\"re\
  quiresApiKey\":false,\"readmeContent\":\"# Echo MCP Server\\n\\n<img
  src=\\\"assets/echo-logo.png\\\" width=\\\"256\\\" height=\\\"256\\\"
  alt=\\\"Echo Logo\\\" />\\n\\nA simple Model Context Protocol (MCP) server
  that echoes back whatever message it is sent. Perfect for testing MCP
  functionality\\n\\n## Features\\n\\n- Simple echo functionality that returns
  any message sent to it\\n- Handles empty messages, special characters, emojis,
  and long messages\\n- Includes test suite\\n\\n## Available Tools\\n\\n-
  `echo`: Takes a message parameter and echoes it back exactly as
  received\\n\\n## Installation\\n\\n```bash\\ngit clone
  https://github.com/Garoth/echo-mcp.git\\ncd echo-mcp\\nnpm
  install\\n```\\n\\n## Configuration\\n\\nAdd the echo server to your Cline MCP
  settings file inside VSCode's settings (ex.
  ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_s\
  ettings.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"echo-server\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/echo-server/build/index.js\\\"],\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\":
  [\\n        \\\"echo\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Usage
  Examples\\n\\n### Basic Echo\\n\\n```\\nInput: \\\"Hello, world!\\\"\\nOutput:
  \\\"Hello, world!\\\"\\n```\\n\\n### Special Characters\\n\\n```\\nInput:
  \\\"Special chars: !@#$%^&*()_+{}[]|\\\\\\\\:;\\\\\\\"'<>,.?/\\\"\\nOutput:
  \\\"Special chars:
  !@#$%^&*()_+{}[]|\\\\\\\\:;\\\\\\\"'<>,.?/\\\"\\n```\\n\\n###
  Emojis\\n\\n```\\nInput: \\\"Message with emojis:    \\\"\\nOutput:
  \\\"Message with emojis:    \\\"\\n```\\n\\n## Development\\n\\n###
  Running Tests\\n\\nThe tests verify the echo functionality works correctly
  with various types of input:\\n\\n```bash\\nnpm test\\n```\\n\\n###
  Building\\n\\n```bash\\nnpm run build\\n```\\n\\n##
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":11,\"downloadCo\
  unt\":4521,\"createdAt\":\"2025-03-18T05:52:43.105423Z\",\"updatedAt\":\"2025\
  -07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T11:40:40.749289Z\"}\
  ,{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/amazon-kendra-index-mcp-se\
  rver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/amazon-ke\
  ndra-index-mcp-server\",\"name\":\"Amazon Kendra
  Index\",\"author\":\"awslabs\",\"description\":\"Enables RAG capabilities by
  integrating with Amazon Kendra indices, allowing AI assistants to query and
  retrieve context from enterprise documents and knowledge
  bases.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/aws.png\",\"category\":\"knowledge-memory\",\"tags\":[\
  \"rag\",\"search\",\"aws\",\"knowledge-base\",\"enterprise-search\"],\"requir\
  esApiKey\":false,\"readmeContent\":\"# AWS Labs Amazon Kendra Index MCP
  Server\\n\\nAn AWS Labs Model Context Protocol (MCP) server for Amazon Kendra.
  This MCP server allows you to use Kendra Indices as additional context for
  RAG.\\n\\n### Features:\\n\\n* Enhance your existing MCP-enabled ChatBot with
  additional RAG indices\\n* Enhance the responses from coding assistants such
  as Cline, Cursor, Windsurf, Amazon Q Developer, etc.\\n\\n###
  Pre-Requisites:\\n\\n1. [Sign-Up for an AWS
  account](https://aws.amazon.com/free/?trk=78b916d7-7c94-4cab-98d9-0ce5e648dd5\
  f&sc_channel=ps&ef_id=Cj0KCQjwxJvBBhDuARIsAGUgNfjOZq8r2bH2OfcYfYTht5v5I1Bn0lB\
  KiI2Ii71A8Gk39ZU5cwMLPkcaAo_CEALw_wcB:G:s&s_kwcid=AL!4422!3!432339156162!e!!g\
  !!aws%20sign%20up!9572385111!102212379327&gad_campaignid=9572385111&gbraid=0A\
  AAAADjHtp99c5A9DUyUaUQVhVEoi8of3&gclid=Cj0KCQjwxJvBBhDuARIsAGUgNfjOZq8r2bH2Of\
  cYfYTht5v5I1Bn0lBKiI2Ii71A8Gk39ZU5cwMLPkcaAo_CEALw_wcB)\\n2. [Create an Amazon
  Kendra Index](https://docs.aws.amazon.com/kendra/latest/dg/create-index.html)
  with your RAG documentation\\n3. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n4. Install
  Python using `uv python install 3.10`\\n\\n\\n\\n### Tools:\\n\\n####
  KendraQueryTool\\n\\n  - The KendraQueryTool takes the query specified by the
  user and queries a Kendra index to gain additional context for the response.
  This queries either the default index, or an index specified in the users
  prompt.\\n  - Required Parameters: query (str)\\n  - Optional Parameters:
  indexId (str), region (str)\\n  - Example:\\n    * `Can you help me understand
  how to implement a progress event in the CreateHandler using Java? Use the
  KendraQueryTool to gain additional context.`\\n    * `Can you use the
  test-kendra-index to help answer the following questions...`\\n\\n####
  KendraListIndexesTool\\n\\n  - The KendraListIndexesTool lists the Kendra
  Indexes in your account. By default it will list all the indices in the
  regions provided as environment variables to the mcp config file. Otherwise
  the region can be specified in the prompt.\\n  - Optional Parameters: region
  (str)\\n  - Example:\\n    * `Can you list the Kendra Indexes in my account in
  the us-west-2 region`\\n\\n\\n## Setup\\n\\n### IAM Configuration\\n\\n1.
  Provision a user in your AWS account IAM\\n2. Attach a policy that contains at
  a minimum the `kendra:Query` and `kendra:ListIndices` permissions.
  Alternatively the AWS Managed `AmazonKendraFullAccess` policy can be attached.
  Always follow the principal or least privilege when granting users
  permissions. See the
  [documentation](https://docs.aws.amazon.com/service-authorization/latest/refe\
  rence/list_amazonkendra.html) for more information on IAM permissions for
  Amazon Kendra.\\n3. Use `aws configure` on your environment to configure the
  credentials (access ID and access key)\\n\\n### Installation\\n\\n[![Install
  MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.amazon-kendra-index-mcp-server&config=eyJjb21tYW5k\
  IjoidXZ4IGF3c2xhYnMuYW1hem9uLWtlbmRyYS1pbmRleC1tY3Atc2VydmVyIiwiZW52Ijp7IkZBU\
  1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IiLCJLRU5EUkFfSU5ERVhfSUQiOiJbWW91ciBLZW5kcmEgSW\
  5kZXggSWRdIiwiQVdTX1BST0ZJTEUiOiJbWW91ciBBV1MgUHJvZmlsZSBOYW1lXSIsIkFXU19SRUd\
  JT04iOiJbUmVnaW9uIHdoZXJlIHlvdXIgS2VuZHJhIEluZGV4IHJlc2lkZXNdIn0sImRpc2FibGVk\
  IjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nConfigure the MCP server in
  your MCP client configuration (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n      \\\"mcpServers\\\":
  {\\n            \\\"awslabs.amazon-kendra-index-mcp-server\\\":
  {\\n                  \\\"command\\\":
  \\\"uvx\\\",\\n                  \\\"args\\\":
  [\\\"awslabs.amazon-kendra-index-mcp-server\\\"],\\n                  \\\"env\
  \\\": {\\n                    \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n                    \\\"KENDRA_INDEX_ID\\\": \\\"[Your Kendra
  Index Id]\\\",\\n                    \\\"AWS_PROFILE\\\": \\\"[Your AWS
  Profile Name]\\\",\\n                    \\\"AWS_REGION\\\": \\\"[Region where
  your Kendra Index
  resides]\\\"\\n                  },\\n                  \\\"disabled\\\":
  false,\\n                  \\\"autoApprove\\\":
  []\\n                }\\n      }\\n}\\n```\\nor docker after a successful
  `docker build -t awslabs/amazon-kendra-index-mcp-server.`:\\n\\n```file\\n#
  fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=<from the profile you set
  up>\\nAWS_SECRET_ACCESS_KEY=<from the profile you set
  up>\\nAWS_SESSION_TOKEN=<from the profile you set
  up>\\n```\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.amazon-kendra-index-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file\
  /above/.env\\\",\\n          \\\"awslabs/amazon-kendra-index-mcp-server:latest\
  \\\"\\n        ],\\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\nNOTE:
  Your credentials will need to be kept refreshed from your host\\n\\n## Best
  Practices\\n\\n- Follow the principle of least privilege when setting up IAM
  permissions\\n- Use separate AWS profiles for different environments (dev,
  test, prod)\\n- Monitor broker metrics and logs for performance and issues\\n-
  Implement proper error handling in your client applications\\n\\n## Security
  Considerations\\n\\nWhen using this MCP server, consider:\\n\\n- This MCP
  server needs permissions to query and list Amazon Kendra Indexes\\n- This MCP
  server cannot create, modify, or delete resources in your account\\n\\n##
  Troubleshooting\\n\\n- If you encounter permission errors, verify your IAM
  user has the correct policies attached\\n- For connection issues, check
  network configurations and security groups\\n- If resource modification fails
  with a tag validation error, it means the resource was not created by the MCP
  server\\n- For general Amazon Kendra issues, consult the [Amazon Kendra
  developer
  guide](https://docs.aws.amazon.com/kendra/latest/dg/what-is-kendra.html)\\n\\\
  n## Version\\n\\nCurrent MCP server version:
  0.0.0\\n\",\"isRecommended\":false,\"githubStars\":4428,\"downloadCount\":68,\
  \"createdAt\":\"2025-06-21T01:59:55.118648Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-08T00:53:01.822358Z\"},{\"mcpId\":\
  \"github.com/NightTrek/Ollama-mcp\",\"githubUrl\":\"https://github.com/NightT\
  rek/Ollama-mcp\",\"name\":\"Ollama\",\"author\":\"NightTrek\",\"description\":\
  \"Enables seamless integration with Ollama's local LLM capabilities, providing
  model management, chat completion, and custom model creation with
  OpenAI-compatible
  API.\",\"codiconIcon\":\"terminal\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/ollama.png\",\"category\":\"developer-tools\",\"tags\
  \":[\"llm\",\"model-management\",\"local-ai\",\"chat-completion\",\"ollama-api\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Ollama MCP Server\\n\\n A
  powerful bridge between Ollama and the Model Context Protocol (MCP), enabling
  seamless integration of Ollama's local LLM capabilities into your MCP-powered
  applications.\\n\\n##  Features\\n\\n### Complete Ollama Integration\\n-
  **Full API Coverage**: Access all essential Ollama functionality through a
  clean MCP interface\\n- **OpenAI-Compatible Chat**: Drop-in replacement for
  OpenAI's chat completion API\\n- **Local LLM Power**: Run AI models locally
  with full control and privacy\\n\\n### Core Capabilities\\n-  **Model
  Management**\\n  - Pull models from registries\\n  - Push models to
  registries\\n  - List available models\\n  - Create custom models from
  Modelfiles\\n  - Copy and remove models\\n\\n-  **Model Execution**\\n  -
  Run models with customizable prompts\\n  - Chat completion API with
  system/user/assistant roles\\n  - Configurable parameters (temperature,
  timeout)\\n  - Raw mode support for direct responses\\n\\n-  **Server
  Control**\\n  - Start and manage Ollama server\\n  - View detailed model
  information\\n  - Error handling and timeout management\\n\\n##  Getting
  Started\\n\\n### Prerequisites\\n- [Ollama](https://ollama.ai) installed on
  your system\\n- Node.js and npm/pnpm\\n\\n### Installation\\n\\n1. Install
  dependencies:\\n```bash\\npnpm install\\n```\\n\\n2. Build the
  server:\\n```bash\\npnpm run build\\n```\\n\\n### Configuration\\n\\nAdd the
  server to your MCP configuration:\\n\\n#### For Claude Desktop:\\nMacOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\nWindows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"ollama\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/ollama-server/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"OLLAMA_HOST\\\": \\\"http://127.0.0.1:11434\\\"  // Optional:
  customize Ollama API endpoint\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## 
  Usage Examples\\n\\n### Pull and Run a Model\\n```typescript\\n// Pull a
  model\\nawait mcp.use_mcp_tool({\\n  server_name:
  \\\"ollama\\\",\\n  tool_name: \\\"pull\\\",\\n  arguments: {\\n    name:
  \\\"llama2\\\"\\n  }\\n});\\n\\n// Run the model\\nawait
  mcp.use_mcp_tool({\\n  server_name: \\\"ollama\\\",\\n  tool_name:
  \\\"run\\\",\\n  arguments: {\\n    name: \\\"llama2\\\",\\n    prompt:
  \\\"Explain quantum computing in simple terms\\\"\\n  }\\n});\\n```\\n\\n###
  Chat Completion (OpenAI-compatible)\\n```typescript\\nawait
  mcp.use_mcp_tool({\\n  server_name: \\\"ollama\\\",\\n  tool_name:
  \\\"chat_completion\\\",\\n  arguments: {\\n    model:
  \\\"llama2\\\",\\n    messages: [\\n      {\\n        role:
  \\\"system\\\",\\n        content: \\\"You are a helpful
  assistant.\\\"\\n      },\\n      {\\n        role:
  \\\"user\\\",\\n        content: \\\"What is the meaning of
  life?\\\"\\n      }\\n    ],\\n    temperature: 0.7\\n  }\\n});\\n```\\n\\n###
  Create Custom Model\\n```typescript\\nawait
  mcp.use_mcp_tool({\\n  server_name: \\\"ollama\\\",\\n  tool_name:
  \\\"create\\\",\\n  arguments: {\\n    name:
  \\\"custom-model\\\",\\n    modelfile:
  \\\"./path/to/Modelfile\\\"\\n  }\\n});\\n```\\n\\n##  Advanced
  Configuration\\n\\n- `OLLAMA_HOST`: Configure custom Ollama API endpoint
  (default: http://127.0.0.1:11434)\\n- Timeout settings for model execution
  (default: 60 seconds)\\n- Temperature control for response randomness (0-2
  range)\\n\\n##  Contributing\\n\\nContributions are welcome! Feel free
  to:\\n- Report bugs\\n- Suggest new features\\n- Submit pull requests\\n\\n##
   License\\n\\nMIT License - feel free to use in your own
  projects!\\n\\n---\\n\\nBuilt with  for the MCP
  ecosystem\\n\",\"isRecommended\":false,\"githubStars\":64,\"downloadCount\":4\
  995,\"createdAt\":\"2025-02-18T23:03:57.065833Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T01:09:24.867821Z\"},{\"mcp\
  Id\":\"github.com/modelcontextprotocol/servers/tree/main/src/aws-kb-retrieval\
  -server\",\"githubUrl\":\"https://github.com/modelcontextprotocol/servers/tre\
  e/main/src/aws-kb-retrieval-server\",\"name\":\"AWS Knowledge
  Base\",\"author\":\"modelcontextprotocol\",\"description\":\"Retrieves
  information from AWS Knowledge Base using Bedrock Agent Runtime, supporting
  RAG-based queries with customizable result
  counts.\",\"codiconIcon\":\"library\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/aws-knowledge-base.png\",\"category\":\"knowledge-m\
  emory\",\"tags\":[\"aws\",\"bedrock\",\"rag\",\"knowledge-retrieval\",\"search\
  \"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\":57332,\"d\
  ownloadCount\":3319,\"createdAt\":\"2025-02-18T05:44:51.508867Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T01:22:38.6\
  67265Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/cloudwatch-logs-m\
  cp-server\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/clou\
  dwatch-logs-mcp-server\",\"name\":\"CloudWatch
  Logs\",\"author\":\"awslabs\",\"description\":\"Enables analysis of AWS
  CloudWatch logs through log group discovery and Log Insights queries,
  supporting anomaly detection and pattern analysis across
  accounts.\",\"codiconIcon\":\"output\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/aws.png\",\"category\":\"monitoring\",\"tags\":[\"\
  aws\",\"log-analysis\",\"cloud-monitoring\",\"observability\",\"analytics\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"# AWS Labs cloudwatch-logs MCP
  Server (DEPRECATED)\\n\\nAn AWS Labs Model Context Protocol (MCP) server for
  cloudwatch-logs. (DEPRECATED). Please use [CloudWatch MCP
  Server](../../src/cloudwatch-mcp-server/README.md) for unified CloudWatch
  Telemetry related tools.\\n\\n## Instructions\\n\\nUse this MCP server to run
  read-only commands and analyze CloudWatchLogs. Supports discovering logs
  groups as well as running CloudWatch Log Insight\\nQueries. With CloudWatch
  Logs Insights, you can interactively search and analyze your log data in
  Amazon CloudWatch Logs and perform queries to help\\nyou more efficiently and
  effectively respond to operational issues.\\n\\n## Features\\n\\n- Discovering
  log groups and metadata about them within your AWS account or accounts
  connected by CloudWatch Cross Account Observability\\n- Converting
  human-readable questions and commands into CloudWatch Log Insight queries and
  executing them against the discovered log groups.\\n\\n##
  Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. An AWS account with [CloudWatch Log
  Groups](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_GettingS\
  tarted.html)\\n4. This MCP server can only be run locally on the same host as
  your LLM client.\\n5. Set up AWS credentials with access to AWS
  services\\n   - You need an AWS account with appropriate permissions\\n   -
  Configure AWS credentials with `aws configure` or environment
  variables\\n\\n## Available Tools\\n* `describe_log_groups` - Describe log
  groups in the account and region, including user saved queries applicable to
  them. Supports Cross Account Observability.\\n* `analyze_log_group` - Analyzes
  a CloudWatch log group for anomalies, top message patterns, and top error
  patterns within a specified time window.\\nLog group must have at least one
  [CloudWatch Log Anomaly
  Detector](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/LogsAnomal\
  yDetection.html) configured to search for anomalies.\\n*
  `execute_log_insights_query` - Execute a Log Insights query against one or
  more log groups. Will wait for the query to complete for a configurable
  timeout.\\n* `get_query_results` - Get the results of a query previously
  started by `execute_log_insights_query`.\\n* `cancel_query` - Cancel an
  ongoing query that was previously started by
  `execute_log_insights_query`.\\n\\n### Required IAM Permissions\\n*
  `logs:Describe*`\\n* `logs:Get*`\\n* `logs:List*`\\n* `logs:StartQuery`\\n*
  `logs:StopQuery`\\n\\n## Installation\\n\\n(DEPRECATED). Please use
  [CloudWatch MCP Server](../../src/cloudwatch-mcp-server/README.md) for unified
  CloudWatch Telemetry related tools.\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.cloudwatch-logs-mcp-server&config=eyJhdXRvQXBwcm92\
  ZSI6W10sImRpc2FibGVkIjpmYWxzZSwidGltZW91dCI6NjAsImNvbW1hbmQiOiJ1dnggYXdzbGFic\
  y5jbG91ZHdhdGNoLWxvZ3MtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOi\
  JbVGhlIEFXUyBQcm9maWxlIE5hbWUgdG8gdXNlIGZvciBBV1MgYWNjZXNzXSIsIkFXU19SRUdJT04\
  iOiJbVGhlIEFXUyByZWdpb24gdG8gcnVuIGluXSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1Ii\
  fSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D)\\n\\nExample for Amazon Q Developer
  CLI (~/.aws/amazonq/mcp.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cloudwatch-logs-mcp-server\\\":
  {\\n      \\\"autoApprove\\\": [],\\n      \\\"disabled\\\":
  false,\\n      \\\"timeout\\\": 60,\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.cloudwatch-logs-mcp-server@latest\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\": \\\"[The AWS Profile Name to use
  for AWS access]\\\",\\n        \\\"AWS_REGION\\\": \\\"[The AWS region to run
  in]\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"transportType\\\":
  \\\"stdio\\\"\\n    }\\n  }\\n}\\n```\\n\\n### Build and install docker image
  locally on the same host of your LLM client\\n\\n1. `git clone
  https://github.com/awslabs/mcp.git`\\n2. Go to sub-directory
  'src/cloudwatch-logs-mcp-server/'\\n3. Run 'docker build -t
  awslabs/cloudwatch-logs-mcp-server:latest .'\\n\\n### Add or update your LLM
  client's config with following:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cloudwatch-logs-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"-e\\\", \\\"AWS_PROFILE=[your data]\\\",\\n        \\\"-e\\\",
  \\\"AWS_REGION=[your
  data]\\\",\\n        \\\"awslabs/cloudwatch-logs-mcp-server:latest\\\"\\n      \
  ]\\n    }\\n  }\\n}\\n```\\n\\n## Contributing\\n\\nContributions are welcome!
  Please see the [CONTRIBUTING.md](../../CONTRIBUTING.md) in the monorepo root
  for
  guidelines.\\n\",\"isRecommended\":false,\"githubStars\":4383,\"downloadCount\
  \":350,\"createdAt\":\"2025-06-21T01:49:59.366457Z\",\"updatedAt\":\"2025-07-\
  08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T13:30:31.038326Z\"},{\"\
  mcpId\":\"github.com/JetBrains/mcp-jetbrains\",\"githubUrl\":\"https://github\
  .com/JetBrains/mcp-jetbrains\",\"name\":\"JetBrains
  IDE\",\"author\":\"JetBrains\",\"description\":\"Proxies requests between AI
  assistants and JetBrains IDEs, enabling direct interaction with the IDE's
  built-in webserver for development
  tasks.\",\"codiconIcon\":\"symbol-class\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/jetbrains-logo.png\",\"category\":\"developer-t\
  ools\",\"tags\":[\"ide-integration\",\"jetbrains\",\"development\",\"proxy\",\
  \"automation\"],\"requiresApiKey\":false,\"readmeContent\":\"[![official
  JetBrains
  project](http://jb.gg/badges/incubator-flat-square.svg)](https://github.com/J\
  etBrains#jetbrains-on-github)\\n# JetBrains MCP Proxy Server\\n\\nThe server
  proxies requests from client to JetBrains IDE.\\n\\n## Install MCP Server
  plugin\\n\\nhttps://plugins.jetbrains.com/plugin/26071-mcp-server\\n\\n## VS
  Code Installation\\n\\nFor one-click installation, click one of the install
  buttons below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=jetbrains&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%\
  22-y%22%2C%22%40jetbrains%2Fmcp-proxy%22%5D%7D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=jetbrains&config=%7B%22command%22%3A%22npx%22%2C%22a\
  rgs%22%3A%5B%22-y%22%2C%22%40jetbrains%2Fmcp-proxy%22%5D%7D&quality=insiders)\
  \\n\\n### Manual Installation\\n\\nAdd the following JSON block to your User
  Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift +
  P` and typing `Preferences: Open User Settings
  (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"jetbrains\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"@jetbrains/mcp-proxy\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n\\nOptional\
  ly, you can add it to a file called `.vscode/mcp.json` in your
  workspace:\\n\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"jetbrains\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@jetbrains/mcp-proxy\\\"]\\n    }\\n  }\\n}\\n```\\n\\n## Usage with
  Claude Desktop\\n\\nTo use this with Claude Desktop, add the following to your
  `claude_desktop_config.json`.\\nThe full path on MacOS:
  `~/Library/Application\\\\ Support/Claude/claude_desktop_config.json`, on
  Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`.\\n\\n```json\\n{\\n  \\\"mcpSe\
  rvers\\\": {\\n    \\\"jetbrains\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@jetbrains/mcp-proxy\\\"]\\n    }\\n  }\\n}\\n```\\n\\nAfter installing
  the MCP Server Plugin, and adding the JSON to the config file, restart Claude
  Desktop, and make sure the Jetbrains product is open before restarting Claude
  Desktop. \\n\\n## Configuration\\n\\nIf you're running multiple IDEs with MCP
  server and want to connect to the specific one, add to the MCP server
  configuration:\\n```json\\n\\\"env\\\": {\\n  \\\"IDE_PORT\\\": \\\"<port of
  IDE's built-in webserver>\\\"\\n}\\n```\\n\\nBy default, we connect to IDE
  on  127.0.0.1 but you can specify a different
  address/host:\\n```json\\n\\\"env\\\": {\\n  \\\"HOST\\\": \\\"<host/address
  of IDE's built-in webserver>\\\"\\n}\\n```\\n\\nTo enable logging
  add:\\n```json\\n\\\"env\\\": {\\n  \\\"LOG_ENABLED\\\":
  \\\"true\\\"\\n}\\n```\\n\\n## Troubleshooting\\n\\n### Node.js Version
  Requirements\\n**Problem:** Error message: `Cannot find module
  'node:path'`\\n\\n**Solution:**\\nMCP Proxy doesn't work on Node 16.\\nUpgrade
  your Node.js installation to version 18 or later. Make sure that `command` in
  config points to the correct Node.js version.\\nTry to use the full path to
  the latest version of NodeJS.\\n\\n### \\n\\n### MacOS: Plugin Unable to
  Detect Node.js Installed via nvm\\n**Problem:** On MacOS, if you have Node.js
  installed through nvm (Node Version Manager), the MCP Server Plugin might be
  unable to detect your Node.js installation.\\n\\n**Solution:** Create a
  symbolic link in `/usr/local/bin` pointing to your nvm npx
  executable:\\n```bash\\nwhich npx &>/dev/null && sudo ln -sf \\\"$(which
  npx)\\\" /usr/local/bin/npx\\n```\\nThis one-liner checks if npx exists in
  your path and creates the necessary symbolic link with proper
  permissions.\\n\\n### Using MCP with External Clients or Docker Containers
  (LibreChat, Cline, etc.)\\n\\n**Problem:** When attempting to connect to the
  JetBrains MCP proxy from external clients, Docker containers, or third-party
  applications (like LibreChat), requests to endpoints such as
  http://host.docker.internal:6365/api/mcp/list_tools may return 404 errors or
  fail to connect.\\n**Solution:** There are two key issues to address:\\n1.
  Enable External Connections:\\n\\nIn your JetBrains IDE, enable \\\"Can accept
  external connections\\\" in the _Settings | Build, Execution, Deployment |
  Debugger_.\\n\\n2. Configure with LAN IP and Port:\\n\\nUse your machine's LAN
  IP address instead of `host.docker.internal`\\nExplicitly set the IDE_PORT and
  HOST in your configuration\\nExample configuration for LibreChat or similar
  external clients:\\n```yaml\\nmcpServers:\\n  intellij:\\n    type:
  stdio\\n    command: sh\\n    args:\\n      - \\\"-c\\\"\\n      -
  \\\"IDE_PORT=YOUR_IDEA_PORT HOST=YOUR_IDEA_LAN_IP npx -y
  @jetbrains/mcp-proxy\\\"\\n```\\nReplace:\\n\\n`YOUR_IDEA_PORT` with your
  IDE's debug port (found in IDE settings)\\n`YOUR_IDEA_LAN_IP` with your
  computer's local network IP (e.g., 192.168.0.12)\\n\\n\\n## How to build\\n1.
  Tested on macOS\\n2. `brew install node pnpm`\\n3. Run `pnpm build` to build
  the
  project\\n\\n\",\"isRecommended\":true,\"githubStars\":817,\"downloadCount\":\
  802,\"createdAt\":\"2025-02-17T22:47:35.793534Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T03:19:35.282686Z\"},{\"mcp\
  Id\":\"github.com/mobile-next/mobile-mcp\",\"githubUrl\":\"https://github.com\
  /mobile-next/mobile-mcp\",\"name\":\"Mobile
  Next\",\"author\":\"mobile-next\",\"description\":\"Platform-agnostic mobile
  automation server for iOS and Android that enables AI assistants to interact
  with mobile apps through accessibility snapshots and coordinate-based
  interactions on simulators and physical
  devices.\",\"codiconIcon\":\"device-mobile\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/mobile-next.png\",\"category\":\"os-automati\
  on\",\"tags\":[\"mobile-automation\",\"ios-android\",\"app-testing\",\"device\
  -control\",\"accessibility\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Mobile Next - MCP server for Mobile Development and Automation  | iOS,
  Android, Simulator, Emulator, and physical devices\\n\\nThis is a [Model
  Context Protocol (MCP) server](https://github.com/modelcontextprotocol) that
  enables scalable mobile automation, development through a platform-agnostic
  interface, eliminating the need for distinct iOS or Android knowledge. You can
  run it on emulators, simulators, and physical devices (iOS and
  Android).\\nThis server allows Agents and LLMs to interact with native
  iOS/Android applications and devices through structured accessibility
  snapshots or coordinate-based taps based on screenshots.\\n\\n<h4
  align=\\\"center\\\">\\n<a
  href=\\\"https://github.com/mobile-next/mobile-mcp\\\">\\n    <img
  src=\\\"https://img.shields.io/github/stars/mobile-next/mobile-mcp\\\"
  alt=\\\"Mobile Next Stars\\\" />\\n  </a>\\n <a
  href=\\\"https://github.com/mobile-next/mobile-mcp\\\">\\n    <img
  src=\\\"https://img.shields.io/github/contributors/mobile-next/mobile-mcp?col\
  or=green\\\" alt=\\\"Mobile Next Downloads\\\" />\\n  </a>\\n  <a
  href=\\\"https://www.npmjs.com/package/@mobilenext/mobile-mcp\\\">\\n    <img
  src=\\\"https://img.shields.io/npm/dm/@mobilenext/mobile-mcp?logo=npm&style=f\
  lat&color=red\\\" alt=\\\"npm\\\">\\n  </a>\\n<a
  href=\\\"https://github.com/mobile-next/mobile-mcp/releases\\\">\\n    <img
  src=\\\"https://img.shields.io/github/release/mobile-next/mobile-mcp\\\">\\n  \
  </a>\\n<a
  href=\\\"https://github.com/mobile-next/mobile-mcp/blob/main/LICENSE\\\">\\n    \
  <img src=\\\"https://img.shields.io/badge/license-Apache 2.0-blue.svg\\\"
  alt=\\\"Mobile MCP is released under the Apache-2.0
  License\\\">\\n  </a>\\n\\n</p>\\n\\n<h4 align=\\\"center\\\">\\n<a
  href=\\\"http://mobilenexthq.com/join-slack\\\">\\n    <img
  src=\\\"https://img.shields.io/badge/join-Slack-blueviolet?logo=slack&style=f\
  lat\\\" alt=\\\"Slack community channel\\\"
  />\\n</a>\\n</p>\\n\\nhttps://github.com/user-attachments/assets/c4e89c4f-cc7\
  1-4424-8184-bdbc8c638fa1\\n\\n<p align=\\\"center\\\">\\n    <a
  href=\\\"https://github.com/mobile-next/\\\">\\n        <img
  alt=\\\"mobile-mcp\\\"
  src=\\\"https://raw.githubusercontent.com/mobile-next/mobile-next-assets/refs\
  /heads/main/mobile-mcp-banner.png\\\"
  width=\\\"600\\\">\\n    </a>\\n</p>\\n\\n###  Mobile MCP Roadmap: Building
  the Future of Mobile\\n\\nJoin us on our journey as we continuously enhance
  Mobile MCP!\\nCheck out our detailed roadmap to see upcoming features,
  improvements, and milestones. Your feedback is invaluable in shaping the
  future of mobile automation.\\n\\n [Explore the
  Roadmap](https://github.com/orgs/mobile-next/projects/3)\\n\\n\\n### Main use
  cases\\n\\nHow we help to scale mobile automation:\\n\\n-  Native app
  automation (iOS and Android) for testing or data-entry scenarios.\\n- 
  Scripted flows and form interactions without manually controlling
  simulators/emulators or physical devices (iPhone, Samsung, Google Pixel
  etc)\\n-  Automating multi-step user journeys driven by an LLM\\n- 
  General-purpose mobile application interaction for agent-based frameworks\\n-
   Enables agent-to-agent communication for mobile automation usecases, data
  extraction\\n\\n## Main Features\\n\\n-  **Fast and lightweight**: Uses
  native accessibility trees for most interactions, or screenshot based
  coordinates where a11y labels are not available.\\n-  **LLM-friendly**: No
  computer vision model required in Accessibility (Snapshot).\\n-  **Visual
  Sense**: Evaluates and analyses whats actually rendered on screen to decide
  the next action. If accessibility data or view-hierarchy coordinates are
  unavailable, it falls back to screenshot-based analysis.\\n- 
  **Deterministic tool application**: Reduces ambiguity found in purely
  screenshot-based approaches by relying on structured data whenever
  possible.\\n-  **Extract structured data**: Enables you to extract structred
  data from anything visible on screen.\\n\\n##  Mobile MCP
  Architecture\\n\\n<p align=\\\"center\\\">\\n    <a
  href=\\\"https://raw.githubusercontent.com/mobile-next/mobile-next-assets/ref\
  s/heads/main/mobile-mcp-arch-1.png\\\">\\n        <img alt=\\\"mobile-mcp\\\"
  src=\\\"https://raw.githubusercontent.com/mobile-next/mobile-next-assets/refs\
  /heads/main/mobile-mcp-arch-1.png\\\"
  width=\\\"600\\\">\\n    </a>\\n</p>\\n\\n\\n##  Wiki page\\n\\nMore details
  in our [wiki page](https://github.com/mobile-next/mobile-mcp/wiki) for setup,
  configuration and debugging related questions.\\n\\n\\n## Installation and
  configuration\\n\\nSetup our MCP with Cline, Cursor, Claude, VS Code, Github
  Copilot:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mobile-mcp\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@mobilenext/mobile-mcp@latest\\\"]\\n    }\\n  }\\n}\\n\\n```\\n[Cline:](\
  https://docs.cline.bot/mcp/configuring-mcp-servers) To setup Cline, just add
  the json above to your MCP settings file.\\n[More in our
  wiki](https://github.com/mobile-next/mobile-mcp/wiki/Cline)\\n\\n[Claude
  Code:](https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overvi\
  ew)\\n\\n```\\nclaude mcp add mobile -- npx -y
  @mobilenext/mobile-mcp@latest\\n```\\n\\n[Read more in our
  wiki](https://github.com/mobile-next/mobile-mcp/wiki)! \\n\\n\\n###  How
  to Use \\n\\nAfter adding the MCP server to your IDE/Client, you can
  instruct your AI assistant to use the available tools.\\nFor example, in
  Cursor's agent mode, you could use the prompts below to quickly validate, test
  and iterate on UI intereactions, read information from screen, go through
  complex workflows.\\nBe descriptive, straight to the point.\\n\\n###  Example
  Prompts\\n\\n#### Workflows\\n\\nYou can specifiy detailed workflows in a
  single prompt, verify business logic, setup automations. You can go
  crazy:\\n\\n**Search for a video, comment, like and share it.**\\n```\\nFind
  the video called \\\" Beginner Recipe for Tonkotsu Ramen\\\" by Way
  of\\nRamen, click on like video, after liking write a comment \\\" this
  was\\ndelicious, will make it next Friday\\\", share the video with the
  first\\ncontact in your whatsapp list.\\n```\\n\\n**Download a successful step
  counter app, register, setup workout and 5-star the app**\\n```\\nFind and
  Download a free \\\"Pomodoro\\\" app that has more than 1k stars.\\nLaunch the
  app, register with my email, after registration find how to\\nstart a pomodoro
  timer. When the pomodoro timer started, go back to the\\napp store and rate
  the app 5 stars, and leave a comment how useful the\\napp
  is.\\n```\\n\\n**Search in Substack, read, highlight, comment and save an
  article**\\n```\\nOpen Substack website, search for \\\"Latest trends in AI
  automation 2025\\\",\\nopen the first article, highlight the section titled
  \\\"Emerging AI trends\\\",\\nand save article to reading list for later
  review, comment a random\\nparagraph summary.\\n```\\n\\n**Reserve a workout
  class, set timer**\\n```\\nOpen ClassPass, search for yoga classes tomorrow
  morning within 2 miles,\\nbook the highest-rated class at 7 AM, confirm
  reservation,\\nsetup a timer for the booked slot in the
  phone\\n```\\n\\n**Find a local event, setup calendar event**\\n```\\nOpen
  Eventbrite, search for AI startup meetup events happening this\\nweekend in
  \\\"Austin, TX\\\", select the most popular one, register and RSVP\\nyes to
  the event, setup a calendar event as a reminder.\\n```\\n\\n**Check weather
  forecast and send a Whatsapp/Telegram/Slack message**\\n```\\nOpen Weather
  app, check tomorrow's weather forecast for \\\"Berlin\\\", and\\nsend the
  summary via Whatsapp/Telegram/Slack to contact \\\"Lauren Trown\\\",\\nthumbs
  up their response.\\n```\\n\\n- **Schedule a meeting in Zoom and share invite
  via email**\\n```\\nOpen Zoom app, schedule a meeting titled \\\"AI
  Hackathon\\\" for tomorrow at\\n10AM with a duration of 1 hour, copy the
  invitation link, and send it via\\nGmail to contacts
  \\\"team@example.com\\\".\\n```\\n[More prompt examples can be found
  here.](https://github.com/mobile-next/mobile-mcp/wiki/Prompt-Example-repo-lis\
  t)\\n\\n## Prerequisites\\n\\nWhat you will need to connect MCP with your
  agent and mobile devices:\\n\\n- [Xcode command line
  tools](https://developer.apple.com/xcode/resources/)\\n- [Android Platform
  Tools](https://developer.android.com/tools/releases/platform-tools)\\n-
  [node.js](https://nodejs.org/en/download/) v22+\\n-
  [MCP](https://modelcontextprotocol.io/introduction) supported foundational
  models or agents, like [Claude
  MCP](https://modelcontextprotocol.io/quickstart/server), [OpenAI Agent
  SDK](https://openai.github.io/openai-agents-python/mcp/), [Copilot
  Studio](https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio\
  /introducing-model-context-protocol-mcp-in-copilot-studio-simplified-integrat\
  ion-with-ai-apps-and-agents/)\\n\\n### Simulators, Emulators, and Physical
  Devices\\n\\nWhen launched, Mobile MCP can connect to:\\n- iOS Simulators on
  macOS/Linux\\n- Android Emulators on Linux/Windows/macOS\\n- Physical iOS or
  Android devices (requires proper platform tools and drivers)\\n\\nMake sure
  you have your mobile platform SDKs (Xcode, Android SDK) installed and
  configured properly before running Mobile Next Mobile MCP.\\n\\n### Running in
  \\\"headless\\\" mode on Simulators/Emulators\\n\\nWhen you do not have a
  physical phone connected to your machine, you can run Mobile MCP with an
  emulator or simulator in the background.\\n\\nFor example, on Android:\\n1.
  Start an emulator (avdmanager / emulator command).\\n2. Run Mobile MCP with
  the desired flags\\n\\nOn iOS, you'll need Xcode and to run the Simulator
  before using Mobile MCP with that simulator instance.\\n- `xcrun simctl
  list`\\n- `xcrun simctl boot \\\"iPhone 16\\\"`\\n\\n# Thanks to all
  contributors \\n\\n### We appreciate everyone who has helped improve this
  project.\\n\\n  <a href =
  \\\"https://github.com/mobile-next/mobile-mcp/graphs/contributors\\\">\\n   <\
  img src = \\\"https://contrib.rocks/image?repo=mobile-next/mobile-mcp\\\"/>\\n
  </a>\\n\\n\",\"isRecommended\":false,\"githubStars\":1200,\"downloadCount\":7\
  22,\"createdAt\":\"2025-05-27T00:04:16.60182Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T20:29:26.150613Z\"},{\"mcpId\
  \":\"github.com/pinecone-io/assistant-mcp\",\"githubUrl\":\"https://github.co\
  m/pinecone-io/assistant-mcp\",\"name\":\"Pinecone
  Assistant\",\"author\":\"pinecone-io\",\"description\":\"Enables retrieval of
  information from Pinecone Assistant with configurable result limits and API
  integration.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/pinecone-assistant.png\",\"category\":\"knowl\
  edge-memory\",\"tags\":[\"vector-database\",\"information-retrieval\",\"pinec\
  one\",\"data-query\",\"knowledge-base\"],\"requiresApiKey\":false,\"readmeCon\
  tent\":\"# Pinecone Assistant MCP Server\\n\\nAn MCP server implementation for
  retrieving information from Pinecone Assistant.\\n\\n## Features\\n\\n-
  Retrieves information from Pinecone Assistant\\n- Supports multiple results
  retrieval with a configurable number of results\\n\\n## Prerequisites\\n\\n-
  Docker installed on your system\\n- Pinecone API key - obtain from the
  [Pinecone Console](https://app.pinecone.io)\\n- Pinecone Assistant API host -
  after creating an Assistant (e.g. in Pinecone Console), you can find the host
  in the Assistant details page\\n\\n## Building with Docker\\n\\nTo build the
  Docker image:\\n\\n```sh\\ndocker build -t pinecone/assistant-mcp
  .\\n```\\n\\n## Running with Docker\\n\\nRun the server with your Pinecone API
  key:\\n\\n```sh\\ndocker run -i --rm \\\\\\n  -e
  PINECONE_API_KEY=<YOUR_PINECONE_API_KEY_HERE> \\\\\\n  -e
  PINECONE_ASSISTANT_HOST=<YOUR_PINECONE_ASSISTANT_HOST_HERE>
  \\\\\\n  pinecone/assistant-mcp\\n```\\n\\n### Environment Variables\\n\\n-
  `PINECONE_API_KEY` (required): Your Pinecone API key\\n-
  `PINECONE_ASSISTANT_HOST` (optional): Pinecone Assistant API host (default:
  https://prod-1-data.ke.pinecone.io)\\n- `LOG_LEVEL` (optional): Logging level
  (default: info)\\n\\n## Usage with Claude Desktop\\n\\nAdd this to your
  `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"pinecone-assistant\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\": [\\n        \\\"run\\\",
  \\n        \\\"-i\\\", \\n        \\\"--rm\\\", \\n        \\\"-e\\\",
  \\n        \\\"PINECONE_API_KEY\\\", \\n        \\\"-e\\\",
  \\n        \\\"PINECONE_ASSISTANT_HOST\\\",
  \\n        \\\"pinecone/assistant-mcp\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"PINECONE_API_KEY\\\":
  \\\"<YOUR_PINECONE_API_KEY_HERE>\\\",\\n        \\\"PINECONE_ASSISTANT_HOST\\\
  \":
  \\\"<YOUR_PINECONE_ASSISTANT_HOST_HERE>\\\"\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\n## Building from Source\\n\\nIf you prefer to build from source without
  Docker:\\n\\n1. Make sure you have Rust installed (https://rustup.rs/)\\n2.
  Clone this repository\\n3. Run `cargo build --release`\\n4. The binary will be
  available at `target/release/assistant-mcp`\\n\\n### Testing with the
  inspector\\n```sh\\nexport
  PINECONE_API_KEY=<YOUR_PINECONE_API_KEY_HERE>\\nexport
  PINECONE_ASSISTANT_HOST=<YOUR_PINECONE_ASSISTANT_HOST_HERE>\\n# Run the
  inspector alone\\nnpx @modelcontextprotocol/inspector cargo run\\n# Or run
  with Docker directly through the inspector\\nnpx
  @modelcontextprotocol/inspector -- docker run -i --rm -e PINECONE_API_KEY -e
  PINECONE_ASSISTANT_HOST pinecone/assistant-mcp\\n```\\n\\n## License\\n\\nThis
  project is licensed under the terms specified in the LICENSE
  file.\\n\",\"isRecommended\":false,\"githubStars\":23,\"downloadCount\":156,\
  \"createdAt\":\"2025-04-24T06:21:03.858176Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-05T06:39:27.791933Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/openapi-mcp-server\",\"githubUrl\":\"h\
  ttps://github.com/awslabs/mcp/tree/main/src/openapi-mcp-server\",\"name\":\"O\
  penAPI Dynamic Tools\",\"author\":\"awslabs\",\"description\":\"Creates MCP
  tools and resources dynamically from OpenAPI specifications, enabling LLMs to
  interact with APIs through intelligent route mapping and optimized
  prompts.\",\"codiconIcon\":\"json\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/aws.png\",\"category\":\"developer-tools\",\"tags\":[\
  \"openapi\",\"api-integration\",\"dynamic-tools\",\"aws\",\"automation\"],\"r\
  equiresApiKey\":false,\"readmeContent\":\"# AWS Labs OpenAPI MCP
  Server\\n\\nThis project is a server that dynamically creates Model Context
  Protocol (MCP) tools and resources from OpenAPI specifications. It allows
  Large Language Models (LLMs) to interact with APIs through the Model Context
  Protocol.\\n\\n## Features\\n\\n- **Dynamic Tool Generation**: Automatically
  creates MCP tools from OpenAPI endpoints\\n- **Intelligent Route Mapping**:
  Maps GET operations with query parameters to TOOLS instead of RESOURCES\\n  -
  Makes API operations with query parameters easier for LLMs to understand and
  use\\n  - Improves usability of search and filtering endpoints\\n  -
  Configurable via the route_patch module\\n- **Dynamic Prompt Generation**:
  Creates helpful prompts based on API structure\\n  - **Operation-Specific
  Prompts**: Generates natural language prompts for each API operation\\n  -
  **API Documentation Prompts**: Creates comprehensive API documentation
  prompts\\n  - **Prompt Optimization**: Implements token efficiency strategies
  to reduce costs and enhance clarity\\n    - Follows MCP-compliant structure
  with name, description, arguments, and metadata\\n    - Achieves 70-75%
  reduction in token usage while maintaining functionality\\n    - Uses concise
  descriptions with essential information for better developer experience\\n-
  **Transport Options**: Supports stdio transport\\n- **Flexible
  Configuration**: Configure via environment variables or command line
  arguments\\n- **OpenAPI Support**: Works with OpenAPI 3.x specifications in
  JSON or YAML format\\n- **OpenAPI Specification Validation**: Validates
  specifications without failing startup if issues detected, logging warnings
  instead to work with specs having minor issues or non-standard extensions\\n-
  **Authentication Support**: Supports multiple authentication methods (Basic,
  Bearer Token, API Key, Cognito)\\n- **AWS Best Practices**: Implements AWS
  best practices for caching, resilience, and observability\\n- **Comprehensive
  Testing**: Includes extensive unit and integration tests with high code
  coverage\\n- **Metrics Collection**: Tracks API calls, tool usage, errors, and
  performance metrics\\n\\n## Installation\\n\\n### From PyPI\\n\\n```bash\\npip
  install \\\"awslabs.openapi-mcp-server\\\"\\n```\\n\\n### Optional
  Dependencies\\n\\nThe package supports several optional
  dependencies:\\n\\n```bash\\n# For YAML OpenAPI specification support\\npip
  install \\\"awslabs.openapi-mcp-server[yaml]\\\"\\n\\n# For Prometheus metrics
  support\\npip install \\\"awslabs.openapi-mcp-server[prometheus]\\\"\\n\\n#
  For testing\\npip install \\\"awslabs.openapi-mcp-server[test]\\\"\\n\\n# For
  all optional dependencies\\npip install
  \\\"awslabs.openapi-mcp-server[all]\\\"\\n```\\n\\n### From
  Source\\n\\n```bash\\ngit clone https://github.com/awslabs/mcp.git\\ncd
  mcp/src/openapi-mcp-server\\npip install -e .\\n```\\n\\n### Using MCP
  Configuration\\n\\nHere are some ways you can work with MCP across AWS (e.g.
  for Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.openapi-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.openapi-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"API_NAME\\\":
  \\\"your-api-name\\\",\\n        \\\"API_BASE_URL\\\":
  \\\"https://api.example.com\\\",\\n          \\\"API_SPEC_URL\\\":
  \\\"https://api.example.com/openapi.json\\\",\\n          \\\"LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n          \\\"ENABLE_PROMETHEUS\\\":
  \\\"false\\\",\\n          \\\"ENABLE_OPERATION_PROMPTS\\\":
  \\\"true\\\",\\n          \\\"UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN\\\":
  \\\"5.0\\\",\\n          \\\"UVICORN_GRACEFUL_SHUTDOWN\\\":
  \\\"true\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Usage\\n\\n### Basic Usage\\n\\n```bash\\n# Start with Petstore API
  example\\nawslabs.openapi-mcp-server --api-name petstore --api-url
  https://petstore3.swagger.io/api/v3 --spec-url
  https://petstore3.swagger.io/api/v3/openapi.json\\n```\\n\\n### Custom
  API\\n\\n```bash\\n# Use a different API\\nawslabs.openapi-mcp-server
  --api-name myapi --api-url https://api.example.com --spec-url
  https://api.example.com/openapi.json\\n```\\n\\n### Authenticated
  API\\n\\n```bash\\n# Basic Authentication\\nawslabs.openapi-mcp-server
  --api-url https://api.example.com --spec-url
  https://api.example.com/openapi.json --auth-type basic --auth-username
  YOUR_USERNAME --auth-password YOUR_PASSWORD # pragma: allowlist secret\\n\\n#
  Bearer Token Authentication\\nawslabs.openapi-mcp-server --api-url
  https://api.example.com --spec-url https://api.example.com/openapi.json
  --auth-type bearer --auth-token YOUR_TOKEN # pragma: allowlist secret\\n\\n#
  API Key Authentication (in header)\\nawslabs.openapi-mcp-server --api-url
  https://api.example.com --spec-url https://api.example.com/openapi.json
  --auth-type api_key --auth-api-key YOUR_API_KEY --auth-api-key-name X-API-Key
  --auth-api-key-in header # pragma: allowlist secret\\n```\\n\\nFor detailed
  information about authentication methods, configuration options, and examples,
  see [AUTHENTICATION.md](AUTHENTICATION.md).\\n\\n### Local OpenAPI
  Specification\\n\\n```bash\\n# Use a local OpenAPI specification
  file\\nawslabs.openapi-mcp-server --spec-path ./openapi.json\\n```\\n\\n###
  YAML OpenAPI Specification\\n\\n```bash\\n# Use a YAML OpenAPI specification
  file (requires pyyaml)\\npip install
  \\\"awslabs.openapi-mcp-server[yaml]\\\"\\nawslabs.openapi-mcp-server
  --spec-path ./openapi.yaml\\n```\\n\\n### Local Development and
  Testing\\n\\nFor local development and testing, you can use the `uvx` command
  with the `--refresh` and `--from` options:\\n\\n```bash\\n# Run the server
  from the local directory with the Petstore API\\nuvx --refresh --from .
  awslabs.openapi-mcp-server --api-url https://petstore3.swagger.io/api/v3
  --spec-url https://petstore3.swagger.io/api/v3/openapi.json --log-level
  DEBUG\\n```\\n\\n**Command Options Explained:**\\n\\n- `uvx` - The uv package
  manager's execution tool for running Python packages\\n- `--refresh` -
  Refreshes the package cache to ensure the latest version is used (important
  during development)\\n- `--from .` - Uses the package from the current
  directory instead of installing from PyPI\\n- `awslabs.openapi-mcp-server` -
  The package name to run\\n- `--api-url` - The base URL of the API\\n-
  `--spec-url` - The URL of the OpenAPI specification\\n- `--log-level DEBUG` -
  Sets the logging level to DEBUG for more detailed logs (useful for
  development)\\n**When to Use These Options:**\\n\\n- Use `--refresh` when
  you've made changes to your code and want to ensure the latest version is
  used\\n- Use `--log-level DEBUG` when you need detailed logs for
  troubleshooting or development\\n\\n**Note:** The Petstore API is a standard
  OpenAPI schema endpoint that can be used for simple testing without any API
  authentication configuration. It's perfect for testing your MCP server
  implementation without setting up your own API.\\n\\n## Configuration\\n\\n###
  Environment Variables\\n\\n```bash\\n# Server configuration\\nexport
  SERVER_NAME=\\\"My API Server\\\"\\nexport SERVER_DEBUG=true\\nexport
  SERVER_MESSAGE_TIMEOUT=60\\nexport SERVER_HOST=\\\"0.0.0.0\\\"\\nexport
  SERVER_PORT=8000\\nexport SERVER_TRANSPORT=\\\"stdio\\\"  # Option:
  stdio\\nexport LOG_LEVEL=\\\"INFO\\\"  # Options: DEBUG, INFO, WARNING, ERROR,
  CRITICAL\\n\\n# Metrics and monitoring configuration\\nexport
  ENABLE_PROMETHEUS=\\\"false\\\"  # Enable/disable Prometheus metrics (default:
  false)\\nexport PROMETHEUS_PORT=9090  # Port for Prometheus metrics
  server\\nexport ENABLE_OPERATION_PROMPTS=\\\"true\\\"  # Enable/disable
  operation-specific prompts (default: true)\\n\\n# Graceful shutdown
  configuration\\nexport UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=5.0  # Timeout for
  graceful shutdown in seconds\\nexport UVICORN_GRACEFUL_SHUTDOWN=true  #
  Enable/disable graceful shutdown\\n\\n# API configuration\\nexport
  API_NAME=\\\"myapi\\\"\\nexport
  API_BASE_URL=\\\"https://api.example.com\\\"\\nexport
  API_SPEC_URL=\\\"https://api.example.com/openapi.json\\\"\\nexport
  API_SPEC_PATH=\\\"/path/to/local/openapi.json\\\"  # Optional: local file
  path\\n\\n# Authentication configuration\\nexport AUTH_TYPE=\\\"none\\\"  #
  Options: none, basic, bearer, api_key\\nexport
  AUTH_USERNAME=\\\"PLACEHOLDER_USERNAME\\\"  # For basic authentication #
  pragma: allowlist secret\\nexport
  AUTH_PASSWORD=\\\"PLACEHOLDER_PASSWORD\\\"  # For basic authentication #
  pragma: allowlist secret\\nexport AUTH_TOKEN=\\\"PLACEHOLDER_TOKEN\\\"  # For
  bearer token authentication # pragma: allowlist secret\\nexport
  AUTH_API_KEY=\\\"PLACEHOLDER_API_KEY\\\"  # For API key authentication #
  pragma: allowlist secret\\nexport AUTH_API_KEY_NAME=\\\"X-API-Key\\\"  # Name
  of the API key (default: api_key)\\nexport AUTH_API_KEY_IN=\\\"header\\\"  #
  Where to place the API key (options: header, query, cookie)\\n```\\n\\n##
  Documentation\\n\\nThe OpenAPI MCP Server includes comprehensive documentation
  to help you get started and make the most of its features:\\n\\n-
  [**AUTHENTICATION.md**](AUTHENTICATION.md): Detailed information about
  authentication methods, configuration options, and troubleshooting\\n-
  [**DEPLOYMENT.md**](DEPLOYMENT.md): Guidelines for deploying the server in
  various environments, including Docker and AWS\\n-
  [**AWS_BEST_PRACTICES.md**](AWS_BEST_PRACTICES.md): AWS best practices
  implemented in the server for resilience, caching, and efficiency\\n-
  [**OBSERVABILITY.md**](OBSERVABILITY.md): Information about metrics, logging,
  and monitoring capabilities\\n- [**tests/README.md**](tests/README.md):
  Overview of the test structure and strategy\\n\\n## AWS Best
  Practices\\n\\nThe OpenAPI MCP Server implements AWS best practices for
  building resilient, observable, and efficient cloud applications. These
  include:\\n\\n- **Caching**: Robust caching system with multiple backend
  options\\n- **Resilience**: Patterns to handle transient failures and ensure
  high availability\\n- **Observability**: Comprehensive monitoring, metrics,
  and logging features\\n\\nFor detailed information about these features,
  including implementation details and configuration options, see
  [AWS_BEST_PRACTICES.md](AWS_BEST_PRACTICES.md).\\n\\n## Docker
  Deployment\\n\\nThe project includes a Dockerfile for containerized
  deployment. To build and run:\\n\\n```bash\\n# Build the Docker image\\ndocker
  build -t openapi-mcp-server:latest .\\n\\n# Run with default settings\\ndocker
  run -p 8000:8000 openapi-mcp-server:latest\\n\\n# Run with custom
  configuration\\ndocker run -p 8000:8000 \\\\\\n  -e API_NAME=myapi \\\\\\n  -e
  API_BASE_URL=https://api.example.com \\\\\\n  -e
  API_SPEC_URL=https://api.example.com/openapi.json \\\\\\n  -e
  SERVER_TRANSPORT=stdio \\\\\\n  -e ENABLE_PROMETHEUS=false \\\\\\n  -e
  ENABLE_OPERATION_PROMPTS=true \\\\\\n  -e
  UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=5.0 \\\\\\n  -e
  UVICORN_GRACEFUL_SHUTDOWN=true
  \\\\\\n  openapi-mcp-server:latest\\n```\\n\\nFor detailed information about
  Docker deployment, AWS service integration, and transport considerations, see
  the [DEPLOYMENT.md](DEPLOYMENT.md) file.\\n\\n## Testing\\n\\nThe project
  includes a comprehensive test suite covering unit tests, integration tests,
  and API functionality tests.\\n\\n### Running Tests\\n\\n```bash\\n# Install
  test dependencies\\npip install
  \\\"awslabs.openapi-mcp-server[test]\\\"\\n\\n# Run all tests\\npytest\\n\\n#
  Run tests with coverage\\npytest --cov=awslabs\\n\\n# Run specific test
  modules\\npytest tests/api/\\npytest tests/utils/\\n```\\n\\nThe test suite
  covers:\\n\\n1. **API Configuration**: Tests for API configuration handling
  and validation\\n2. **API Discovery**: Tests for API endpoint discovery and
  tool generation\\n3. **Caching**: Tests for the caching system and
  providers\\n4. **HTTP Client**: Tests for the HTTP client with resilience
  features\\n5. **Metrics**: Tests for metrics collection and reporting\\n6.
  **OpenAPI Validation**: Tests for OpenAPI specification validation\\n\\nFor
  more information about the test structure and strategy, see the
  [tests/README.md](tests/README.md) file.\\n\\n## Instructions\\n\\nThis server
  acts as a bridge between OpenAPI specifications and LLMs, allowing models to
  have a better understanding of available API capabilities without requiring
  manual tool definitions. The server creates structured MCP tools that LLMs can
  use to understand and interact with your API endpoints, parameters, and
  response formats.\\n\\n### Key Features\\n\\n1. **Dynamic Tool Generation**:
  Automatically creates MCP tools from your API endpoints\\n2.
  **Operation-Specific Prompts**: Generates natural language prompts for each
  API operation\\n3. **API Documentation**: Creates comprehensive documentation
  prompts for the entire API\\n4. **Authentication Support**: Works with Basic
  Auth, Bearer Token, API Key, and Cognito authentication\\n\\n### Getting
  Started\\n\\n1. Point the server to your API by providing:\\n   - API
  name\\n   - API base URL\\n   - OpenAPI specification URL or local file
  path\\n2. Set up appropriate authentication if your API requires it\\n3.
  Configure the stdio transport option\\n\\n### Monitoring and Metrics\\n\\nThe
  server includes built-in monitoring capabilities:\\n- Prometheus metrics
  (disabled by default)\\n- Detailed logging of API calls and tool usage\\n-
  Performance tracking for API operations\\n## Testing with Amazon Q\\n\\nTo
  test the OpenAPI MCP Server with Amazon Q, you need to configure Amazon Q to
  use your MCP server. Here's how:\\n\\n1. **Configure Amazon Q MCP
  Integration**\\n\\n   Create or edit the MCP configuration
  file:\\n\\n   ```bash\\n   mkdir -p ~/.aws/amazonq\\n   nano
  ~/.aws/amazonq/mcp.json\\n   ```\\n\\n   Add the following
  configuration:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"awslabs.openapi-mcp-server\\\": {\\n         \\\"command\\\":
  \\\"python\\\",\\n         \\\"args\\\": [\\\"-m\\\",
  \\\"awslabs.openapi_mcp_server\\\"],\\n         \\\"cwd\\\":
  \\\"/path/to/your/openapi-mcp-server\\\",\\n         \\\"env\\\":
  {\\n           \\\"API_NAME\\\":
  \\\"petstore\\\",\\n           \\\"API_BASE_URL\\\":
  \\\"https://petstore3.swagger.io/api/v3\\\",\\n           \\\"API_SPEC_URL\\\
  \":
  \\\"https://petstore3.swagger.io/api/v3/openapi.json\\\",\\n           \\\"LO\
  G_LEVEL\\\": \\\"INFO\\\",\\n           \\\"ENABLE_PROMETHEUS\\\":
  \\\"false\\\",\\n           \\\"ENABLE_OPERATION_PROMPTS\\\":
  \\\"true\\\",\\n           \\\"UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN\\\":
  \\\"5.0\\\",\\n           \\\"UVICORN_GRACEFUL_SHUTDOWN\\\":
  \\\"true\\\",\\n           \\\"PYTHONPATH\\\":
  \\\"/path/to/your/openapi-mcp-server\\\"\\n         },\\n         \\\"disabled\
  \\\": false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n2. **Start Amazon Q
  CLI**\\n\\n   Launch the Amazon Q CLI:\\n\\n   ```bash\\n   q
  chat\\n   ```\\n\\n3. **Test the Operation Prompts**\\n\\n   Once connected,
  you can test the operation prompts by asking Amazon Q to help you with
  specific API operations:\\n\\n   ```\\n   I need to find a pet by ID using the
  Petstore API\\n   ```\\n\\n   Amazon Q should respond with guidance using the
  natural language
  prompt.\\n\",\"isRecommended\":false,\"githubStars\":4396,\"downloadCount\":1\
  20,\"createdAt\":\"2025-06-21T01:34:11.594958Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T07:50:09.7423Z\"},{\"mcpId\
  \":\"github.com/esignaturescom/mcp-server-esignatures\",\"githubUrl\":\"https\
  ://github.com/esignaturescom/mcp-server-esignatures\",\"name\":\"eSignatures\
  \",\"author\":\"esignaturescom\",\"description\":\"Manages digital contract
  workflows including creation, sending, and template management for electronic
  signatures through the eSignatures
  platform.\",\"codiconIcon\":\"file-text\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/esignatures.png\",\"category\":\"license\",\"ta\
  gs\":[\"digital-signatures\",\"contracts\",\"document-management\",\"templates\
  \",\"collaboration\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  mcp-server-esignatures MCP server\\n\\nMCP server for eSignatures
  (https://esignatures.com)\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/0ev38n83u4\\\"><img width=\\\"380\\\"
  height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/0ev38n83u4/badge\\\"
  alt=\\\"Server for eSignatures MCP server\\\" /></a>\\n\\n## Tools\\n\\n\\n|
  Tool                           | Category      |
  Description                        |\\n|--------------------------------|----\
  -----------|------------------------------------|\\n|
  `create_contract`              | Contracts     | Draft for review or send
  contract  |\\n| `query_contract`               | Contracts     | Retrieve
  contract info             |\\n| `withdraw_contract`            |
  Contracts     | Withdraw an unsigned contract      |\\n|
  `delete_contract`              | Contracts     | Delete a draft or test
  contract    |\\n| `list_recent_contracts`        | Contracts     | List the
  recent
  contracts          |\\n|                                |               |                                    \
  |\\n| `create_template`              | Templates     | Create a new contract
  template     |\\n| `update_template`              | Templates     | Update an
  existing template        |\\n| `query_template`               |
  Templates     | Retrieve template content and info |\\n|
  `delete_template`              | Templates     | Delete a
  template                  |\\n| `list_templates`               |
  Templates     | List all your
  templates            |\\n|                                |               |                                    \
  |\\n| `add_template_collaborator`    | Collaborators | Invite someone to edit
  a template  |\\n| `remove_template_collaborator` | Collaborators | Revoke
  template editing rights     |\\n| `list_template_collaborators`  |
  Collaborators | View who can edit a template       |\\n\\n\\n##
  Examples\\n\\n#### Creating a Draft Contract\\n\\n`Generate a draft NDA
  contract for a publisher, which I can review and send. Signer: John Doe, ACME
  Corp, john@acme.com`\\n\\n#### Sending a Contract\\n\\n`Send an NDA based on
  my template to John Doe, ACME Corp, john@acme.com. Set the term to 2
  years.`\\n\\n#### Updating templates\\n\\n`Review my templates for legal
  compliance, and ask me about updating each one individually`\\n\\n####
  Inviting template collaborators\\n\\n`Invite John Doe to edit the NDA
  template, email: john@acme.com`\\n\\n\\n## Install\\n\\n### Create an
  eSignatures account\\n\\nCreate an eSignatures account at
  https://esignatures.com for free, to test the Agent AI by creating templates
  and sending test contracts.\\n\\n### Claude Desktop\\n\\nOn MacOS:
  `~/Library/Application\\\\ Support/Claude/claude_desktop_config.json`\\nOn
  Windows: `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n#####
  Development/Unpublished Servers Configuration\\n```\\n\\\"mcpServers\\\":
  {\\n  \\\"mcp-server-esignatures\\\": {\\n    \\\"command\\\":
  \\\"uv\\\",\\n    \\\"env\\\": {\\n      \\\"ESIGNATURES_SECRET_TOKEN\\\":
  \\\"your-esignatures-api-secret-token\\\"\\n    },\\n    \\\"args\\\":
  [\\n      \\\"--directory\\\",\\n      \\\"/your-local-directories/mcp-server\
  -esignatures\\\",\\n      \\\"run\\\",\\n      \\\"mcp-server-esignatures\\\"\
  \\n    ]\\n  }\\n}\\n```\\n\\n#### Published Servers
  Configuration\\n```\\n\\\"mcpServers\\\":
  {\\n  \\\"mcp-server-esignatures\\\": {\\n    \\\"command\\\":
  \\\"uvx\\\",\\n    \\\"args\\\":
  [\\n      \\\"mcp-server-esignatures\\\"\\n    ],\\n    \\\"env\\\":
  {\\n      \\\"ESIGNATURES_SECRET_TOKEN\\\":
  \\\"your-esignatures-api-secret-token\\\"\\n    }\\n  }\\n}\\n```\\n\\n###
  Authentication\\n\\nTo use this server, you need to set the
  `ESIGNATURES_SECRET_TOKEN` environment variable with your eSignatures API
  secret token.\\n\\n## eSignatures API Documentation\\n\\nFor a detailed guide
  on API endpoints, parameters, and responses, see [eSignatures
  API](https://esignatures.com/docs/api).\\n\\n## eSignatures Support\\n\\nFor
  support, please navigate to [Support](https://esignatures.com/support) or
  contact [support@esignatures.com](mailto:support@esignatures.com).\\n\\n##
  Contributing\\n\\nContributions are welcome! If you'd like to contribute,
  please fork the repository and make changes as you see fit. Here are some
  guidelines:\\n\\n- **Bug Reports**: Please open an issue to report any bugs
  you encounter.\\n- **Feature Requests**: Suggest new features by opening an
  issue with the \\\"enhancement\\\" label.\\n- **Pull Requests**: Ensure your
  pull request follows the existing code style.\\n- **Documentation**: Help
  improve or translate documentation. Any form of documentation enhancement is
  appreciated.\\n\\nFor major changes, please open an issue first to discuss
  what you would like to change. We're looking forward to your
  contributions!\\n\",\"isRecommended\":true,\"githubStars\":19,\"downloadCount\
  \":69,\"createdAt\":\"2025-02-18T05:46:04.573832Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T00:28:30.926795Z\"},{\"m\
  cpId\":\"github.com/awslabs/mcp/tree/main/src/nova-canvas-mcp-server\",\"gith\
  ubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/nova-canvas-mcp-server\
  \",\"name\":\"Nova Canvas\",\"author\":\"awslabs\",\"description\":\"Generates
  AI images using Amazon Nova Canvas, supporting text prompts and color palettes
  with customizable dimensions, quality options, and multi-image
  generation.\",\"codiconIcon\":\"paintcan\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/aws.png\",\"category\":\"image-video-processing\
  \",\"tags\":[\"image-generation\",\"ai-art\",\"aws\",\"text-to-image\",\"colo\
  r-palettes\"],\"requiresApiKey\":false,\"readmeContent\":\"# Amazon Nova
  Canvas MCP Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/@awslabs/nova-canvas-mcp-server)](https://sm\
  ithery.ai/server/@awslabs/nova-canvas-mcp-server)\\n\\nMCP server for
  generating images using Amazon Nova Canvas\\n\\n## Features\\n\\n###
  Text-based image generation\\n\\n- Create images from text prompts with
  `generate_image`\\n- Customizable dimensions (320-4096px), quality options,
  and negative prompting\\n- Supports multiple image generation (1-5) in single
  request\\n- Adjustable parameters like cfg_scale (1.1-10.0) and seeded
  generation\\n\\n### Color-guided image generation\\n\\n- Generate images with
  specific color palettes using `generate_image_with_colors`\\n- Define up to 10
  hex color values to influence the image style and mood\\n- Same customization
  options as text-based generation\\n\\n### Workspace integration\\n\\n- Images
  saved to user-specified workspace directories with automatic folder
  creation\\n\\n### AWS authentication\\n\\n- Uses AWS profiles for secure
  access to Amazon Nova Canvas services\\n\\n## Prerequisites\\n\\n1. Install
  `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or
  the [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to Amazon Bedrock and Nova Canvas\\n   - You need an AWS account with Amazon
  Bedrock and Amazon Nova Canvas enabled\\n   - Configure AWS credentials with
  `aws configure` or environment variables\\n   - Ensure your IAM role/user has
  permissions to use Amazon Bedrock and Nova Canvas\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.nova-canvas-mcp-server&config=eyJjb21tYW5kIjoidXZ4\
  IGF3c2xhYnMubm92YS1jYW52YXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJT\
  EUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSIsIkZBU1RNQ1BfTE\
  9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\n\
  Configure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.nova-canvas-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.nova-canvas-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/nova-canvas-mcp-server
  .`:\\n\\n```file\\n# fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\": {\\n      \\\"awslabs.nova-canvas-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"AWS_REGION=us-east-1\\\
  \",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\\
  n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file/above/.env\\\
  \",\\n          \\\"awslabs/nova-canvas-mcp-server:latest\\\"\\n        ],\\n        \
  \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\n### Installing via Smithery\\n\\nTo install
  Amazon Nova Canvas MCP Server for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@awslabs/nova-canvas-mcp-server):\\n\\n\
  ```bash\\nnpx -y @smithery/cli install @awslabs/nova-canvas-mcp-server
  --client claude\\n```\\n\\n### AWS Authentication\\n\\nThe MCP server uses the
  AWS profile specified in the `AWS_PROFILE` environment variable. If not
  provided, it defaults to the \\\"default\\\" profile in your AWS configuration
  file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n  \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n}\\n```\\n\\nMake sure the AWS profile has permissions to
  access Amazon Bedrock and Amazon Nova Canvas. The MCP server creates a boto3
  session using the specified profile to authenticate with AWS services. Your
  AWS IAM credentials remain on your local machine and are strictly used for
  using the Amazon Bedrock model
  APIs.\\n\",\"isRecommended\":false,\"githubStars\":4383,\"downloadCount\":982,\
  \"createdAt\":\"2025-04-04T01:22:59.095407Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-05T13:26:03.119761Z\"},{\"mcpId\":\
  \"github.com/Saik0s/mcp-browser-use\",\"githubUrl\":\"https://github.com/Saik\
  0s/mcp-browser-use\",\"name\":\"Browser
  Use\",\"author\":\"Saik0s\",\"description\":\"AI-driven browser automation
  server enabling natural language control of web browsers with features like
  page navigation, form filling, visual understanding, and session
  persistence.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/browseruse.png\",\"category\":\"browser-automa\
  tion\",\"tags\":[\"browser-automation\",\"web-interaction\",\"visual-analysis\
  \",\"session-management\",\"multi-llm\"],\"requiresApiKey\":false,\"readmeCon\
  tent\":\"<img src=\\\"./assets/header.png\\\" alt=\\\"Browser Use Web UI\\\"
  width=\\\"full\\\"/>\\n\\n<br/>\\n\\n# browser-use MCP server &
  CLI\\n[![Documentation](https://img.shields.io/badge/Documentation--blue)](\
  https://docs.browser-use.com)\\n[![License](https://img.shields.io/badge/Lice\
  nse-MIT-green)](LICENSE)\\n\\n> **Project Note**: This MCP server
  implementation builds upon the
  [browser-use/web-ui](https://github.com/browser-use/web-ui) foundation. Core
  browser automation logic and configuration patterns are adapted from the
  original project.\\n\\nAI-driven browser automation server implementing the
  Model Context Protocol (MCP) for natural language browser control and web
  research. Also provides CLI access to its core functionalities.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/@Saik0s/mcp-browser-use\\\"><img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/@Saik0s/mcp-browser-use/badge\\\"
  alt=\\\"Browser-Use MCP server\\\" /></a>\\n\\n## Features\\n\\n-    **MCP
  Integration** - Full protocol implementation for AI agent
  communication.\\n-    **Browser Automation** - Page navigation, form
  filling, element interaction via natural language (`run_browser_agent`
  tool).\\n-    **Visual Understanding** - Optional screenshot analysis for
  vision-capable LLMs.\\n-    **State Persistence** - Option to manage a
  server browser session across multiple MCP calls or connect to user's
  browser.\\n-    **Multi-LLM Support** - Integrates with OpenAI, Anthropic,
  Azure, DeepSeek, Google, Mistral, Ollama, OpenRouter, Alibaba, Moonshot,
  Unbound AI.\\n-    **Deep Research Tool** - Dedicated tool for multi-step
  web research and report generation (`run_deep_research` tool).\\n-   
  **Environment Variable Configuration** - Fully configurable via environment
  variables using a structured Pydantic model.\\n-    **CDP Connection** -
  Ability to connect to and control a user-launched Chrome/Chromium instance via
  Chrome DevTools Protocol.\\n-    **CLI Interface** - Access core agent
  functionalities (`run_browser_agent`, `run_deep_research`) directly from the
  command line for testing and scripting.\\n\\n## Quick Start\\n\\n### The
  Essentials\\n\\n1. Install UV - the rocket-powered Python installer:\\n`curl
  -LsSf https://astral.sh/uv/install.sh | sh`\\n\\n2. Get Playwright browsers
  (required for automation):\\n`uvx --from mcp-server-browser-use@latest python
  -m playwright install`\\n\\n### Integration Patterns\\n\\nFor MCP clients like
  Claude Desktop, add a server configuration that's as simple
  as:\\n\\n```json\\n// Example 1: One-Line Latest Version (Always
  Fresh)\\n\\\"mcpServers\\\": {\\n    \\\"browser-use\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-browser-use@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"MCP_LLM_GOOGLE_API_KEY\\\":
  \\\"YOUR_KEY_HERE_IF_USING_GOOGLE\\\",\\n        \\\"MCP_LLM_PROVIDER\\\":
  \\\"google\\\",\\n        \\\"MCP_LLM_MODEL_NAME\\\":
  \\\"gemini-2.5-flash-preview-04-17\\\",\\n        \\\"MCP_BROWSER_HEADLESS\\\
  \": \\\"true\\\",\\n      }\\n    }\\n}\\n```\\n\\n```json\\n// Example 2:
  Advanced Configuration with CDP\\n\\\"mcpServers\\\":
  {\\n    \\\"browser-use\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-browser-use@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"MCP_LLM_OPENROUTER_API_KEY\\\":
  \\\"YOUR_KEY_HERE_IF_USING_OPENROUTER\\\",\\n        \\\"MCP_LLM_PROVIDER\\\":
  \\\"openrouter\\\",\\n        \\\"MCP_LLM_MODEL_NAME\\\":
  \\\"anthropic/claude-3.5-haiku\\\",\\n        \\\"MCP_LLM_TEMPERATURE\\\":
  \\\"0.4\\\",\\n\\n        \\\"MCP_BROWSER_HEADLESS\\\":
  \\\"false\\\",\\n        \\\"MCP_BROWSER_WINDOW_WIDTH\\\":
  \\\"1440\\\",\\n        \\\"MCP_BROWSER_WINDOW_HEIGHT\\\":
  \\\"1080\\\",\\n        \\\"MCP_AGENT_TOOL_USE_VISION\\\":
  \\\"true\\\",\\n\\n        \\\"MCP_RESEARCH_TOOL_SAVE_DIR\\\":
  \\\"/path/to/your/research\\\",\\n        \\\"MCP_RESEARCH_TOOL_MAX_PARALLEL_\
  BROWSERS\\\": \\\"5\\\",\\n\\n        \\\"MCP_PATHS_DOWNLOADS\\\":
  \\\"/path/to/your/downloads\\\",\\n\\n        \\\"MCP_BROWSER_USE_OWN_BROWSER\
  \\\": \\\"true\\\",\\n        \\\"MCP_BROWSER_CDP_URL\\\":
  \\\"http://localhost:9222\\\",\\n\\n        \\\"MCP_AGENT_TOOL_HISTORY_PATH\\\
  \":
  \\\"/path/to/your/history\\\",\\n\\n        \\\"MCP_SERVER_LOGGING_LEVEL\\\":
  \\\"DEBUG\\\",\\n        \\\"MCP_SERVER_LOG_FILE\\\":
  \\\"/path/to/your/log/mcp_server_browser_use.log\\\",\\n      }\\n    }\\n}\\\
  n```\\n\\n```json\\n// Example 3: Advanced Configuration with User Data and
  custom chrome path\\n\\\"mcpServers\\\": {\\n    \\\"browser-use\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-browser-use@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"MCP_LLM_OPENAI_API_KEY\\\":
  \\\"YOUR_KEY_HERE_IF_USING_OPENAI\\\",\\n        \\\"MCP_LLM_PROVIDER\\\":
  \\\"openai\\\",\\n        \\\"MCP_LLM_MODEL_NAME\\\":
  \\\"gpt-4.1-mini\\\",\\n        \\\"MCP_LLM_TEMPERATURE\\\":
  \\\"0.2\\\",\\n\\n        \\\"MCP_BROWSER_HEADLESS\\\":
  \\\"false\\\",\\n\\n        \\\"MCP_BROWSER_BINARY_PATH\\\":
  \\\"/path/to/your/chrome/binary\\\",\\n        \\\"MCP_BROWSER_USER_DATA_DIR\\\
  \":
  \\\"/path/to/your/user/data\\\",\\n        \\\"MCP_BROWSER_DISABLE_SECURITY\\\
  \": \\\"true\\\",\\n        \\\"MCP_BROWSER_KEEP_OPEN\\\":
  \\\"true\\\",\\n        \\\"MCP_BROWSER_TRACE_PATH\\\":
  \\\"/path/to/your/trace\\\",\\n\\n        \\\"MCP_AGENT_TOOL_HISTORY_PATH\\\":
  \\\"/path/to/your/history\\\",\\n\\n        \\\"MCP_SERVER_LOGGING_LEVEL\\\":
  \\\"DEBUG\\\",\\n        \\\"MCP_SERVER_LOG_FILE\\\":
  \\\"/path/to/your/log/mcp_server_browser_use.log\\\",\\n      }\\n    }\\n}\\\
  n```\\n\\n```json\\n// Example 4: Local Development Flow\\n\\\"mcpServers\\\":
  {\\n    \\\"browser-use\\\": {\\n      \\\"command\\\":
  \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/your/dev/path\\\",\\n        \
  \\\"run\\\",\\n        \\\"mcp-server-browser-use\\\"\\n      ],\\n      \\\"\
  env\\\": {\\n        \\\"MCP_LLM_OPENROUTER_API_KEY\\\":
  \\\"YOUR_KEY_HERE_IF_USING_OPENROUTER\\\",\\n        \\\"MCP_LLM_PROVIDER\\\":
  \\\"openrouter\\\",\\n        \\\"MCP_LLM_MODEL_NAME\\\":
  \\\"openai/gpt-4o-mini\\\",\\n        \\\"MCP_BROWSER_HEADLESS\\\":
  \\\"true\\\",\\n      }\\n    }\\n}\\n```\\n\\n**Key Insight:** The best
  configurations emerge from starting simple (Example 1). The .env.example file
  contains all possible dials.\\n\\n## MCP Tools\\n\\nThis server exposes the
  following tools via the Model Context Protocol:\\n\\n### Synchronous Tools
  (Wait for
  Completion)\\n\\n1.  **`run_browser_agent`**\\n    *   **Description:**
  Executes a browser automation task based on natural language instructions and
  waits for it to complete. Uses settings from `MCP_AGENT_TOOL_*`, `MCP_LLM_*`,
  and `MCP_BROWSER_*` environment
  variables.\\n    *   **Arguments:**\\n        *   `task` (string, required):
  The primary task or objective.\\n    *   **Returns:** (string) The final
  result extracted by the agent or an error message. Agent history (JSON,
  optional GIF) saved if `MCP_AGENT_TOOL_HISTORY_PATH` is
  set.\\n\\n2.  **`run_deep_research`**\\n    *   **Description:** Performs
  in-depth web research on a topic, generates a report, and waits for
  completion. Uses settings from `MCP_RESEARCH_TOOL_*`, `MCP_LLM_*`, and
  `MCP_BROWSER_*` environment variables. If `MCP_RESEARCH_TOOL_SAVE_DIR` is set,
  outputs are saved to a subdirectory within it; otherwise, operates in
  memory-only mode.\\n    *   **Arguments:**\\n        *   `research_task`
  (string, required): The topic or question for the
  research.\\n        *   `max_parallel_browsers` (integer, optional): Overrides
  `MCP_RESEARCH_TOOL_MAX_PARALLEL_BROWSERS` from
  environment.\\n    *   **Returns:** (string) The generated research report in
  Markdown format, including the file path (if saved), or an error
  message.\\n\\n## CLI Usage\\n\\nThis package also provides a command-line
  interface `mcp-browser-cli` for direct testing and scripting.\\n\\n**Global
  Options:**\\n*   `--env-file PATH, -e PATH`: Path to a `.env` file to load
  configurations from.\\n*   `--log-level LEVEL, -l LEVEL`: Override the logging
  level (e.g., `DEBUG`, `INFO`).\\n\\n**Commands:**\\n\\n1.  **`mcp-browser-cli
  run-browser-agent [OPTIONS] TASK`**\\n    *   **Description:** Runs a browser
  agent task.\\n    *   **Arguments:**\\n        *   `TASK` (string, required):
  The primary task for the
  agent.\\n    *   **Example:**\\n        ```bash\\n        mcp-browser-cli
  run-browser-agent \\\"Go to example.com and find the title.\\\" -e
  .env\\n        ```\\n\\n2.  **`mcp-browser-cli run-deep-research [OPTIONS]
  RESEARCH_TASK`**\\n    *   **Description:** Performs deep web
  research.\\n    *   **Arguments:**\\n        *   `RESEARCH_TASK` (string,
  required): The topic or question for
  research.\\n    *   **Options:**\\n        *   `--max-parallel-browsers
  INTEGER, -p INTEGER`: Override
  `MCP_RESEARCH_TOOL_MAX_PARALLEL_BROWSERS`.\\n    *   **Example:**\\n        `\
  ``bash\\n        mcp-browser-cli run-deep-research \\\"What are the latest
  advancements in AI-driven browser automation?\\\" --max-parallel-browsers 5 -e
  .env\\n        ```\\n\\nAll other configurations (LLM keys, paths, browser
  settings) are picked up from environment variables (or the specified `.env`
  file) as detailed in the Configuration section.\\n\\n## Configuration
  (Environment Variables)\\n\\nConfigure the server and CLI using environment
  variables. You can set these in your system or place them in a `.env` file in
  the project root (use `--env-file` for CLI). Variables are structured with
  prefixes.\\n\\n| Variable Group (Prefix)             | Example
  Variable                               |
  Description                                                                                                \
  | Default Value                     |\\n| :----------------------------------
  | :--------------------------------------------- |
  :----------------------------------------------------------------------------\
  ----------------------------- | :-------------------------------- |\\n| **Main
  LLM
  (MCP_LLM_)**             |                                                |
  Settings for the primary LLM used by
  agents.                                                               |                                   \
  |\\n|                                     |
  `MCP_LLM_PROVIDER`                             | LLM provider. Options:
  `openai`, `azure_openai`, `anthropic`, `google`, `mistral`, `ollama`,
  etc.         |
  `openai`                          |\\n|                                     |
  `MCP_LLM_MODEL_NAME`                           | Specific model name for the
  provider.                                                                      \
  | `gpt-4.1`                         |\\n|                                     \
  | `MCP_LLM_TEMPERATURE`                          | LLM temperature
  (0.0-2.0).                                                                                 \
  | `0.0`                             |\\n|                                     \
  | `MCP_LLM_BASE_URL`                             | Optional: Generic override
  for LLM provider's base
  URL.                                                    |
  Provider-specific                 |\\n|                                     |
  `MCP_LLM_API_KEY`                              | Optional: Generic LLM API key
  (takes precedence).                                                          |
  -                                 |\\n|                                     |
  `MCP_LLM_OPENAI_API_KEY`                       | API Key for OpenAI (if
  provider is
  `openai`).                                                              |
  -                                 |\\n|                                     |
  `MCP_LLM_ANTHROPIC_API_KEY`                    | API Key for
  Anthropic.                                                                                     \
  | -                                 |\\n|                                     \
  | `MCP_LLM_GOOGLE_API_KEY`                       | API Key for Google AI
  (Gemini).                                                                            \
  | -                                 |\\n|                                     \
  | `MCP_LLM_AZURE_OPENAI_API_KEY`                 | API Key for Azure
  OpenAI.                                                                                  \
  | -                                 |\\n|                                     \
  | `MCP_LLM_AZURE_OPENAI_ENDPOINT`                | **Required if using
  Azure.** Your Azure resource
  endpoint.                                                 |
  -                                 |\\n|                                     |
  `MCP_LLM_OLLAMA_ENDPOINT`                      | Ollama API endpoint
  URL.                                                                                   \
  | `http://localhost:11434`          |\\n|                                     \
  | `MCP_LLM_OLLAMA_NUM_CTX`                       | Context window size for
  Ollama
  models.                                                                     |
  `32000`                           |\\n| **Planner LLM
  (MCP_LLM_PLANNER_)**  |                                                |
  Optional: Settings for a separate LLM for agent planning. Defaults to Main LLM
  if not
  set.                |                                   |\\n|                                     \
  | `MCP_LLM_PLANNER_PROVIDER`                     | Planner LLM
  provider.                                                                                      \
  | Main LLM
  Provider                 |\\n|                                     |
  `MCP_LLM_PLANNER_MODEL_NAME`                   | Planner LLM model
  name.                                                                                    \
  | Main LLM Model                    |\\n| **Browser
  (MCP_BROWSER_)**          |                                                |
  General browser
  settings.                                                                                  \
  |                                   |\\n|                                     \
  | `MCP_BROWSER_HEADLESS`                         | Run browser without UI
  (general
  setting).                                                                  |
  `false`                           |\\n|                                     |
  `MCP_BROWSER_DISABLE_SECURITY`                 | Disable browser security
  features (general setting, use
  cautiously).                                       |
  `false`                           |\\n|                                     |
  `MCP_BROWSER_BINARY_PATH`                      | Path to Chrome/Chromium
  executable.                                                                        \
  | -                                 |\\n|                                     \
  | `MCP_BROWSER_USER_DATA_DIR`                    | Path to Chrome user data
  directory.                                                                        \
  | -                                 |\\n|                                     \
  | `MCP_BROWSER_WINDOW_WIDTH`                     | Browser window width
  (pixels).                                                                             \
  | `1280`                            |\\n|                                     \
  | `MCP_BROWSER_WINDOW_HEIGHT`                    | Browser window height
  (pixels).                                                                            \
  | `1080`                            |\\n|                                     \
  | `MCP_BROWSER_USE_OWN_BROWSER`                  | Connect to user's browser
  via CDP
  URL.                                                                     |
  `false`                           |\\n|                                     |
  `MCP_BROWSER_CDP_URL`                          | CDP URL (e.g.,
  `http://localhost:9222`). Required if
  `MCP_BROWSER_USE_OWN_BROWSER=true`.                  |
  -                                 |\\n|                                     |
  `MCP_BROWSER_KEEP_OPEN`                        | Keep server-managed browser
  open between MCP calls (if
  `MCP_BROWSER_USE_OWN_BROWSER=false`).               |
  `false`                           |\\n|                                     |
  `MCP_BROWSER_TRACE_PATH`                       | Optional: Directory to save
  Playwright trace files. If not set, tracing to file is
  disabled.               | ` ` (empty, tracing disabled)     |\\n| **Agent Tool
  (MCP_AGENT_TOOL_)**    |                                                |
  Settings for the `run_browser_agent`
  tool.                                                                 |                                   \
  |\\n|                                     |
  `MCP_AGENT_TOOL_MAX_STEPS`                     | Max steps per agent
  run.                                                                                   \
  | `100`                             |\\n|                                     \
  | `MCP_AGENT_TOOL_MAX_ACTIONS_PER_STEP`          | Max actions per agent
  step.                                                                                \
  | `5`                               |\\n|                                     \
  | `MCP_AGENT_TOOL_TOOL_CALLING_METHOD`           | Method for tool invocation
  ('auto', 'json_schema',
  'function_calling').                                    |
  `auto`                            |\\n|                                     |
  `MCP_AGENT_TOOL_MAX_INPUT_TOKENS`              | Max input tokens for LLM
  context.                                                                          \
  | `128000`                          |\\n|                                     \
  | `MCP_AGENT_TOOL_USE_VISION`                    | Enable vision capabilities
  (screenshot
  analysis).                                                          |
  `true`                            |\\n|                                     |
  `MCP_AGENT_TOOL_HEADLESS`                      | Override
  `MCP_BROWSER_HEADLESS` for this tool
  (true/false/empty).                                          | ` ` (uses
  general)                |\\n|                                     |
  `MCP_AGENT_TOOL_DISABLE_SECURITY`              | Override
  `MCP_BROWSER_DISABLE_SECURITY` for this tool
  (true/false/empty).                                  | ` ` (uses
  general)                |\\n|                                     |
  `MCP_AGENT_TOOL_ENABLE_RECORDING`              | Enable Playwright video
  recording.                                                                         \
  | `false`                           |\\n|                                     \
  | `MCP_AGENT_TOOL_SAVE_RECORDING_PATH`           | Optional: Path to save
  recordings. If not set, recording to file is disabled even if
  `ENABLE_RECORDING=true`. | ` ` (empty, recording
  disabled)   |\\n|                                     |
  `MCP_AGENT_TOOL_HISTORY_PATH`                  | Optional: Directory to save
  agent history JSON files. If not set, history saving is
  disabled.              | ` ` (empty, history saving disabled) |\\n| **Research
  Tool (MCP_RESEARCH_TOOL_)** |                                             |
  Settings for the `run_deep_research`
  tool.                                                                 |                                   \
  |\\n|                                     |
  `MCP_RESEARCH_TOOL_MAX_PARALLEL_BROWSERS`      | Max parallel browser
  instances for deep
  research.                                                          |
  `3`                               |\\n|                                     |
  `MCP_RESEARCH_TOOL_SAVE_DIR`                   | Optional: Base directory to
  save research artifacts. Task ID will be appended. If not set, operates in
  memory-only mode. | `None`                           |\\n| **Paths
  (MCP_PATHS_)**              |                                                |
  General path
  settings.                                                                                     \
  |                                   |\\n|                                     \
  | `MCP_PATHS_DOWNLOADS`                          | Optional: Directory for
  downloaded files. If not set, persistent downloads to a specific path are
  disabled.  | ` ` (empty, downloads disabled)  |\\n| **Server
  (MCP_SERVER_)**            |                                                |
  Server-specific
  settings.                                                                                  \
  |                                   |\\n|                                     \
  | `MCP_SERVER_LOG_FILE`                          | Path for the server log
  file. Empty for
  stdout.                                                            | ` `
  (empty, logs to stdout)       |\\n|                                     |
  `MCP_SERVER_LOGGING_LEVEL`                     | Logging level (`DEBUG`,
  `INFO`, `WARNING`, `ERROR`,
  `CRITICAL`).                                           |
  `ERROR`                           |\\n|                                     |
  `MCP_SERVER_ANONYMIZED_TELEMETRY`              | Enable/disable anonymized
  telemetry
  (`true`/`false`).                                                      |
  `true`                            |\\n|                                     |
  `MCP_SERVER_MCP_CONFIG`                        | Optional: JSON string for MCP
  client config used by the internal controller.                               |
  `null`                            |\\n\\n**Supported LLM Providers
  (`MCP_LLM_PROVIDER`):**\\n`openai`, `azure_openai`, `anthropic`, `google`,
  `mistral`, `ollama`, `deepseek`, `openrouter`, `alibaba`, `moonshot`,
  `unbound`\\n\\n*(Refer to `.env.example` for a comprehensive list of all
  supported environment variables and their specific provider
  keys/endpoints.)*\\n\\n## Connecting to Your Own Browser (CDP)\\n\\nInstead of
  having the server launch and manage its own browser instance, you can connect
  it to a Chrome/Chromium browser that you launch and manage
  yourself.\\n\\n**Steps:**\\n\\n1.  **Launch Chrome/Chromium with Remote
  Debugging Enabled:**\\n    (Commands for macOS, Linux, Windows as previously
  listed, e.g., `google-chrome
  --remote-debugging-port=9222`)\\n\\n2.  **Configure Environment
  Variables:**\\n    Set the following environment
  variables:\\n    ```dotenv\\n    MCP_BROWSER_USE_OWN_BROWSER=true\\n    MCP_B\
  ROWSER_CDP_URL=http://localhost:9222 # Use the same port\\n    # Optional:
  MCP_BROWSER_USER_DATA_DIR=/path/to/your/profile\\n    ```\\n\\n3.  **Run the
  MCP Server or CLI:**\\n    Start the server (`uv run mcp-server-browser-use`)
  or CLI (`mcp-browser-cli ...`) as usual.\\n\\n**Important
  Considerations:**\\n*   The browser launched with `--remote-debugging-port`
  must remain open.\\n*   Settings like `MCP_BROWSER_HEADLESS` and
  `MCP_BROWSER_KEEP_OPEN` are ignored when
  `MCP_BROWSER_USE_OWN_BROWSER=true`.\\n\\n## Development\\n\\n```bash\\n#
  Install dev dependencies and sync project deps\\nuv sync --dev\\n\\n# Install
  playwright browsers\\nuv run playwright install\\n\\n# Run MCP server with
  debugger (Example connecting to own browser via CDP)\\n# 1. Launch Chrome:
  google-chrome --remote-debugging-port=9222
  --user-data-dir=\\\"optional/path/to/user/profile\\\"\\n# 2. Run inspector
  command with environment variables:\\nnpx
  @modelcontextprotocol/inspector@latest \\\\\\n  -e
  MCP_LLM_GOOGLE_API_KEY=$GOOGLE_API_KEY \\\\\\n  -e MCP_LLM_PROVIDER=google
  \\\\\\n  -e MCP_LLM_MODEL_NAME=gemini-2.5-flash-preview-04-17 \\\\\\n  -e
  MCP_BROWSER_USE_OWN_BROWSER=true \\\\\\n  -e
  MCP_BROWSER_CDP_URL=http://localhost:9222 \\\\\\n  -e
  MCP_RESEARCH_TOOL_SAVE_DIR=./tmp/dev_research_output \\\\\\n  uv --directory .
  run mcp-server-browser-use\\n\\n# Note: Change timeout in inspector's config
  panel if needed (default is 10 seconds)\\n\\n# Run CLI example\\n# Create a
  .env file with your settings (including MCP_RESEARCH_TOOL_SAVE_DIR) or use
  environment variables\\nuv run mcp-browser-cli -e .env run-browser-agent
  \\\"What is the title of example.com?\\\"\\nuv run mcp-browser-cli -e .env
  run-deep-research \\\"What is the best material for a pan for everyday use on
  amateur kitchen and dishwasher?\\\"\\n```\\n\\n##
  Troubleshooting\\n\\n-   **Configuration Error on Startup**: If the
  application fails to start with an error about a missing setting, ensure all
  **mandatory** environment variables (like `MCP_RESEARCH_TOOL_SAVE_DIR`) are
  set correctly in your environment or `.env` file.\\n-   **Browser Conflicts**:
  If *not* using CDP (`MCP_BROWSER_USE_OWN_BROWSER=false`), ensure no
  conflicting Chrome instances are running with the same user data directory if
  `MCP_BROWSER_USER_DATA_DIR` is specified.\\n-   **CDP Connection Issues**: If
  using `MCP_BROWSER_USE_OWN_BROWSER=true`:\\n    *   Verify Chrome was launched
  with `--remote-debugging-port`.\\n    *   Ensure the port in
  `MCP_BROWSER_CDP_URL` matches.\\n    *   Check firewalls and ensure the
  browser is running.\\n-   **API Errors**: Double-check API keys
  (`MCP_LLM_<PROVIDER>_API_KEY` or `MCP_LLM_API_KEY`) and endpoints (e.g.,
  `MCP_LLM_AZURE_OPENAI_ENDPOINT` for Azure).\\n-   **Vision Issues**: Ensure
  `MCP_AGENT_TOOL_USE_VISION=true` and your LLM supports
  vision.\\n-   **Dependency Problems**: Run `uv sync` and `uv run playwright
  install`.\\n-   **File/Path Issues**:\\n    *   If optional features like
  history saving, tracing, or downloads are not working, ensure the
  corresponding path variables (`MCP_AGENT_TOOL_HISTORY_PATH`,
  `MCP_BROWSER_TRACE_PATH`, `MCP_PATHS_DOWNLOADS`) are set and the application
  has write permissions to those locations.\\n    *   For deep research, ensure
  `MCP_RESEARCH_TOOL_SAVE_DIR` is set to a valid, writable
  directory.\\n-   **Logging**: Check the log file (`MCP_SERVER_LOG_FILE`, if
  set) or console output. Increase `MCP_SERVER_LOGGING_LEVEL` to `DEBUG` for
  more details. For CLI, use `--log-level DEBUG`.\\n\\n## License\\n\\nMIT - See
  [LICENSE](LICENSE) for
  details.\\n\",\"isRecommended\":false,\"githubStars\":720,\"downloadCount\":2\
  5687,\"createdAt\":\"2025-03-27T20:09:01.19066Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T02:22:01.469323Z\"},{\"mcp\
  Id\":\"github.com/awslabs/mcp/tree/main/src/amazon-keyspaces-mcp-server\",\"g\
  ithubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/amazon-keyspaces-mc\
  p-server\",\"name\":\"Amazon
  Keyspaces\",\"author\":\"awslabs\",\"description\":\"Enables natural language
  interaction with Amazon Keyspaces and Apache Cassandra databases, supporting
  schema exploration, query execution, and performance
  analysis.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\
  \"cassandra\",\"aws\",\"database-management\",\"query-analysis\",\"schema-exp\
  loration\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Labs
  amazon-keyspaces MCP Server\\n\\nAn Amazon Keyspaces (for Apache Cassandra)
  MCP server for interacting with Amazon Keyspaces and Apache Cassandra.\\n\\n##
  Overview\\n\\nThe Amazon Keyspaces MCP server implements the Model Context
  Protocol (MCP) to enable AI assistants like Amazon Q to\\ninteract with Amazon
  Keyspaces or Apache Cassandra databases through natural language. This server
  allows you to explore\\n database schemas, execute queries, and analyze query
  performance without having to write CQL code directly.\\n\\n##
  Features\\n\\nThe Amazon Keyspaces (for Apache Cassandra) MCP server provides
  the following capabilities:\\n1. **Schema**: Explore keyspaces and
  tables.\\n2. **Run Queries**: Execute CQL SELECT queries against the
  configured database.\\n3. **Query Analysis**: Get feedback and suggestions for
  improving query performance.\\n4. **Cassandra-Compatible**: Use with Amazon
  Keyspaces, or with Apache Cassandra.\\n\\nHere are some example prompts that
  this MCP server can help with:\\n- \\\"List all keyspaces in my Cassandra
  database\\\"\\n- \\\"Show me the tables in the 'sales' keyspace\\\"\\n-
  \\\"Describe the 'users' table in the 'sales' keyspace\\\"\\n- \\\"What's the
  schema of the 'products' table?\\\"\\n- \\\"Run a SELECT query to get all
  users from the 'users' table in 'sales'\\\"\\n- \\\"Query the first 10 records
  from the 'events' table\\\"\\n- \\\"Analyze the performance of this query:
  SELECT * FROM users WHERE last_name = 'Smith'\\\"\\n- \\\"Is this query
  efficient: SELECT * FROM orders WHERE order_date > '2023-01-01'?\\\"\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.amazon-keyspaces-mcp-server&config=eyJjb21tYW5kIjo\
  idXZ4IGF3c2xhYnMuYW1hem9uLWtleXNwYWNlcy1tY3Atc2VydmVyIiwiZGlzYWJsZWQiOmZhbHNl\
  LCJhdXRvQXBwcm92ZSI6W119)\\n\\n### Prerequisites\\n\\n- Python 3.10 or 3.11
  (Python 3.12+ is not fully supported due to asyncore module removal)\\n-
  Access to an Amazon Keyspaces instance or Apache Cassandra cluster that
  supports password authentication\\n- Appropriate Cassandra log-in
  credentials\\n- Starfield digital certificate (required for Amazon
  Keyspaces)\\n\\n### Install from PyPI\\n\\n```bash\\npip install
  awslabs.amazon-keyspaces-mcp-server\\n```\\n\\n### Install from Source\\n\\n1.
  Clone the repository:\\n   ```bash\\n   git clone
  https://github.com/awslabs/mcp.git\\n   cd
  mcp/src/amazon-keyspaces-mcp-server\\n   ```\\n\\n2. Create a virtual
  environment:\\n   ```bash\\n   python -m venv .venv\\n   source
  .venv/bin/activate  # On Windows:
  .venv\\\\Scripts\\\\activate\\n   ```\\n\\n3. Install the
  package:\\n   ```bash\\n   pip install -e .\\n   ```\\n\\n##
  Configuration\\n\\nCreate a `.keyspaces-mcp` directory in your home directory.
  In the `.keyspaces-mcp` directory, create an\\n`env` file with your database
  connection settings:\\n\\n```\\n# Set to true for Amazon Keyspaces, false for
  Apache Cassandra\\nDB_USE_KEYSPACES=true\\n\\n# Cassandra configuration (for
  native
  Cassandra)\\nDB_CASSANDRA_CONTACT_POINTS=127.0.0.1\\nDB_CASSANDRA_PORT=9042\\\
  nDB_CASSANDRA_LOCAL_DATACENTER=datacenter1\\nDB_CASSANDRA_USERNAME=\\nDB_CASS\
  ANDRA_PASSWORD=\\n\\n# Keyspaces configuration (for Amazon
  Keyspaces)\\nDB_KEYSPACES_ENDPOINT=cassandra.us-west-2.amazonaws.com\\nDB_KEY\
  SPACES_REGION=us-west-2\\n```\\n\\nNote that all of these settings can be set
  directly as environment variables, if you prefer that\\nto using a
  configuration file.\\n\\n### Authentication Credentials\\n\\nThis MCP server
  uses username and password authentication for both Amazon Keyspaces and Apache
  Cassandra:\\n\\n- For **Amazon Keyspaces**: Set the `DB_CASSANDRA_USERNAME`
  and `DB_CASSANDRA_PASSWORD` environment variables with\\nyour Keyspaces
  username and password. These are the same service-specific credentials you
  would use to access Keyspaces\\nvia the Cassandra Query Language (CQL)
  shell.\\n\\n- For **Apache Cassandra**: Set the `DB_CASSANDRA_USERNAME` and
  `DB_CASSANDRA_PASSWORD` environment variables with\\nyour Cassandra username
  and password.\\n\\n### Starfield Digital Certificate for Amazon
  Keyspaces\\n\\nBefore connecting to Amazon Keyspaces, you need to download and
  install the Starfield digital certificate that Amazon\\nKeyspaces uses for TLS
  connections:\\n\\n1. Download the Starfield digital
  certificate:\\n   ```bash\\n   curl -O
  https://certs.secureserver.net/repository/sf-class2-root.crt\\n   ```\\n\\n2.
  Place the certificate in the correct location:\\n   ```bash\\n   mkdir -p
  ~/.keyspaces-mcp/certs\\n   cp sf-class2-root.crt
  ~/.keyspaces-mcp/certs/\\n   ```\\n\\n## Running the MCP Server\\n\\nAfter
  installation, you can run the server
  directly:\\n\\n```bash\\nawslabs.amazon-keyspaces-mcp-server\\n```\\n\\n##
  Configuring Amazon Q to Use the MCP Server\\n\\nTo use the Amazon Keyspaces
  MCP server with Amazon Q CLI, you need to configure it in your Q configuration
  file.\\n\\n### Configuration for Amazon Q CLI\\n\\nEdit the Q configuration
  file at `~/.aws/amazonq/mcp.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  [\\n    {\\n      \\\"name\\\":
  \\\"keyspaces-mcp\\\",\\n      \\\"command\\\":
  \\\"awslabs.amazon-keyspaces-mcp-server\\\",\\n      \\\"args\\\":
  [],\\n      \\\"env\\\": {}\\n    }\\n  ]\\n}\\n```\\n\\nIf the file doesn't
  exist yet or doesn't have an `mcpServers` section, create it with the
  structure shown above.\\n\\nNow when you use Q Chat by running `q chat`, it
  will automatically connect to your Keyspaces MCP server.\\n\\n## Available
  Tools\\n\\nThe Amazon Keyspaces MCP server provides the following tools that
  AI assistants can use:\\n\\n- `listKeyspaces`: Lists all keyspaces in the
  database\\n- `listTables`: Lists all tables in a specified keyspace\\n-
  `describeKeyspace`: Gets detailed information about a keyspace\\n-
  `describeTable`: Gets detailed information about a table\\n- `executeQuery`:
  Executes a read-only SELECT query against the database\\n-
  `analyzeQueryPerformance`: Analyzes the performance characteristics of a CQL
  query\\n\\n## Security Considerations\\n\\n- When using Amazon Keyspaces,
  ensure your IAM policies follow the principle of least privilege. While
  this\\nMCP server does not mutate Keyspaces data or resources, it cannot
  prevent agent-driven attempts to (for example)\\ninvoke AWS SDK operations on
  your behalf, including mutating operations.\\n- This MCP server only allows
  read-only SELECT queries to protect your data.\\n- Queries are validated to
  prevent potentially harmful operations.\\n\\n## Troubleshooting\\n\\n###
  Connection Issues\\n\\n- Verify your database connection settings in the
  `.keyspaces-mcp/env` file in your home directory.\\n- Ensure your logged-in
  user has the necessary permissions for the operations performed by this
  server.\\n- Check that your database is accessible from your network.\\n- For
  Amazon Keyspaces, verify that the Starfield certificate is correctly installed
  in the `.keyspaces-mcp/certs` directory.\\n- If you get SSL/TLS errors, check
  that the certificate path is correct and the certificate is valid.\\n\\n###
  Python Version Compatibility\\n\\n- The MCP server works best with Python 3.10
  or 3.11.\\n- Python 3.12+ may have issues due to the removal of the asyncore
  module which the Cassandra driver depends on.\\n\\n### Cassandra Driver
  Issues\\n\\nIf you encounter issues with the Cassandra driver:\\n\\n1. Ensure
  you have the necessary C dependencies installed for the Cassandra driver.\\n2.
  Try installing the driver with: `pip install cassandra-driver --no-binary
  :all:`\\n\\n## License\\n\\nThis project is licensed under the Apache License
  2.0 - see the LICENSE file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":4427,\"downloadCount\":\
  7,\"createdAt\":\"2025-06-21T01:58:40.403773Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T23:39:33.431489Z\"},{\"mcpId\
  \":\"github.com/cline/cline-community\",\"githubUrl\":\"https://github.com/cl\
  ine/cline-community\",\"name\":\"Cline
  Community\",\"author\":\"cline\",\"description\":\"Streamlines Cline issue
  reporting with automatic system information collection, preview functionality,
  and direct submission via GitHub CLI
  integration.\",\"codiconIcon\":\"bug\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/cline-community.png\",\"category\":\"developer-too\
  ls\",\"tags\":[\"github-integration\",\"issue-tracking\",\"bug-reporting\",\"\
  automation\",\"cli-tools\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Cline Community MCP Server\\n\\nA Model Context Protocol server that
  simplifies reporting issues from Cline to GitHub.\\n\\n## Overview\\n\\nThis
  MCP server provides tools to streamline the process of reporting issues from
  Cline to the GitHub repository. It automatically gathers relevant system
  information (OS, Cline version, API provider, model), formats it alongside the
  user's issue description, and can preview how the issue would look before
  submitting it to GitHub.\\n\\n## Features\\n\\n- **Cross-platform support**:
  Works on Windows, macOS, and Linux\\n- **Multiple IDE support**: Compatible
  with VS Code, Cursor, and Windsurf\\n- **Automatic metadata extraction**: Gets
  API provider, model, and IDE information from task metadata\\n- **Two-step
  issue reporting workflow**:\\n  1. Preview the issue before submission\\n  2.
  Submit to GitHub with a single command\\n- **GitHub Integration**: Uses the
  GitHub CLI (`gh`) to create issues\\n\\n## Tools\\n\\n###
  `preview_cline_issue`\\n\\nPreviews how an issue would look when reported to
  GitHub without actually submitting it. This should be in the autoApprove list
  by default\\n\\n**Parameters**:\\n\\n- `title`: The title for the GitHub issue
  (required)\\n- `description`: Detailed description of the problem
  (required)\\n- `labels`: Optional array of GitHub labels to
  apply\\n\\n**Returns**: JSON object containing the formatted issue
  with:\\n\\n- Title\\n- Body (including system information)\\n- Labels\\n-
  Target repository\\n\\n### `report_cline_issue`\\n\\nReports an issue to the
  GitHub repository using the locally authenticated GitHub
  CLI.\\n\\n**Parameters**:\\n\\n- `title`: The title for the GitHub issue
  (required)\\n- `description`: Detailed description of the problem
  (required)\\n- `labels`: Optional array of GitHub labels to
  apply\\n\\n**Returns**: The URL of the created GitHub issue or an error
  message\\n\\n## Automatic Information Gathering\\n\\nThe server automatically
  collects:\\n\\n- **OS Information**: Platform and release version\\n- **Cline
  Version**: Detected from installed extensions\\n- **IDE Information**:
  Identifies which IDE is being used (VS Code, Cursor, or Windsurf)\\n- **API
  Provider**: Extracted from the task metadata file\\n- **Model**: Extracted
  from the task metadata file\\n\\n## Requirements\\n\\n- GitHub CLI (`gh`)
  installed and authenticated\\n- Access to task metadata directories (where
  Cline stores information about the current task)\\n\\n## Installation\\n\\n###
  Clone the repo\\n\\n```\\ngit clone
  git@github.com:cline/cline-community.git\\n```\\n\\nor if you are sure you
  have the gh cli,\\n\\n```\\ngh repo clone cline/cline-community\\n```\\n\\n###
  Build from Source\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n#
  Build the server\\nnpm run build\\n```\\n\\n### Authenticate with GH
  CLI\\n\\nThis MCP server relies on the authentication status of your installed
  GitHub CLI (`gh`). Ensure you are logged in:\\n\\n```bash\\n# Check to see if
  the user is already authenticated\\ngh auth status\\n```\\n\\nIf they are not
  authenticated, take the following steps:\\n\\n```bash\\n# Log in to
  GitHub\\ngh auth login\\n```\\n\\n1. Select GitHub.com for where you use
  GitHub\\n\\n```\\n? Where do you use GitHub?  [Use arrows to move, type to
  filter]\\n> GitHub.com\\n  Other\\n```\\n\\n2. Select HTTPS for your your
  preferred protocol\\n\\n```\\n? What is your preferred protocol for Git
  operations on this host?  [Use arrows to move, type to filter]\\n>
  HTTPS\\n  SSH\\n```\\n\\n3. Indicate Yes that you want to
  authenticate\\n\\n`\\n? Authenticate Git with your GitHub credentials?
  (Y/n)\\n`\\n\\n4. Select Login with a web browser\\n\\n```\\n? How would you
  like to authenticate GitHub CLI?  [Use arrows to move, type to filter]\\n>
  Login with a web browser\\n  Paste an authentication token\\n```\\n\\n5. Copy
  your one-time code\\n\\n```\\n! First copy your one-time code:
  XXXX-XXXX\\nPress Enter to open https://github.com/login/device in your
  browser... \\n```\\n\\n6. Presss Enter\\n\\n7. Login in the bowser\\n\\n8.
  Enter the code that you copied\\n\\n9. Continue\\n\\n10. You're ready to use
  cline community!\\n\\n### Configure with Cline\\n\\nAdd the server to your MCP
  settings:\\n\\n#### For Cline in VS Code/Cursor\\n\\nAdd to Cline MCP
  settings:\\n\\n- **macOS**: `~/Library/Application
  Support/[Code|Cursor|Windsurf]/User/globalStorage/saoudrizwan.claude-dev/sett\
  ings/cline_mcp_settings.json`\\n- **Windows**:
  `%APPDATA%/[Code|Cursor|Windsurf]/User/globalStorage/saoudrizwan.claude-dev/s\
  ettings/cline_mcp_settings.json`\\n- **Linux**:
  `~/.config/[Code|Cursor|Windsurf]/User/globalStorage/saoudrizwan.claude-dev/s\
  ettings/cline_mcp_settings.json`\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"cline-community\\\": {\\n      \\\"autoApprove\\\":
  [\\n        \\\"preview_cline_issue\\\"\\n      ],\\n      \\\"timeout\\\":
  10,\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/cline-community/build/index.js\\\"],\\n      \\\"transportType\\\
  \": \\\"stdio\\\"\\n    }\\n  }\\n}\\n```\\n\\n### Windows-Specific
  Configuration\\n\\nOn Windows, you may need to explicitly set the APPDATA
  environment variable in the MCP
  settings:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"cline-community\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/cline-community/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"APPDATA\\\":
  \\\"C:\\\\\\\\Users\\\\\\\\[username]\\\\\\\\AppData\\\\\\\\Roaming\\\"\\n      \
  }\\n    }\\n  }\\n}\\n```\\n\\nReplace `[username]` with your Windows
  username.\\n\\n## Usage Example\\n\\nTo report an issue:\\n\\n1. Use
  `preview_cline_issue` first to see how your issue will
  look:\\n\\n   ```\\n   preview_cline_issue(\\n     title: \\\"Feature request:
  Add dark mode\\\",\\n     description: \\\"It would be great to have a dark
  mode option to reduce eye strain.\\\",\\n     labels:
  [\\\"Enhancement\\\"]\\n   )\\n   ```\\n\\n2. Review the preview and then
  submit with:\\n   ```\\n   report_cline_issue(\\n     title: \\\"Feature
  request: Add dark mode\\\",\\n     description: \\\"It would be great to have
  a dark mode option to reduce eye strain.\\\",\\n     labels:
  [\\\"Enhancement\\\"]\\n   )\\n   ```\\n\\n## Development\\n\\nFor development
  with auto-rebuild:\\n\\n```bash\\nnpm run watch\\n```\\n\\n###
  Debugging\\n\\nSince MCP servers communicate over stdio, use the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector) for
  debugging:\\n\\n```bash\\nnpm run
  inspector\\n```\",\"isRecommended\":false,\"githubStars\":0,\"downloadCount\"\
  :2009,\"createdAt\":\"2025-04-18T21:18:45.87301Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T19:04:45.889918Z\"},{\"mc\
  pId\":\"github.com/kagisearch/kagimcp\",\"githubUrl\":\"https://github.com/ka\
  gisearch/kagimcp\",\"name\":\"Kagi
  Search\",\"author\":\"kagisearch\",\"description\":\"Integrates Kagi's
  advanced search API to provide AI assistants with up-to-date web search
  capabilities and accurate information
  retrieval.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/kagisearch.jpeg\",\"category\":\"search\",\"tags\
  \":[\"web-search\",\"information-retrieval\",\"kagi-api\",\"real-time-data\",\
  \"search-engine\"],\"requiresApiKey\":false,\"readmeContent\":\"# Kagi MCP
  server\\n\\n[![smithery
  badge](https://smithery.ai/badge/kagimcp)](https://smithery.ai/server/kagimcp)\
  \\n\\n<a href=\\\"https://glama.ai/mcp/servers/xabrrs4bka\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/xabrrs4bka/badge\\\" alt=\\\"Kagi Server
  MCP server\\\" />\\n</a>\\n\\n## Setup Intructions\\n> Before anything, unless
  you are just using non-search tools, ensure you have access to the search API.
  It is currently in closed beta and available upon request. Please reach out to
  support@kagi.com for an invite.\\n\\nInstall uv
  first.\\n\\nMacOS/Linux:\\n```bash\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n```\\n\\nWindows:\\n```\\npowershell
  -ExecutionPolicy ByPass -c \\\"irm https://astral.sh/uv/install.ps1 |
  iex\\\"\\n```\\n### Installing via Smithery\\n\\nAlternatively, you can
  install Kagi for Claude Desktop via
  [Smithery](https://smithery.ai/server/kagimcp):\\n\\n```bash\\nnpx -y
  @smithery/cli install kagimcp --client claude\\n```\\n\\n### Setup with Claude
  Desktop\\n```json\\n// claude_desktop_config.json\\n// Can find location
  through:\\n// Hamburger Menu -> File -> Settings -> Developer -> Edit
  Config\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"kagi\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"kagimcp\\\"],\\n      \\\"env\\\": {\\n        \\\"KAGI_API_KEY\\\":
  \\\"YOUR_API_KEY_HERE\\\",\\n        \\\"KAGI_SUMMARIZER_ENGINE\\\":
  \\\"YOUR_ENGINE_CHOICE_HERE\\\" // Defaults to \\\"cecil\\\" engine if env var
  not present\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Pose query that
  requires use of a tool\\ne.g. \\\"Who was time's 2024 person of the year?\\\"
  for search, or \\\"summarize this video:
  https://www.youtube.com/watch?v=jNQXAC9IVRw\\\" for summarizer.\\n\\n###
  Debugging\\nRun:\\n```bash\\nnpx @modelcontextprotocol/inspector uvx
  kagimcp\\n```\\n\\n## Local/Dev Setup Instructions\\n\\n### Clone repo\\n`git
  clone https://github.com/kagisearch/kagimcp.git`\\n\\n### Install
  dependencies\\nInstall uv first.\\n\\nMacOS/Linux:\\n```bash\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n```\\n\\nWindows:\\n```\\npowershell
  -ExecutionPolicy ByPass -c \\\"irm https://astral.sh/uv/install.ps1 |
  iex\\\"\\n```\\n\\nThen install MCP server dependencies:\\n```bash\\ncd
  kagimcp\\n\\n# Create virtual environment and activate it\\nuv
  venv\\n\\nsource .venv/bin/activate # MacOS/Linux\\n#
  OR\\n.venv/Scripts/activate # Windows\\n\\n# Install dependencies\\nuv
  sync\\n```\\n### Setup with Claude Desktop\\n\\n#### Using MCP CLI
  SDK\\n```bash\\n# `pip install mcp[cli]` if you haven't\\nmcp install
  /ABSOLUTE/PATH/TO/PARENT/FOLDER/kagimcp/src/kagimcp/server.py -v
  \\\"KAGI_API_KEY=API_KEY_HERE\\\"\\n```\\n\\n#### Manually\\n```json\\n#
  claude_desktop_config.json\\n# Can find location through:\\n# Hamburger Menu
  -> File -> Settings -> Developer -> Edit Config\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"kagi\\\": {\\n      \\\"command\\\":
  \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/ABSOLUTE/PATH/TO/PARENT/FOLDE\
  R/kagimcp\\\",\\n        \\\"run\\\",\\n        \\\"kagimcp\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"KAGI_API_KEY\\\":
  \\\"YOUR_API_KEY_HERE\\\",\\n        \\\"KAGI_SUMMARIZER_ENGINE\\\":
  \\\"YOUR_ENGINE_CHOICE_HERE\\\" // Defaults to \\\"cecil\\\" engine if env var
  not present\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Pose query that
  requires use of a tool\\ne.g. \\\"Who was time's 2024 person of the year?\\\"
  for search, or \\\"summarize this video:
  https://www.youtube.com/watch?v=jNQXAC9IVRw\\\" for summarizer.\\n\\n###
  Debugging\\nRun:\\n```bash\\n# If mcp cli installed (`pip install
  mcp[cli]`)\\nmcp dev
  /ABSOLUTE/PATH/TO/PARENT/FOLDER/kagimcp/src/kagimcp/server.py\\n\\n# If
  not\\nnpx @modelcontextprotocol/inspector \\\\\\n      uv
  \\\\\\n      --directory /ABSOLUTE/PATH/TO/PARENT/FOLDER/kagimcp
  \\\\\\n      run \\\\\\n      kagimcp\\n```\\nThen access MCP Inspector at
  `http://localhost:5173`. You may need to add your Kagi API key in the
  environment variables in the inspector under `KAGI_API_KEY`.\\n\\n# Advanced
  Configuration\\n- Level of logging is adjustable through the
  `FASTMCP_LOG_LEVEL` environment variable (e.g.
  `FASTMCP_LOG_LEVEL=\\\"ERROR\\\"`)\\n  - Relevant issue:
  https://github.com/kagisearch/kagimcp/issues/4\\n- Summarizer engine can be
  customized using the `KAGI_SUMMARIZER_ENGINE` environment variable (e.g.
  `KAGI_SUMMARIZER_ENGINE=\\\"daphne\\\"`)\\n  - Learn about the different
  summarization engines
  [here](https://help.kagi.com/kagi/api/summarizer.html#summarization-engines)\
  \\n\",\"isRecommended\":true,\"githubStars\":123,\"downloadCount\":396,\"crea\
  tedAt\":\"2025-02-18T06:28:08.669226Z\",\"updatedAt\":\"2025-07-08T01:10:48.3\
  98933Z\",\"lastGithubSync\":\"2025-07-02T08:07:58.525581Z\"},{\"mcpId\":\"git\
  hub.com/modelcontextprotocol/servers/tree/main/src/postgres\",\"githubUrl\":\
  \"https://github.com/modelcontextprotocol/servers/tree/main/src/postgres\",\"\
  name\":\"PostgreSQL
  Reader\",\"author\":\"modelcontextprotocol\",\"description\":\"Provides
  read-only access to PostgreSQL databases, allowing LLMs to inspect database
  schemas and execute read-only queries within protected
  transactions.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/postgresql-reader.png\",\"category\":\"datab\
  ases\",\"tags\":[\"postgresql\",\"database-queries\",\"schema-inspection\",\"\
  read-only\",\"sql\"],\"requiresApiKey\":false,\"isRecommended\":true,\"github\
  Stars\":56960,\"downloadCount\":9141,\"createdAt\":\"2025-02-17T22:23:06.6852\
  98Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025\
  -07-01T06:18:48.290851Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/\
  amazon-neptune-mcp-server\",\"githubUrl\":\"https://github.com/awslabs/mcp/tr\
  ee/main/src/amazon-neptune-mcp-server\",\"name\":\"Neptune
  Query\",\"author\":\"awslabs\",\"description\":\"Query Amazon Neptune
  databases and analytics using openCypher and Gremlin, with support for schema
  retrieval and status
  checking.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\
  \"graph-database\",\"aws-neptune\",\"cypher\",\"gremlin\",\"query-execution\"\
  ],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Labs Amazon Neptune MCP
  Server\\n\\nAn Amazon Neptune MCP server that allows for fetching status,
  schema, and querying using openCypher and Gremlin for Neptune Database and
  openCypher for Neptune Analytics.\\n\\n## Features\\n\\nThe Amazon Neptune MCP
  Server provides the following capabilities:\\n\\n1. **Run Queries**: Execute
  openCypher and/or Gremlin queries against the configured database\\n2.
  **Schema**: Get the schema in the configured graph as a text string\\n3.
  **Status**: Find if the graph is \\\"Available\\\" or \\\"Unavailable\\\" to
  your server.  This is useful in helping to ensure that the graph is
  connected.\\n\\n### AWS Requirements\\n\\n1. **AWS CLI Configuration**: You
  must have the AWS CLI configured with credentials and an AWS_PROFILE that has
  access to Amazon Neptune\\n2. **Amazon Neptune**: You must have at least one
  Amazon Neptune Database or Amazon Neptune Analytics graph.\\n3. **IAM
  Permissions**: Your IAM role/user must have appropriate permissions to:\\n   -
  Access Amazon Neptune\\n   - Query Amazon Neptune\\n4. **Access**: The
  location where you are running the server must have access to the Amazon
  Neptune instance.  Neptune Database resides in a private VPC so access into
  the private VPC.  Neptune Analytics can be access either using a public
  endpoint, if configured, or the access will be needed to the private
  endpoint.\\n\\nNote: This server will run any query sent to it, which could
  include both mutating and read-only actions.  Properly configuring the
  permissions of the role to allow/disallow specific data plane actions as
  specified here:\\n* [Neptune
  Database](https://docs.aws.amazon.com/neptune/latest/userguide/security.html)\
  \\n* [Neptune
  Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/sec\
  urity.html)\\n\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=Neptune%20Query&config=eyJjb21tYW5kIjoidXZ4IGF3c2xhYnMuYW1\
  hem9uLW5lcHR1bmUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVWRUwi\
  OiJJTkZPIiwiTkVQVFVORV9FTkRQT0lOVCI6IjxJTlNFUlQgTkVQVFVORSBFTkRQT0lOVCBJTiBGT\
  1JNQVQgU1BFQ0lGSUVEIEJFTE9XPiJ9fQ%3D%3D)\\n\\nBelow is an example of how to
  configure your MCP client, although different clients may require a different
  format.\\n\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Neptune
  Query\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.amazon-neptune-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\",\\n        \\\"NEPTUNE_ENDPOINT\\\": \\\"<INSERT NEPTUNE ENDPOINT
  IN FORMAT SPECIFIED BELOW>\\\"\\n      }\\n    }\\n  }\\n}\\n\\n```\\n###
  Docker Configuration\\nAfter building with `docker build -t
  awslabs/amazon-neptune-mcp-server .`:\\n\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.amazon-neptune-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"-i\\\",\
  \\n          \\\"awslabs/amazon-neptune-mcp-server\\\"\\n        ],\\n        \
  \\\"env\\\": {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\",\\n        \\\"NEPTUNE_ENDPOINT\\\": \\\"<INSERT NEPTUNE ENDPOINT
  IN FORMAT SPECIFIED BELOW>\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nWhen
  specifying the Neptune Endpoint the following formats are expected:\\n\\nFor
  Neptune Database:\\n`neptune-db://<Cluster Endpoint>`\\n\\nFor Neptune
  Analytics:\\n`neptune-graph://<graph
  identifier>`\\n\",\"isRecommended\":false,\"githubStars\":4295,\"downloadCount\
  \":13,\"createdAt\":\"2025-06-21T01:56:54.828036Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T04:56:48.601147Z\"},{\"m\
  cpId\":\"github.com/webflow/mcp-server\",\"githubUrl\":\"https://github.com/w\
  ebflow/mcp-server\",\"name\":\"Webflow\",\"author\":\"webflow\",\"description\
  \":\"Enables AI agents to interact with Webflow's APIs for managing sites,
  pages, and CMS content through features like publishing, content updates, and
  collection
  management.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/webflow.png\",\"category\":\"cloud-platforms\",\
  \"tags\":[\"webflow\",\"cms\",\"web-development\",\"content-management\",\"si\
  te-builder\"],\"requiresApiKey\":false,\"readmeContent\":\"# Webflow's
  Official MCP Server\\n\\nA Node.js server implementing Model Context Protocol
  (MCP) for Webflow using the [Webflow JavaScript
  SDK](https://github.com/webflow/js-webflow-api). Enable AI agents to interact
  with Webflow APIs. Learn more about Webflow's Data API in the [developer
  documentation](https://developers.webflow.com/data/reference).\\n\\n[![npm
  shield](https://img.shields.io/npm/v/webflow-mcp-server)](https://www.npmjs.c\
  om/package/webflow-mcp-server)\\n[![fern
  shield](https://img.shields.io/badge/%F0%9F%8C%BF-Built%20with%20Fern-brightg\
  reen)](https://buildwithfern.com/?utm_source=github&utm_medium=github&utm_cam\
  paign=readme&utm_source=https%3A%2F%2Fgithub.com%2Fwebflow%2Fmcp-server)\\n\\\
  n##  Prerequisites\\n\\n-
  [Node.js](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\
  \\n-
  [NPM](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\\n-
  [A Webflow Account](https://webflow.com/signup)\\n\\n##  Quick start (hosted
  on Cloudflare workers)\\n\\n**For Cursor:**\\n\\n1. Go to `Settings`  `Cursor
  Settings`  `MCP`\\n2. Click `+ Add New Global MCP Server`\\n3. Paste the
  following configuration (or add the `webflow` part to your existing
  configuration)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"webflow\\\": {\\n      \\\"command\\\": \\\"npx mcp-remote
  https://mcp.webflow.com/sse\\\"\\n    }\\n  }\\n}\\n```\\n\\n4. Save, Cursor
  will automatically open a new browser window showing an OAuth login page to
  authorize the Webflow sites you want the MCP server to have access
  to.\\n\\n**For Claude Desktop:**\\n\\n1. Open `Settings`  `Developer`\\n2.
  Click `Edit Config`\\n3. Open `claude_desktop_config.json` in a code editor
  and paste the following configuration (or add the `webflow` part to your
  existing configuration)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"webflow\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"mcp-remote\\\",
  \\\"https://mcp.webflow.com/sse\\\"]\\n    }\\n  }\\n}\\n```\\n\\n4. Save the
  file and restart Claude Desktop (command/ctrl + R). When Claude restarts, it
  will automatically open a new browser window showing an OAuth login page to
  authorize the Webflow sites you want the MCP server to have access
  to.\\n\\n**For Windsurf:**\\n\\n1. Navigate to `Windsurf - Settings` 
  `Advanced Settings`\\n2. Scroll down to the `Cascade` section  `Add Server` 
  `Add custom server +`\\n3. Paste the following configuration (or add the
  `webflow` part to your existing
  configuration)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"webflow\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"mcp-remote\\\",
  \\\"https://mcp.webflow.com/sse\\\"]\\n    }\\n  }\\n}\\n```\\n\\n4. Click
  `Save`, Windsurf will automatically open a new browser window showing an OAuth
  login page to authorize the Webflow sites you want the MCP server to have
  access to.\\n\\n**For VS Code:**\\n\\n1. Open `settings.json`\\n2. Paste the
  following configuration (or add the `webflow` part to your existing
  configuration)\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"webflow\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"mcp-remote\\\",
  \\\"https://mcp.webflow.com/sse\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n4.
  `Save` the file. You should see a `start` button appear over the
  \\\"webflow\\\" key which you can click to open and run the auth flow.
  Alternatively, restart VS Code and the auth flow should start
  automatically.\\n\\n**Important note**\\n\\nAll these methods rely on the
  `mcp-remote` [npm package](https://www.npmjs.com/package/mcp-remote) which is
  still considered experimental as of 04/30/2025.\\nIf at any point you have
  issues, and want to reset your OAuth tokens, you can run the following command
  before restarting your MCP client:\\n\\n```shell\\nrm -rf
  ~/.mcp-auth\\n```\\n\\n##  Quick start (local installation)\\n\\n1. **Get
  your Webflow API token**\\n\\n- Go to [Webflow's API
  Playground](https://developers.webflow.com/data/reference/token/authorized-by)\
  \\n- Log in and generate a token\\n- Copy the token from the Request
  Generator\\n  ![Get API
  Token](https://prod.ferndocs.com/_next/image?url=https%3A%2F%2Ffiles.buildwit\
  hfern.com%2Fwebflow-preview-6a549203-c0da-4038-8adf-1dbed286cb83.docs.buildwi\
  thfern.com%2F2025-03-28T17%3A56%3A04.435Z%2Fassets%2Fimages%2Fapi-key-playgro\
  und.png&w=3840&q=75)\\n\\n2. **Add to your AI
  editor**\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"webflow\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"webflow-mcp-server@0.6.0\\\"],\\n      \\\"env\\\":
  {\\n        \\\"WEBFLOW_TOKEN\\\":
  \\\"<YOUR_WEBFLOW_TOKEN>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n**For
  Cursor:**\\n\\n1. Go to Settings  Cursor Settings  MCP\\n2. Click `+ Add New
  Global MCP Server`\\n3. Paste configuration\\n4. Replace `YOUR_WEBFLOW_TOKEN`
  with the token you copied earlier\\n5. Save and **restart** Cursor\\n\\n**For
  Claude Desktop:**\\n\\n1. Open Settings  Developer\\n2. Click `Edit
  Config`\\n3. Open `claude_desktop_config.json` in a code editor and paste
  configuration\\n4. Replace `YOUR_WEBFLOW_TOKEN` with the token you copied
  earlier 5. Save and **restart** Claude\\n\\n##  Troubleshooting\\n\\nIf you
  are having issues starting the server in your MCP client e.g. Cursor or Claude
  Desktop, please try the following.\\n\\n### Ensure you have a valid Webflow
  API token\\n\\n1. Go to [Webflow's API
  Playground](https://developers.webflow.com/data/reference/token/authorized-by\
  ), log in and generate a token, then copy the token from the Request
  Generator\\n2. Replace `YOUR_WEBFLOW_TOKEN` in your MCP client configuration
  with the token you copied\\n3. Save and **restart** your MCP client\\n\\n###
  Ensure you have the Node and NPM installed\\n\\n-
  [Node.js](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\
  \\n-
  [NPM](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm)\\n\\\
  nRun the following commands to confirm you have Node and NPM
  installed:\\n\\n```shell\\nnode -v\\nnpm -v\\n```\\n\\n### Clear your NPM
  cache\\n\\nSometimes clearing your [NPM
  cache](https://docs.npmjs.com/cli/v8/commands/npm-cache) can resolve issues
  with `npx`.\\n\\n```shell\\nnpm cache clean --force\\n```\\n\\n### Fix NPM
  global package permissions\\n\\nIf `npm -v` doesn't work for you but `sudo npm
  -v` does, you may need to fix NPM global package permissions. See the official
  [NPM
  docs](https://docs.npmjs.com/resolving-eacces-permissions-errors-when-install\
  ing-packages-globally) for more information.\\n\\nNote: if you are making
  changes to your shell configuration, you may need to restart your shell for
  changes to take effect.\\n\\n##  Available tools\\n\\n###
  Sites\\n\\n```\\nsites - list; // List all sites\\nsites - get; // Get site
  details\\nsites - publish; // Publish site changes\\n```\\n\\n###
  Pages\\n\\n```\\npages - list; // List all pages\\npages - get - metadata; //
  Get page metadata\\npages - update - page - settings; // Update page
  settings\\npages - get - content; // Get page content\\npages - update -
  static - content; // Update page content\\n```\\n\\n###
  Components\\n\\n```\\ncomponents - list // List all components in a
  site\\ncomponents - get - content // Get component content (text, images,
  nested components)\\ncomponents - update - content // Update component content
  for localization\\ncomponents - get - properties // Get component properties
  (default values)\\ncomponents - update - properties // Update component
  properties for localization\\n```\\n\\n### CMS\\n\\n```\\ncollections - list;
  // List collections\\ncollections - get; // Get collection
  details\\ncollections - create; // Create a collection\\ncollection - fields -
  create - static; // Create a static field\\ncollection - fields - create -
  option; // Create an option field\\ncollection - fields - create - reference;
  // Create a reference field\\ncollection - fields - update; // Update a custom
  field\\ncollections - items - create - item - live; // Create
  items\\ncollections - items - update - items - live; // Update
  items\\ncollections - items - list - items; // List collection
  items\\ncollections - items - create - item; // Create collection items
  (staged)\\ncollections - items - update - items; // Update collection items
  (staged)\\ncollections - items - publish - items; // Publish collection
  items\\n```\\n\\n### Custom Code\\n\\n```\\ncustom code - add - inline - site
  - script // Register an inline script for a site\\ncustom code - get -
  registered - site - script - list // List all scripts registered to a
  site\\ncustom code - get - applied - site - script - list //Get all scripts
  applied to a site\\ncustom code - delete site custom code // Remove scripts
  from a site\\n```\\n\\n### Components \\n\\n```\\ncomponents - list; // List
  all components for a site\\ncomponents - content - get; // Get static content
  from a component definition\\ncomponents - content - update; // Update content
  within a component definition for secondary locales\\ncomponents - properties
  - get; // Get the default property values of a component
  definition\\ncomponents - properties - update; // Update the default property
  values of a component definition for secondary locales\\n```\\n\\n### Ask
  Webflow AI \\n\\n```\\nask - webflow - ai; // Search Webflow Docs using AI
  search\\n```\\n\\n#  Prompts & Resources\\n\\nThis implementation **does
  not** include `prompts` or `resources` from the MCP specification. However,
  this may change in the future when there is broader support across popular MCP
  clients.\\n\\n#  Development mode\\n\\nIf you want to run the server in
  development mode, you can install dependencies and run the server using the
  following command:\\n\\n1. Clone and install:\\n\\n```shell\\ngit clone
  git@github.com:webflow/mcp-server.git\\ncd mcp-server\\nnpm
  install\\n```\\n\\n2. Add your token to a `.env` file at the root of the
  project:\\n\\n```shell\\n#
  .env\\nWEBFLOW_TOKEN=<YOUR_WEBFLOW_TOKEN>\\n```\\n\\n3. Start development
  server:\\n\\n```shell\\nnpm start\\n```\\n\\n##  Webflow Developer
  resources\\n\\n- [Webflow API
  Documentation](https://developers.webflow.com/data/reference)\\n- [Webflow
  JavaScript SDK](https://github.com/webflow/js-webflow-api)\\n\\n##  Known
  Limitations\\n\\n### Static Page Content Updates\\n\\nThe
  pages_update_static_content endpoint currently only supports updates to
  localized static pages in secondary locales. Updates to static content in the
  default locale are not supported and will result in
  errors.\\n\",\"isRecommended\":false,\"githubStars\":47,\"downloadCount\":445,\
  \"createdAt\":\"2025-04-24T06:38:52.39813Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-07-06T10:39:38.265482Z\"},{\"mcpId\":\
  \"github.com/MiniMax-AI/MiniMax-MCP\",\"githubUrl\":\"https://github.com/Mini\
  Max-AI/MiniMax-MCP\",\"name\":\"MiniMax Media
  Studio\",\"author\":\"MiniMax-AI\",\"description\":\"Provides powerful media
  generation capabilities including text-to-speech, voice cloning, video
  generation, and image creation through MiniMax's API
  suite.\",\"codiconIcon\":\"device-camera\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/minimax-media-studio.png\",\"category\":\"imag\
  e-video-processing\",\"tags\":[\"text-to-speech\",\"video-generation\",\"imag\
  e-generation\",\"voice-cloning\",\"media-creation\"],\"requiresApiKey\":false,\
  \"readmeContent\":\"![export](https://github.com/MiniMax-AI/MiniMax-01/raw/ma\
  in/figures/MiniMaxLogo-Light.png)\\n\\n<div align=\\\"center\\\"
  style=\\\"line-height: 1;\\\">\\n  <a href=\\\"https://www.minimax.io\\\"
  target=\\\"_blank\\\" style=\\\"margin: 2px; color:
  var(--fgColor-default);\\\">\\n    <img alt=\\\"Homepage\\\"
  src=\\\"https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-squa\
  re&labelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL\
  3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3\
  hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw\
  6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgx\
  YTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsM\
  FYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS\
  42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDA\
  sMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcu\
  NTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyO\
  DEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLD\
  AsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODI\
  sNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGEx\
  MS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWN\
  DAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42My\
  wwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDI\
  zLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWid\
  th=20\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n  <a href=\\\"https://arxiv.org/abs/2501.08313\\\"
  target=\\\"_blank\\\" style=\\\"margin: 2px;\\\">\\n    <img alt=\\\"Paper\\\"
  src=\\\"https://img.shields.io/badge/_Paper-MiniMax--01-FF4040?style=flat-s\
  quare&labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n   <a href=\\\"https://chat.minimax.io/\\\"
  target=\\\"_blank\\\" style=\\\"margin: 2px;\\\">\\n    <img alt=\\\"Chat\\\"
  src=\\\"https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square&l\
  abelColor=2C3E50&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3d\
  y53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW\
  5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2Z\
  mZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3\
  LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxN\
  DVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42My\
  wwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCw\
  wLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUs\
  MCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuN\
  TZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMC\
  w0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDA\
  uODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42\
  MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuO\
  DFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVj\
  E0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI\
  2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&logoWidth=20\
  \\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n  <a href=\\\"https://www.minimax.io/platform\\\"
  style=\\\"margin: 2px;\\\">\\n    <img alt=\\\"API\\\"
  src=\\\"https://img.shields.io/badge/_API-Platform-FF4040?style=flat-square&\
  labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>  \\n</div>\\n<div align=\\\"center\\\"
  style=\\\"line-height: 1;\\\">\\n  <a
  href=\\\"https://huggingface.co/MiniMaxAI\\\" target=\\\"_blank\\\"
  style=\\\"margin: 2px;\\\">\\n    <img alt=\\\"Hugging Face\\\"
  src=\\\"https://img.shields.io/badge/_Hugging_Face-MiniMax-FF4040?style=fla\
  t-square&labelColor=2C3E50\\\" style=\\\"display: inline-block;
  vertical-align: middle;\\\"/>\\n  </a>\\n  <a
  href=\\\"https://github.com/MiniMax-AI/MiniMax-AI.github.io/blob/main/images/\
  wechat-qrcode.jpeg\\\" target=\\\"_blank\\\" style=\\\"margin:
  2px;\\\">\\n    <img alt=\\\"WeChat\\\"
  src=\\\"https://img.shields.io/badge/_WeChat-MiniMax-FF4040?style=flat-square\
  &labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n  <a
  href=\\\"https://www.modelscope.cn/organization/MiniMax\\\"
  target=\\\"_blank\\\" style=\\\"margin: 2px;\\\">\\n    <img
  alt=\\\"ModelScope\\\"
  src=\\\"https://img.shields.io/badge/_ModelScope-MiniMax-FF4040?style=flat-sq\
  uare&labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n</div>\\n<div align=\\\"center\\\"
  style=\\\"line-height: 1;\\\">\\n   <a
  href=\\\"https://github.com/MiniMax-AI/MiniMax-MCP/blob/main/LICENSE\\\"
  style=\\\"margin: 2px;\\\">\\n    <img alt=\\\"Code License\\\"
  src=\\\"https://img.shields.io/badge/_Code_License-MIT-FF4040?style=flat-squa\
  re&labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n  </a>\\n</div>\\n\\n<p align=\\\"center\\\">\\n  Official
  MiniMax Model Context Protocol (MCP) server that enables interaction with
  powerful Text to Speech and video/image generation APIs. This server allows
  MCP clients like <a href=\\\"https://www.anthropic.com/claude\\\">Claude
  Desktop</a>, <a href=\\\"https://www.cursor.so\\\">Cursor</a>, <a
  href=\\\"https://codeium.com/windsurf\\\">Windsurf</a>, <a
  href=\\\"https://github.com/openai/openai-agents-python\\\">OpenAI Agents</a>
  and others to generate speech, clone voices, generate video, generate image
  and more.\\n</p>\\n\\n## Documentation\\n- [](README-CN.md)\\n-
  [MiniMax-MCP-JS](https://github.com/MiniMax-AI/MiniMax-MCP-JS) - Official
  JavaScript implementation of MiniMax MCP\\n\\n## Quickstart with MCP
  Client\\n1. Get your API key from
  [MiniMax](https://www.minimax.io/platform/user-center/basic-information/inter\
  face-key). \\n2. Install `uv` (Python package manager), install with `curl
  -LsSf https://astral.sh/uv/install.sh | sh` or see the `uv`
  [repo](https://github.com/astral-sh/uv) for additional install methods.\\n3.
  **Important**: The API host and key vary by region and must match; otherwise,
  you'll encounter an `Invalid API key` error.\\n\\n|Region| Global  |
  Mainland  |\\n|:--|:-----|:-----|\\n|MINIMAX_API_KEY| go get from [MiniMax
  Global](https://www.minimax.io/platform/user-center/basic-information/interfa\
  ce-key) | go get from
  [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interfa\
  ce-key) |\\n|MINIMAX_API_HOST| https://api.minimax.io |
  https://api.minimaxi.com |\\n\\n\\n### Claude Desktop\\nGo to `Claude >
  Settings > Developer > Edit Config > claude_desktop_config.json` to include
  the following:\\n\\n```\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"MiniMax\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"minimax-mcp\\\",\\n        \\\"-y\\\"\\n      ],\\n      \\\"\
  env\\\": {\\n        \\\"MINIMAX_API_KEY\\\":
  \\\"insert-your-api-key-here\\\",\\n        \\\"MINIMAX_MCP_BASE_PATH\\\":
  \\\"local-output-dir-path, such as
  /User/xxx/Desktop\\\",\\n        \\\"MINIMAX_API_HOST\\\": \\\"api host,
  https://api.minimax.io |
  https://api.minimaxi.com\\\",\\n        \\\"MINIMAX_API_RESOURCE_MODE\\\":
  \\\"optional, [url|local], url is default, audio/image/video are downloaded
  locally or provided in URL
  format\\\"\\n      }\\n    }\\n  }\\n}\\n\\n```\\n Warning: The API key
  needs to match the host. If an error \\\"API Error: invalid api key\\\"
  occurs, please check your api host:\\n- Global
  Host`https://api.minimax.io`\\n- Mainland
  Host`https://api.minimaxi.com`\\n\\nIf you're using Windows, you will have to
  enable \\\"Developer Mode\\\" in Claude Desktop to use the MCP server. Click
  \\\"Help\\\" in the hamburger menu in the top left and select \\\"Enable
  Developer Mode\\\".\\n\\n\\n### Cursor\\nGo to `Cursor -> Preferences ->
  Cursor Settings -> MCP -> Add new global MCP Server` to add above
  config.\\n\\nThat's it. Your MCP client can now interact with MiniMax through
  these tools:\\n\\n## Transport\\nWe support two transport types: stdio and
  sse.\\n| stdio  | SSE  |\\n|:-----|:-----|\\n| Run locally | Can be deployed
  locally or in the cloud |\\n| Communication through `stdout` | Communication
  through `network` |\\n| Input: Supports processing `local files` or valid
  `URL` resources | Input: When deployed in the cloud, it is recommended to use
  `URL` for input |\\n\\n## Available Tools\\n| tool  |
  description  |\\n|-|-|\\n|`text_to_audio`|Convert text to audio with a given
  voice|\\n|`list_voices`|List all voices available|\\n|`voice_clone`|Clone a
  voice using provided audio files|\\n|`generate_video`|Generate a video from a
  prompt|\\n|`text_to_image`|Generate a image from a
  prompt|\\n|`query_video_generation`|Query the result of video generation
  task|\\n|`music_generation`|Generate a music track from a prompt and
  lyrics|\\n|`voice_design`|Generate a voice from a prompt using preview
  text|\\n\\n## Release Notes\\n\\n### July 2, 2025\\n\\n####  What's New\\n-
  **Voice Design**: New `voice_design` tool - create custom voices from
  descriptive prompts with preview audio\\n- **Video Enhancement**: Added
  `MiniMax-Hailuo-02` model with ultra-clear quality and duration/resolution
  controls  \\n- **Music Generation**: Enhanced `music_generation` tool powered
  by `music-1.5` model\\n\\n####  Enhanced Tools\\n- `voice_design` - Generate
  personalized voices from text descriptions\\n- `generate_video` - Now supports
  MiniMax-Hailuo-02 with 6s/10s duration and 768P/1080P resolution options\\n-
  `music_generation` - High-quality music creation with music-1.5 model\\n\\n##
  FAQ\\n### 1. invalid api key\\nPlease ensure your API key and API host are
  regionally aligned\\n|Region| Global  |
  Mainland  |\\n|:--|:-----|:-----|\\n|MINIMAX_API_KEY| go get from [MiniMax
  Global](https://www.minimax.io/platform/user-center/basic-information/interfa\
  ce-key) | go get from
  [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interfa\
  ce-key) |\\n|MINIMAX_API_HOST| https://api.minimax.io |
  https://api.minimaxi.com |\\n\\n### 2. spawn uvx ENOENT\\nPlease confirm its
  absolute path by running this command in your terminal:\\n```sh\\nwhich
  uvx\\n```\\nOnce you obtain the absolute path (e.g., /usr/local/bin/uvx),
  update your configuration to use that path (e.g., \\\"command\\\":
  \\\"/usr/local/bin/uvx\\\"). \\n\\n### 3. How to use `generate_video` in
  async-mode\\nDefine completion rules before starting:\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/c\
  ursor_rule2.png?x-oss-process=image/resize,p_50/format,webp\\\"
  style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\nAlternatively, these rules can be configured in your IDE
  settings (e.g., Cursor):\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/c\
  ursor_video_rule.png?x-oss-process=image/resize,p_50/format,webp\\\"
  style=\\\"display: inline-block; vertical-align: middle;\\\"/>\\n\\n\\n##
  Example usage\\n\\n Warning: Using these tools may incur costs.\\n\\n### 1.
  broadcast a segment of the evening news\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/S\
  nipaste_2025-04-09_20-07-53.png?x-oss-process=image/resize,p_50/format,webp\\\
  \" style=\\\"display: inline-block; vertical-align: middle;\\\"/>\\n\\n### 2.
  clone a voice\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/S\
  nipaste_2025-04-09_19-45-13.png?x-oss-process=image/resize,p_50/format,webp\\\
  \" style=\\\"display: inline-block; vertical-align: middle;\\\"/>\\n\\n### 3.
  generate a video\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/S\
  nipaste_2025-04-09_19-58-52.png?x-oss-process=image/resize,p_50/format,webp\\\
  \" style=\\\"display: inline-block; vertical-align: middle;\\\"/>\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/S\
  nipaste_2025-04-09_19-59-43.png?x-oss-process=image/resize,p_50/format,webp\\\
  \" style=\\\"display: inline-block; vertical-align: middle; \\\"/>\\n\\n### 4.
  generate images\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/g\
  en_image.png?x-oss-process=image/resize,p_50/format,webp\\\"
  style=\\\"display: inline-block; vertical-align: middle;\\\"/>\\n<img
  src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/g\
  en_image1.png?x-oss-process=image/resize,p_50/format,webp\\\"
  style=\\\"display: inline-block; vertical-align: middle;
  \\\"/>\\n\",\"isRecommended\":false,\"githubStars\":770,\"downloadCount\":620,\
  \"createdAt\":\"2025-04-24T06:29:55.996417Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-05T06:25:50.602785Z\"},{\"mcpId\":\
  \"github.com/Garoth/dalle-mcp\",\"githubUrl\":\"https://github.com/Garoth/dal\
  le-mcp\",\"name\":\"DALL-E\",\"author\":\"Garoth\",\"description\":\"Generate,
  edit, and create variations of images using OpenAI's DALL-E 2 and DALL-E 3
  APIs, with support for customizable parameters and local image
  saving.\",\"codiconIcon\":\"image\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/dall-e.png\",\"category\":\"image-video-processing\",\
  \"tags\":[\"image-generation\",\"dall-e\",\"ai-art\",\"image-editing\",\"open\
  ai\"],\"requiresApiKey\":false,\"readmeContent\":\"# DALL-E MCP
  Server\\n\\n<img src=\\\"assets/dall-e-logo.png\\\" alt=\\\"DALL-E MCP
  Logo\\\" width=\\\"256\\\" height=\\\"256\\\">\\n\\nAn MCP (Model Context
  Protocol) server for generating images using OpenAI's DALL-E API.\\n\\n##
  Features\\n\\n- Generate images using DALL-E 2 or DALL-E 3\\n- Edit existing
  images (DALL-E 2 only)\\n- Create variations of existing images (DALL-E 2
  only)\\n- Validate OpenAI API key\\n\\n## Installation\\n\\n```bash\\n# Clone
  the repository\\ngit clone https://github.com/Garoth/dalle-mcp.git\\ncd
  dalle-mcp\\n\\n# Install dependencies\\nnpm install\\n\\n# Build the
  project\\nnpm run build\\n```\\n\\n## Important Note for Cline Users\\n\\nWhen
  using this DALL-E MCP server with Cline, it's recommended to save generated
  images in your current workspace directory by setting the `saveDir` parameter
  to match your current working directory. This ensures Cline can properly
  locate and display the generated images in your conversation.\\n\\nExample
  usage with Cline:\\n```json\\n{\\n  \\\"prompt\\\": \\\"A tropical beach at
  sunset\\\",\\n  \\\"saveDir\\\":
  \\\"/path/to/current/workspace\\\"\\n}\\n```\\n\\n\\n## Usage\\n\\n### Running
  the Server\\n\\n```bash\\n# Run the server\\nnode
  build/index.js\\n```\\n\\n### Configuration for Cline\\n\\nAdd the dall-e
  server to your Cline MCP settings file inside VSCode's settings (ex.
  ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_s\
  ettings.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"dalle-mcp\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/dalle-mcp-server/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"OPENAI_API_KEY\\\":
  \\\"your-api-key-here\\\",\\n        \\\"SAVE_DIR\\\":
  \\\"/path/to/save/directory\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nMake sure
  to:\\n1. Replace `/path/to/dalle-mcp-server/build/index.js` with the actual
  path to the built index.js file\\n2. Replace `your-api-key-here` with your
  OpenAI API key\\n\\n### Available Tools\\n\\n#### generate_image\\n\\nGenerate
  an image using DALL-E based on a text
  prompt.\\n\\n```json\\n{\\n  \\\"prompt\\\": \\\"A futuristic city with flying
  cars and neon lights\\\",\\n  \\\"model\\\":
  \\\"dall-e-3\\\",\\n  \\\"size\\\": \\\"1024x1024\\\",\\n  \\\"quality\\\":
  \\\"standard\\\",\\n  \\\"style\\\": \\\"vivid\\\",\\n  \\\"n\\\":
  1,\\n  \\\"saveDir\\\": \\\"/path/to/save/directory\\\",\\n  \\\"fileName\\\":
  \\\"futuristic-city\\\"\\n}\\n```\\n\\nParameters:\\n- `prompt` (required):
  Text description of the desired image\\n- `model` (optional): DALL-E model to
  use (\\\"dall-e-2\\\" or \\\"dall-e-3\\\", default: \\\"dall-e-3\\\")\\n-
  `size` (optional): Size of the generated image (default:
  \\\"1024x1024\\\")\\n  - DALL-E 3: \\\"1024x1024\\\", \\\"1792x1024\\\", or
  \\\"1024x1792\\\"\\n  - DALL-E 2: \\\"256x256\\\", \\\"512x512\\\", or
  \\\"1024x1024\\\"\\n- `quality` (optional): Quality of the generated image,
  DALL-E 3 only (\\\"standard\\\" or \\\"hd\\\", default: \\\"standard\\\")\\n-
  `style` (optional): Style of the generated image, DALL-E 3 only (\\\"vivid\\\"
  or \\\"natural\\\", default: \\\"vivid\\\")\\n- `n` (optional): Number of
  images to generate (1-10, default: 1)\\n- `saveDir` (optional): Directory to
  save the generated images (default: current directory or SAVE_DIR from .env).
  **For Cline users:** Setting this to your current workspace directory is
  recommended for proper image display.\\n- `fileName` (optional): Base filename
  for the generated images without extension (default:
  \\\"dalle-{timestamp}\\\")\\n\\n#### edit_image\\n\\nEdit an existing image
  using DALL-E based on a text prompt.\\n\\n> ** Known Issue (March 18,
  2025):** The DALL-E 2 image edit API currently has a bug where it sometimes
  ignores the prompt and returns the original image without any edits, even when
  using proper RGBA format images and masks. This issue has been reported in the
  [OpenAI community
  forum](https://community.openai.com/t/dall-e-2-image-edit-issue/668376/7). If
  you experience this issue, try using the `create_variation` tool instead,
  which seems to work more reliably.\\n\\n```json\\n{\\n  \\\"prompt\\\":
  \\\"Add a red hat\\\",\\n  \\\"imagePath\\\":
  \\\"/path/to/image.png\\\",\\n  \\\"mask\\\":
  \\\"/path/to/mask.png\\\",\\n  \\\"model\\\":
  \\\"dall-e-2\\\",\\n  \\\"size\\\": \\\"1024x1024\\\",\\n  \\\"n\\\":
  1,\\n  \\\"saveDir\\\": \\\"/path/to/save/directory\\\",\\n  \\\"fileName\\\":
  \\\"edited-image\\\"\\n}\\n```\\n\\nParameters:\\n- `prompt` (required): Text
  description of the desired edits\\n- `imagePath` (required): Path to the image
  to edit\\n- `mask` (optional): Path to the mask image (white areas will be
  edited, black areas preserved)\\n- `model` (optional): DALL-E model to use
  (currently only \\\"dall-e-2\\\" supports editing, default:
  \\\"dall-e-2\\\")\\n- `size` (optional): Size of the generated image (default:
  \\\"1024x1024\\\")\\n- `n` (optional): Number of images to generate (1-10,
  default: 1)\\n- `saveDir` (optional): Directory to save the edited images
  (default: current directory or SAVE_DIR from .env). **For Cline users:**
  Setting this to your current workspace directory is recommended for proper
  image display.\\n- `fileName` (optional): Base filename for the edited images
  without extension (default: \\\"dalle-edit-{timestamp}\\\")\\n\\n####
  create_variation\\n\\nCreate variations of an existing image using
  DALL-E.\\n\\n```json\\n{\\n  \\\"imagePath\\\":
  \\\"/path/to/image.png\\\",\\n  \\\"model\\\":
  \\\"dall-e-2\\\",\\n  \\\"size\\\": \\\"1024x1024\\\",\\n  \\\"n\\\":
  4,\\n  \\\"saveDir\\\": \\\"/path/to/save/directory\\\",\\n  \\\"fileName\\\":
  \\\"image-variation\\\"\\n}\\n```\\n\\nParameters:\\n- `imagePath` (required):
  Path to the image to create variations of\\n- `model` (optional): DALL-E model
  to use (currently only \\\"dall-e-2\\\" supports variations, default:
  \\\"dall-e-2\\\")\\n- `size` (optional): Size of the generated image (default:
  \\\"1024x1024\\\")\\n- `n` (optional): Number of variations to generate (1-10,
  default: 1)\\n- `saveDir` (optional): Directory to save the variation images
  (default: current directory or SAVE_DIR from .env). **For Cline users:**
  Setting this to your current workspace directory is recommended for proper
  image display.\\n- `fileName` (optional): Base filename for the variation
  images without extension (default:
  \\\"dalle-variation-{timestamp}\\\")\\n\\n#### validate_key\\n\\nValidate the
  OpenAI API key.\\n\\n```json\\n{}\\n```\\n\\nNo parameters required.\\n\\n##
  Development\\n\\n## Testing Configuration\\n\\n**Note: The following .env
  configuration is ONLY needed for running tests, not for normal
  operation.**\\n\\nIf you're developing or running tests for this project,
  create a `.env` file in the root directory with your OpenAI API
  key:\\n\\n```\\n# Required for TESTS ONLY: OpenAI API
  Key\\nOPENAI_API_KEY=your-api-key-here\\n\\n# Optional: Default save directory
  for test images\\n# If not specified, images will be saved to the current
  directory\\n# SAVE_DIR=/path/to/save/directory\\n```\\n\\nFor normal operation
  with Cline, configure your API key in the MCP settings JSON as described in
  the \\\"Adding to MCP Settings\\\" section above.\\n\\nYou can get your API
  key from [OpenAI's API Keys
  page](https://platform.openai.com/api-keys).\\n\\n### Running
  Tests\\n\\n```bash\\n# Run basic tests\\nnpm test\\n\\n# Run all tests
  including edit and variation tests\\nnpm run test:all\\n\\n# Run tests in
  watch mode\\nnpm run test:watch\\n\\n# Run specific test by name\\nnpm run
  test:name \\\"should validate API key\\\"\\n```\\n\\nNote: Tests use real API
  calls and may incur charges on your OpenAI account.\\n\\n### Generating Test
  Images\\n\\nThe project includes a script to generate test images for
  development and testing:\\n\\n```bash\\n# Generate a test image in the assets
  directory\\nnpm run generate-test-image\\n  ```\\n\\nThis will create a simple
  test image in the `assets` directory that can be used for testing the edit and
  variation features.\\n\\n##
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":8,\"downloadCou\
  nt\":2361,\"createdAt\":\"2025-03-18T05:52:01.005466Z\",\"updatedAt\":\"2025-\
  07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T20:35:07.276298Z\"},{\
  \"mcpId\":\"github.com/Dhravya/apple-mcp\",\"githubUrl\":\"https://github.com\
  /Dhravya/apple-mcp\",\"name\":\"Apple Native
  Tools\",\"author\":\"Dhravya\",\"description\":\"Comprehensive suite of macOS
  native tools enabling AI assistants to interact with Messages, Notes,
  Contacts, Email, Reminders, Calendar, Maps, and web search
  functionality.\",\"codiconIcon\":\"apple\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/apple-native-tools.png\",\"category\":\"os-aut\
  omation\",\"tags\":[\"macos\",\"automation\",\"productivity\",\"apple-services\
  \",\"system-integration\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Apple MCP tools\\n\\nLove this MCP? Check out supermemory MCP too -
  https://mcp.supermemory.ai\\n\\n\\n[![smithery
  badge](https://smithery.ai/badge/@Dhravya/apple-mcp)](https://smithery.ai/ser\
  ver/@Dhravya/apple-mcp)\\n\\nThis is a collection of apple-native tools for
  the [MCP
  protocol](https://modelcontextprotocol.com/docs/mcp-protocol).\\n\\nHere's a
  step-by-step video about how to set this up, with a demo. -
  https://x.com/DhravyaShah/status/1892694077679763671\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/gq2qg6kxtu\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/gq2qg6kxtu/badge\\\" alt=\\\"Apple Server
  MCP server\\\"
  />\\n</a>\\n\\n![image](https://github.com/user-attachments/assets/56a5ccfa-c\
  b1a-4226-80c5-6cc794cefc34)\\n\\n\\n<details>\\n<summary>Here's the JSON to
  copy</summary>\\n\\n```\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"apple-mcp\\\":
  {\\n      \\\"command\\\": \\\"bunx\\\",\\n      \\\"args\\\":
  [\\\"--no-cache\\\",
  \\\"apple-mcp@latest\\\"]\\n    }\\n}\\n\\n```\\n\\n</details>\\n\\n#### Quick
  install\\n\\nTo install Apple MCP for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@Dhravya/apple-mcp):\\n\\n```bash\\nnpx
  -y @smithery/cli@latest install @Dhravya/apple-mcp --client
  claude\\n```\\n\\n... and for cursor, you can do:\\n\\n```bash\\nnpx -y
  @smithery/cli@latest install @Dhravya/apple-mcp --client
  cursor\\n```\\n\\n\\n## Features\\n\\n- Messages:\\n  - Send messages using
  the Apple Messages app\\n  - Read out messages\\n- Notes:\\n  - List
  notes\\n  - Search & read notes in Apple Notes app\\n- Contacts:\\n  - Search
  contacts for sending messages\\n- Emails:\\n  - Send emails with multiple
  recipients (to, cc, bcc) and file attachments\\n  - Search emails with custom
  queries, mailbox selection, and result limits\\n  - Schedule emails for future
  delivery\\n  - List and manage scheduled emails\\n  - Check unread email
  counts globally or per mailbox\\n- Reminders:\\n  - List all reminders and
  reminder lists\\n  - Search for reminders by text\\n  - Create new reminders
  with optional due dates and notes\\n  - Open the Reminders app to view
  specific reminders\\n- Calendar:\\n  - Search calendar events with
  customizable date ranges\\n  - List upcoming events\\n  - Create new calendar
  events with details like title, location, and notes\\n  - Open calendar events
  in the Calendar app\\n- Web Search:\\n  - Search the web using
  DuckDuckGo\\n  - Retrieve and process content from search results\\n-
  Maps:\\n  - Search for locations and addresses\\n  - Save locations to
  favorites\\n  - Get directions between locations\\n  - Drop pins on the
  map\\n  - Create and list guides\\n  - Add places to guides\\n\\n- TODO:
  Search and open photos in Apple Photos app\\n- TODO: Search and open music in
  Apple Music app\\n\\n\\nYou can also daisy-chain commands to create a
  workflow. Like:\\n\\\"can you please read the note about people i met in the
  conference, find their contacts and emails, and send them a message saying
  thank you for the time.\\\"\\n\\n(it works!)\\n\\n\\n#### Manual
  installation\\n\\nYou just need bun, install with `brew install
  oven-sh/bun/bun`\\n\\nNow, edit your `claude_desktop_config.json` with
  this:\\n\\n```claude_desktop_config.json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"apple-mcp\\\": {\\n      \\\"command\\\":
  \\\"bunx\\\",\\n      \\\"args\\\":
  [\\\"@dhravya/apple-mcp@latest\\\"]\\n    }\\n  }\\n}\\n```\\n\\n###
  Usage\\n\\nNow, ask Claude to use the `apple-mcp` tool.\\n\\n```\\nCan you
  send a message to John Doe?\\n```\\n\\n```\\nfind all the notes related to AI
  and send it to my girlfriend\\n```\\n\\n```\\ncreate a reminder to \\\"Buy
  groceries\\\" for tomorrow at 5pm\\n```\\n\\n## Local
  Development\\n\\n```bash\\ngit clone
  https://github.com/dhravya/apple-mcp.git\\ncd apple-mcp\\nbun install\\nbun
  run
  index.ts\\n```\\n\\nenjoy!\\n\",\"isRecommended\":false,\"githubStars\":2098,\
  \"downloadCount\":2855,\"createdAt\":\"2025-04-05T08:51:23.021478Z\",\"update\
  dAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T17:25:2\
  5.394205Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/core-mcp-server\
  \",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/core-mcp-serv\
  er\",\"name\":\"Core Server\",\"author\":\"awslabs\",\"description\":\"Manages
  and coordinates MCP servers, providing automated installation, configuration
  management, and orchestration of AWS Labs servers with centralized logging and
  environment
  control.\",\"codiconIcon\":\"server-environment\",\"logoUrl\":\"https://stora\
  ge.googleapis.com/cline_public_images/aws.png\",\"category\":\"developer-tools\
  \",\"tags\":[\"server-management\",\"configuration\",\"aws-integration\",\"au\
  tomation\",\"orchestration\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Core MCP Server\\n\\nMCP server that provides a starting point for using the
  following awslabs MCP servers\\n- awslabs.cdk-mcp-server\\n-
  awslabs.bedrock-kb-retrieval-mcp-server\\n- awslabs.nova-canvas-mcp-server\\n-
  awslabs.cost-analysis-mcp-server\\n- awslabs.aws-documentation-mcp-server\\n-
  awslabs.aws-diagram-mcp-server\\n\\n## Features\\n\\n\\n### Planning and
  orchestration\\n\\n- Provides tool for prompt understanding and translation to
  AWS services\\n\\n## Prerequisites\\n\\n- Python 3.12 or higher\\n-
  [uv](https://github.com/astral-sh/uv) - Fast Python package installer and
  resolver\\n- AWS credentials configured with Bedrock access\\n- Node.js (for
  UVX installation support)\\n\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.core-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2x\
  hYnMuY29yZS1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVS\
  Uk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D)\\n\\nConfigure
  the MCP server in your MCP client configuration (e.g., for Amazon Q Developer
  CLI, edit `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.core-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.core-mcp-server@latest\\\"\\n      ],\\n      \\\"env\
  \\\": {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"autoApprove\\\":
  [],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/core-mcp-server
  .`:\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.core-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"awslabs/core-mcp-server:latest\\\"\\n        ],\\n        \
  \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n\\n##
  Tools and Resources\\n\\nThe server exposes the following tools through the
  MCP interface:\\n\\n- `prompt_understanding` - Helps to provide guidance and
  planning support when building AWS Solutions for the given
  prompt\\n\",\"isRecommended\":false,\"githubStars\":4391,\"downloadCount\":57\
  72,\"createdAt\":\"2025-04-04T19:48:29.604163Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T00:33:58.950822Z\"},{\"mcpId\
  \":\"github.com/ykhli/mcp-send-email\",\"githubUrl\":\"https://github.com/ykh\
  li/mcp-send-email\",\"name\":\"Email
  Sender\",\"author\":\"ykhli\",\"description\":\"Sends emails directly through
  Resend's API, enabling AI assistants to compose and send emails without manual
  copying and
  pasting.\",\"codiconIcon\":\"mail\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/resend.png\",\"category\":\"communication\",\"tags\":[\
  \"email\",\"resend-api\",\"messaging\",\"automation\",\"communication\"],\"re\
  quiresApiKey\":false,\"readmeContent\":\"# Email sending MCP
  \\n\\n[![smithery
  badge](https://smithery.ai/badge/@resend/mcp-send-email)](https://smithery.ai\
  /server/@resend/mcp-send-email)\\n\\nThis is a simple MCP server that sends
  emails using Resend's API. Why? Now you can let Cursor or Claude Desktop
  compose emails for you and send it right away without having to copy and paste
  the email content.\\n\\nAs an example, you could use this to run local
  scripts, chat with Claude, or process data and send the results to yourself or
  your team.\\n\\nBuilt with:\\n\\n- [Resend](https://resend.com/)\\n-
  [Anthropic MCP](https://docs.anthropic.com/en/docs/agents-and-tools/mcp)\\n-
  [Cursor](https://cursor.so/)\\n\\n## Features\\n\\n- Send plain text and HTML
  emails\\n- Schedule emails for future delivery\\n- Add CC and BCC
  recipients\\n- Configure reply-to addresses\\n- Customizable sender email
  (requires verification)\\n\\n##
  Demo\\n\\nhttps://github.com/user-attachments/assets/8c05cbf0-1664-4b3b-afb1-\
  663b46af3464\\n\\n## Setup\\n\\nCurrently, you must build the project locally
  to use this MCP server. Then add the server in [Cursor](#cursor) or [Claude
  Desktop](#claude-desktop) to use it in any Cursor or Claude Desktop
  chat.\\n\\n1. Clone this project locally.\\n\\n```\\ngit clone
  https://github.com/resend/mcp-send-email.git\\n```\\n\\n2. Build the
  project\\n\\n```\\nnpm install\\nnpm run build\\n```\\n3. Setup
  Resend\\n\\nCreate a free Resend account and [Create an API
  Key](https://resend.com/api-keys). To send to other addresses, you'll also
  need to [verify your own domain](https://resend.com/domains).\\n\\n>
  [!NOTE]\\n> For more info on how to send emails with Resend, see the
  [docs](https://resend.com/docs/send-with-nodejs).\\n\\n## Cursor\\n\\n1. Open
  Cursor Settings.\\n\\nOpen the command palette (`cmd`+`shift`+`p` on macOS or
  `ctrl`+`shift`+`p` on Windows) and choose \\\"Cursor Settings\\\".\\n\\n2. Add
  the MCP server\\n\\nSelect \\\"MCP\\\" from the left sidebar and click \\\"Add
  new global MCP server\\\".\\n\\nAdd the following
  config:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"resend\\\":
  {\\n      \\\"type\\\": \\\"command\\\",\\n      \\\"command\\\": \\\"node
  ABSOLUTE_PATH_TO_MCP_SEND_EMAIL_PROJECT/build/index.js
  --key=YOUR_RESEND_API_KEY\\\"\\n    }\\n  }\\n}\\n```\\n\\nYou can get the
  absolute path to your build script by right-clicking on the `/build/index.js`
  file in Cursor and selecting `Copy Path`.\\n\\n**Possible arguments**\\n\\n-
  `--key`: Your Resend API key (required)\\n- `--sender`: Your sender email
  address from a verified domain (optional)\\n- `--reply-to`: Your reply-to
  email address (optional)\\n\\n> [!NOTE]\\n> If you don't provide a sender
  email address, the MCP server will ask you to provide one each time you call
  the tool.\\n\\n3. Test the sending\\n\\nNow you can test out sending emails by
  going to `email.md`.\\n- Replace the to: email address with your own\\n-
  Select all text in `email.md`, and press `cmd+l`\\n- Tell cursor to \\\"send
  this as an email\\\" in the chat (make sure cursor is in Agent mode by
  selecting \\\"Agent\\\" on lower left side dropdown).\\n\\n<img
  width=\\\"441\\\" alt=\\\"Cursor chat with email.md file selected and Agent
  mode enabled\\\"
  src=\\\"https://github.com/user-attachments/assets/b07e9cbf-42d8-4910-8e90-37\
  61d8d3bc06\\\" />\\n\\n## Claude Desktop\\n\\n1. Open Claude's Developer
  config file\\n\\nOpen Claude Desktop settings and navigate to the
  \\\"Developer\\\" tab. Click `Edit Config`.\\n\\n2. Add the MCP
  server\\n\\nAdd the following config:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"resend\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"ABSOLUTE_PATH_TO_MCP_SEND_EMAIL_PROJECT/build/index.js\\\"\\n      \
  ],\\n      \\\"env\\\": {\\n        \\\"RESEND_API_KEY\\\":
  \\\"YOUR_RESEND_API_KEY\\\",\\n      }\\n    }\\n  }\\n}\\n```\\n\\nYou can
  get the absolute path to your build script by right-clicking on the
  `/build/index.js` file in your IDE and selecting `Copy Path`.\\n\\n**Possible
  environment variables**\\n\\n- `RESEND_API_KEY`: Your Resend API key
  (required)\\n- `SENDER_EMAIL_ADDRESS`: Your sender email address from a
  verified domain (optional)\\n- `REPLY_TO_EMAIL_ADDRESS`: Your reply-to email
  address (optional)\\n\\n> [!NOTE]\\n> If you don't provide a sender email
  address, the MCP server will ask you to provide one each time you call the
  tool.\\n\\n3. Test the sending\\n\\nClose and reopen Claude Desktop. Verify
  that the `resend` tool is available in the Claude developer
  settings.\\n\\n![Claude Desktop developer settings with Resend MCP server
  showing](https://github.com/user-attachments/assets/be9549e5-eaef-4946-b10a-e\
  708c1864acf)\\n\\nChat with Claude and tell it to send you an email using the
  `resend`
  tool.\\n\",\"isRecommended\":false,\"githubStars\":376,\"downloadCount\":1583,\
  \"createdAt\":\"2025-03-03T11:05:30.27228Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-07-06T21:17:46.322992Z\"},{\"mcpId\":\
  \"github.com/tavily-ai/tavily-mcp\",\"githubUrl\":\"https://github.com/tavily\
  -ai/tavily-mcp\",\"name\":\"Tavily\",\"author\":\"tavily-ai\",\"description\":\
  \"Enables real-time web search and data extraction capabilities through
  Tavily's API, providing AI assistants with filtered search results and
  intelligent content extraction from web
  pages.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/tavily.jpg\",\"category\":\"search\",\"tags\":[\"web-\
  search\",\"data-extraction\",\"real-time-information\",\"content-filtering\",\
  \"news-search\"],\"requiresApiKey\":false,\"readmeContent\":\"# ![Tavily Crawl
  Beta](./assets/Banner_NEW.png)\\n\\n\\n![GitHub Repo
  stars](https://img.shields.io/github/stars/tavily-ai/tavily-mcp?style=social)\
  \\n![npm](https://img.shields.io/npm/dt/tavily-mcp)\\n![smithery
  badge](https://smithery.ai/badge/@tavily-ai/tavily-mcp)\\n\\n ## 
  **Introducing
  [tavily-crawl](https://docs.tavily.com/documentation/api-reference/endpoint/c\
  rawl) +
  [tavily-map](https://docs.tavily.com/documentation/api-reference/endpoint/map)
  in v0.2.4!** \\n\\n\\n![MCP demo](./assets/demo_new.gif)\\n\\nThe Model
  Context Protocol (MCP) is an open standard that enables AI systems to interact
  seamlessly with various data sources and tools, facilitating secure, two-way
  connections.\\n\\nDeveloped by Anthropic, the Model Context Protocol (MCP)
  enables AI assistants like Claude to seamlessly integrate with Tavily's
  advanced search and data extraction capabilities. This integration provides AI
  models with real-time access to web information, complete with sophisticated
  filtering options and domain-specific search features.\\n\\nThe Tavily MCP
  server provides:\\n- search, extract, map, crawl tools\\n- Real-time web
  search capabilities through the tavily-search tool\\n- Intelligent data
  extraction from web pages via the tavily-extract tool\\n- Powerful web mapping
  tool that creates a structured map of website \\n- Web crawler that
  systematically explores websites \\n\\n\\n###  Helpful Resources\\n-
  [Tutorial](https://medium.com/@dustin_36183/building-a-knowledge-graph-assist\
  ant-combining-tavily-and-neo4j-mcp-servers-with-claude-db92de075df9) on
  combining Tavily MCP with Neo4j MCP server\\n-
  [Tutorial](https://medium.com/@dustin_36183/connect-your-coding-assistant-to-\
  the-web-integrating-tavily-mcp-with-cline-in-vs-code-5f923a4983d1) on
  integrating Tavily MCP with Cline in VS Code\\n\\n## Prerequisites
  \\n\\nBefore you begin, ensure you have:\\n\\n- [Tavily API
  key](https://app.tavily.com/home)\\n  - If you don't have a Tavily API key,
  you can sign up for a free account [here](https://app.tavily.com/home)\\n-
  [Claude Desktop](https://claude.ai/download) or
  [Cursor](https://cursor.sh)\\n- [Node.js](https://nodejs.org/) (v20 or
  higher)\\n  - You can verify your Node.js installation by running:\\n    -
  `node --version`\\n- [Git](https://git-scm.com/downloads) installed (only
  needed if using Git installation method)\\n  - On macOS: `brew install
  git`\\n  - On Linux: \\n    - Debian/Ubuntu: `sudo apt install git`\\n    -
  RedHat/CentOS: `sudo yum install git`\\n  - On Windows: Download [Git for
  Windows](https://git-scm.com/download/win)\\n\\n## Tavily MCP server
  installation \\n\\n### Running with NPX \\n\\n```bash\\nnpx -y
  tavily-mcp@latest \\n```\\n\\n### Installing via Smithery\\n\\nTo install
  Tavily MCP Server for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@tavily-ai/tavily-mcp):\\n\\n```bash\\n\
  npx -y @smithery/cli install @tavily-ai/tavily-mcp --client
  claude\\n```\\n\\nAlthough you can launch a server on its own, it's not
  particularly helpful in isolation. Instead, you should integrate it into an
  MCP client. Below is an example of how to configure the Claude Desktop app to
  work with the tavily-mcp server.\\n\\n\\n## Configuring MCP Clients
  \\n\\nThis repository will explain how to configure [VS
  Code](https://code.visualstudio.com), [Cursor](https://cursor.sh) and [Claude
  Desktop](https://claude.ai/desktop) to work with the tavily-mcp
  server.\\n\\n### Configuring VS Code \\n\\nFor one-click installation, click
  one of the install buttons below:\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=tavily&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-\
  y%22%2C%22tavily-mcp%400.1.4%22%5D%2C%22env%22%3A%7B%22TAVILY_API_KEY%22%3A%2\
  2%24%7Binput%3Atavily_api_key%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22prompt\
  String%22%2C%22id%22%3A%22tavily_api_key%22%2C%22description%22%3A%22Tavily+A\
  PI+Key%22%2C%22password%22%3Atrue%7D%5D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=tavily&config=%7B%22command%22%3A%22npx%22%2C%22args\
  %22%3A%5B%22-y%22%2C%22tavily-mcp%400.1.4%22%5D%2C%22env%22%3A%7B%22TAVILY_AP\
  I_KEY%22%3A%22%24%7Binput%3Atavily_api_key%7D%22%7D%7D&inputs=%5B%7B%22type%2\
  2%3A%22promptString%22%2C%22id%22%3A%22tavily_api_key%22%2C%22description%22%\
  3A%22Tavily+API+Key%22%2C%22password%22%3Atrue%7D%5D&quality=insiders)\\n\\n#\
  ## Manual Installation\\n\\nFirst check if there are install buttons at the
  top of this section that match your needs. If you prefer manual installation,
  follow these steps:\\n\\nAdd the following JSON block to your User Settings
  (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` (or
  `Cmd + Shift + P` on macOS) and typing `Preferences: Open User Settings
  (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"tavily_api_key\\\",\\n        \\\"description\\\": \\\"Tavily API
  Key\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"tavily\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"tavily-mcp@latest\\\"],\\n        \\\"env\\\":
  {\\n          \\\"TAVILY_API_KEY\\\":
  \\\"${input:tavily_api_key}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nOptionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace:\\n\\n```json\\n{\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"tavily_api_key\\\",\\n      \\\"description\\\": \\\"Tavily API
  Key\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\":
  {\\n    \\\"tavily\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"tavily-mcp@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"TAVILY_API_KEY\\\":
  \\\"${input:tavily_api_key}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n###
  Configuring Cline \\n\\nThe easiest way to set up the Tavily MCP server in
  Cline is through the marketplace with a single click:\\n\\n1. Open Cline in VS
  Code\\n2. Click on the Cline icon in the sidebar\\n3. Navigate to the \\\"MCP
  Servers\\\" tab ( 4 squares )\\n4. Search \\\"Tavily\\\" and click
  \\\"install\\\"\\n5. When prompted, enter your Tavily API
  key\\n\\nAlternatively, you can manually set up the Tavily MCP server in
  Cline:\\n\\n1. Open the Cline MCP settings file:\\n\\n   ### For
  macOS:\\n   ```bash\\n   # Using Visual Studio Code\\n   code
  ~/Library/Application\\\\
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json\\n   \\n   # Or using TextEdit\\n   open -e
  ~/Library/Application\\\\
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json\\n   ```\\n\\n   ### For Windows:\\n   ```bash\\n   code
  %APPDATA%\\\\Code\\\\User\\\\globalStorage\\\\saoudrizwan.claude-dev\\\\setti\
  ngs\\\\cline_mcp_settings.json\\n   ```\\n\\n2. Add the Tavily server
  configuration to the file:\\n\\n   Replace `your-api-key-here` with your
  actual [Tavily API
  key](https://tavily.com/api-keys).\\n\\n   ```json\\n   {\\n     \\\"mcpServe\
  rs\\\": {\\n       \\\"tavily-mcp\\\": {\\n         \\\"command\\\":
  \\\"npx\\\",\\n         \\\"args\\\": [\\\"-y\\\",
  \\\"tavily-mcp@latest\\\"],\\n         \\\"env\\\":
  {\\n           \\\"TAVILY_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n3. Save the file and restart Cline
  if it's already running.\\n\\n4. When using Cline, you'll now have access to
  the Tavily MCP tools. You can ask Cline to use the tavily-search and
  tavily-extract tools directly in your conversations.\\n\\n\\n### Configuring
  Cursor \\n\\n> **Note**: Requires Cursor version 0.45.6 or higher\\n\\nTo
  set up the Tavily MCP server in Cursor:\\n\\n1. Open Cursor Settings\\n2.
  Navigate to Features > MCP Servers\\n3. Click on the \\\"+ Add New MCP
  Server\\\" button\\n4. Fill out the following information:\\n   - **Name**:
  Enter a nickname for the server (e.g., \\\"tavily-mcp\\\")\\n   - **Type**:
  Select \\\"command\\\" as the type\\n   - **Command**: Enter the command to
  run the server:\\n     ```bash\\n     env TAVILY_API_KEY=your-api-key npx -y
  tavily-mcp@latest\\n     ```\\n     > **Important**: Replace `your-api-key`
  with your Tavily API key. You can get one at
  [app.tavily.com/home](https://app.tavily.com/home)\\n\\nAfter adding the
  server, it should appear in the list of MCP servers. You may need to manually
  press the refresh button in the top right corner of the MCP server to populate
  the tool list.\\n\\nThe Composer Agent will automatically use the Tavily MCP
  tools when relevant to your queries. It is better to explicitly request to use
  the tools by describing what you want to do (e.g., \\\"User tavily-search to
  search the web for the latest news on AI\\\"). On mac press command + L to
  open the chat, select the composer option at the top of the screen, beside the
  submit button select agent and submit the query when ready.\\n\\n![Cursor
  Interface Example](./assets/cursor-reference.png)\\n\\n### Configuring the
  Claude Desktop app \\n### For macOS:\\n\\n```bash\\n# Create the config
  file if it doesn't exist\\ntouch \\\"$HOME/Library/Application
  Support/Claude/claude_desktop_config.json\\\"\\n\\n# Opens the config file in
  TextEdit \\nopen -e \\\"$HOME/Library/Application
  Support/Claude/claude_desktop_config.json\\\"\\n\\n# Alternative method using
  Visual Studio Code (requires VS Code to be installed)\\ncode
  \\\"$HOME/Library/Application
  Support/Claude/claude_desktop_config.json\\\"\\n```\\n\\n### For
  Windows:\\n```bash\\ncode
  %APPDATA%\\\\Claude\\\\claude_desktop_config.json\\n```\\n\\n### Add the
  Tavily server configuration:\\n\\nReplace `your-api-key-here` with your actual
  [Tavily API
  key](https://tavily.com/api-keys).\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"tavily-mcp\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"tavily-mcp@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"TAVILY_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### 2. Git
  Installation\\n\\n1. Clone the repository:\\n```bash\\ngit clone
  https://github.com/tavily-ai/tavily-mcp.git\\ncd tavily-mcp\\n```\\n\\n2.
  Install dependencies:\\n```bash\\nnpm install\\n```\\n\\n3. Build the
  project:\\n```bash\\nnpm run build\\n```\\n### Configuring the Claude Desktop
  app \\nFollow the configuration steps outlined in the [Configuring the
  Claude Desktop app](#configuring-the-claude-desktop-app-) section above,
  using the below JSON configuration.\\n\\nReplace `your-api-key-here` with your
  actual [Tavily API key](https://tavily.com/api-keys) and `/path/to/tavily-mcp`
  with the actual path where you cloned the repository on your
  system.\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"tavily\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\\"/path/to/tavily-mcp/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"TAVILY_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Usage in
  Claude Desktop App \\n\\nOnce the installation is complete, and the Claude
  desktop app is configured, you must completely close and re-open the Claude
  desktop app to see the tavily-mcp server. You should see a hammer icon in the
  bottom left of the app, indicating available MCP tools, you can click on the
  hammer icon to see more detial on the tavily-search and tavily-extract
  tools.\\n\\n![Alt text](./assets/claude-desktop-ref.png)\\n\\nNow claude will
  have complete access to the tavily-mcp server, including the tavily-search and
  tavily-extract tools. If you insert the below examples into the Claude desktop
  app, you should see the tavily-mcp server tools in action.\\n\\n### Tavily
  Search Examples\\n\\n1. **General Web Search**:\\n```\\nCan you search for
  recent developments in quantum computing?\\n```\\n\\n2. **News
  Search**:\\n```\\nSearch for news articles about AI startups from the last 7
  days.\\n```\\n\\n3. **Domain-Specific Search**:\\n```\\nSearch for climate
  change research on nature.com and sciencedirect.com\\n```\\n\\n### Tavily
  Extract Examples \\n\\n1. **Extract Article Content**:\\n```\\nExtract the
  main content from this article: https://example.com/article\\n```\\n\\n### 
  Combine Search and Extract \\n\\nYou can also combine the tavily-search and
  tavily-extract tools to perform more complex tasks.\\n\\n```\\nSearch for news
  articles about AI startups from the last 7 days and extract the main content
  from each article to generate a detailed report.\\n```\\n\\n## Troubleshooting
  \\n\\n### Common Issues\\n\\n1. **Server Not Found**\\n   - Verify the npm
  installation by running `npm --verison`\\n   - Check Claude Desktop
  configuration syntax by running `code ~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json`\\n   - Ensure Node.js is properly
  installed by running `node --version`\\n   \\n2. **NPX related issues**\\n  -
  If you encounter errors related to `npx`, you may need to use the full path to
  the npx executable instead. \\n  - You can find this path by running `which
  npx` in your terminal, then replace the `\\\"command\\\":  \\\"npx\\\"` line
  with `\\\"command\\\": \\\"/full/path/to/npx\\\"` in your
  configuration.\\n\\n3. **API Key Issues**\\n   - Confirm your Tavily API key
  is valid\\n   - Check the API key is correctly set in the config\\n   - Verify
  no spaces or quotes around the API key\\n\\n## Acknowledgments \\n\\n- [Model
  Context Protocol](https://modelcontextprotocol.io) for the MCP
  specification\\n- [Anthropic](https://anthropic.com) for Claude
  Desktop\\n\",\"isRecommended\":true,\"githubStars\":527,\"downloadCount\":837\
  7,\"createdAt\":\"2025-02-17T22:46:47.267489Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T08:41:36.532191Z\"},{\"mcpId\
  \":\"github.com/GLips/Figma-Context-MCP\",\"githubUrl\":\"https://github.com/\
  GLips/Figma-Context-MCP\",\"name\":\"Figma\",\"author\":\"GLips\",\"descripti\
  on\":\"Provides AI assistants with access to Figma design data, enabling
  accurate code generation from design files by fetching and simplifying Figma
  API responses for optimal
  context.\",\"codiconIcon\":\"symbol-color\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/figma.png\",\"category\":\"developer-tools\",\
  \"tags\":[\"figma\",\"design\",\"ui-development\",\"code-generation\",\"curso\
  r-integration\"],\"requiresApiKey\":false,\"readmeContent\":\"<a
  href=\\\"https://www.framelink.ai/?utm_source=github&utm_medium=referral&utm_\
  campaign=readme\\\" target=\\\"_blank\\\"
  rel=\\\"noopener\\\">\\n  <picture>\\n    <source
  media=\\\"(prefers-color-scheme: dark)\\\"
  srcset=\\\"https://www.framelink.ai/github/HeaderDark.png\\\" />\\n    <img
  alt=\\\"Framelink\\\"
  src=\\\"https://www.framelink.ai/github/HeaderLight.png\\\"
  />\\n  </picture>\\n</a>\\n\\n<div align=\\\"center\\\">\\n  <h1>Framelink
  Figma MCP Server</h1>\\n  <p>\\n     Available in:\\n    <a
  href=\\\"README.ko.md\\\"> (Korean)</a> |\\n    <a
  href=\\\"README.ja.md\\\"> (Japanese)</a> |\\n    <a
  href=\\\"README.zh.md\\\"> (Chinese)</a>\\n  </p>\\n  <h3>Give your coding
  agent access to your Figma data.<br/>Implement designs in any framework in
  one-shot.</h3>\\n  <a
  href=\\\"https://npmcharts.com/compare/figma-developer-mcp?interval=30\\\">\\\
  n    <img alt=\\\"weekly downloads\\\"
  src=\\\"https://img.shields.io/npm/dm/figma-developer-mcp.svg\\\">\\n  </a>\\\
  n  <a
  href=\\\"https://github.com/GLips/Figma-Context-MCP/blob/main/LICENSE\\\">\\n    \
  <img alt=\\\"MIT License\\\"
  src=\\\"https://img.shields.io/github/license/GLips/Figma-Context-MCP\\\"
  />\\n  </a>\\n  <a href=\\\"https://framelink.ai/discord\\\">\\n    <img
  alt=\\\"Discord\\\"
  src=\\\"https://img.shields.io/discord/1352337336913887343?color=7389D8&label\
  &logo=discord&logoColor=ffffff\\\" />\\n  </a>\\n  <br />\\n  <a
  href=\\\"https://twitter.com/glipsman\\\">\\n    <img alt=\\\"Twitter\\\"
  src=\\\"https://img.shields.io/twitter/url?url=https%3A%2F%2Fx.com%2Fglipsman\
  &label=%40glipsman\\\" />\\n  </a>\\n</div>\\n\\n<br/>\\n\\nGive
  [Cursor](https://cursor.sh/) and other AI-powered coding tools access to your
  Figma files with this [Model Context
  Protocol](https://modelcontextprotocol.io/introduction) server.\\n\\nWhen
  Cursor has access to Figma design data, it's **way** better at one-shotting
  designs accurately than alternative approaches like pasting
  screenshots.\\n\\n<h3><a
  href=\\\"https://www.framelink.ai/docs/quickstart?utm_source=github&utm_mediu\
  m=referral&utm_campaign=readme\\\">See quickstart instructions
  </a></h3>\\n\\n## Demo\\n\\n[Watch a demo of building a UI in Cursor with
  Figma design data](https://youtu.be/6G9yb-LrEqg)\\n\\n[![Watch the
  video](https://img.youtube.com/vi/6G9yb-LrEqg/maxresdefault.jpg)](https://you\
  tu.be/6G9yb-LrEqg)\\n\\n## How it works\\n\\n1. Open your IDE's chat (e.g.
  agent mode in Cursor).\\n2. Paste a link to a Figma file, frame, or
  group.\\n3. Ask Cursor to do something with the Figma filee.g. implement the
  design.\\n4. Cursor will fetch the relevant metadata from Figma and use it to
  write your code.\\n\\nThis MCP server is specifically designed for use with
  Cursor. Before responding with context from the [Figma
  API](https://www.figma.com/developers/api), it simplifies and translates the
  response so only the most relevant layout and styling information is provided
  to the model.\\n\\nReducing the amount of context provided to the model helps
  make the AI more accurate and the responses more relevant.\\n\\n## Getting
  Started\\n\\nMany code editors and other AI clients use a configuration file
  to manage MCP servers.\\n\\nThe `figma-developer-mcp` server can be configured
  by adding the following to your configuration file.\\n\\n> NOTE: You will need
  to create a Figma access token to use this server. Instructions on how to
  create a Figma API access token can be found
  [here](https://help.figma.com/hc/en-us/articles/8085703771159-Manage-personal\
  -access-tokens).\\n\\n### MacOS /
  Linux\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Framelink Figma
  MCP\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\\"-y\\\", \\\"figma-developer-mcp\\\", \\\"--figma-api-key=YOUR-KEY\\\",
  \\\"--stdio\\\"]\\n    }\\n  }\\n}\\n```\\n\\n###
  Windows\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"Framelink Figma
  MCP\\\": {\\n      \\\"command\\\": \\\"cmd\\\",\\n      \\\"args\\\":
  [\\\"/c\\\", \\\"npx\\\", \\\"-y\\\", \\\"figma-developer-mcp\\\",
  \\\"--figma-api-key=YOUR-KEY\\\",
  \\\"--stdio\\\"]\\n    }\\n  }\\n}\\n```\\n\\nOr you can set `FIGMA_API_KEY`
  and `PORT` in the `env` field.\\n\\nIf you need more information on how to
  configure the Framelink Figma MCP server, see the [Framelink
  docs](https://www.framelink.ai/docs/quickstart?utm_source=github&utm_medium=r\
  eferral&utm_campaign=readme).\\n\\n## Star History\\n\\n<a
  href=\\\"https://star-history.com/#GLips/Figma-Context-MCP\\\"><img
  src=\\\"https://api.star-history.com/svg?repos=GLips/Figma-Context-MCP&type=D\
  ate\\\" alt=\\\"Star History Chart\\\" width=\\\"600\\\" /></a>\\n\\n## Learn
  More\\n\\nThe Framelink Figma MCP server is simple but powerful. Get the most
  out of it by learning more at the
  [Framelink](https://framelink.ai?utm_source=github&utm_medium=referral&utm_ca\
  mpaign=readme) site.\\n\\n<!-- SPONSORS:LIST:START -->\\n<!--
  prettier-ignore-start -->\\n<!-- markdownlint-disable -->\\n\\n##
  Sponsors\\n\\n###  Gold Sponsors\\n\\n<table>\\n  <tr>\\n   <td
  align=\\\"center\\\"><a
  href=\\\"https://framelink.ai/?ref=framelink-mcp&utm_source=github&utm_medium\
  =referral&utm_campaign=framelink-mcp\\\"><img
  src=\\\"https://avatars.githubusercontent.com/u/204619719\\\"
  width=\\\"180\\\" alt=\\\"Framelink\\\"/><br
  />Framelink</a></td>\\n  </tr>\\n</table>\\n\\n###  Silver
  Sponsors\\n\\n<table>\\n  <tr>\\n   <!-- <td align=\\\"center\\\"><a
  href=\\\"\\\"><img src=\\\"\\\" width=\\\"150\\\" alt=\\\"tbd\\\"/><br
  />Title</a></td> -->\\n  </tr>\\n</table>\\n\\n###  Bronze
  Sponsors\\n\\n<table>\\n  <tr>\\n   <!-- <td align=\\\"center\\\"><a
  href=\\\"\\\"><img src=\\\"\\\" width=\\\"120\\\" alt=\\\"tbd\\\"/><br
  />tbd</a></td>-->\\n  </tr>\\n</table>\\n\\n###  Smaller
  Backers\\n\\n<table>\\n  <tr>\\n   <!-- <td align=\\\"center\\\"><a
  href=\\\"\\\"><img src=\\\"\\\" width=\\\"100\\\" alt=\\\"tbd\\\"/><br
  />tbd</a></td>-->\\n  </tr>\\n  <tr>\\n   <!-- <td align=\\\"center\\\"><a
  href=\\\"\\\"><img src=\\\"\\\" width=\\\"100\\\" alt=\\\"tbd\\\"/><br
  />tbd</a></td>-->\\n  </tr>\\n</table>\\n\\n<!-- markdownlint-restore
  -->\\n<!-- prettier-ignore-end -->\\n\\n<!-- SPONSORS:LIST:END
  -->\\n\",\"isRecommended\":false,\"githubStars\":8699,\"downloadCount\":20627,\
  \"createdAt\":\"2025-02-17T22:27:13.107046Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-01T03:31:29.624299Z\"},{\"mcpId\":\
  \"github.com/modelcontextprotocol/servers/tree/main/src/google-maps\",\"githu\
  bUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/google\
  -maps\",\"name\":\"Google
  Maps\",\"author\":\"modelcontextprotocol\",\"description\":\"Provides
  comprehensive access to Google Maps services including geocoding, place
  search, directions, distance calculations, and elevation data through the
  Google Maps
  API.\",\"codiconIcon\":\"location\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/google-maps.png\",\"category\":\"location-services\",\
  \"tags\":[\"maps\",\"geocoding\",\"navigation\",\"places-api\",\"location-data\
  \"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\":57098,\"d\
  ownloadCount\":4374,\"createdAt\":\"2025-02-17T22:46:16.116171Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T23:51:02.0\
  75488Z\"},{\"mcpId\":\"github.com/NightTrek/Serper-search-mcp\",\"githubUrl\":\
  \"https://github.com/NightTrek/Serper-search-mcp\",\"name\":\"Serper
  Search\",\"author\":\"NightTrek\",\"description\":\"Provides Google search
  capabilities through Serper API, delivering rich search results including
  knowledge graphs, organic results, related questions, and customizable search
  parameters.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/serper.jpg\",\"category\":\"search\",\"tags\":[\
  \"google-search\",\"serper-api\",\"web-search\",\"knowledge-graph\",\"search-\
  results\"],\"requiresApiKey\":false,\"readmeContent\":\"# Serper Search MCP
  Server\\n\\nA Model Context Protocol server that provides Google search
  capabilities through the Serper API, along with an AI-powered Deep Research
  tool. This server enables easy integration of search and research
  functionality into your MCP-enabled applications.\\n\\n##  Features\\n\\n- 
  Powerful Google search integration through Serper API\\n-  Rich search
  response data including:\\n  - Knowledge Graph information\\n  - Organic
  search results\\n  - \\\"People Also Ask\\\" questions\\n  - Related
  searches\\n-  AI-powered Deep Research tool:\\n  - Performs multi-step,
  iterative research\\n  - Generates sub-queries to explore topics
  thoroughly\\n  - Synthesizes information from multiple sources\\n  - Provides
  citations for all information\\n  - Adjustable research depth levels\\n  -
  Built-in quality metrics for continuous improvement\\n-  Configurable search
  parameters:\\n  - Country targeting\\n  - Language selection\\n  - Result
  count customization\\n  - Autocorrect options\\n-  Secure API key
  handling\\n-  Rate limiting and caching support\\n-  TypeScript support
  with full type definitions\\n-  Integrated performance metrics for result
  optimization\\n\\n##  Installation\\n\\n1. Clone the
  repository:\\n```bash\\ngit clone
  https://github.com/yourusername/serper-search-server.git\\ncd
  serper-search-server\\n```\\n\\n2. Install dependencies:\\n```bash\\npnpm
  install\\n```\\n\\n3. Build the server:\\n```bash\\npnpm run
  build\\n```\\n\\n##  Configuration\\n\\n1. Get your Serper API key from
  [Serper.dev](https://serper.de\\n\\n2. Create a `.env` file in the root
  directory:\\n```env\\n# Required\\nSERPER_API_KEY=your_api_key_here\\n\\n#
  Optional - Advanced Quality Metrics Configuration (pre-configured by
  default)\\nUSAGE_METRICS_KEY=your-custom-metrics-key     #
  Optional\\nUSAGE_PROJECT_ID=your-custom-project-id       #
  Optional\\nMETRICS_ENDPOINT=https://your-custom-host.com #
  Optional\\nDISABLE_METRICS=false                         # Not
  recommended\\n```\\n\\nSee [TELEMETRY.md](TELEMETRY.md) for detailed
  information about:\\n- Quality metrics collection\\n- Performance
  monitoring\\n- Usage analytics\\n- Dashboard setup\\n- Continuous
  improvement\\n\\n##  Integration\\n\\n### Claude Desktop\\n\\nAdd the server
  config to your Claude Desktop configuration:\\n\\n**MacOS**:
  `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n**Windows**:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"serper-search-server\\\": {\\n      \\\"command\\\":
  \\\"/path/to/serper-search-server/build/index.js\\\",\\n      \\\"env\\\":
  {\\n        \\\"SERPER_API_KEY\\\":
  \\\"your_api_key_here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## 
  Usage\\n\\n### Search Tool\\n\\nThe server provides a powerful search tool
  with the following parameters:\\n\\n```typescript\\n{\\n  \\\"query\\\":
  string,          // Search query\\n  \\\"numResults\\\"?: number,    // Number
  of results (default: 10, max: 100)\\n  \\\"gl\\\"?: string,           //
  Country code (e.g., \\\"us\\\", \\\"uk\\\")\\n  \\\"hl\\\"?:
  string,           // Language code (e.g., \\\"en\\\",
  \\\"es\\\")\\n  \\\"autocorrect\\\"?: boolean, // Enable autocorrect (default:
  true)\\n  \\\"type\\\"?: \\\"search\\\"        // Search type (more types
  coming soon)\\n}\\n```\\n\\n### Deep Research Tool\\n\\nFor more comprehensive
  research needs, the server provides a deep research tool that performs
  multi-step research with the following
  parameters:\\n\\n```typescript\\n{\\n  \\\"query\\\": string,          //
  Research query or question\\n  \\\"depth\\\"?: \\\"basic\\\" |
  \\\"standard\\\" | \\\"deep\\\",  // Research depth (default:
  \\\"standard\\\")\\n  \\\"maxSources\\\"?: number     // Maximum sources to
  include (default: 10)\\n}\\n```\\n\\nThe deep research tool:\\n- Breaks down
  complex queries into focused sub-queries\\n- Executes multiple searches to
  gather comprehensive information\\n- Uses AI to synthesize information from
  multiple sources\\n- Formats results with proper citations and references\\n-
  Adapts its research strategy based on intermediate results\\n- Collects
  anonymous quality metrics to improve search results\\n\\nDepth Levels:\\n-
  basic: Quick overview (3-5 sources, ~5 min)\\n  Good for: Simple facts, quick
  definitions, straightforward questions\\n- standard: Comprehensive analysis
  (5-10 sources, ~10 min)\\n  Good for: Most research needs, balanced depth and
  speed\\n- deep: Exhaustive research (10+ sources, ~15-20 min)\\n  Good for:
  Complex topics, academic research, thorough analysis\\n\\n### Search Tool
  Example Response\\n\\nThe search results include rich
  data:\\n\\n```json\\n{\\n  \\\"searchParameters\\\": {\\n    \\\"q\\\":
  \\\"apple inc\\\",\\n    \\\"gl\\\": \\\"us\\\",\\n    \\\"hl\\\":
  \\\"en\\\",\\n    \\\"autocorrect\\\": true,\\n    \\\"type\\\":
  \\\"search\\\"\\n  },\\n  \\\"knowledgeGraph\\\": {\\n    \\\"title\\\":
  \\\"Apple\\\",\\n    \\\"type\\\": \\\"Technology
  company\\\",\\n    \\\"website\\\":
  \\\"http://www.apple.com/\\\",\\n    \\\"description\\\": \\\"Apple Inc. is an
  American multinational technology company...\\\",\\n    \\\"attributes\\\":
  {\\n      \\\"Headquarters\\\": \\\"Cupertino, CA\\\",\\n      \\\"CEO\\\":
  \\\"Tim Cook (Aug 24, 2011)\\\",\\n      \\\"Founded\\\": \\\"April 1, 1976,
  Los Altos, CA\\\"\\n    }\\n  },\\n  \\\"organic\\\":
  [\\n    {\\n      \\\"title\\\": \\\"Apple\\\",\\n      \\\"link\\\":
  \\\"https://www.apple.com/\\\",\\n      \\\"snippet\\\": \\\"Discover the
  innovative world of Apple...\\\",\\n      \\\"position\\\":
  1\\n    }\\n  ],\\n  \\\"peopleAlsoAsk\\\":
  [\\n    {\\n      \\\"question\\\": \\\"What does Apple Inc
  mean?\\\",\\n      \\\"snippet\\\": \\\"Apple Inc., formerly Apple Computer,
  Inc....\\\",\\n      \\\"link\\\":
  \\\"https://www.britannica.com/topic/Apple-Inc\\\"\\n    }\\n  ],\\n  \\\"rel\
  atedSearches\\\": [\\n    {\\n      \\\"query\\\": \\\"Who invented the
  iPhone\\\"\\n    }\\n  ]\\n}\\n```\\n\\n##  Response Types\\n\\n###
  Knowledge Graph\\nContains entity information when available:\\n- Title and
  type\\n- Website URL\\n- Description\\n- Key attributes\\n\\n### Organic
  Results\\nList of search results including:\\n- Title and URL\\n- Snippet
  (description)\\n- Position in results\\n- Sitelinks when available\\n\\n###
  People Also Ask\\nCommon questions related to the search:\\n- Question
  text\\n- Answer snippet\\n- Source link\\n\\n### Related Searches\\nList of
  related search queries users often make.\\n\\n##  Quality Metrics\\n\\nThe
  Deep Research tool includes integrated quality metrics:\\n\\n- Research
  process metrics\\n- Performance monitoring\\n- Issue tracking\\n- Usage
  patterns\\n- Result quality indicators\\n\\nSee [TELEMETRY.md](TELEMETRY.md)
  for detailed information about the metrics collected to improve search
  quality.\\n\\n##  Contributing\\n\\nContributions are welcome! Please feel
  free to submit a Pull Request.\\n\\n##  License\\n\\nThis project is
  licensed under the MIT License - see the [LICENSE](LICENSE) file for
  details.\\n\\n##  Acknowledgments\\n\\n- [Serper API](https://serper.dev)
  for providing the Google search capabilities\\n- [Model Context
  Protocol](https://github.com/modelcontextprotocol/mcp) for the MCP
  framework\\n- [PostHog](https://posthog.com) for analytics
  capabilities\\n\",\"isRecommended\":false,\"githubStars\":33,\"downloadCount\
  \":4318,\"createdAt\":\"2025-02-18T23:05:46.398856Z\",\"updatedAt\":\"2025-07\
  -08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T09:48:47.878104Z\"},{\
  \"mcpId\":\"github.com/exa-labs/exa-mcp-server\",\"githubUrl\":\"https://gith\
  ub.com/exa-labs/exa-mcp-server\",\"name\":\"Exa
  Search\",\"author\":\"exa-labs\",\"description\":\"Enables AI assistants to
  perform real-time web searches using Exa's AI Search API, providing structured
  results with titles, URLs, and content
  snippets.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/exa.jpg\",\"category\":\"search\",\"tags\":[\"web-\
  search\",\"exa-api\",\"real-time-data\",\"content-discovery\",\"information-r\
  etrieval\"],\"requiresApiKey\":false,\"readmeContent\":\"# Exa MCP Server
  \\n[![npm
  version](https://badge.fury.io/js/exa-mcp-server.svg)](https://www.npmjs.com/\
  package/exa-mcp-server)\\n[![smithery
  badge](https://smithery.ai/badge/exa)](https://smithery.ai/server/exa)\\n\\nA
  Model Context Protocol (MCP) server lets AI assistants like Claude use the Exa
  AI Search API for web searches. This setup allows AI models to get real-time
  web information in a safe and controlled way.\\n\\n## Remote Exa MCP
  \\n\\nConnect directly to Exa's hosted MCP server (instead of running it
  locally).\\n\\n### Remote Exa MCP
  URL\\n\\n```\\nhttps://mcp.exa.ai/mcp?exaApiKey=your-exa-api-key\\n```\\n\\nR\
  eplace `your-api-key-here` with your actual Exa API key from
  [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).\\n\\n###
  Claude Desktop Configuration for Remote MCP\\n\\nAdd this to your Claude
  Desktop configuration file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"exa\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"mcp-remote\\\",\\n        \\\"https://m\
  cp.exa.ai/mcp?exaApiKey=your-exa-api-key\\\"\\n      ]\\n    }\\n  }\\n}\\n```\
  \\n\\n### NPM Installation\\n\\n```bash\\nnpm install -g
  exa-mcp-server\\n```\\n\\n### Using Smithery\\n\\nTo install the Exa MCP
  server for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/exa):\\n\\n```bash\\nnpx -y
  @smithery/cli install exa --client claude\\n```\\n\\n## Configuration
  \\n\\n### 1. Configure Claude Desktop to recognize the Exa MCP
  server\\n\\nYou can find claude_desktop_config.json inside the settings of
  Claude Desktop app:\\n\\nOpen the Claude Desktop app and enable Developer Mode
  from the top-left menu bar. \\n\\nOnce enabled, open Settings (also from the
  top-left menu bar) and navigate to the Developer Option, where you'll find the
  Edit Config button. Clicking it will open the claude_desktop_config.json file,
  allowing you to make the necessary edits. \\n\\nOR (if you want to open
  claude_desktop_config.json from terminal)\\n\\n#### For macOS:\\n\\n1. Open
  your Claude Desktop configuration:\\n\\n```bash\\ncode
  ~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json\\n```\\n\\n#### For Windows:\\n\\n1.
  Open your Claude Desktop configuration:\\n\\n```powershell\\ncode
  %APPDATA%\\\\Claude\\\\claude_desktop_config.json\\n```\\n\\n### 2. Add the
  Exa server configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"exa\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"exa-mcp-server\\\"],\\n      \\\"env\\\": {\\n        \\\"EXA_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nReplace
  `your-api-key-here` with your actual Exa API key from
  [dashboard.exa.ai/api-keys](https://dashboard.exa.ai/api-keys).\\n\\n### 3.
  Available Tools & Tool Selection\\n\\nThe Exa MCP server includes the
  following tools, which can be enabled by adding the `--tools`:\\n\\n-
  **web_search_exa**: Performs real-time web searches with optimized results and
  content extraction.\\n- **research_paper_search**: Specialized search focused
  on academic papers and research content.\\n- **company_research**:
  Comprehensive company research tool that crawls company websites to gather
  detailed information about businesses.\\n- **crawling**: Extracts content from
  specific URLs, useful for reading articles, PDFs, or any web page when you
  have the exact URL.\\n- **competitor_finder**: Identifies competitors of a
  company by searching for businesses offering similar products or services.\\n-
  **linkedin_search**: Search LinkedIn for companies and people using Exa AI.
  Simply include company names, person names, or specific LinkedIn URLs in your
  query.\\n- **wikipedia_search_exa**: Search and retrieve information from
  Wikipedia articles on specific topics, giving you accurate, structured
  knowledge from the world's largest encyclopedia.\\n- **github_search**: Search
  GitHub repositories using Exa AI - performs real-time searches on GitHub.com
  to find relevant repositories, issues, and GitHub accounts.\\n\\nYou can
  choose which tools to enable by adding the `--tools` parameter to your Claude
  Desktop configuration:\\n\\n#### Specify which tools to
  enable:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"exa\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"exa-mcp-server\\\",\\n        \\\"--too\
  ls=web_search_exa,research_paper_search,company_research,crawling,competitor_\
  finder,linkedin_search,wikipedia_search_exa,github_search\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"EXA_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor enabling
  multiple tools, use a comma-separated
  list:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"exa\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"exa-mcp-server\\\",\\n        \\\"--too\
  ls=web_search_exa,research_paper_search,company_research,crawling,competitor_\
  finder,linkedin_search,wikipedia_search_exa,github_search\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"EXA_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nIf you don't
  specify any tools, all tools enabled by default will be used.\\n\\n### 4.
  Restart Claude Desktop\\n\\nFor the changes to take effect:\\n\\n1. Completely
  quit Claude Desktop (not just close the window)\\n2. Start Claude Desktop
  again\\n3. Look for the icon to verify the Exa server is connected\\n\\n##
  Using via NPX\\n\\nIf you prefer to run the server directly, you can use
  npx:\\n\\n```bash\\n# Run with all tools enabled by default\\nnpx
  exa-mcp-server\\n\\n# Enable specific tools only\\nnpx exa-mcp-server
  --tools=web_search_exa\\n\\n# Enable multiple tools\\nnpx exa-mcp-server
  --tools=web_search_exa,research_paper_search\\n\\n# List all available
  tools\\nnpx exa-mcp-server --list-tools\\n```\\n\\n## Troubleshooting
  \\n\\n### Common Issues\\n\\n1. **Server Not Found**\\n   * Verify the npm
  link is correctly set up\\n   * Check Claude Desktop configuration syntax
  (json file)\\n\\n2. **API Key Issues**\\n   * Confirm your EXA_API_KEY is
  valid\\n   * Check the EXA_API_KEY is correctly set in the Claude Desktop
  config\\n   * Verify no spaces or quotes around the API key\\n\\n3.
  **Connection Issues**\\n   * Restart Claude Desktop completely\\n   * Check
  Claude Desktop logs:\\n\\n<br>\\n\\n---\\n\\nBuilt with  by team
  Exa\",\"isRecommended\":true,\"githubStars\":1788,\"downloadCount\":1500,\"cr\
  eatedAt\":\"2025-02-17T22:46:53.872366Z\",\"updatedAt\":\"2025-07-08T01:10:48\
  .398933Z\",\"lastGithubSync\":\"2025-07-02T18:30:17.844434Z\"},{\"mcpId\":\"g\
  ithub.com/awslabs/mcp/tree/main/src/memcached-mcp-server\",\"githubUrl\":\"ht\
  tps://github.com/awslabs/mcp/tree/main/src/memcached-mcp-server\",\"name\":\"\
  ElastiCache Memcached\",\"author\":\"awslabs\",\"description\":\"Enables
  secure interaction with Amazon ElastiCache Memcached, supporting full protocol
  operations, SSL/TLS encryption, connection pooling, and optional read-only
  mode.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\"mem\
  cached\",\"caching\",\"aws\",\"elasticache\",\"key-value-store\"],\"requiresA\
  piKey\":false,\"readmeContent\":\"# Amazon ElastiCache Memcached MCP
  Server\\n\\nMCP server for interacting with Amazon ElastiCache Memcached
  through a secure and reliable connection\\n\\n## Features\\n\\n### Complete
  Memcached Protocol Support\\n\\n- Full support for all standard Memcached
  operations\\n- Secure communication with SSL/TLS encryption\\n- Automatic
  connection management and pooling\\n- Built-in retry mechanism for failed
  operations\\n- Readonly mode to prevent write operations\\n\\n### Readonly
  Mode\\n\\nThe server can be started in readonly mode, which prevents any write
  operations from being performed. This is useful for scenarios where you want
  to ensure that no data is modified, such as:\\n\\n- Read-only replicas\\n-
  Production environments where writes should be restricted\\n- Debugging and
  monitoring without risk of data modification\\n\\nWhen readonly mode is
  enabled, any attempt to perform a write operation (set, add, replace, delete,
  etc.) will return an error message.\\n\\n## Prerequisites\\n\\n1. Install `uv`
  from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Access to a Memcached server.\\n4.
  For instructions to connect to an Amazon ElastiCache Memcached cache [click
  here](https://github.com/awslabs/mcp/blob/main/src/memcached-mcp-server/ELAST\
  ICACHECONNECT.md)\\n\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.memcached-mcp-server&config=eyJjb21tYW5kIjoidXZ4IG\
  F3c2xhYnMubWVtY2FjaGVkLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0x\
  FVkVMIjoiRVJST1IiLCJNRU1DQUNIRURfSE9TVCI6InlvdXItbWVtY2FjaGVkLWhvc3QiLCJNRU1D\
  QUNIRURfUE9SVCI6IjExMjExIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D\
  %3D)\\n\\nHere are some ways you can work with MCP (e.g. for Amazon Q
  Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.memcached-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.memcached-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"MEMCACHED_HOST\\\":
  \\\"your-memcached-host\\\",\\n        \\\"MEMCACHED_PORT\\\":
  \\\"11211\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nTo run in
  readonly mode:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.memcached-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.memcached-mcp-server@latest\\\",
  \\\"--readonly\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"MEMCACHED_HOST\\\":
  \\\"your-memcached-host\\\",\\n        \\\"MEMCACHED_PORT\\\":
  \\\"11211\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/memcached-mcp-server
  .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.memcached-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"MEMCACHED_HOST=your-memcached-host\\\",\\n        \
  \\\"--env\\\",\\n        \\\"MEMCACHED_PORT=11211\\\",\\n        \\\"awslabs/\
  memcached-mcp-server:latest\\\"\\n      ],\\n      \\\"env\\\":
  {},\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\nTo run in readonly mode with
  Docker:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.memcached-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"MEMCACHED_HOST=your-memcached-host\\\",\\n        \
  \\\"--env\\\",\\n        \\\"MEMCACHED_PORT=11211\\\",\\n        \\\"awslabs/\
  memcached-mcp-server:latest\\\",\\n        \\\"--readonly\\\"\\n      ],\\n      \
  \\\"env\\\": {},\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n## Configuration\\n\\n### Basic Connection
  Settings\\n\\nConfigure the connection using these environment
  variables:\\n\\n```bash\\n# Basic
  settings\\nMEMCACHED_HOST=127.0.0.1          # Memcached server
  hostname\\nMEMCACHED_PORT=11211              # Memcached server
  port\\nMEMCACHED_TIMEOUT=1              # Operation timeout in
  seconds\\nMEMCACHED_CONNECT_TIMEOUT=5      # Connection timeout in
  seconds\\nMEMCACHED_RETRY_TIMEOUT=1        # Retry delay in
  seconds\\nMEMCACHED_MAX_RETRIES=3         # Maximum number of retry
  attempts\\n```\\n\\n### SSL/TLS Configuration\\n\\nEnable and configure
  SSL/TLS support with these variables:\\n\\n```bash\\n# SSL/TLS
  settings\\nMEMCACHED_USE_TLS=true                           # Enable
  SSL/TLS\\nMEMCACHED_TLS_CERT_PATH=/path/to/client-cert.pem # Client
  certificate\\nMEMCACHED_TLS_KEY_PATH=/path/to/client-key.pem   # Client
  private key\\nMEMCACHED_TLS_CA_CERT_PATH=/path/to/ca-cert.pem  # CA
  certificate\\nMEMCACHED_TLS_VERIFY=true                        # Enable cert
  verification\\n```\\n\\nThe server automatically handles:\\n- Connection
  establishment and management\\n- SSL/TLS encryption when enabled\\n- Automatic
  retrying of failed operations\\n- Timeout enforcement and error
  handling\\n\\n## Development\\n\\n### Running Tests\\n```bash\\nuv
  venv\\nsource .venv/bin/activate\\nuv sync\\nuv run --frozen
  pytest\\n```\\n\\n### Building Docker Image\\n```bash\\ndocker build -t
  awslabs/memcached-mcp-server .\\n```\\n\\n### Running Docker
  Container\\n```bash\\ndocker run -p 8080:8080 \\\\\\n  -e
  MEMCACHED_HOST=host.docker.internal \\\\\\n  -e MEMCACHED_PORT=11211
  \\\\\\n  awslabs/memcached-mcp-server\\n```\\n\\nTo run in readonly
  mode:\\n```bash\\ndocker run -p 8080:8080 \\\\\\n  -e
  MEMCACHED_HOST=host.docker.internal \\\\\\n  -e MEMCACHED_PORT=11211
  \\\\\\n  awslabs/memcached-mcp-server
  --readonly\\n```\\n\",\"isRecommended\":false,\"githubStars\":4319,\"download\
  Count\":4,\"createdAt\":\"2025-06-21T01:42:10.952678Z\",\"updatedAt\":\"2025-\
  07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T07:25:13.135174Z\"},{\
  \"mcpId\":\"github.com/Verodat/verodat-mcp-server\",\"githubUrl\":\"https://g\
  ithub.com/Verodat/verodat-mcp-server\",\"name\":\"Verodat\",\"author\":\"Vero\
  dat\",\"description\":\"Enables AI systems to interact with Verodat's data
  management platform, providing capabilities for dataset creation, querying,
  and AI-powered analysis across workspaces and
  accounts.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/verodata.png\",\"category\":\"databases\",\"tags\
  \":[\"data-management\",\"dataset-operations\",\"workspace-management\",\"dat\
  a-validation\",\"ai-integration\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"[![MseeP.ai Security Assessment
  Badge](https://mseep.net/pr/verodat-verodat-mcp-server-badge.png)](https://ms\
  eep.ai/app/verodat-verodat-mcp-server)\\n\\n# Verodat MCP Server
  \\n[![MCP](https://img.shields.io/badge/MCP-Server-blue.svg)](https://github.\
  com/modelcontextprotocol)\\n[![smithery
  badge](https://smithery.ai/badge/@Verodat/verodat-mcp-server)](https://smithe\
  ry.ai/server/@Verodat/verodat-mcp-server)\\n\\n## Overview\\nA Model Context
  Protocol (MCP) server implementation for [Verodat](https://verodat.io),
  enabling seamless integration of Verodat's data management capabilities with
  AI systems like Claude
  Desktop.\\n\\n![image](https://github.com/user-attachments/assets/ec26c3e1-07\
  7f-46bb-915d-690cfde0833e)\\n\\n# Verodat MCP Server\\n\\nThis repository
  contains a Model Context Protocol (MCP) server implementation for Verodat,
  allowing AI models to interact with Verodat's data management capabilities
  through well-defined tools.\\n\\n## Overview\\n\\nThe Verodat MCP Server
  provides a standardized way for AI models to access and manipulate data in
  Verodat. It implements the Model Context Protocol specification, providing
  tools for data consumption, design, and management.\\n\\n## Tool
  Categories\\n\\nThe server is organized into three main tool categories, each
  offering a progressive set of capabilities:\\n\\n### 1. Consume (8
  tools)\\n\\nThe base category focused on data retrieval operations:\\n\\n*
  `get-accounts`: Retrieve available accounts\\n* `get-workspaces`: List
  workspaces within an account\\n* `get-datasets`: List datasets in a
  workspace\\n* `get-dataset-output`: Retrieve actual data from a dataset\\n*
  `get-dataset-targetfields`: Retrieve field definitions for a dataset\\n*
  `get-queries`: Retrieve existing AI queries\\n* `get-ai-context`: Get
  workspace context and data structure\\n* `execute-ai-query`: Execute
  AI-powered queries on datasets\\n\\n### 2. Design (9 tools)\\n\\nIncludes all
  tools from Consume, plus:\\n\\n* `create-dataset`: Create a new dataset with
  defined schema\\n\\n### 3. Manage (10 tools)\\n\\nIncludes all tools from
  Design, plus:\\n\\n* `upload-dataset-rows`: Upload data rows to existing
  datasets\\n\\n## Prerequisites\\n\\n* Node.js (v18 or higher)\\n* Git\\n*
  Claude Desktop (for Claude integration)\\n* Verodat account and AI API
  key\\n\\n## Installation\\n\\n### Quick Start\\n\\n#### Installing via
  Smithery\\n\\nTo install Verodat MCP Server for Claude Desktop automatically
  via Smithery:\\n\\n```\\nnpx -y @smithery/cli install
  @Verodat/verodat-mcp-server --client claude\\n```\\n\\n#### Manual
  Installation\\n\\n1. Clone the repository:\\n\\n```\\ngit clone
  https://github.com/Verodat/verodat-mcp-server.git\\ncd
  verodat-mcp-server\\n```\\n\\n2. Install dependencies and
  build:\\n\\n```\\nnpm install\\nnpm run build\\n```\\n\\n3. Configure Claude
  Desktop:\\n   Create or modify the config file:\\n   * MacOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\n   *
  Windows: `%APPDATA%/Claude/claude_desktop_config.json`\\n   \\n   Add the
  configuration which is mensioned below in configuration:\\n\\n\\n### Getting
  Started with Verodat\\n\\n1. Sign up for a Verodat account at verodat.com\\n2.
  Generate an AI API key from your Verodat dashboard\\n3. Add the API key to
  your Claude Desktop configuration\\n\\n## Configuration\\n\\nThe server
  requires configuration for authentication and API endpoints. Create a
  configuration file for your AI model to
  use:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"verodat-consume\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"path/to/verodat-mcp-server/build/src/consume.js\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n        \\\"VERODAT_AI_API_KEY\\\":
  \\\"your-api-key\\\",\\n        \\\"VERODAT_API_BASE_URL\\\":
  \\\"https://verodat.io/api/v3\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n###
  Configuration Options\\n\\nYou can configure any of the three tool categories
  by specifying the appropriate JS file one at a time in claude:\\n\\n*
  **Consume only**: Use `consume.js` (8 tools for data retrieval)\\n* **Design
  capabilities**: Use `design.js` (9 tools, includes dataset creation)\\n*
  **Full management**: Use `manage.js` (10 tools, includes data
  upload)\\n\\nExample for configuring all three categories
  simultaneously:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"verodat-consume\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"path/to/verodat-mcp-server/build/src/consume.js\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n        \\\"VERODAT_AI_API_KEY\\\":
  \\\"your-api-key\\\",\\n        \\\"VERODAT_API_BASE_URL\\\":
  \\\"https://verodat.io/api/v3\\\"\\n      }\\n    },\\n    \\\"verodat-design\
  \\\": {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"path/to/verodat-mcp-server/build/src/design.js\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n        \\\"VERODAT_AI_API_KEY\\\":
  \\\"your-api-key\\\",\\n        \\\"VERODAT_API_BASE_URL\\\":
  \\\"https://verodat.io/api/v3\\\"\\n      }\\n    },\\n    \\\"verodat-manage\
  \\\": {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"path/to/verodat-mcp-server/build/src/manage.js\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n        \\\"VERODAT_AI_API_KEY\\\":
  \\\"your-api-key\\\",\\n        \\\"VERODAT_API_BASE_URL\\\":
  \\\"https://verodat.io/api/v3\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n###
  Environment Variables\\n\\n* `VERODAT_AI_API_KEY`: Your Verodat API key for
  authentication\\n* `VERODAT_API_BASE_URL`: The base URL for the Verodat API
  (defaults to \\\"https://verodat.io/api/v3\\\" if not specified)\\n\\n## Tool
  Usage Guide\\n\\n### Available Commands\\n\\nThe server provides the following
  MCP commands:\\n\\n```\\n// Account & Workspace
  Management\\nget-accounts        // List accessible
  accounts\\nget-workspaces      // List workspaces in an
  account\\nget-queries         // Retrieve existing AI queries\\n\\n// Dataset
  Operations\\ncreate-dataset      // Create a new
  dataset\\nget-datasets        // List datasets in a
  workspace\\nget-dataset-output  // Retrieve dataset
  records\\nget-dataset-targetfields // Retrieve dataset
  targetfields\\nupload-dataset-rows // Add new data rows to an existing
  dataset\\n\\n// AI Operations\\nget-ai-context      // Get workspace AI
  context\\nexecute-ai-query    // Run AI queries on datasets\\n```\\n\\n###
  Selecting the Right Tool Category\\n\\n* **For read-only operations**: Use the
  `consume.js` server configuration\\n* **For creating datasets**: Use the
  `design.js` server configuration\\n* **For uploading data**: Use the
  `manage.js` server configuration\\n\\n## Security Considerations\\n\\n*
  Authentication is required via API key\\n* Request validation ensures properly
  formatted data\\n\\n## Development\\n\\nThe codebase is written in TypeScript
  and organized into:\\n\\n* **Tool handlers**: Implementation of each tool's
  functionality\\n* **Transport layer**: Handles communication with the AI
  model\\n* **Validation**: Ensures proper data formats using Zod
  schemas\\n\\n### Debugging\\n\\nThe MCP server communicates over stdio, which
  can make debugging challenging. We provide an MCP Inspector tool to
  help:\\n\\n```\\nnpm run inspector\\n```\\n\\nThis will provide a URL to
  access debugging tools in your browser.\\n\\n## Contributing\\n\\nWe welcome
  contributions! Please feel free to submit a Pull Request.\\n\\n##
  License\\n\\n[LICENSE](LICENSE) file for details\\n\\n## Support\\n\\n-
  Documentation: [Verodat Docs](https://verodat.io/docs)\\n- Issues: [GitHub
  Issues](https://github.com/Verodat/verodat-mcp-server/issues)\\n- Community:
  [Verodat
  Community](https://github.com/orgs/Verodat/discussions)\\n\\n---\\n\",\"isRec\
  ommended\":true,\"githubStars\":2,\"downloadCount\":41,\"createdAt\":\"2025-0\
  2-18T06:27:44.307829Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastG\
  ithubSync\":\"2025-07-06T15:57:10.177128Z\"},{\"mcpId\":\"github.com/awslabs/\
  mcp/tree/main/src/code-doc-gen-mcp-server\",\"githubUrl\":\"https://github.co\
  m/awslabs/mcp/tree/main/src/code-doc-gen-mcp-server\",\"name\":\"Code
  Documentation
  Generator\",\"author\":\"awslabs\",\"description\":\"Automatically analyzes
  repository structure and generates comprehensive documentation for code
  projects using repomix, supporting multiple document types and project
  analysis.\",\"codiconIcon\":\"book\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"developer-tools\",\"tags\":[\
  \"documentation\",\"code-analysis\",\"project-structure\",\"automation\",\"re\
  pomix\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Labs Code
  Documentation Generation MCP Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/@awslabs/code-doc-gen-mcp-server)](https://s\
  mithery.ai/server/@awslabs/code-doc-gen-mcp-server)\\n\\nA Model Context
  Protocol (MCP) server that automatically analyzes repository structure and
  generates comprehensive documentation for code projects. This server uses
  [repomix](https://github.com/yamadashy/repomix/tree/main) to extract project
  structure and creates tailored documentation based on project type.\\n\\n##
  Architecture\\n\\n### How the Server Works\\n\\nThe code-doc-gen-mcp-server
  follows this workflow:\\n\\n1. **prepare_repository**:\\n   - Uses
  RepomixManager to analyze a project directory\\n   - Runs `repomix` to
  generate an XML representation of the repo\\n   - Extracts directory structure
  from this XML\\n   - Returns a ProjectAnalysis with the directory
  structure\\n\\n2. **create_context**:\\n   - Creates a DocumentationContext
  with the ProjectAnalysis\\n\\n3. **plan_documentation**:\\n   - Uses the
  directory structure from DocumentationContext\\n   - Creates a
  DocumentationPlan with document structure and sections\\n\\n4.
  **generate_documentation**:\\n   - Generates document templates based on the
  plan\\n\\n### Key Components\\n\\n1. **RepomixManager**: Manages the execution
  of repomix and parses its XML output to extract directory structure\\n2.
  **DocumentationContext**: Central state container that tracks project info and
  documentation progress\\n3. **ProjectAnalysis**: Data structure containing
  analyzed project metadata (languages, dependencies, etc.)\\n4.
  **DocumentationPlan**: Structured plan for document generation with section
  outlines\\n5. **DocumentGenerator**: Creates actual document templates based
  on the plan\\n\\n## Features\\n\\n- **Project Structure Analysis**: Uses
  repomix to analyze repository structure and extract key components\\n-
  **Content Organization**: Creates appropriately structured documentation based
  on project type\\n- **Multiple Document Types**: Supports README, API docs,
  backend docs, frontend docs, and more\\n- **Integration with Other MCP
  Servers**: Works with AWS Diagram MCP server\\n- **Custom Document
  Templates**: Templates for different document types with appropriate
  sections\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Install `repomix` using `pip
  install repomix>=0.2.6`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.code-doc-gen-mcp-server&config=eyJjb21tYW5kIjoidXZ\
  4IGF3c2xhYnMuY29kZS1kb2MtZ2VuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1Bf\
  TE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\
  \\nThis MCP server can be added to your AWS AI assistants via the appropriate
  MCP configuration file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.code-doc-gen-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.code-doc-gen-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n## Core
  Concepts\\n\\n### DocumentationContext\\n\\nThe `DocumentationContext` class
  maintains the state of the documentation process throughout its
  lifecycle:\\n\\n- `project_name`: Name of the project being documented\\n-
  `working_dir`: Working directory for the project (source code location)\\n-
  `repomix_path`: Path where documentation files will be generated\\n- `status`:
  Current status of the documentation process\\n- `current_step`: Current step
  in the documentation workflow\\n- `analysis_result`: Contains the
  ProjectAnalysis with project metadata\\n\\n### ProjectAnalysis\\n\\nThe
  `ProjectAnalysis` class contains detailed information about the
  project:\\n\\n- `project_type`: Type of project (e.g., \\\"Web
  Application\\\", \\\"CLI Tool\\\")\\n- `features`: Key capabilities and
  functions of the project\\n- `file_structure`: Project organization with
  directory structure\\n- `dependencies`: Project dependencies with versions\\n-
  `primary_languages`: Programming languages used in the project\\n- `apis`
  (optional): API endpoint details\\n- `backend` (optional): Backend
  implementation details\\n- `frontend` (optional): Frontend implementation
  details\\n\\n## Tools\\n\\n### prepare_repository\\n\\n```python\\nasync def
  prepare_repository(\\n    project_root: str = Field(..., description='Path to
  the code repository'),\\n    ctx: Context = None,\\n) ->
  ProjectAnalysis\\n```\\n\\nThis tool:\\n1. Extracts directory structure from
  the repository using repomix\\n2. Returns a ProjectAnalysis template for the
  MCP client to fill\\n3. Provides directory structure in
  file_structure[\\\"directory_structure\\\"]\\n\\nThe MCP client then:\\n1.
  Reviews the directory structure\\n2. Uses read_file to examine key files\\n3.
  Fills out the ProjectAnalysis fields\\n4. Sets has_infrastructure_as_code=True
  if CDK/Terraform code is detected\\n\\n###
  create_context\\n\\n```python\\nasync def create_context(\\n    project_root:
  str = Field(..., description='Path to the code repository'),\\n    analysis:
  ProjectAnalysis = Field(..., description='Completed
  ProjectAnalysis'),\\n    ctx: Context = None,\\n) ->
  DocumentationContext\\n```\\n\\nCreates a DocumentationContext from the
  completed ProjectAnalysis.\\n\\n### plan_documentation\\n\\n```python\\nasync
  def plan_documentation(\\n    doc_context: DocumentationContext,\\n    ctx:
  Context,\\n) -> DocumentationPlan\\n```\\n\\nCreates a documentation plan
  based on the project analysis, determining what document types are needed and
  creating appropriate document structures.\\n\\n###
  generate_documentation\\n\\n```python\\nasync def
  generate_documentation(\\n    plan: DocumentationPlan,\\n    doc_context:
  DocumentationContext,\\n    ctx: Context,\\n) ->
  List[GeneratedDocument]\\n```\\n\\nGenerates document structures with sections
  for the MCP client to fill with content.\\n\\n## Integration with Other MCP
  Servers\\n\\nThis MCP server is designed to work with:\\n\\n- **AWS Diagram
  MCP Server**: For generating architecture diagrams\\n- **AWS CDK MCP Server**:
  For documenting CDK infrastructure code\\n\\n## License\\n\\nThis project is
  licensed under the Apache License, Version 2.0. See the [LICENSE](LICENSE)
  file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":4382,\"downloadCount\":\
  416,\"createdAt\":\"2025-06-21T01:49:05.874596Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T09:22:22.4994Z\"},{\"mcpId\
  \":\"github.com/awslabs/mcp/tree/main/src/aws-serverless-mcp-server\",\"githu\
  bUrl\":\"https://github.com/awslabs/mcp/tree/main/src/aws-serverless-mcp-serv\
  er\",\"name\":\"AWS
  Serverless\",\"author\":\"awslabs\",\"description\":\"Provides AI-powered
  tools for building, deploying, and managing serverless applications on AWS,
  including SAM deployment, web application hosting, observability, and
  serverless architecture
  guidance.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\"\
  :[\"aws\",\"serverless\",\"lambda\",\"deployment\",\"infrastructure\"],\"requ\
  iresApiKey\":false,\"readmeContent\":\"# AWS Serverless MCP Server\\n\\n##
  Overview\\n\\nThe AWS Serverless Model Context Protocol (MCP) Server is an
  open-source tool that combines AI assistance with serverless expertise to
  streamline how developers build serverless applications. It provides
  contextual guidance specific to serverless development, helping developers
  make informed decisions about architecture, implementation, and deployment
  throughout the entire application development lifecycle. With AWS Serverless
  MCP, developers can build reliable, efficient, and production-ready serverless
  applications with confidence.\\n\\nKey benefits of the Serverless MCP Server
  include:\\n\\n- AI-powered serverless development: Provides rich contextual
  information to AI coding assistants to ensure your serverless application
  aligns with AWS best practices.\\n- Comprehensive tooling: Offers tools for
  initialization, deployment, monitoring, and troubleshooting of serverless
  applications.\\n- Architecture guidance: Helps evaluate design choices and
  select optimal serverless patterns based on application needs. Offers
  recommendations on event sources, function boundaries, and service
  integrations.\\n- Operational best practices: Ensures alignment with AWS
  architectural principles. Suggests effective use of AWS services for event
  processing, data persistence, and service communication, and guides
  implementation of security controls, performance tuning, and cost
  optimization.\\n- Security-first approach: Implements built-in guardrails with
  read-only defaults and controlled access to sensitive data.\\n\\n##
  Features\\nThe set of tools provided by the Serverless MCP server can be
  broken down into four categories:\\n\\n1. Serverless Application
  Lifecycle\\n    - Initialize, build, and deploy Serverless Application Model
  (SAM) applications with SAM CLI\\n    - Test Lambda functions locally and
  remotely\\n2. Web Application Deployment & Management\\n    - Deploy
  full-stack, frontend, and backend web applications onto AWS Serverless using
  Lambda Web Adapter\\n    - Update frontend assets and optionally invaliate
  CloudFront caches\\n    - Create custom domain names, including certificate
  and DNS setup\\n3. Observability\\n    - Retrieve and logs and metrics of
  serverless resources\\n4. Guidance, Templates, and Deployment Help\\n    -
  Provides guidance on AWS Lambda use-cases, selecting an IaC framework, and
  deployment process onto AWS Serverless\\n    - Provides sample SAM templates
  for different serverless application types from [Serverless
  Land](https://serverlessland.com/)\\n    - Provides schema types for different
  Lambda event sources and runtimes\\n    - Provides schema registry management
  and discovery for AWS EventBridge events\\n    - Enables type-safe Lambda
  function development with complete event schemas\\n\\n## Prerequisites\\n-
  Have an AWS account with [credentials
  configured](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-files.\
  html)\\n- Install uv from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n- Install
  Python 3.10 or newer using uv python install 3.10 (or a more recent
  version)\\n- Install [AWS SAM
  CLI](https://docs.aws.amazon.com/serverless-application-model/latest/develope\
  rguide/install-sam-cli.html)\\n- Install [AWS
  CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install\
  .html)\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.aws-serverless-mcp-server&config=eyJjb21tYW5kIjoid\
  XZ4IGF3c2xhYnMuYXdzLXNlcnZlcmxlc3MtbWNwLXNlcnZlckBsYXRlc3QgLS1hbGxvdy13cml0ZS\
  AtLWFsbG93LXNlbnNpdGl2ZS1kYXRhLWFjY2VzcyIsImVudiI6eyJBV1NfUFJPRklMRSI6InlvdXI\
  tYXdzLXByb2ZpbGUiLCJBV1NfUkVHSU9OIjoidXMtZWFzdC0xIn0sImRpc2FibGVkIjpmYWxzZSwi\
  YXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nYou can download the AWS Serverless MCP
  Server from GitHub. To get started using your favorite code assistant with MCP
  support, like Q Developer, Cursor or Cline.\\n\\nAdd the following code to
  your MCP client configuration. The Serverless MCP server uses the default AWS
  profile by default. Specify a value in AWS_PROFILE if you want to use a
  different profile. Similarly, adjust the AWS Region and log level values as
  needed.\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-serverless-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.aws-serverless-mcp-server@latest\\\",\\n        \\\"-\
  -allow-write\\\",\\n        \\\"--allow-sensitive-data-access\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n          \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n        },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n### Using
  temporary credentials\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-serverless-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"awslabs.aws-serverless-mcp-server@latest\\\"],\\n        \\\"env\\\":
  {\\n          \\\"AWS_ACCESS_KEY_ID\\\":
  \\\"your-temporary-access-key\\\",\\n          \\\"AWS_SECRET_ACCESS_KEY\\\":
  \\\"your-temporary-secret-key\\\",\\n          \\\"AWS_SESSION_TOKEN\\\":
  \\\"your-session-token\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Serverless MCP Server configuration options\\n### `--allow-write`\\nEnables
  write access mode, which allows mutating operations and creation of public
  resources. By default, the server runs in read-only mode, which restricts
  operations to only perform read actions, preventing any changes to AWS
  resources.\\n\\nMutating operations:\\n\\n- sam_deploy: Deploys a SAM
  application into AWS Cloud using CloudFormation\\n- deploy_webapp: Generates
  SAM template and deploys a web application into AWS CloudFormation. Creates
  public resources, including Route 53 DNS records, and CloudFront
  distributions\\n- configure_domain: Create custom domain using Route53 and ACM
  certificate and associates it with the project's CloudFront distribution\\n-
  update_frontend: Uploads frontend assets to S3 bucket\\n\\n\\n###
  `--allow-sensitive-data-access`\\nEnables access to sensitive data such as
  logs. By default, the server restricts access to sensitive
  data.\\n\\nOperations returning sensitive data:\\n\\n- sam_logs: Returns
  Lambda function logs and API Gateway logs\\n\\n## Local development\\n\\nTo
  make changes to this MCP locally and run it:\\n\\n1. Clone this
  repository:\\n   ```bash\\n   git clone
  https://github.com/awslabs/mcp.git\\n   cd
  mcp/src/aws-serverless-mcp-server\\n   ```\\n\\n2. Install
  dependencies:\\n   ```bash\\n   pip install -e .\\n   ```\\n\\n3. Configure
  AWS credentials:\\n   - Ensure you have AWS credentials configured in
  `~/.aws/credentials` or set the appropriate environment variables.\\n   - You
  can also set the AWS_PROFILE and AWS_REGION environment variables.\\n\\n4. Run
  the server:\\n   ```bash\\n   python -m
  awslabs.aws_serverless_mcp_server.server\\n   ```\\n\\n5. To use this MCP
  server with AI clients, add the following to your MCP
  configuration:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-serverless-mcp-server\\\":
  {\\n        \\\"command\\\":
  \\\"mcp/src/aws-serverless-mcp-server/bin/awslabs.aws-serverless-mcp-server/\\\
  \",\\n        \\\"env\\\": {\\n          \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Environment variables\\n\\nBy default, the default AWS profile is used.
  However, the server can be configured through environment variables in the MCP
  configuration:\\n\\n- `AWS_PROFILE`: AWS CLI profile to use for
  credentials\\n- `AWS_REGION`: AWS region to use (default: us-east-1)\\n-
  `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`: Explicit AWS credentials
  (alternative to AWS_PROFILE)\\n- `AWS_SESSION_TOKEN`: Session token for
  temporary credentials (used with AWS_ACCESS_KEY_ID and
  AWS_SECRET_ACCESS_KEY)\\n- `FASTMCP_LOG_LEVEL`: Logging level (ERROR, WARNING,
  INFO, DEBUG)\\n\\n## Available resources\\n\\nThe server provides the
  following resources:\\n\\n### Template resources\\n- `template://list`: List
  of available deployment templates.\\n- `template://{template_name}`: Details
  of a specific deployment template.\\n\\n### Deployment resources\\n-
  `deployment://list`: List of all AWS deployments managed by the MCP
  server.\\n- `deployment://{project_name}`: Details about a specific
  deployment.\\n\\n## Available tools\\n\\nThe server exposes deployment
  capabilities as tools:\\n\\n### sam_init\\n\\nInitializes a serverless
  application using AWS SAM (Serverless Application Model) CLI.\\nThis tool
  creates a new SAM project that consists of:\\n- An AWS SAM template to define
  your infrastructure code\\n- A folder structure that organizes your
  application\\n- Configuration for your AWS Lambda functions\\nYou should have
  AWS SAM CLI installed and configured in your
  environment.\\n\\n**Parameters:**\\n\\n- `project_name` (required): Name of
  the SAM project to create\\n- `runtime` (required): Runtime environment for
  the Lambda function\\n- `project_directory` (required): Absolute path to
  directory where the SAM application will be initialized\\n-
  `dependency_manager` (required): Dependency manager for the Lambda
  function\\n- `architecture` (default: x86_64): Architecture for the Lambda
  function\\n- `package_type` (default: Zip): Package type for the Lambda
  function\\n- `application_template` (default: hello-world): Template for the
  SAM application, e.g., hello-world, quick-start, etc.\\n-
  `application_insights`: Activate Amazon CloudWatch Application Insights
  monitoring\\n- `no_application_insights`: Deactivate Amazon CloudWatch
  Application Insights monitoring\\n- `base_image`: Base image for the
  application when package type is Image\\n- `config_env`: Environment name
  specifying default parameter values in the configuration file\\n-
  `config_file`: Absolute path to configuration file containing default
  parameter values\\n- `debug`: Turn on debug logging\\n- `extra_content`:
  Override custom parameters in the template's cookiecutter.json\\n- `location`:
  Template or application location (Git, HTTP/HTTPS, zip file path)\\n-
  `save_params`: Save parameters to the SAM configuration file\\n- `tracing`:
  Activate AWS X-Ray tracing for Lambda functions\\n- `no_tracing`: Deactivate
  AWS X-Ray tracing for Lambda functions\\n\\n### sam_build\\n\\nBuilds a
  serverless application using AWS SAM (Serverless Application Model)
  CLI.\\nThis command compiles your Lambda function code, creates deployment
  artifacts, and prepares your application for deployment.\\nBefore running this
  tool, the application should already be initialized with 'sam_init'
  tool.\\nYou should have AWS SAM CLI installed and configured in your
  environment.\\n\\n**Parameters:**\\n\\n- `project_directory` (required):
  Absolute path to directory containing the SAM project\\n- `template_file`:
  Absolute path to the template file (defaults to template.yaml)\\n- `base_dir`:
  Resolve relative paths to function's source code with respect to this
  folder\\n- `build_dir`: The absolute path to a directory where the built
  artifacts are stored\\n- `use_container` (default: false): Use a container to
  build the function\\n- `no_use_container` (default: false): Run build in local
  machine instead of Docker container\\n- `parallel` (default: true): Build your
  AWS SAM application in parallel\\n- `container_env_vars`: Environment
  variables to pass to the build container\\n- `container_env_var_file`:
  Absolute path to a JSON file containing container environment variables\\n-
  `build_image`: The URI of the container image that you want to pull for the
  build\\n- `debug` (default: false): Turn on debug logging\\n- `manifest`:
  Absolute path to a custom dependency manifest file (e.g., package.json)
  instead of the default\\n- `parameter_overrides`: CloudFormation parameter
  overrides encoded as key-value pairs\\n- `region`: AWS Region to deploy to
  (e.g., us-east-1)\\n- `save_params` (default: false): Save parameters to the
  SAM configuration file\\n- `profile`: AWS profile to use\\n\\n###
  sam_deploy\\n\\nDeploys a serverless application using AWS SAM (Serverless
  Application Model) CLI.\\nThis command deploys your application to AWS
  CloudFormation.\\nEvery time an appplication is deployed, it should be built
  with 'sam_build' tool before.\\nYou should have AWS SAM CLI installed and
  configured in your environment.\\n\\n**Parameters:**\\n\\n- `application_name`
  (required): Name of the application to be deployed\\n- `project_directory`
  (required): Absolute path to directory containing the SAM project (defaults to
  current directory)\\n- `template_file`: Absolute path to the template file
  (defaults to template.yaml)\\n- `s3_bucket`: S3 bucket to deploy artifacts
  to\\n- `s3_prefix`: S3 prefix for the artifacts\\n- `region`: AWS region to
  deploy to\\n- `profile`: AWS profile to use\\n- `parameter_overrides`:
  CloudFormation parameter overrides encoded as key-value pairs\\n-
  `capabilities` (default: [\\\"CAPABILITY_IAM\\\"]): IAM capabilities required
  for the deployment\\n- `config_file`: Absolute path to the SAM configuration
  file\\n- `config_env`: Environment name specifying default parameter values in
  the configuration file\\n- `metadata`: Metadata to include with the stack\\n-
  `tags`: Tags to apply to the stack\\n- `resolve_s3` (default: false):
  Automatically create an S3 bucket for deployment artifacts\\n- `debug`
  (default: false): Turn on debug logging\\n\\n### sam_logs\\n\\nFetches
  CloudWatch logs that are generated by resources in a SAM application. Use this
  tool\\nto help debug invocation failures and find root
  causes.\\n\\n**Parameters:**\\n\\n- `resource_name`: Name of the resource to
  fetch logs for (logical ID in CloudFormation/SAM template)\\n- `stack_name`:
  Name of the CloudFormation stack\\n- `start_time`: Fetch logs starting from
  this time (format: 5mins ago, tomorrow, or YYYY-MM-DD HH:MM:SS)\\n-
  `end_time`: Fetch logs up until this time (format: 5mins ago, tomorrow, or
  YYYY-MM-DD HH:MM:SS)\\n- `output` (default: text): Output format (text or
  json)\\n- `region`: AWS region to use (e.g., us-east-1)\\n- `profile`: AWS
  profile to use\\n- `cw_log_group`: CloudWatch Logs log groups to fetch logs
  from\\n- `config_env`: Environment name specifying default parameter values in
  the configuration file\\n- `config_file`: Absolute path to configuration file
  containing default parameter values\\n- `save_params` (default: false): Save
  parameters to the SAM configuration file\\n\\n###
  sam_local_invoke\\n\\nLocally invokes a Lambda function using AWS SAM
  CLI.\\nThis command runs your Lambda function locally in a Docker container
  that simulates the AWS Lambda environment.\\nYou can use this tool to test
  your Lambda functions before deploying them to AWS. Docker must be installed
  and running in your environment.\\n\\n**Parameters:**\\n\\n-
  `project_directory` (required): Absolute path to directory containing the SAM
  project\\n- `resource_name` (required): Name of the Lambda function to invoke
  locally\\n- `template_file`: Absolute path to the SAM template file (defaults
  to template.yaml)\\n- `event_file`: Absolute path to a JSON file containing
  event data\\n- `event_data`: JSON string containing event data (alternative to
  event_file)\\n- `environment_variables_file`: Absolute path to a JSON file
  containing environment variables to pass to the function\\n- `docker_network`:
  Docker network to run the Lambda function in\\n- `container_env_vars`:
  Environment variables to pass to the container\\n- `parameter`: Override
  parameters from the template file\\n- `log_file`: Absolute path to a file
  where the function logs will be written\\n- `layer_cache_basedir`: Directory
  where the layers will be cached\\n- `region`: AWS region to use (e.g.,
  us-east-1)\\n- `profile`: AWS profile to use\\n\\n###
  get_iac_guidance\\n\\nReturns guidance on selecting an infrastructure as code
  (IaC) platform to deploy Serverless application to AWS.\\nChoices include AWS
  SAM, CDK, and CloudFormation. Use this tool to decide which IaC tool to use
  for your Lambda deployments\\nbased on your specific use case and
  requirements.\\n\\n**Parameters:**\\n\\n- `iac_tool` (default:
  CloudFormation): IaC tool to use (CloudFormation, SAM, CDK, Terraform)\\n-
  `include_examples` (default: true): Whether to include examples\\n\\n###
  get_lambda_event_schemas\\n\\nReturns AWS Lambda event schemas for different
  event sources (e.g. s3, sns, apigw) and programming languages.  Each Lambda
  event source defines its own schema and language-specific types, which should
  be used in\\nthe Lambda function handler to correctly parse the event data. If
  you cannot find a schema for your event source, you can directly parse\\nthe
  event data as a JSON object. For EventBridge events,\\nyou must use the
  list_registries, search_schema, and describe_schema tools to access the schema
  registry directly, get schema definitions,\\nand generate code processing
  logic.\\n\\n**Parameters:**\\n\\n- `event_source` (required): Event source
  (e.g., api-gw, s3, sqs, sns, kinesis, eventbridge, dynamodb)\\n- `runtime`
  (required): Programming language for the schema references (e.g., go, nodejs,
  python, java)\\n\\n### get_lambda_guidance\\n\\nUse this tool to determine if
  AWS Lambda is suitable platform to deploy an application.\\nReturns a
  comprehensive guide on when to choose AWS Lambda as a deployment
  platform.\\nIt includes scenarios when to use and not use Lambda, advantages
  and disadvantages,\\ndecision criteria, and specific guidance for various use
  cases.\\n\\n**Parameters:**\\n\\n- `use_case` (required): Description of the
  use case\\n- `include_examples` (default: true): Whether to include
  examples\\n\\n### deploy_webapp\\n\\nDeploy web applications to AWS
  Serverless, including Lambda as compute, DynamoDB as databases, API GW, ACM
  Certificates, and Route 53 DNS records.\\nThis tool uses the Lambda Web
  Adapter framework so that applications can be written in a standard web
  framework like Express or Next.js can be easily\\ndeployed to Lambda. You do
  not need to use integrate the code with any adapter framework when using this
  tool.\\n\\n**Parameters:**\\n\\n- `deployment_type` (required): Type of
  deployment (backend, frontend, fullstack)\\n- `project_name` (required):
  Project name\\n- `project_root` (required): Absolute path to the project root
  directory\\n- `region`: AWS Region to deploy to (e.g., us-east-1)\\n-
  `backend_configuration`: Backend configuration\\n- `frontend_configuration`:
  Frontend configuration\\n\\n### configure_domain\\n\\nConfigures a custom
  domain for a deployed web application on AWS Serverless.\\nThis tool sets up
  Route 53 DNS records, ACM certificates, and CloudFront custom domain mappings
  as needed.\\nUse this tool after deploying your web application to associate
  it with your own domain name.\\n\\n**Parameters:**\\n\\n- `project_name`
  (required): Project name\\n- `domain_name` (required): Custom domain name\\n-
  `create_certificate` (default: true): Whether to create a ACM certificate\\n-
  `create_route53_record` (default: true): Whether to create a Route 53
  record\\n- `region`: AWS region to use (e.g., us-east-1)\\n\\n###
  webapp_deployment_help\\n\\nGet help information about using the deploy_webapp
  to perform web application deployments.\\nIf deployment_type is provided,
  returns help information for that deployment type.\\nOtherwise, returns a list
  of deployments and general help information.\\n\\n**Parameters:**\\n\\n-
  `deployment_type` (required): Type of deployment to get help information for
  (backend, frontend, fullstack)\\n\\n### get_metrics\\n\\nRetrieves CloudWatch
  metrics from a deployed web application. Use this tool get metrics\\non error
  rates, latency, concurrency, etc.\\n\\n**Parameters:**\\n\\n- `project_name`
  (required): Project name\\n- `start_time`: Start time for metrics (ISO
  format)\\n- `end_time`: End time for metrics (ISO format)\\n- `period`
  (default: 60): Period for metrics in seconds\\n- `resources` (default:
  [\\\"lambda\\\", \\\"apiGateway\\\"]): Resources to get metrics for\\n-
  `region`: AWS region to use (e.g., us-east-1)\\n- `stage` (default:
  \\\"prod\\\"): API Gateway stage\\n\\n### update_webapp_frontend\\n\\nUpdate
  the frontend assets of a deployed web application.\\nThis tool uploads new
  frontend assets to S3 and optionally invalidates the CloudFront
  cache.\\n\\n**Parameters:**\\n\\n- `project_name` (required): Project name\\n-
  `project_root` (required): Project root\\n- `built_assets_path` (required):
  Absolute path to pre-built frontend assets\\n- `invalidate_cache` (default:
  true): Whether to invalidate the CloudFront cache\\n- `region`: AWS region to
  use (e.g., us-east-1)\\n\\n### deploy_serverless_app_help\\n\\nProvides
  instructions on how to deploy a serverless application to AWS
  Lambda.\\nDeploying a Lambda application requires generating IaC templates,
  building the code, packaging\\nthe code, selecting a deployment tool, and
  executing the deployment commands. For deploying\\nweb applications
  specifically, use the deploy_webapp tool.\\n\\n**Parameters:**\\n\\n-
  `application_type` (required): Type of application to deploy (event_driven,
  backend, fullstack)\\n\\n### get_serverless_templates\\n\\nReturns example SAM
  templates from the Serverless Land GitHub repo. Use this tool to
  get\\nexamples for building serverless applications with AWS Lambda and best
  practices of serverless architecture.\\n\\n**Parameters:**\\n\\n-
  `template_type` (required): Template type (e.g., API, ETL, Web)\\n- `runtime`:
  Lambda runtime (e.g., nodejs22.x, python3.13)\\n\\n### Schema Tools\\n\\n####
  list_registries\\n\\nLists the registries in your
  account.\\n\\n**Parameters:**\\n\\n- `registry_name_prefix`: Limits results to
  registries starting with this prefix\\n- `scope`: Filter by registry scope
  (LOCAL or AWS)\\n- `limit`: Maximum number of results to return (1-100)\\n-
  `next_token`: Pagination token for subsequent requests\\n\\n####
  search_schema\\n\\nSearch for schemas in a registry using
  keywords.\\n\\n**Parameters:**\\n\\n- `keywords` (required): Keywords to
  search for (prefix with \\\"aws.\\\" for service events)\\n- `registry_name`
  (required): Registry to search in (use \\\"aws.events\\\" for AWS service
  events)\\n- `limit`: Maximum number of results (1-100)\\n- `next_token`:
  Pagination token\\n\\n#### describe_schema\\n\\nRetrieve the schema definition
  for the specified schema version.\\n\\n**Parameters:**\\n\\n- `registry_name`
  (required): Registry containing the schema (use \\\"aws.events\\\" for AWS
  service events)\\n- `schema_name` (required): Name of schema to retrieve
  (e.g., \\\"aws.s3@ObjectCreated\\\" for S3 events)\\n- `schema_version`:
  Version number of schema (latest by default)\\n\\n## Example usage\\n\\n###
  Creating a Lambda Function with SAM\\n\\nExample user prompt:\\n\\n```\\nI
  want to build a simple backend for a todo app using Python and deploy it to
  the cloud with AWS Serverless. Can you help me create a new project called
  my-todo-app. It should include basic functionality to add and list todos. Once
  it's set up, please build and deploy it with all the necessary permissions. I
  dont need to review the changeset before deployment.\\n```\\n\\nThis prompt
  would trigger the AI assistant to:\\n1. Initialize a new SAM project using a
  template.\\n2. Make modifications to code and infra for a todo app.\\n3. Build
  the SAM application\\n4. Deploy the application with CAPABILITY_IAM
  permissions\\n\\n### Deploying a Web Application\\n\\nExample user
  prompt:\\n\\n```\\nI have a full-stack web app built with Node.js called
  my-web-app, and I want to deploy it to the cloud using AWS. Everythings ready
   both frontend and backend. Can you set it up and deploy it with AWS Lambda
  so it's live and works smoothly?\\n```\\n\\nThis prompt would trigger the AI
  assistant to use the deploy_webapp to deploy the full stack application with
  the specified configuration.\\n\\n### Working with EventBridge
  Schemas\\n\\nExample user prompt:\\n\\n```\\nI need to create a Lambda
  function that processes autoscaling events. Can you help me find the right
  event schema and implement type-safe event handling?\\n```\\n\\nThis prompt
  would trigger the AI assistant to:\\n1. Search for autoscaling event schemas
  in aws.events registry using search_schema\\n2. Retrieve complete schema
  definition using describe_schema\\n3. Generate type-safe handler code based on
  schema structure\\n4. Implement validation for required fields\\n\\n##
  Security features\\n1. **AWS Authentication**: Uses AWS credentials from the
  environment for secure authentication\\n2. **TLS Verification**: Enforces TLS
  verification for all AWS API calls\\n3. **Resource Tagging**: Tags all created
  resources for traceability\\n4. **Least Privilege**: Uses IAM roles with
  appropriate permissions for CloudFormation templates\\n\\n## Security
  considerations\\n\\n### Production use cases\\nThe AWS Serverless MCP Server
  can be used for production environments with proper security controls in
  place. For production use cases, consider the following:\\n\\n* **Read-Only
  Mode by Default**: The server runs in read-only mode by default, which is
  safer for production environments. Only explicitly enable write access when
  necessary.\\n* **Disable auto-approve**: Require the user to approve each time
  the AI assitant executes a tool\\n\\n### Role scoping recommendations\\nTo
  follow security best practices:\\n\\n1. **Create dedicated IAM roles** to be
  used by the AWS Serverless MCP Server with the principle of least
  privilege\\n2. **Use separate roles** for read-only and write operations\\n3.
  **Implement resource tagging** to limit actions to resources created by the
  server\\n4. **Enable AWS CloudTrail** to audit all API calls made by the
  server\\n5. **Regularly review** the permissions granted to the server's IAM
  role\\n6. **Use IAM Access Analyzer** to identify unused permissions that can
  be removed\\n\\n### Sensitive information handling\\n**IMPORTANT**: Do not
  pass secrets or sensitive information via allowed input mechanisms:\\n\\n- Do
  not include secrets or credentials in CloudFormation templates\\n- Do not pass
  sensitive information directly in the prompt to the model\\n\\n## Links\\n\\n-
  [Homepage](https://awslabs.github.io/mcp/)\\n-
  [Documentation](https://awslabs.github.io/mcp/servers/aws-serverless-mcp-serv\
  er/)\\n- [Source Code](https://github.com/awslabs/mcp.git)\\n- [Bug
  Tracker](https://github.com/awslabs/mcp/issues)\\n-
  [Changelog](https://github.com/awslabs/mcp/blob/main/src/aws-serverless-mcp-s\
  erver/CHANGELOG.md)\\n\\n##
  License\\n\\nApache-2.0\\n\",\"isRecommended\":false,\"githubStars\":4385,\"d\
  ownloadCount\":263,\"createdAt\":\"2025-06-21T01:52:30.830613Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T18:21:25.6\
  69528Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/elasticache-mcp-s\
  erver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/elastica\
  che-mcp-server\",\"name\":\"ElastiCache\",\"author\":\"awslabs\",\"description\
  \":\"Manages AWS ElastiCache resources including serverless caches,
  replication groups, and cache clusters with comprehensive monitoring and cost
  analysis
  capabilities.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\
  \":[\"aws\",\"caching\",\"redis\",\"memcached\",\"cloud-infrastructure\"],\"r\
  equiresApiKey\":false,\"readmeContent\":\"# AWS ElastiCache MCP
  Server\\n\\nThe official MCP Server for interacting with AWS ElastiCache
  control plane. In order to interact with your data in ElastiCache Serverless
  caches and self-designed clusters use the [Valkey MCP
  Server](https://github.com/awslabs/mcp/blob/main/src/valkey-mcp-server) or the
  [Memcached MCP
  Server](https://github.com/awslabs/mcp/blob/main/src/memcached-mcp-server).\\n\
  \\n## Available MCP Tools\\n\\n### Serverless Cache Operations\\n-
  `create-serverless-cache` - Create a new ElastiCache serverless cache\\n-
  `delete-serverless-cache` - Delete a serverless cache\\n-
  `describe-serverless-caches` - Get information about serverless caches\\n-
  `modify-serverless-cache` - Modify settings of a serverless cache\\n-
  `connect-jump-host-serverless-cache` - Configure an EC2 instance as a jump
  host for serverless cache access\\n- `create-jump-host-serverless-cache` -
  Create an EC2 jump host to access a serverless cache via SSH tunnel\\n-
  `get-ssh-tunnel-command-serverless-cache` - Generate SSH tunnel command for
  serverless cache access\\n\\n### Replication Group Operations\\n-
  `create-replication-group` - Create an Amazon ElastiCache replication group
  with specified configuration\\n- `delete-replication-group` - Delete an
  ElastiCache replication group with optional final snapshot\\n-
  `describe-replication-groups` - Get detailed information about one or more
  replication groups\\n- `modify-replication-group` - Modify settings of an
  existing replication group\\n- `modify-replication-group-shard-configuration`
  - Modify the shard configuration of a replication group\\n- `test-migration` -
  Test migration from a Redis instance to an ElastiCache replication group\\n-
  `start-migration` - Start migration from a Redis instance to an ElastiCache
  replication group\\n- `complete-migration` - Complete migration from a Redis
  instance to an ElastiCache replication group\\n-
  `connect-jump-host-replication-group` - Configure an EC2 instance as a jump
  host for replication group access\\n- `create-jump-host-replication-group` -
  Create an EC2 jump host to access a replication group via SSH tunnel\\n-
  `get-ssh-tunnel-command-replication-group` - Generate SSH tunnel command for
  replication group access\\n\\n### Cache Cluster Operations\\n-
  `create-cache-cluster` - Create a new ElastiCache cache cluster\\n-
  `delete-cache-cluster` - Delete a cache cluster with optional final
  snapshot\\n- `describe-cache-clusters` - Get detailed information about one or
  more cache clusters\\n- `modify-cache-cluster` - Modify settings of an
  existing cache cluster\\n- `connect-jump-host-cache-cluster` - Configure an
  EC2 instance as a jump host for cluster access\\n-
  `create-jump-host-cache-cluster` - Create an EC2 jump host to access a cluster
  via SSH tunnel\\n- `get-ssh-tunnel-command-cache-cluster` - Generate SSH
  tunnel command for cluster access\\n\\n### CloudWatch Operations\\n-
  `get-metric-statistics` - Get CloudWatch metric statistics for ElastiCache
  resources with customizable time periods and dimensions\\n\\n### CloudWatch
  Logs Operations\\n- `describe-log-groups` - List and describe CloudWatch Logs
  log groups\\n- `create-log-group` - Create a new CloudWatch Logs log group\\n-
  `describe-log-streams` - List and describe log streams in a log group\\n-
  `filter-log-events` - Search and filter log events across log streams\\n-
  `get-log-events` - Retrieve log events from a specific log stream\\n\\n###
  Firehose Operations\\n- `list-delivery-streams` - List your Kinesis Data
  Firehose delivery streams\\n\\n### Cost Explorer Operations\\n-
  `get-cost-and-usage` - Get cost and usage data for ElastiCache resources with
  customizable time periods and granularity\\n\\n### Misc Operations\\n-
  `describe-cache-engine-versions` - List available cache engines and their
  versions\\n- `describe-engine-default-parameters` - Get default parameters for
  a cache engine family\\n- `describe-events` - Get events related to clusters,
  security groups, and parameters\\n- `describe-service-updates` - Get
  information about available service updates\\n- `batch-apply-update-action` -
  Apply service updates to resources\\n- `batch-stop-update-action` - Stop
  service updates on resources\\n\\n## Instructions\\n\\nThe official MCP Server
  for interacting with AWS ElastiCache provides a comprehensive set of tools for
  managing ElastiCache resources. Each tool maps directly to ElastiCache API
  operations and supports all relevant parameters.\\n\\nTo use these tools,
  ensure you have proper AWS credentials configured with appropriate permissions
  for ElastiCache operations. The server will automatically use credentials from
  environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY,
  AWS_SESSION_TOKEN) or other standard AWS credential sources.\\n\\nAll tools
  support an optional `region_name` parameter to specify which AWS region to
  operate in. If not provided, it will use the AWS_REGION environment variable
  or default to 'us-west-2'.\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS services\\n   - Consider setting up Read-only permission if you don't
  want the LLM to modify any resources\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.elasticache-mcp-server&config=eyJjb21tYW5kIjoidXZ4\
  IGF3c2xhYnMuZWxhc3RpY2FjaGUtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJT\
  EUiOiJkZWZhdWx0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIj\
  oiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nAdd the MCP
  to your favorite agentic tools. (e.g. for Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.elasticache-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.elasticache-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"default\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\nIf you would
  like to prevent the MCP from taking any mutating actions (i.e.
  Create/Update/Delete Resource), you can specify the readonly flag as
  demonstrated below:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.elasticache-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.elasticache-mcp-server@latest\\\",\\n        \\\"--re\
  adonly\\\"\\n      ],\\n      \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"default\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/elasticache-mcp-server
  .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.elasticache-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"awslabs/elasticache-mcp-server:latest\\\",\\n        \\\"--readonly\\\" //
  Optional paramter if you would like to restrict the MCP to only read
  actions\\n      ],\\n      \\\"env\\\": {},\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Configuration\\n\\n### AWS Configuration\\n\\nConfigure AWS credentials and
  region:\\n\\n```bash\\n# AWS settings\\nAWS_PROFILE=default              # AWS
  credential profile to use\\nAWS_REGION=us-east-1            # AWS region to
  connect to\\n```\\n\\n### Connection Settings\\n\\nConfigure connection
  behavior and timeouts:\\n\\n```bash\\n# Connection
  settings\\nELASTICACHE_MAX_RETRIES=3        # Maximum number of retry attempts
  for AWS API calls\\nELASTICACHE_RETRY_MODE=standard  # AWS SDK retry mode for
  API calls\\nELASTICACHE_CONNECT_TIMEOUT=5    # Connection timeout in
  seconds\\nELASTICACHE_READ_TIMEOUT=10      # Read timeout in seconds\\n\\n#
  Cost Explorer settings\\nCOST_EXPLORER_MAX_RETRIES=3      # Maximum number of
  retry attempts for Cost Explorer API calls\\nCOST_EXPLORER_RETRY_MODE=standard
  # AWS SDK retry mode for Cost Explorer API
  calls\\nCOST_EXPLORER_CONNECT_TIMEOUT=5   # Connection timeout in seconds for
  Cost Explorer\\nCOST_EXPLORER_READ_TIMEOUT=10     # Read timeout in seconds
  for Cost Explorer\\n\\n# CloudWatch
  settings\\nCLOUDWATCH_MAX_RETRIES=3         # Maximum number of retry attempts
  for CloudWatch API calls\\nCLOUDWATCH_RETRY_MODE=standard    # AWS SDK retry
  mode for CloudWatch API calls\\nCLOUDWATCH_CONNECT_TIMEOUT=5      # Connection
  timeout in seconds for CloudWatch\\nCLOUDWATCH_READ_TIMEOUT=10        # Read
  timeout in seconds for CloudWatch\\n\\n# CloudWatch Logs
  settings\\nCLOUDWATCH_LOGS_MAX_RETRIES=3     # Maximum number of retry
  attempts for CloudWatch Logs API calls\\nCLOUDWATCH_LOGS_RETRY_MODE=standard #
  AWS SDK retry mode for CloudWatch Logs API
  calls\\nCLOUDWATCH_LOGS_CONNECT_TIMEOUT=5  # Connection timeout in seconds for
  CloudWatch Logs\\nCLOUDWATCH_LOGS_READ_TIMEOUT=10    # Read timeout in seconds
  for CloudWatch Logs\\n\\n# Firehose
  settings\\nFIREHOSE_MAX_RETRIES=3            # Maximum number of retry
  attempts for Firehose API calls\\nFIREHOSE_RETRY_MODE=standard      # AWS SDK
  retry mode for Firehose API calls\\nFIREHOSE_CONNECT_TIMEOUT=5        #
  Connection timeout in seconds for
  Firehose\\nFIREHOSE_READ_TIMEOUT=10          # Read timeout in seconds for
  Firehose\\n```\\n\\nThe server automatically handles:\\n- AWS authentication
  and credential management\\n- Connection establishment and management\\n-
  Automatic retrying of failed operations\\n- Timeout enforcement and error
  handling\\n\\n## Development\\n\\n### Running Tests\\n```bash\\nuv
  venv\\nsource .venv/bin/activate\\nuv sync\\nuv run --frozen
  pytest\\n```\\n\\n### Building Docker Image\\n```bash\\ndocker build -t
  awslabs/elasticache-mcp-server .\\n```\\n\\n### Running Docker
  Container\\n```bash\\ndocker run -p 8080:8080 \\\\\\n  -e AWS_PROFILE=default
  \\\\\\n  -e AWS_REGION=us-west-2
  \\\\\\n  awslabs/elasticache-mcp-server\\n\",\"isRecommended\":false,\"github\
  Stars\":4254,\"downloadCount\":52,\"createdAt\":\"2025-06-21T02:01:46.210897Z\
  \",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06\
  -29T04:09:30.402382Z\"},{\"mcpId\":\"github.com/snaggle-ai/openapi-mcp-server\
  \",\"githubUrl\":\"https://github.com/snaggle-ai/openapi-mcp-server\",\"name\
  \":\"OpenAPI Proxy\",\"author\":\"snaggle-ai\",\"description\":\"Creates a
  proxy server that converts any OpenAPI v3.1 compliant API into
  Claude-compatible tools, enabling natural language interaction with APIs
  including file upload
  support.\",\"codiconIcon\":\"link\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/openapi.png\",\"category\":\"developer-tools\",\"tags\
  \":[\"openapi\",\"api-integration\",\"proxy\",\"file-upload\",\"documentation\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# OpenAPI MCP
  Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/@janwilmake/openapi-mcp-server)](https://smi\
  thery.ai/server/@janwilmake/openapi-mcp-server)
  [![janwilmake/openapi-mcp-server
  context](https://badge.forgithub.com/janwilmake/openapi-mcp-server?excludePat\
  hPatterns=README-v1.md&excludePathPatterns=*.yaml)](https://uithub.com/janwil\
  make/openapi-mcp-server?excludePathPatterns=README-v1.md&excludePathPatterns=\
  *.yaml)\\n\\nA Model Context Protocol (MCP) server for Claude/Cursor that
  enables searching and exploring OpenAPI specifications through
  oapis.org.\\n\\n- Demo:
  https://x.com/janwilmake/status/1903497808134496583\\n- HN Thread:
  https://news.ycombinator.com/item?id=43447278\\n- OpenAPISearch:
  https://github.com/janwilmake/openapisearch\\n- OAPIS:
  https://github.com/janwilmake/oapis\\n\\nThe MCP works by applying a 3 step
  process :\\n\\n1. It figures out the openapi identifier you need\\n2. It
  requests a summary of that in simple language\\n3. It determines which
  endpoints you need, and checks out how exactly they work (again, in simple
  language)\\n\\n> [!IMPORTANT]\\n> OpenAPI MCP has found a [new
  owner](https://github.com/janwilmake) and has been migrated from v1.2 to v2,
  which works different to the previous version. You can still access any
  version prior to v2.0.0 and their README is [here](README-v1.md)\\n>\\n>
  OpenAPI MCP v2 is a Work In Progress and focuses on exploration and providing
  context about APIs. It **does not** allow executing the endpoints as tools
  directly, as authentication isn't a solved problem with MCP yet. However, it's
  great for codegen!\\n>\\n> Expect bugs. Open To Contributers,
  [DM](https://x.com/janwilmake)\\n\\n## Features\\n\\n- Get an overview of any
  OpenAPI specification\\n- Retrieve details about specific API operations\\n-
  Support for both JSON and YAML formats\\n- Tested with Claude Desktop and
  Cursor\\n\\n| Summary | Prompt it |\\n|---------|-----------|\\n| Basic
  understanding of the OpenAPI MCP Server |
  [![](https://b.lmpify.com/overview)](https://lmpify.com?q=https%3A%2F%2Fuuith\
  ub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3DREADM\
  E.md%26pathPatterns%3Dopenapi-mcp.drawio.png%0A%0ACan%20you%20explain%20what%\
  20OpenAPI%20MCP%20Server%20does%20and%20how%20I%20can%20use%20it%20with%20Cla\
  ude%20Desktop%3F) |\\n| Core implementation details of the MCP server |
  [![](https://b.lmpify.com/implementation)](https://lmpify.com?q=https%3A%2F%2\
  Fuuithub.com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3\
  Dindex.js%26pathPatterns%3Dpackage.json%0A%0AHow%20does%20the%20OpenAPI%20MCP\
  %20Server%20handle%20API%20requests%3F%20Can%20you%20explain%20the%20tool%20h\
  andlers%3F) |\\n| How to extend or contribute to the project |
  [![](https://b.lmpify.com/extend)](https://lmpify.com?q=https%3A%2F%2Fuuithub\
  .com%2Fjanwilmake%2Fopenapi-mcp-server%2Ftree%2Fmain%3FpathPatterns%3Dindex.j\
  s%26pathPatterns%3Dpackage.json%26pathPatterns%3DREADME.md%0A%0AI'd%20like%20\
  to%20add%20support%20for%20a%20new%20feature%20to%20the%20OpenAPI%20MCP%20Ser\
  ver.%20Where%20should%20I%20start%3F) |\\n\\n## Installation\\n\\n###
  Installing via Smithery\\n\\nTo install openapi-mcp-server for Claude Desktop
  automatically via
  [Smithery](https://smithery.ai/server/@janwilmake/openapi-mcp-server):\\n\\n`\
  ``bash\\nnpx -y @smithery/cli install @janwilmake/openapi-mcp-server --client
  claude\\n```\\n\\n### Installing via npx\\n\\nRun and follow
  instructions:\\n\\n```bash\\nnpx openapi-mcp-server@latest init\\n```\\n\\n##
  Usage in Claude\\n\\nOnce installed, you can ask Claude to:\\n\\n- \\\"Find
  information about the Stripe API\\\"\\n- \\\"Explain how to use the GitHub
  API's repository endpoints\\\"\\n\\nClaude will use the MCP server to:\\n\\n1.
  First get an overview of the requested API\\n2. Then retrieve specific
  operation details as needed\\n\\n## Requirements\\n\\n- Node.js >= 16.17.0\\n-
  Claude Desktop, Cursor, or any other MCP client.\\n\\n##
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":706,\"downloadC\
  ount\":789,\"createdAt\":\"2025-02-17T22:45:43.055912Z\",\"updatedAt\":\"2025\
  -07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T05:57:20.997222Z\"}\
  ,{\"mcpId\":\"github.com/supabase-community/mcp-supabase/tree/HEAD/packages/m\
  cp-server-postgrest\",\"githubUrl\":\"https://github.com/supabase-community/m\
  cp-supabase/tree/HEAD/packages/mcp-server-postgrest\",\"name\":\"Postgrest\",\
  \"author\":\"supabase-community\",\"description\":\"Enables database
  operations on PostgreSQL through PostgREST, supporting SQL-to-REST conversion
  and direct API requests for querying and modifying
  data.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/postgrest.png\",\"category\":\"databases\",\"tags\":[\
  \"postgresql\",\"postgrest\",\"database-api\",\"sql\",\"supabase\"],\"require\
  sApiKey\":false,\"readmeContent\":\"# @supabase/mcp-server-postgrest\\n\\nThis
  is an MCP server for [PostgREST](https://postgrest.org). It allows LLMs to
  perform CRUD operations on your app via REST API.\\n\\nThis server works with
  Supabase projects (which run PostgREST) and any standalone PostgREST
  server.\\n\\n## Tools\\n\\nThe following tools are available:\\n\\n###
  `postgrestRequest`\\n\\nPerforms an HTTP request to a [configured](#usage)
  PostgREST server. It accepts the following arguments:\\n\\n- `method`: The
  HTTP method to use (eg. `GET`, `POST`, `PATCH`, `DELETE`)\\n- `path`: The path
  to query (eg. `/todos?id=eq.1`)\\n- `body`: The request body (for `POST` and
  `PATCH` requests)\\n\\nIt returns the JSON response from the PostgREST server,
  including selected rows for `GET` requests and updated rows for `POST` and
  `PATCH` requests.\\n\\n### `sqlToRest`\\n\\nConverts a SQL query to the
  equivalent PostgREST syntax (as method and path). Useful for complex queries
  that LLMs would otherwise struggle to convert to valid PostgREST
  syntax.\\n\\nNote that PostgREST only supports a subset of SQL, so not all
  queries will convert. See
  [`sql-to-rest`](https://github.com/supabase-community/sql-to-rest) for more
  details.\\n\\nIt accepts the following arguments:\\n\\n- `sql`: The SQL query
  to convert.\\n\\nIt returns an object containing `method` and `path`
  properties for the request. LLMs can then use the `postgrestRequest` tool to
  execute the request.\\n\\n## Usage\\n\\n### With Claude Desktop\\n\\n[Claude
  Desktop](https://claude.ai/download) is a popular LLM client that supports the
  Model Context Protocol. You can connect your PostgREST server to Claude
  Desktop to query your database via natural language commands.\\n\\nYou can add
  MCP servers to Claude Desktop via its config file at:\\n\\n- macOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\n\\n-
  Windows:`%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\\n\\nTo add your
  Supabase project _(or any PostgREST server)_ to Claude Desktop, add the
  following configuration to the `mcpServers` object in the config
  file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"todos\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@supabase/mcp-server-postgrest@latest\\\
  \",\\n        \\\"--apiUrl\\\",\\n        \\\"https://your-project-ref.supaba\
  se.co/rest/v1\\\",\\n        \\\"--apiKey\\\",\\n        \\\"your-anon-key\\\
  \",\\n        \\\"--schema\\\",\\n        \\\"public\\\"\\n      ]\\n    }\\n  \
  }\\n}\\n```\\n\\n#### Configuration\\n\\n- `apiUrl`: The base URL of your
  PostgREST endpoint\\n\\n- `apiKey`: Your API key for authentication
  _(optional)_\\n\\n- `schema`: The Postgres schema to serve the API from (eg.
  `public`). Note any non-public schemas must be manually exposed from
  PostgREST.\\n\\n### Programmatically (custom MCP client)\\n\\nIf you're
  building your own MCP client, you can connect to a PostgREST server
  programmatically using your preferred transport. The [MCP
  SDK](https://github.com/modelcontextprotocol/typescript-sdk) offers built-in
  [stdio](https://modelcontextprotocol.io/docs/concepts/transports#standard-inp\
  ut-output-stdio) and
  [SSE](https://modelcontextprotocol.io/docs/concepts/transports#server-sent-ev\
  ents-sse) transports. We also offer a
  [`StreamTransport`](../mcp-utils#streamtransport) if you wish to directly
  connect to MCP servers in-memory or by piping over your own stream-based
  transport.\\n\\n#### Installation\\n\\n```bash\\nnpm i
  @supabase/mcp-server-postgrest\\n```\\n\\n```bash\\nyarn add
  @supabase/mcp-server-postgrest\\n```\\n\\n```bash\\npnpm add
  @supabase/mcp-server-postgrest\\n```\\n\\n#### Example\\n\\nThe following
  example uses the [`StreamTransport`](../mcp-utils#streamtransport) to connect
  directly between an MCP client and server.\\n\\n```ts\\nimport { Client } from
  '@modelcontextprotocol/sdk/client/index.js';\\nimport { StreamTransport } from
  '@supabase/mcp-utils';\\nimport { createPostgrestMcpServer } from
  '@supabase/mcp-server-postgrest';\\n\\n// Create a stream transport for both
  client and server\\nconst clientTransport = new StreamTransport();\\nconst
  serverTransport = new StreamTransport();\\n\\n// Connect the streams
  together\\nclientTransport.readable.pipeTo(serverTransport.writable);\\nserve\
  rTransport.readable.pipeTo(clientTransport.writable);\\n\\nconst client = new
  Client(\\n  {\\n    name: 'MyClient',\\n    version:
  '0.1.0',\\n  },\\n  {\\n    capabilities: {},\\n  }\\n);\\n\\nconst
  supabaseUrl = 'https://your-project-ref.supabase.co'; //
  http://127.0.0.1:54321 for local\\nconst apiKey = 'your-anon-key'; // or
  service role, or user JWT\\nconst schema = 'public'; // or any other exposed
  schema\\n\\nconst server = createPostgrestMcpServer({\\n  apiUrl:
  `${supabaseUrl}/rest/v1`,\\n  apiKey,\\n  schema,\\n});\\n\\n// Connect the
  client and server to their respective transports\\nawait
  server.connect(serverTransport);\\nawait
  client.connect(clientTransport);\\n\\n// Call tools, etc\\nconst output =
  await client.callTool({\\n  name: 'postgrestRequest',\\n  arguments:
  {\\n    method: 'GET',\\n    path:
  '/todos',\\n  },\\n});\\n```\\n\",\"isRecommended\":true,\"githubStars\":1728,\
  \"downloadCount\":1218,\"createdAt\":\"2025-02-17T22:27:20.529942Z\",\"update\
  dAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T15:07:4\
  5.209408Z\"},{\"mcpId\":\"github.com/pashpashpash/mcp-webresearch\",\"githubU\
  rl\":\"https://github.com/pashpashpash/mcp-webresearch\",\"name\":\"Web
  Research\",\"author\":\"pashpashpash\",\"description\":\"Enables comprehensive
  web research with Google search integration, webpage content extraction,
  session tracking, and screenshot capabilities for real-time information
  gathering.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/web-research.png\",\"category\":\"search\",\"tags\
  \":[\"web-research\",\"google-search\",\"content-extraction\",\"screenshots\",\
  \"session-tracking\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP Web
  Research Server\\n\\nA Model Context Protocol (MCP) server for web research.
  \\nBring real-time info into Claude and easily research any topic.\\n\\n##
  Features\\n- Google search integration\\n- Webpage content extraction\\n-
  Research session tracking (list of visited pages, search queries, etc.)\\n-
  Screenshot capture\\n\\n## Prerequisites\\n- [Node.js](https://nodejs.org/) >=
  18\\n- [Claude Desktop app](https://claude.ai/download)\\n-
  [pnpm](https://pnpm.io/installation) (recommended) or npm\\n\\n##
  Installation\\n\\n1. **Clone the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-webresearch.git\\n   cd
  mcp-webresearch\\n   ```\\n\\n2. **Install
  Dependencies**:\\n   ```bash\\n   pnpm install\\n   ```\\n\\n3. **Build the
  Project**:\\n   ```bash\\n   pnpm build\\n   ```\\n\\n4. **Configure Claude
  Desktop**:\\n\\nAdd this entry to your `claude_desktop_config.json` (on Mac,
  found at `~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json`):\\n```json\\n{\\n  \\\"mcpServers\
  \\\": {\\n    \\\"webresearch\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/mcp-webresearch/dist/index.js\\\"]\\n    }\\n  }\\n}\\n```\\nNot\
  e: Replace \\\"path/to/mcp-webresearch\\\" with the actual path to your cloned
  repository.\\n\\n## Usage\\n\\nSimply start a chat with Claude and send a
  prompt that would benefit from web research. If you'd like a prebuilt prompt
  customized for deeper web research, you can use the `agentic-research` prompt
  that we provide through this package. Access that prompt in Claude Desktop by
  clicking the Paperclip icon in the chat input and then selecting `Choose an
  integration`  `webresearch`  `agentic-research`.\\n\\n<img
  src=\\\"https://i.ibb.co/N6Y3C0q/Screenshot-2024-12-05-at-11-01-27-PM.png\\\"
  alt=\\\"Example screenshot of web research\\\" width=\\\"400\\\"/>\\n\\n###
  Tools\\n\\n1. `search_google`\\n   - Performs Google searches and extracts
  results\\n   - Arguments: `{ query: string }`\\n\\n2. `visit_page`\\n   -
  Visits a webpage and extracts its content\\n   - Arguments: `{ url: string,
  takeScreenshot?: boolean }`\\n\\n3. `take_screenshot`\\n   - Takes a
  screenshot of the current page\\n   - No arguments required\\n\\n###
  Prompts\\n\\n#### `agentic-research`\\nA guided research prompt that helps
  Claude conduct thorough web research. The prompt instructs Claude to:\\n-
  Start with broad searches to understand the topic landscape\\n- Prioritize
  high-quality, authoritative sources\\n- Iteratively refine the research
  direction based on findings\\n- Keep you informed and let you guide the
  research interactively\\n- Always cite sources with URLs\\n\\n###
  Resources\\n\\nWe expose two things as MCP resources: (1) captured webpage
  screenshots, and (2) the research session.\\n\\n#### Screenshots\\nWhen you
  take a screenshot, it's saved as an MCP resource. You can access captured
  screenshots in Claude Desktop via the Paperclip icon.\\n\\n#### Research
  Session\\nThe server maintains a research session that includes:\\n- Search
  queries\\n- Visited pages\\n- Extracted content\\n- Screenshots\\n-
  Timestamps\\n\\n### Suggestions\\n\\nFor the best results, if you choose not
  to use the `agentic-research` prompt when doing your research, it may be
  helpful to suggest high-quality sources for Claude to use when researching
  general topics. For example, you could prompt `news today from reuters or AP`
  instead of `news today`.\\n\\n## Debugging\\n\\nIf you run into issues, check
  Claude Desktop's MCP logs:\\n```bash\\ntail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n```\\n\\n## Development\\n\\n```bash\\n#
  Install dependencies\\npnpm install\\n\\n# Build the project\\npnpm
  build\\n\\n# Watch for changes\\npnpm watch\\n\\n# Run in development
  mode\\npnpm dev\\n```\\n\\n## Requirements\\n- Node.js >= 18\\n- Playwright
  (automatically installed as a dependency)\\n\\n## Verified Platforms\\n- [x]
  macOS\\n- [ ] Linux\\n\\n## License\\nMIT\\n\\n---\\nNote: This is a fork of
  the [original mcp-webresearch
  repository](https://github.com/mzxrai/mcp-webresearch).\\n\",\"isRecommended\
  \":false,\"githubStars\":21,\"downloadCount\":5279,\"createdAt\":\"2025-02-18\
  T23:05:09.409851Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithu\
  bSync\":\"2025-07-02T13:49:54.461401Z\"},{\"mcpId\":\"github.com/base/base-mcp\
  \",\"githubUrl\":\"https://github.com/base/base-mcp\",\"name\":\"Base\",\"aut\
  hor\":\"base\",\"description\":\"Enables blockchain interactions with Base and
  Coinbase APIs, providing tools for wallet management, fund transfers, smart
  contract deployment, and testnet
  operations.\",\"codiconIcon\":\"server-process\",\"logoUrl\":\"https://storag\
  e.googleapis.com/cline_public_images/base.png\",\"category\":\"finance\",\"ta\
  gs\":[\"blockchain\",\"coinbase\",\"web3\",\"smart-contracts\",\"crypto-wallet\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Base MCP Server
  \\n\\n![OpenRouter Integration](public/OpenRouter.gif)\\n\\n[![npm
  version](https://img.shields.io/npm/v/base-mcp.svg)](https://www.npmjs.com/pa\
  ckage/base-mcp)\\n[![License:
  MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource\
  .org/licenses/MIT)\\n\\nA Model Context Protocol (MCP) server that provides
  onchain tools for AI applications like Claude Desktop and Cursor, allowing
  them to interact with the Base Network and Coinbase API.\\n\\n##
  Overview\\n\\nThis MCP server extends any MCP client's capabilities by
  providing tools to do anything on Base:\\n\\n- Retrieve wallet addresses\\n-
  List wallet balances\\n- Transfer funds between wallets\\n- Deploy smart
  contracts\\n- Interact with Morpho vaults for onchain lending\\n- Call
  contract functions\\n- Onramp funds via
  [Coinbase](https://www.coinbase.com/developer-platform/products/onramp)\\n-
  Manage ERC20 tokens\\n- List and transfer NFTs (ERC721 and ERC1155)\\n- Buy
  [OpenRouter](http://openrouter.ai/) credits with USDC\\n- Resolve Farcaster
  usernames to Ethereum addresses\\n\\nThe server interacts with Base, powered
  by Base Developer Tools and
  [AgentKit](https://github.com/coinbase/agentkit).\\n\\n## Extending Base MCP
  with 3P Protocols, Tools, and Data Sources\\n\\nBase MCP is designed to be
  extensible, allowing you to add your own third-party protocols, tools, and
  data sources. This section provides an overview of how to extend the Base MCP
  server with new capabilities.\\n\\n### Adding New Tools\\n\\nIf you want to
  add a new tool to the Base MCP server, follow these steps:\\n\\n1. Create a
  new directory in the `src/tools` directory for your tool\\n2. Implement the
  tool following the existing patterns:\\n   - `index.ts`: Define and export
  your tools. Tools are defined as AgentKit ActionProviders.\\n   -
  `schemas.ts`: Define input schemas for your tools\\n   - `types.ts`: Define
  types required for your tools\\n   - `utils.ts`: Utilities for your tools\\n3.
  Add your tool to the list of available tools in `src/main.ts`\\n4. Add
  documentation for your tool in the README.md\\n5. Add examples of how to use
  your tool in examples.md\\n6. Write tests for your tool\\n\\n### Project
  Structure\\n\\nThe Base MCP server follows this structure for
  tools:\\n\\n```\\nsrc/\\n tools/\\n    [TOOL_NAME]/
  <-------------------------- ADD DIR HERE\\n       index.ts (defines and
  exports tools)\\n       schemas.ts (defines input schema)\\n   
  utils/ (shared tool utilities)\\n```\\n\\n### Best Practices for Tool
  Development\\n\\nWhen developing new tools for Base MCP:\\n\\n- Follow the
  existing code style and patterns\\n- Ensure your tool has a clear, focused
  purpose\\n- Provide comprehensive input validation\\n- Include detailed error
  handling\\n- Write thorough documentation\\n- Add examples demonstrating how
  to use your tool\\n- Include tests for your tool\\n\\nFor more detailed
  information on contributing to Base MCP, including adding new tools and
  protocols, see the [CONTRIBUTING.md](CONTRIBUTING.md) file.\\n\\n##
  Prerequisites\\n\\n- Node.js (v16 or higher)\\n- npm or yarn\\n- Coinbase API
  credentials (API Key Name and Private Key)\\n- A wallet seed phrase\\n-
  Coinbase Project ID (for onramp functionality)\\n- Alchemy API Key (required
  for NFT functionality)\\n- Optional: OpenRouter API Key (for buying OpenRouter
  credits)\\n\\n## Installation\\n\\n### Option 1: Install from npm
  (Recommended)\\n\\n```bash\\n# Install globally\\nnpm install -g
  base-mcp\\n\\n# Or install locally in your project\\nnpm install
  base-mcp\\n```\\n\\nOnce the package is installed, you can configure clients
  with the following command:\\n\\n```bash\\nbase-mcp --init\\n```\\n\\n###
  Option 2: Install from Source\\n\\n1. Clone this
  repository:\\n\\n   ```bash\\n   git clone
  https://github.com/base/base-mcp.git\\n   cd base-mcp\\n   ```\\n\\n2. Install
  dependencies:\\n\\n   ```bash\\n   npm install\\n   ```\\n\\n3. Build the
  project:\\n\\n   ```bash\\n   npm run build\\n   ```\\n\\n4. Optionally, link
  it globally:\\n   ```bash\\n   npm link\\n   ```\\n\\n##
  Configuration\\n\\nCreate a `.env` file with your credentials:\\n\\n```\\n#
  Coinbase API credentials\\n# You can obtain these from the Coinbase Developer
  Portal:
  https://cdp.coinbase.com/\\nCOINBASE_API_KEY_NAME=your_api_key_name\\nCOINBAS\
  E_API_PRIVATE_KEY=your_private_key\\n\\n# Wallet seed phrase (12 or 24
  words)\\n# This is the mnemonic phrase for your wallet\\nSEED_PHRASE=your seed
  phrase here\\n\\n# Coinbase Project ID (for onramp functionality)\\n# You can
  obtain this from the Coinbase Developer
  Portal\\nCOINBASE_PROJECT_ID=your_project_id\\n\\n# Alchemy API Key (required
  for NFT functionality)\\n# You can obtain this from
  https://alchemy.com\\nALCHEMY_API_KEY=your_alchemy_api_key\\n\\n# OpenRouter
  API Key (optional for buying OpenRouter credits)\\n# You can obtain this from
  https://openrouter.ai/keys\\nOPENROUTER_API_KEY=your_openrouter_api_key\\n\\n#
  Chain ID (optional for Base Sepolia testnet)\\n# Use 84532 for Base Sepolia
  testnet\\n# You do not have to include this if you want to use Base
  Mainnet\\nCHAIN_ID=your_chain_id\\n\\n# Neynar API Key (required for Farcaster
  functionality)\\n# You can obtain this from
  https://neynar.com\\nNEYNAR_API_KEY=your_neynar_api_key\\n```\\n\\n##
  Testing\\n\\nTest the MCP server to verify it's working
  correctly:\\n\\n```bash\\nnpm test\\n```\\n\\nThis script will verify that
  your MCP server is working correctly by testing the connection and available
  tools.\\n\\n## Examples\\n\\nSee the [examples.md](examples.md) file for
  detailed examples of how to interact with the Base MCP tools through
  Claude.\\n\\n## Integration with Claude Desktop\\n\\nTo add this MCP server to
  Claude Desktop:\\n\\n1. Create or edit the Claude Desktop configuration file
  at:\\n\\n   - macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n   - Windows:
  `%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\\n   - Linux:
  `~/.config/Claude/claude_desktop_config.json`\\n\\nYou can easily access this
  file via the Claude Desktop app by navigating to Claude > Settings > Developer
  > Edit Config.\\n\\n2. Add the following
  configuration:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"base-mcp\\\": {\\n         \\\"command\\\":
  \\\"npx\\\",\\n         \\\"args\\\": [\\\"-y\\\",
  \\\"base-mcp@latest\\\"],\\n         \\\"env\\\":
  {\\n           \\\"COINBASE_API_KEY_NAME\\\":
  \\\"your_api_key_name\\\",\\n           \\\"COINBASE_API_PRIVATE_KEY\\\":
  \\\"your_private_key\\\",\\n           \\\"SEED_PHRASE\\\": \\\"your seed
  phrase here\\\",\\n           \\\"COINBASE_PROJECT_ID\\\":
  \\\"your_project_id\\\",\\n           \\\"ALCHEMY_API_KEY\\\":
  \\\"your_alchemy_api_key\\\",\\n           \\\"PINATA_JWT\\\":
  \\\"your_pinata_jwt\\\",\\n           \\\"OPENROUTER_API_KEY\\\":
  \\\"your_openrouter_api_key\\\",\\n           \\\"CHAIN_ID\\\":
  \\\"optional_for_base_sepolia_testnet\\\"\\n         },\\n         \\\"disabl\
  ed\\\": false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n3. Restart Claude Desktop for the
  changes to take effect.\\n\\n## Available Tools\\n\\n###
  get-address\\n\\nRetrieves the address for your wallet.\\n\\nExample query to
  Claude:\\n\\n> \\\"What's my wallet address?\\\"\\n\\n###
  list-balances\\n\\nLists all balances for your wallet.\\n\\nExample query to
  Claude:\\n\\n> \\\"Show me my wallet balances.\\\"\\n\\n###
  transfer-funds\\n\\nTransfers funds from your wallet to another
  address.\\n\\nParameters:\\n\\n- `destination`: The address to which to
  transfer funds\\n- `assetId`: The asset ID to transfer\\n- `amount`: The
  amount of funds to transfer\\n\\nExample query to Claude:\\n\\n> \\\"Transfer
  0.01 ETH to 0x1234567890abcdef1234567890abcdef12345678.\\\"\\n\\n###
  deploy-contract\\n\\nDeploys a smart contract to the
  blockchain.\\n\\nParameters:\\n\\n- `constructorArgs`: The arguments for the
  contract constructor\\n- `contractName`: The name of the contract to
  deploy\\n- `solidityInputJson`: The JSON input for the Solidity compiler
  containing contract source and settings\\n- `solidityVersion`: The version of
  the solidity compiler\\n\\nExample query to Claude:\\n\\n> \\\"Deploy a simple
  ERC20 token contract for me.\\\"\\n\\n### check-address-reputation\\n\\nChecks
  the reputation of an address.\\n\\nParameters:\\n\\n- `address`: The Ethereum
  address to check\\n\\nExample query to Claude:\\n\\n> \\\"What's the
  reputation of 0x1234567890abcdef1234567890abcdef12345678?\\\"\\n\\n###
  get_morpho_vaults\\n\\nGets the vaults for a given asset on
  Morpho.\\n\\nParameters:\\n\\n- `assetSymbol`: Asset symbol by which to filter
  vaults (optional)\\n\\nExample query to Claude:\\n\\n> \\\"Show me the
  available Morpho vaults for USDC.\\\"\\n\\n### call_contract\\n\\nCalls a
  contract function on the blockchain.\\n\\nParameters:\\n\\n-
  `contractAddress`: The address of the contract to call\\n- `functionName`: The
  name of the function to call\\n- `functionArgs`: The arguments to pass to the
  function\\n- `abi`: The ABI of the contract\\n- `value`: The value of ETH to
  send with the transaction (optional)\\n\\nExample query to Claude:\\n\\n>
  \\\"Call the balanceOf function on the contract at
  0x1234567890abcdef1234567890abcdef12345678.\\\"\\n\\n###
  get_onramp_assets\\n\\nGets the assets available for onramping in a given
  country/subdivision.\\n\\nParameters:\\n\\n- `country`: ISO 3166-1 two-digit
  country code string representing the purchasing user's country of
  residence\\n- `subdivision`: ISO 3166-2 two-digit country subdivision code
  (required for US)\\n\\nExample query to Claude:\\n\\n> \\\"What assets can I
  onramp in the US, specifically in New York?\\\"\\n\\n### onramp\\n\\nGets a
  URL for onramping funds via Coinbase.\\n\\nParameters:\\n\\n- `amountUsd`: The
  amount of funds to onramp\\n- `assetId`: The asset ID to onramp\\n\\nExample
  query to Claude:\\n\\n> \\\"I want to onramp $100 worth of ETH.\\\"\\n\\n###
  erc20_balance\\n\\nGets the balance of an ERC20 token.\\n\\nParameters:\\n\\n-
  `contractAddress`: The address of the ERC20 contract\\n\\nExample query to
  Claude:\\n\\n> \\\"What's my balance of the token at
  0x1234567890abcdef1234567890abcdef12345678?\\\"\\n\\n###
  erc20_transfer\\n\\nTransfers an ERC20 token to another
  address.\\n\\nParameters:\\n\\n- `contractAddress`: The address of the ERC20
  contract\\n- `toAddress`: The address of the recipient\\n- `amount`: The
  amount of tokens to transfer\\n\\nExample query to Claude:\\n\\n> \\\"Transfer
  10 USDC to 0x1234567890abcdef1234567890abcdef12345678.\\\"\\n\\n###
  list_nfts\\n\\nLists NFTs owned by a specific address.\\n\\nParameters:\\n\\n-
  `ownerAddress`: The address of the owner whose NFTs to list\\n- `limit`:
  Maximum number of NFTs to return (default: 50)\\n\\nExample query to
  Claude:\\n\\n> \\\"Show me the NFTs owned by
  0x89A93a48C6Ef8085B9d07e46AaA96DFDeC717040.\\\"\\n\\n###
  transfer_nft\\n\\nTransfers an NFT to another address. Supports both ERC721
  and ERC1155 standards.\\n\\nParameters:\\n\\n- `contractAddress`: The address
  of the NFT contract\\n- `tokenId`: The token ID of the NFT to transfer\\n-
  `toAddress`: The address of the recipient\\n- `amount`: The amount to transfer
  (only used for ERC1155, default: 1)\\n\\nExample query to Claude:\\n\\n>
  \\\"Transfer my NFT with contract 0x3F06FcF75f45F1bb61D56D68fA7b3F32763AA15c
  and token ID
  56090175025510453004781233574040052668718235229192064098345825090519343038548
  to 0x1234567890abcdef1234567890abcdef12345678.\\\"\\n\\n###
  buy_openrouter_credits\\n\\nBuys OpenRouter credits with
  USDC.\\n\\nParameters:\\n\\n- `amountUsd`: The amount of credits to buy, in
  USD\\n\\nExample query to Claude:\\n\\n> \\\"Buy $20 worth of OpenRouter
  credits.\\\"\\n\\n## Security Considerations\\n\\n- The configuration file
  contains sensitive information (API keys and seed phrases). Ensure it's
  properly secured and not shared.\\n- Consider using environment variables or a
  secure credential manager instead of hardcoding sensitive information.\\n- Be
  cautious when transferring funds or deploying contracts, as these operations
  are irreversible on the blockchain.\\n- When using the onramp functionality,
  ensure you're on a secure connection.\\n- Verify all transaction details
  before confirming, especially when transferring funds or buying
  credits.\\n\\n## Troubleshooting\\n\\nIf you encounter issues:\\n\\n1. Check
  that your Coinbase API credentials are correct\\n2. Verify that your seed
  phrase is valid\\n3. Ensure you're on the correct network (Base Mainnet)\\n4.
  Check the Claude Desktop logs for any error messages\\n\\n## License\\n\\n[MIT
  License](LICENSE)\\n\\n## Contributing\\n\\nContributions are welcome! Please
  feel free to submit a Pull Request.\\n\\nFor detailed guidelines on
  contributing to Base MCP, including:\\n\\n- Reporting bugs\\n- Suggesting
  enhancements\\n- Development setup\\n- Coding standards\\n- **Adding new
  tools, protocols, and data sources** (see also the [Extending Base
  MCP](#extending-base-mcp-with-3p-protocols-tools-and-data-sources) section
  above)\\n- Testing requirements\\n- Documentation standards\\n\\nPlease refer
  to our comprehensive [CONTRIBUTING.md](CONTRIBUTING.md) guide.\\n\\nBasic
  contribution steps:\\n\\n1. Fork the repository\\n2. Create your feature
  branch (`git checkout -b feature/amazing-feature`)\\n3. Commit your changes
  (`git commit -m 'Add some amazing feature'`)\\n4. Push to the branch (`git
  push origin feature/amazing-feature`)\\n5. Open a Pull Request\\n\\nPlease
  make sure your code follows the existing style and includes appropriate
  tests.\\n\",\"isRecommended\":false,\"githubStars\":258,\"downloadCount\":995,\
  \"createdAt\":\"2025-03-09T05:49:30.085654Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-03T11:01:49.875292Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/amazon-qindex-mcp-server\",\"githubUrl\
  \":\"https://github.com/awslabs/mcp/tree/main/src/amazon-qindex-mcp-server\",\
  \"name\":\"Amazon Q Search\",\"author\":\"awslabs\",\"description\":\"Enables
  ISVs to search enterprise customer data through Amazon Q Business's
  SearchRelevantContent API with secure authentication and cross-account
  capabilities.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/aws.png\",\"category\":\"search\",\"tags\":[\"\
  amazon-q\",\"enterprise-search\",\"oauth\",\"cross-account\",\"aws\"],\"requi\
  resApiKey\":false,\"readmeContent\":\"# AWS Labs amazon-qindex MCP
  Server\\n\\nThe AWS Labs amazon-qindex MCP Server is a Model Context Protocol
  (MCP) server designed to facilitate integration with Amazon Q Business's
  [SearchRelevantContent
  API](https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/isv-calling-api-\
  idc.html). While the server provides essential tools and functions for
  authentication and search capabilities using Amazon Q index, it currently
  serves for Independent Software Vendors (ISVs) who are [AWS registered data
  accessors](https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/isv.html).
  The server enables cross-account search capabilities, allowing ISVs who are
  data accessors to search through enterprise customers' Q index and access
  relevant content across their data sources using specific authentication and
  authorization flows.\\n\\nFor Amazon Q Business application owners, direct
  integration support is not yet available. This MCP server represents a
  comprehensive solution that aims to serve ISVs.\\n\\n## Features\\n\\n- Boto3
  client implementation for Q Business interactions\\n- Support for various
  authentication methods (IAM credentials, profile-based)\\n- MCP server
  implementation for handling Q index requests\\n- Token-based authorization
  support\\n- Error handling and mapping for Q Business API responses\\n\\n##
  Tools\\n\\n#### AuthorizeQIndex\\n- Generates OIDC authorization URL for Q
  index authentication\\n- Required Parameters:\\n  - idc_region (str): AWS
  region for IAM Identity Center (e.g., us-west-2)\\n  - isv_redirect_url (str):
  Redirect URL registered during ISV registration\\n  - oauth_state (str):
  Random string for CSRF protection\\n  - idc_application_arn (str): Amazon Q
  Business application ID\\n- Returns: Authorization URL for user
  authentication\\n\\n#### CreateTokenWithIAM\\n- Creates authentication token
  using authorization code through IAM\\n- Required Parameters:\\n  -
  idc_application_arn (str): Amazon Q Business application ID\\n  - redirect_uri
  (str): Registered redirect URL\\n  - code (str): Authorization code from OIDC
  endpoint\\n  - idc_region (str): AWS region for IAM Identity Center\\n  -
  role_arn (str): IAM role ARN to assume\\n- Returns: Token information
  including access token, refresh token, and expiration\\n\\n####
  AssumeRoleWithIdentityContext\\n- Assumes IAM role using identity context from
  token\\n- Required Parameters:\\n  - role_arn (str): IAM role ARN to
  assume\\n  - identity_context (str): Identity context from decoded token\\n  -
  role_session_name (str): Session identifier (default:
  \\\"qbusiness-session\\\")\\n  - idc_region (str): AWS region for IAM Identity
  Center\\n- Returns: Temporary AWS credentials\\n\\n####
  SearchRelevantContent\\n- Searches content within Amazon Q Business
  application\\n- Required Parameters:\\n  - application_id (str): Q Business
  application identifier\\n  - query_text (str): Search query text\\n- Optional
  Parameters:\\n  - attribute_filter (AttributeFilter): Document attribute
  filters\\n  - content_source (ContentSource): Content source
  configuration\\n  - max_results (int): Maximum results to return (1-100)\\n  -
  next_token (str): Pagination token\\n  - qbuiness_region (str): AWS region
  (default: us-east-1)\\n  - aws_credentials: Temporary AWS credentials\\n-
  Returns: Search results with relevant content matches\\n\\n## Setup\\n\\n###
  Pre-Requisites\\n- Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n- Install
  Python using `uv python install 3.10`\\n\\n- Two AWS Accounts (one account as
  ISV running this tester application, another account acting as enterprise
  customer running Amazon Q Business)\\n- [Data accessor registered for your
  ISV](https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/isv-info-to-prov\
  ide.html)\\n- IAM Identity Center (IDC) instance setup with user added on
  enterprise customer AWS account\\n- Amazon Q Business application setup with
  IAM IDC as access management on enterprise customer AWS account\\n\\n\\n###
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.amazon_qindex_mcp_server&config=eyJjb21tYW5kIjoidX\
  Z4IGF3c2xhYnMuYW1hem9uX3FpbmRleF9tY3Bfc2VydmVyIiwiZW52Ijp7IkFXU19QUk9GSUxFIjo\
  ieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEifX0%3D)\\n\\nConfigu\
  re the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.amazon_qindex_mcp_server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.amazon_qindex_mcp_server\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n```bash\\n# Clone the
  repository\\ngit clone [repository-url]\\n\\n# Go to root directory of this
  server\\ncd <your repo path>/mcp/src/amazon-qindex-mcp-server/\\n\\n# Install
  dependencies\\npip install -e .\\n```\\n\\n## Usage\\n\\n1. Enter a text
  prompt describing what you want to query from enterprise
  data\\n\\n```\\nsearch <your query> on enterprise data\\n```\\n\\n2. You also
  need to provide the following details to proceed with the authentication flow
  in order to process SearchRelevantContent API\\n\\n```\\napplication id -
  (enterprise account's Amazon Q Business application ID)\\nretriever id -
  (enterprise account's Amazon Q Business retriever ID)\\niam idc arn -
  (enterprise account's IdC application ARN)\\nidc region - (Region for the IAM
  Identity Center instance)\\nqbuiness region - (enterprise account's Amazon Q
  Business application region)\\nredirect url - (ISV's redirect url - this could
  be anything within allowlisted for the data accessor - ie
  https://localhost:8081)\\niam role arn - (ISV's IAM Role ARN registered with
  the data accessor)\\n```\\n\\n3. After providing the data through above two
  steps, you will be asked to visit the authorization URL on your browser and
  after successfully authenticated and taken to redirect url with an
  authorization code in the URL parameters (it will look like
  ?code=ABC123...&state=xxx), copy and paste the code portion to the client to
  resume the process.\\n\\n```\\ncode is <your authorization code>\\n```\\n\\n4.
  This MCP server will then process CreateTokenWithIAM to create authentication
  token, AssumeRoleWithIdentityContext to assume the role and get temporary
  credentials, then finally call SearchRelevantContent to searches user queried
  content within Amazon Q Business application.\\n\\n## Testing\\n\\nRun tests
  using pytest:\\n```\\npytest --cache-clear -v\\n```\\n\\n## Security
  Considerations\\n\\nThis MCP server implementation is for demonstration
  purposes only to showcase how to access the SearchRelevantContent API through
  an MCP server with user-aware authentication. For production use, please
  consider the following security measures:\\n\\n### Authentication &
  Authorization\\n- Never hardcode credentials or sensitive information in the
  code\\n- Implement proper session management and token refresh mechanisms\\n-
  Use strong CSRF protection mechanisms for the OAuth flow\\n- Implement proper
  validation of all authorization codes and tokens\\n- Store tokens securely and
  never log them\\n- Implement proper token revocation when sessions
  end\\n\",\"isRecommended\":false,\"githubStars\":4391,\"downloadCount\":172,\
  \"createdAt\":\"2025-06-21T02:00:55.672461Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-06T00:12:25.617143Z\"},{\"mcpId\":\
  \"github.com/modelcontextprotocol/servers/tree/main/src/sqlite\",\"githubUrl\
  \":\"https://github.com/modelcontextprotocol/servers/tree/main/src/sqlite\",\
  \"name\":\"SQLite\",\"author\":\"modelcontextprotocol\",\"description\":\"Pro\
  vides database interaction and business intelligence capabilities through
  SQLite, enabling SQL queries, data analysis, and automated business insight
  generation.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/sqlite.png\",\"category\":\"databases\",\"tags\
  \":[\"sql\",\"data-analysis\",\"business-intelligence\",\"database-management\
  \",\"sqlite\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\
  \":57018,\"downloadCount\":10383,\"createdAt\":\"2025-02-18T05:45:28.005191Z\
  \",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07\
  -01T12:06:16.878255Z\"},{\"mcpId\":\"github.com/neo4j-contrib/mcp-neo4j\",\"g\
  ithubUrl\":\"https://github.com/neo4j-contrib/mcp-neo4j\",\"name\":\"Neo4j\",\
  \"author\":\"neo4j-contrib\",\"description\":\"Enables natural language
  interactions with Neo4j graph databases, supporting Cypher query generation
  and knowledge graph memory management for
  LLMs.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/Neo4j.png\",\"category\":\"databases\",\"tags\":[\"g\
  raph-database\",\"cypher\",\"knowledge-graph\",\"memory-storage\",\"neo4j-aura\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Neo4j MCP Clients &
  Servers\\n\\nModel Context Protocol (MCP) is a [standardized
  protocol](https://modelcontextprotocol.io/introduction) for managing context
  between large language models (LLMs) and external systems. \\n\\nThis lets you
  use Claude Desktop, or any other MCP Client (VS Code, Cursor, Windsurf), to
  use natural language to accomplish things with Neo4j and your Aura account,
  e.g.:\\n\\n* What is in this graph?\\n* Render a chart from the top products
  sold by frequency, total and average volume\\n* List my instances\\n* Create a
  new instance named mcp-test for Aura Professional with 4GB and Graph Data
  Science enabled\\n* Store the fact that I worked on the Neo4j MCP Servers
  today with Andreas and Oskar\\n\\n## Servers\\n\\n### `mcp-neo4j-cypher` -
  natural language to Cypher queries\\n\\n[Details in
  Readme](./servers/mcp-neo4j-cypher/)\\n\\nGet database schema for a configured
  database and execute generated read and write Cypher queries on that
  database.\\n\\n### `mcp-neo4j-memory` - knowledge graph memory stored in
  Neo4j\\n\\n[Details in Readme](./servers/mcp-neo4j-memory/)\\n\\nStore and
  retrieve entities and relationships from your personal knowledge graph in a
  local or remote Neo4j instance.\\nAccess that information over different
  sessions, conversations, clients.\\n\\n### `mcp-neo4j-cloud-aura-api` - Neo4j
  Aura cloud service management API\\n\\n[Details in
  Readme](./servers/mcp-neo4j-cloud-aura-api//)\\n\\nManage your [Neo4j
  Aura](https://console.neo4j.io) instances directly from the comfort of your AI
  assistant chat.\\n\\nCreate and destroy instances, find instances by name,
  scale them up and down and enable features.\\n\\n### `mcp-neo4j-data-modeling`
  - interactive graph data modeling and visualization\\n\\n[Details in
  Readme](./servers/mcp-neo4j-data-modeling/)\\n\\nCreate, validate, and
  visualize Neo4j graph data models. Allows for model import/export from
  Arrows.app.\\n\\n## Contributing\\n\\nContributions are welcome! Please feel
  free to submit a Pull Request.\\n\\n## Blog Posts\\n\\n* [Everything a
  Developer Needs to Know About the Model Context Protocol
  (MCP)](https://neo4j.com/blog/developer/model-context-protocol/)\\n* [Claude
  Converses With Neo4j Via MCP - Graph Database &
  Analytics](https://neo4j.com/blog/developer/claude-converses-neo4j-via-mcp/)\
  \\n* [Building Knowledge Graphs With Claude and Neo4j: A No-Code MCP Approach
  - Graph Database &
  Analytics](https://neo4j.com/blog/developer/knowledge-graphs-claude-neo4j-mcp\
  /)\\n\\n## License\\n\\nMIT
  License\\n\",\"isRecommended\":false,\"githubStars\":483,\"downloadCount\":15\
  39,\"createdAt\":\"2025-02-18T06:28:19.461292Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T15:13:26.350991Z\"},{\"mcpId\
  \":\"github.com/justinpbarnett/unity-mcp\",\"githubUrl\":\"https://github.com\
  /justinpbarnett/unity-mcp\",\"name\":\"Unity
  Bridge\",\"author\":\"justinpbarnett\",\"description\":\"Enables bidirectional
  communication between Unity and LLMs, allowing programmatic control of Unity
  Editor features including asset management, scene control, and editor
  automation.\",\"codiconIcon\":\"game\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/unity-bridge.png\",\"category\":\"developer-tools\
  \",\"tags\":[\"unity\",\"game-development\",\"asset-management\",\"automation\
  \",\"editor-tools\"],\"requiresApiKey\":false,\"readmeContent\":\"# Unity MCP
  \\n\\n**Connect your Unity Editor to LLMs using the Model Context
  Protocol.**\\n\\nUnity MCP acts as a bridge, allowing AI assistants (like
  Claude, Cursor) to interact directly with your Unity Editor via a local **MCP
  (Model Context Protocol) Client**. Give your LLM tools to manage assets,
  control scenes, edit scripts, and automate tasks within
  Unity.\\n\\n---\\n\\n## <picture><source media=\\\"(prefers-color-scheme:
  dark)\\\"
  srcset=\\\"https://github.com/justinpbarnett/unity-mcp/assets/11047284/c27967\
  5a-dd58-406b-9613-5b16b5c6bb63\\\"><source media=\\\"(prefers-color-scheme:
  light)\\\"
  srcset=\\\"https://github.com/justinpbarnett/unity-mcp/assets/11047284/b54f89\
  1d-961b-4048-a9c4-3af46e2a52fc\\\"><img alt=\\\"UnityMCP Workflow\\\"
  width=\\\"100%\\\" style=\\\"max-width: 600px; display: block; margin-left:
  auto; margin-right: auto;\\\"></picture>\\n\\n## Key Features
  \\n\\n*   ** Natural Language Control:** Instruct your LLM to perform
  Unity tasks.\\n*   ** Powerful Tools:** Manage assets, scenes, materials,
  scripts, and editor functions.\\n*   ** Automation:** Automate repetitive
  Unity workflows.\\n*   ** Extensible:** Designed to work with various MCP
  Clients.\\n\\n<details>\\n  <summary><strong>Expand for Available
  Tools...</strong></summary>\\n\\n  Your LLM can use functions
  like:\\n\\n  *   `read_console`: Gets messages from or clears the
  console.\\n  *   `manage_script`: Manages C# scripts (create, read, update,
  delete).\\n  *   `manage_editor`: Controls and queries the editor's state and
  settings.\\n  *   `manage_scene`: Manages scenes (load, save, create, get
  hierarchy, etc.).\\n  *   `manage_asset`: Performs asset operations (import,
  create, modify, delete, etc.).\\n  *   `manage_gameobject`: Manages
  GameObjects: create, modify, delete, find, and component
  operations.\\n  *   `execute_menu_item`: Executes a menu item via its path
  (e.g., \\\"File/Save Project\\\").\\n</details>\\n\\n---\\n\\n## How It Works
  \\n\\nUnity MCP connects your tools using two components:\\n\\n1.  **Unity
  MCP Bridge:** A Unity package running inside the Editor. (Installed via
  Package Manager).\\n2.  **Unity MCP Server:** A Python server that runs
  locally, communicating between the Unity Bridge and your MCP Client.
  (Installed manually).\\n\\n**Flow:** `[Your LLM via MCP Client] <-> [Unity MCP
  Server (Python)] <-> [Unity MCP Bridge (Unity Editor)]`\\n\\n---\\n\\n##
  Installation \\n\\n> **Note:** The setup is constantly improving as we
  update the package. Check back if you randomly start to run into
  issues.\\n\\n### Prerequisites\\n\\n<details>\\n  <summary><strong>Click to
  view required software...</strong></summary>\\n\\n  *   **Git CLI:** For
  cloning the server code. [Download
  Git](https://git-scm.com/downloads)\\n  *   **Python:** Version 3.12 or newer.
  [Download Python](https://www.python.org/downloads/)\\n  *   **Unity Hub &
  Editor:** Version 2020.3 LTS or newer. [Download
  Unity](https://unity.com/download)\\n  *   **uv (Python package
  manager):**\\n      ```bash\\n      pip install uv\\n      # Or see:
  https://docs.astral.sh/uv/getting-started/installation/\\n      ```\\n  *   *\
  *An MCP Client:**\\n      *   [Claude
  Desktop](https://claude.ai/download)\\n      *   [Cursor](https://www.cursor.\
  com/en/downloads)\\n      *   *(Others may work with manual
  config)*\\n</details>\\n\\n### Step 1: Install the Unity Package
  (Bridge)\\n\\n1.  Open your Unity project.\\n2.  Go to `Window > Package
  Manager`.\\n3.  Click `+` -> `Add package from git
  URL...`.\\n4.  Enter:\\n    ```\\n    https://github.com/justinpbarnett/unity\
  -mcp.git?path=/UnityMcpBridge\\n    ```\\n5.  Click `Add`.\\n6. The MCP Server
  should automatically be installed onto your machine as a result of this
  process.\\n\\n### Step 2: Configure Your MCP Client\\n\\nConnect your MCP
  Client (Claude, Cursor, etc.) to the Python server you installed in Step
  1.\\n\\n**Option A: Auto-Configure (Recommended for
  Claude/Cursor)**\\n\\n1.  In Unity, go to `Window > Unity MCP`.\\n2.  Click
  `Auto Configure Claude` or `Auto Configure Cursor`.\\n3.  Look for a green
  status indicator  and \\\"Connected\\\". *(This attempts to modify the MCP
  Client's config file automatically)*.\\n\\n**Option B: Manual
  Configuration**\\n\\nIf Auto-Configure fails or you use a different
  client:\\n\\n1.  **Find your MCP Client's configuration file.** (Check client
  documentation).\\n    *   *Claude Example (macOS):* `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n    *   *Claude Example
  (Windows):* `%APPDATA%\\\\Claude\\\\claude_desktop_config.json`\\n2.  **Edit
  the file** to add/update the `mcpServers` section, using the *exact* paths
  from Step 1.\\n\\n<details>\\n<summary><strong>Click for OS-Specific JSON
  Configuration
  Snippets...</strong></summary>\\n\\n**Windows:**\\n\\n  ```json\\n  {\\n    \\\
  \"mcpServers\\\": {\\n      \\\"UnityMCP\\\": {\\n        \\\"command\\\":
  \\\"uv\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--directory\\\",\\n          \\\"C:\
  \\\\\\\\Users\\\\\\\\YOUR_USERNAME\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\
  \\\\\\\\UnityMCP\\\\\\\\UnityMcpServer\\\\\\\\src\\\",\\n          \\\"server\
  .py\\\"\\n        ]\\n      }\\n      // ... other servers might be here
  ...\\n    }\\n  }\\n``` \\n\\n(Remember to replace YOUR_USERNAME and use
  double backslashes
  \\\\\\\\)\\n\\n**macOS:**\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"UnityMCP\\\": {\\n      \\\"command\\\":
  \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--directory\\\",\\n        \\\"/usr/lo\
  cal/bin/UnityMCP/UnityMcpServer/src\\\",\\n        \\\"server.py\\\"\\n      ]\
  \\n    }\\n    // ... other servers might be here
  ...\\n  }\\n}\\n```\\n(Replace YOUR_USERNAME if using
  ~/bin)\\n\\n**Linux:**\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"UnityMCP\\\": {\\n      \\\"command\\\":
  \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--directory\\\",\\n        \\\"/home/Y\
  OUR_USERNAME/bin/UnityMCP/UnityMcpServer/src\\\",\\n        \\\"server.py\\\"\
  \\n      ]\\n    }\\n    // ... other servers might be here
  ...\\n  }\\n}\\n```\\n\\n(Replace
  YOUR_USERNAME)\\n\\n</details>\\n\\n---\\n\\n## Usage \\n\\n1. **Open your
  Unity Project.** The Unity MCP Bridge (package) should connect automatically.
  Check status via Window > Unity MCP.\\n    \\n2. **Start your MCP Client**
  (Claude, Cursor, etc.). It should automatically launch the Unity MCP Server
  (Python) using the configuration from Installation Step 3.\\n    \\n3.
  **Interact!** Unity tools should now be available in your MCP
  Client.\\n    \\n    Example Prompt: `Create a 3D player
  controller.`\\n    \\n\\n---\\n\\n## Contributing \\n\\nHelp make Unity MCP
  better!\\n\\n1. **Fork** the main repository.\\n    \\n2. **Create a branch**
  (`feature/your-idea` or `bugfix/your-fix`).\\n    \\n3. **Make
  changes.**\\n    \\n4. **Commit** (feat: Add cool new feature).\\n    \\n5.
  **Push** your branch.\\n    \\n6. **Open a Pull Request** against the master
  branch.\\n    \\n\\n---\\n\\n## Troubleshooting
  \\n\\n<details>  \\n<summary><strong>Click to view common issues and
  fixes...</strong></summary>  \\n\\n- **Unity Bridge Not
  Running/Connecting:**\\n    \\n    - Ensure Unity Editor is
  open.\\n        \\n    - Check the status window: Window > Unity
  MCP.\\n        \\n    - Restart Unity.\\n        \\n- **MCP Client Not
  Connecting / Server Not Starting:**\\n    \\n    - **Verify Server Path:**
  Double-check the --directory path in your MCP Client's JSON config. It must
  exactly match the location where you cloned the UnityMCP repository in
  Installation Step 1 (e.g.,
  .../Programs/UnityMCP/UnityMcpServer/src).\\n        \\n    - **Verify uv:**
  Make sure uv is installed and working (pip show uv).\\n        \\n    - **Run
  Manually:** Try running the server directly from the terminal to see errors:
  `# Navigate to the src directory first! cd
  /path/to/your/UnityMCP/UnityMcpServer/src uv run server.py`\\n        \\n    -
  **Permissions (macOS/Linux):** If you installed the server in a system
  location like /usr/local/bin, ensure the user running the MCP client has
  permission to execute uv and access files there. Installing in ~/bin might be
  easier.\\n        \\n- **Auto-Configure Failed:**\\n    \\n    - Use the
  Manual Configuration steps. Auto-configure might lack permissions to write to
  the MCP client's config file.\\n        \\n\\n</details>  \\n\\nStill stuck?
  [Open an
  Issue](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fjustinpba\
  rnett%2Funity-mcp%2Fissues).\\n\\n---\\n\\n## License \\n\\nMIT License. See
  [LICENSE](https://www.google.com/url?sa=E&q=https%3A%2F%2Fgithub.com%2Fjustin\
  pbarnett%2Funity-mcp%2Fblob%2Fmaster%2FLICENSE) file.\\n\\n---\\n\\n## Contact
  \\n\\n- **X/Twitter:**
  [@justinpbarnett](https://www.google.com/url?sa=E&q=https%3A%2F%2Fx.com%2Fjus\
  tinpbarnett)\\n    \\n\\n---\\n\\n## Acknowledgments \\n\\nThanks to the
  contributors and the Unity
  team.\\n\",\"isRecommended\":false,\"githubStars\":2384,\"downloadCount\":334\
  2,\"createdAt\":\"2025-03-27T20:06:42.151332Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T07:15:42.570927Z\"},{\"mcpId\
  \":\"github.com/awslabs/mcp/tree/main/src/aws-bedrock-data-automation-mcp-ser\
  ver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/aws-bedroc\
  k-data-automation-mcp-server\",\"name\":\"Bedrock Data
  Automation\",\"author\":\"awslabs\",\"description\":\"Enables analysis of
  documents, images, videos, and audio files using Amazon Bedrock Data
  Automation projects, with support for project management and S3
  integration.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"\
  tags\":[\"aws\",\"data-analysis\",\"content-processing\",\"automation\",\"doc\
  ument-analysis\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Bedrock
  Data Automation MCP Server\\n\\nA Model Context Protocol (MCP) server for
  Amazon Bedrock Data Automation that enables AI assistants to analyze
  documents, images, videos, and audio files using Amazon Bedrock Data
  Automation projects.\\n\\n## Features\\n\\n- **Project Management**: List and
  get details about Bedrock Data Automation projects\\n- **Asset Analysis**:
  Extract insights from unstructured content using Bedrock Data Automation\\n-
  **Support for Multiple Content Types**: Process documents, images, videos, and
  audio files\\n- **Integration with Amazon S3**: Seamlessly upload and download
  assets and results\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to Amazon Bedrock Data Automation\\n   - You need an AWS account with Amazon
  Bedrock Data Automation enabled\\n   - Configure AWS credentials with `aws
  configure` or environment variables\\n   - Ensure your IAM role/user has
  permissions to use Amazon Bedrock Data Automation\\n4. Create an AWS S3
  Bucket\\n   - Example AWS CLI command to create the bucket\\n   -
  ```bash\\n      aws s3 create-bucket <bucket-name>\\n      ```\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=bedrock-data-automation-mcp-server&config=eyJjb21tYW5kIjoi\
  dXZ4IGF3c2xhYnMuYXdzLWJlZHJvY2stZGF0YS1hdXRvbWF0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0I\
  iwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy\
  1lYXN0LTEiLCJBV1NfQlVDS0VUX05BTUUiOiJ5b3VyLXMzLWJ1Y2tldC1uYW1lIiwiQkFTRV9ESVI\
  iOiIvcGF0aC90by9iYXNlL2RpcmVjdG9yeSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwi\
  ZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nConfigure the MCP server in
  your MCP client configuration (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"bedrock-data-automation-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.aws-bedrock-data-automation-mcp-server@latest\\\"],\\n      \\\"\
  env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"AWS_BUCKET_NAME\\\":
  \\\"your-s3-bucket-name\\\",\\n        \\\"BASE_DIR\\\":
  \\\"/path/to/base/directory\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t
  awslabs/aws-bedrock-data-automation-mcp-server
  .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"bedrock-data-automation-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"AWS_PROFILE\\\",\\n        \\\"--e\
  nv\\\",\\n        \\\"AWS_REGION\\\",\\n        \\\"--env\\\",\\n        \\\"\
  AWS_BUCKET_NAME\\\",\\n        \\\"--env\\\",\\n        \\\"BASE_DIR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\",\\n        \\\"awslabs/aws\
  -bedrock-data-automation-mcp-server:latest\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"AWS_BUCKET_NAME\\\":
  \\\"your-s3-bucket-name\\\",\\n        \\\"BASE_DIR\\\":
  \\\"/path/to/base/directory\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Environment Variables\\n\\n- `AWS_PROFILE`: AWS CLI profile to use for
  credentials\\n- `AWS_REGION`: AWS region to use (default: us-east-1)\\n-
  `AWS_BUCKET_NAME`: S3 bucket name for storing assets and results\\n-
  `BASE_DIR`: Base directory for file operations (optional)\\n-
  `FASTMCP_LOG_LEVEL`: Logging level (ERROR, WARNING, INFO, DEBUG)\\n\\n## AWS
  Authentication\\n\\nThe server uses the AWS profile specified in the
  `AWS_PROFILE` environment variable. If not provided, it defaults to the
  default credential provider chain.\\n\\n```json\\n\\\"env\\\":
  {\\n  \\\"AWS_PROFILE\\\": \\\"your-aws-profile\\\",\\n  \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n}\\n```\\n\\nMake sure the AWS profile has permissions to
  access Amazon Bedrock Data Automation services. The MCP server creates a boto3
  session using the specified profile to authenticate with AWS services. Amazon
  Bedrock Data Automation services is currently available in the following
  regions: us-east-1 and us-west-2.\\n\\n## Tools\\n\\n### getprojects\\n\\nGet
  a list of data automation projects.\\n\\n```python\\ngetprojects() ->
  list\\n```\\n\\nReturns a list of available Bedrock Data Automation
  projects.\\n\\n### getprojectdetails\\n\\nGet details of a specific data
  automation project.\\n\\n```python\\ngetprojectdetails(projectArn: str) ->
  dict\\n```\\n\\nReturns detailed information about a specific Bedrock Data
  Automation project.\\n\\n### analyzeasset\\n\\nAnalyze an asset using a data
  automation project.\\n\\n```python\\nanalyzeasset(assetPath: str, projectArn:
  Optional[str] = None) -> dict\\n```\\n\\nExtracts insights from unstructured
  content (documents, images, videos, audio) using Amazon Bedrock Data
  Automation.\\n\\n- `assetPath`: Path to the asset file to analyze\\n-
  `projectArn`: ARN of the Bedrock Data Automation project to use (optional,
  uses default public project if not provided)\\n\\n## Example
  Usage\\n\\n```python\\n# List available projects\\nprojects = await
  getprojects()\\n\\n# Get details of a specific project\\nproject_details =
  await
  getprojectdetails(projectArn=\\\"arn:aws:bedrock:us-east-1:123456789012:data-\
  automation-project/my-project\\\")\\n\\n# Analyze a document\\nresults = await
  analyzeasset(assetPath=\\\"/path/to/document.pdf\\\")\\n\\n# Analyze an image
  with a specific project\\nresults = await
  analyzeasset(\\n    assetPath=\\\"/path/to/image.jpg\\\",\\n    projectArn=\\\
  \"arn:aws:bedrock:us-east-1:123456789012:data-automation-project/my-project\\\
  \"\\n)\\n```\\n\\n## Security Considerations\\n\\n- Use AWS IAM roles with
  appropriate permissions\\n- Store credentials securely\\n- Use temporary
  credentials when possible\\n- Ensure S3 bucket permissions are properly
  configured\\n\\n## License\\n\\nThis project is licensed under the Apache
  License, Version 2.0. See the [LICENSE](LICENSE) file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":4378,\"downloadCount\":\
  90,\"createdAt\":\"2025-06-21T01:54:07.768654Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T03:36:22.186764Z\"},{\"mcpId\
  \":\"github.com/codegen-sh/codegen-sdk/tree/develop/codegen-examples/examples\
  /codegen-mcp-server\",\"githubUrl\":\"https://github.com/codegen-sh/codegen-s\
  dk/tree/develop/codegen-examples/examples/codegen-mcp-server\",\"name\":\"Cod\
  egen\",\"author\":\"codegen-sh\",\"description\":\"Enables parsing codebases
  and executing codemods through standardized model inference, supporting
  various LLM providers via integration with the Codegen
  SDK.\",\"codiconIcon\":\"code\",\"logoUrl\":\"https://storage.googleapis.com/\
  cline_public_images/codegen.png\",\"category\":\"developer-tools\",\"tags\":[\
  \"code-generation\",\"codemod\",\"code-parsing\",\"sdk-integration\",\"llm-to\
  ols\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\":468,\"\
  downloadCount\":1803,\"createdAt\":\"2025-02-18T23:04:15.445062Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T22:45:28.0\
  1569Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/documentdb-mcp-ser\
  ver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/documentdb\
  -mcp-server\",\"name\":\"DocumentDB\",\"author\":\"awslabs\",\"description\":\
  \"Enables AI assistants to interact with AWS DocumentDB databases, providing
  tools for querying, managing collections, and analyzing schemas with optional
  read-only security
  mode.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\"aws\
  \",\"documentdb\",\"mongodb\",\"database-management\",\"nosql\"],\"requiresAp\
  iKey\":false,\"readmeContent\":\"# AWS DocumentDB MCP Server\\n\\nAn AWS Labs
  Model Context Protocol (MCP) server for AWS DocumentDB that enables AI
  assistants to interact with DocumentDB databases.\\n\\n## Overview\\n\\nThe
  DocumentDB MCP Server provides tools to connect to and query AWS DocumentDB
  databases. It serves as a bridge between AI assistants and AWS DocumentDB,
  allowing for safe and efficient database operations through the Model Context
  Protocol (MCP).\\n\\n## Features\\n\\n- **Connection Management**: Establish
  and maintain connections to DocumentDB clusters\\n- **Database Management**:
  List databases and retrieve database statistics\\n- **Collection Management**:
  List, create, drop collections and retrieve collection statistics\\n-
  **Document Operations**: Query, insert, update, and delete documents\\n-
  **Aggregation Pipelines**: Execute DocumentDB aggregation pipelines\\n-
  **Query Planning**: Get explanations of how operations will be executed\\n-
  **Schema Analysis**: Analyze collection schemas by sampling documents\\n-
  **Read-Only Mode**: Optional security feature to restrict operations to
  read-only operations\\n\\n## Available Tools\\n\\nThe DocumentDB MCP Server
  provides the following tools:\\n\\n### Connection Management\\n\\n- `connect`:
  Connect to a DocumentDB cluster and get a connection ID\\n- `disconnect`:
  Close an active connection\\n\\n### Database Management\\n\\n-
  `listDatabases`: List all available databases in the DocumentDB cluster\\n-
  `getDatabaseStats`: Get statistics about a DocumentDB database\\n\\n###
  Collection Management\\n\\n- `listCollections`: List collections in a
  database\\n- `createCollection`: Create a new collection in a database
  (blocked in read-only mode)\\n- `dropCollection`: Drop a collection from a
  database (blocked in read-only mode)\\n- `getCollectionStats`: Get statistics
  about a collection\\n- `countDocuments`: Count documents in a collection\\n-
  `analyzeSchema`: Analyze the schema of a collection by sampling documents and
  providing field coverage\\n\\n### Document Operations\\n\\n- `find`: Query
  documents from a collection\\n- `aggregate`: Run aggregation pipelines\\n-
  `insert`: Insert documents (blocked in read-only mode)\\n- `update`: Update
  documents (blocked in read-only mode)\\n- `delete`: Delete documents (blocked
  in read-only mode)\\n\\n### Query Planning\\n\\n- `explainOperation`: Get an
  explanation of how an operation will be executed\\n\\n## Server
  Configuration\\n\\n### Starting the Server\\n\\n```bash\\n# Basic
  usage\\npython -m awslabs.documentdb_mcp_server.server\\n\\n# With custom port
  and host\\npython -m awslabs.documentdb_mcp_server.server --port 9000 --host
  0.0.0.0\\n\\n# With write operations enabled\\npython -m
  awslabs.documentdb_mcp_server.server --allow-write\\n```\\n\\n### Command Line
  Options\\n\\n| Option | Description | Default
  |\\n|--------|-------------|---------|\\n| `--log-level` | Set logging level
  (TRACE, DEBUG, INFO, etc.) | INFO |\\n| `--connection-timeout` | Idle
  connection timeout in minutes | 30 |\\n| `--allow-write` | Enable write
  operations (otherwise defaults to read-only mode) | False |\\n\\n### Read-Only
  Mode\\n\\nBy default, the server runs in read-only mode that only allows read
  operations. This enhances security by preventing any modifications to the
  database. In read-only mode:\\n\\n- Read operations (`find`, `aggregate`,
  `listCollections`) work normally\\n- Write operations (`insert`, `update`,
  `delete`) are blocked and return a permission error\\n- Connection management
  operations (`connect`, `disconnect`) work normally\\n\\nThis mode is
  particularly useful for:\\n- Demonstration environments\\n- Security-sensitive
  applications\\n- Integration with public-facing AI assistants\\n- Protecting
  production databases from unintended modifications\\n\\n## Usage
  Examples\\n\\n### Basic Connection and Query (Read-Only
  Operations)\\n\\n```python\\n# Connect to a DocumentDB
  cluster\\nconnection_result = await
  use_mcp_tool(\\n    server_name=\\\"awslabs.aws-documentdb-mcp-server\\\",\\n    \
  tool_name=\\\"connect\\\",\\n    arguments={\\n        \\\"connection_string\\\
  \":
  \\\"mongodb://<username>:<password>@docdb-cluster.cluster-xyz.us-west-2.docdb\
  .amazonaws.com:27017/?tls=true&tlsCAFile=global-bundle.pem\\\"\\n    }\\n)\\n\
  connection_id = connection_result[\\\"connection_id\\\"]\\n\\n# Query
  documents\\nquery_result = await
  use_mcp_tool(\\n    server_name=\\\"awslabs.aws-documentdb-mcp-server\\\",\\n    \
  tool_name=\\\"find\\\",\\n    arguments={\\n        \\\"connection_id\\\":
  connection_id,\\n        \\\"database\\\":
  \\\"my_database\\\",\\n        \\\"collection\\\":
  \\\"users\\\",\\n        \\\"query\\\": {\\\"active\\\":
  True},\\n        \\\"limit\\\": 5\\n    }\\n)\\n\\n# Close the connection when
  done\\nawait
  use_mcp_tool(\\n    server_name=\\\"awslabs.aws-documentdb-mcp-server\\\",\\n    \
  tool_name=\\\"disconnect\\\",\\n    arguments={\\\"connection_id\\\":
  connection_id}\\n)\\n```\\n\\n### Enabling Write Operations\\n\\nTo enable
  write operations, start the server with the `--allow-write`
  flag:\\n\\n```bash\\npython -m awslabs.documentdb_mcp_server.server
  --allow-write\\n```\\n\\nWhen the server is running with write operations
  enabled:\\n\\n```python\\n# This operation will succeed\\nquery_result = await
  use_mcp_tool(\\n    server_name=\\\"awslabs.aws-documentdb-mcp-server\\\",\\n    \
  tool_name=\\\"find\\\",\\n    arguments={\\n        \\\"connection_id\\\":
  connection_id,\\n        \\\"database\\\":
  \\\"my_database\\\",\\n        \\\"collection\\\":
  \\\"users\\\",\\n        \\\"query\\\": {\\\"active\\\":
  True}\\n    }\\n)\\n\\n# This operation will now succeed when --allow-write is
  used\\ninsert_result = await
  use_mcp_tool(\\n    server_name=\\\"awslabs.aws-documentdb-mcp-server\\\",\\n    \
  tool_name=\\\"insert\\\",\\n    arguments={\\n        \\\"connection_id\\\":
  connection_id,\\n        \\\"database\\\":
  \\\"my_database\\\",\\n        \\\"collection\\\":
  \\\"users\\\",\\n        \\\"documents\\\": {\\\"name\\\": \\\"New User\\\",
  \\\"active\\\": True}\\n    }\\n)\\n\\n# Without the --allow-write flag, you
  would receive this error:\\n# ValueError: \\\"Operation not permitted: Server
  is configured in read-only mode. Use --allow-write flag when starting the
  server to enable write operations.\\\"\\n```\\n\\n### Configure in your MCP
  client\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.documentdb-mcp-server&config=eyJjb21tYW5kIjoidXZ4I\
  GF3c2xhYnMuZG9jdW1lbnRkYi1tY3Atc2VydmVAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0\
  xFVkVMIjoiRVJST1IiLCJBV1NfUFJPRklMRSI6InlvdXItYXdzLXByb2ZpbGUifSwiZGlzYWJsZWQ\
  iOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nConfigure the MCP server in your MCP
  client configuration (e.g., for Amazon Q Developer CLI, edit
  ~/.aws/amazonq/mcp.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.documentdb-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.documentdb-mcp-server@latest\\\",\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Prerequisites\\n\\n- Network access to your DocumentDB cluster\\n- SSL/TLS
  certificate if your cluster requires TLS (typically
  `global-bundle.pem`)\\n\",\"isRecommended\":false,\"githubStars\":4398,\"down\
  loadCount\":35,\"createdAt\":\"2025-06-21T01:48:16.230182Z\",\"updatedAt\":\"\
  2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T13:31:06.466361Z\
  \"},{\"mcpId\":\"github.com/elevenlabs/elevenlabs-mcp\",\"githubUrl\":\"https\
  ://github.com/elevenlabs/elevenlabs-mcp\",\"name\":\"ElevenLabs\",\"author\":\
  \"elevenlabs\",\"description\":\"Enables AI assistants to interact with
  ElevenLabs' Text-to-Speech and audio processing APIs, supporting voice
  cloning, speech generation, transcription, and audio
  manipulation.\",\"codiconIcon\":\"unmute\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/elevenlabs.png\",\"category\":\"speech-process\
  ing\",\"tags\":[\"text-to-speech\",\"voice-cloning\",\"audio-processing\",\"t\
  ranscription\",\"voice-design\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"![export](https://github.com/user-attachments/assets/ee379feb-348d-48e7-899\
  c-134f7f7cd74f)\\n\\n<div class=\\\"title-block\\\" style=\\\"text-align:
  center;\\\" align=\\\"center\\\">\\n\\n  [![Discord
  Community](https://img.shields.io/badge/discord-@elevenlabs-000000.svg?style=\
  for-the-badge&logo=discord&labelColor=000)](https://discord.gg/elevenlabs)\\n  \
  [![Twitter](https://img.shields.io/badge/Twitter-@elevenlabsio-000000.svg?sty\
  le=for-the-badge&logo=twitter&labelColor=000)](https://x.com/ElevenLabsDevs)\
  \\n  [![PyPI](https://img.shields.io/badge/PyPI-elevenlabs--mcp-000000.svg?st\
  yle=for-the-badge&logo=pypi&labelColor=000)](https://pypi.org/project/elevenl\
  abs-mcp)\\n  [![Tests](https://img.shields.io/badge/tests-passing-000000.svg?\
  style=for-the-badge&logo=github&labelColor=000)](https://github.com/elevenlab\
  s/elevenlabs-mcp-server/actions/workflows/test.yml)\\n\\n</div>\\n\\n\\n<p
  align=\\\"center\\\">\\n  Official ElevenLabs <a
  href=\\\"https://github.com/modelcontextprotocol\\\">Model Context Protocol
  (MCP)</a> server that enables interaction with powerful Text to Speech and
  audio processing APIs. This server allows MCP clients like <a
  href=\\\"https://www.anthropic.com/claude\\\">Claude Desktop</a>, <a
  href=\\\"https://www.cursor.so\\\">Cursor</a>, <a
  href=\\\"https://codeium.com/windsurf\\\">Windsurf</a>, <a
  href=\\\"https://github.com/openai/openai-agents-python\\\">OpenAI Agents</a>
  and others to generate speech, clone voices, transcribe audio, and
  more.\\n</p>\\n\\n## Quickstart with Claude Desktop\\n\\n1. Get your API key
  from [ElevenLabs](https://elevenlabs.io/app/settings/api-keys). There is a
  free tier with 10k credits per month.\\n2. Install `uv` (Python package
  manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh` or
  see the `uv` [repo](https://github.com/astral-sh/uv) for additional install
  methods.\\n3. Go to Claude > Settings > Developer > Edit Config >
  claude_desktop_config.json to include the
  following:\\n\\n```\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"ElevenLabs\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"elevenlabs-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"ELEVENLABS_API_KEY\\\":
  \\\"<insert-your-api-key-here>\\\"\\n      }\\n    }\\n  }\\n}\\n\\n```\\n\\n\
  If you're using Windows, you will have to enable \\\"Developer Mode\\\" in
  Claude Desktop to use the MCP server. Click \\\"Help\\\" in the hamburger menu
  at the top left and select \\\"Enable Developer Mode\\\".\\n\\n## Other MCP
  clients\\n\\nFor other clients like Cursor and Windsurf, run:\\n1. `pip
  install elevenlabs-mcp`\\n2. `python -m elevenlabs_mcp
  --api-key={{PUT_YOUR_API_KEY_HERE}} --print` to get the configuration. Paste
  it into appropriate configuration directory specified by your MCP
  client.\\n\\nThat's it. Your MCP client can now interact with ElevenLabs
  through these tools:\\n\\n## Example usage\\n\\n Warning: ElevenLabs credits
  are needed to use these tools.\\n\\nTry asking Claude:\\n\\n- \\\"Create an AI
  agent that speaks like a film noir detective and can answer questions about
  classic movies\\\"\\n- \\\"Generate three voice variations for a wise, ancient
  dragon character, then I will choose my favorite voice to add to my voice
  library\\\"\\n- \\\"Convert this recording of my voice to sound like a
  medieval knight\\\"\\n- \\\"Create a soundscape of a thunderstorm in a dense
  jungle with animals reacting to the weather\\\"\\n- \\\"Turn this speech into
  text, identify different speakers, then convert it back using unique voices
  for each person\\\"\\n\\n## Optional features\\n\\nYou can add the
  `ELEVENLABS_MCP_BASE_PATH` environment variable to the
  `claude_desktop_config.json` to specify the base path MCP server should look
  for and output files specified with relative paths.\\n\\n##
  Contributing\\n\\nIf you want to contribute or run from source:\\n\\n1. Clone
  the repository:\\n\\n```bash\\ngit clone
  https://github.com/elevenlabs/elevenlabs-mcp\\ncd elevenlabs-mcp\\n```\\n\\n2.
  Create a virtual environment and install dependencies [using
  uv](https://github.com/astral-sh/uv):\\n\\n```bash\\nuv venv\\nsource
  .venv/bin/activate\\nuv pip install -e \\\".[dev]\\\"\\n```\\n\\n3. Copy
  `.env.example` to `.env` and add your ElevenLabs API key:\\n\\n```bash\\ncp
  .env.example .env\\n# Edit .env and add your API key\\n```\\n\\n4. Run the
  tests to make sure everything is working:\\n\\n```bash\\n./scripts/test.sh\\n#
  Or with options\\n./scripts/test.sh --verbose --fail-fast\\n```\\n\\n5.
  Install the server in Claude Desktop: `mcp install
  elevenlabs_mcp/server.py`\\n\\n6. Debug and test locally with MCP Inspector:
  `mcp dev elevenlabs_mcp/server.py`\\n\\n## Troubleshooting\\n\\nLogs when
  running with Claude Desktop can be found at:\\n\\n- **Windows**:
  `%APPDATA%\\\\Claude\\\\logs\\\\mcp-server-elevenlabs.log`\\n- **macOS**:
  `~/Library/Logs/Claude/mcp-server-elevenlabs.log`\\n\\n### Timeouts when using
  certain tools\\n\\nCertain ElevenLabs API operations, like voice design and
  audio isolation, can take a long time to resolve. When using the MCP inspector
  in dev mode, you might get timeout errors despite the tool completing its
  intended task.\\n\\nThis shouldn't occur when using a client like
  Claude.\\n\\n### MCP ElevenLabs: spawn uvx ENOENT\\n\\nIf you encounter the
  error \\\"MCP ElevenLabs: spawn uvx ENOENT\\\", confirm its absolute path by
  running this command in your terminal:\\n\\n```bash\\nwhich
  uvx\\n```\\n\\nOnce you obtain the absolute path (e.g., `/usr/local/bin/uvx`),
  update your configuration to use that path (e.g., `\\\"command\\\":
  \\\"/usr/local/bin/uvx\\\"`). This ensures that the correct executable is
  referenced.\\n\\n\\n\\n\",\"isRecommended\":false,\"githubStars\":790,\"downl\
  oadCount\":1344,\"createdAt\":\"2025-04-07T20:07:46.994814Z\",\"updatedAt\":\
  \"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T04:03:55.5956\
  35Z\"},{\"mcpId\":\"github.com/motherduckdb/mcp-server-motherduck\",\"githubU\
  rl\":\"https://github.com/motherduckdb/mcp-server-motherduck\",\"name\":\"Mot\
  herDuck\",\"author\":\"motherduckdb\",\"description\":\"Enables database
  operations with MotherDuck and local DuckDB, providing tools for connection
  initialization, schema reading, and query
  execution.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/motherduck-db.png\",\"category\":\"databases\",\
  \"tags\":[\"duckdb\",\"motherduck\",\"sql\",\"database-management\",\"query-e\
  xecution\"],\"requiresApiKey\":false,\"readmeContent\":\"# MotherDuck's DuckDB
  MCP Server\\n\\nAn MCP server implementation that interacts with DuckDB and
  MotherDuck databases, providing SQL analytics capabilities to AI Assistants
  and IDEs.\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=DuckDB&config=eyJjb21tYW5kIjoidXZ4IG1jcC1zZXJ2ZXItbW90aGVyZ\
  HVjayAtLWRiLXBhdGggbWQ6IiwiZW52Ijp7Im1vdGhlcmR1Y2tfdG9rZW4iOiIifX0%3D)\\n\\n##
  Resources\\n- [Close the Loop: Faster Data Pipelines with MCP, DuckDB & AI
  (Blogpost)](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb\
  -ai/)\\n- [Faster Data Pipelines development with MCP and DuckDB
  (YouTube)](https://www.youtube.com/watch?v=yG1mv8ZRxcU)\\n\\n##
  Features\\n\\n- **Hybrid execution**: query data from local DuckDB or/and
  cloud-based MotherDuck databases\\n- **Cloud storage integration**: access
  data stored in Amazon S3 or other cloud storage thanks to MotherDuck's
  integrations\\n- **Data sharing**: create and share databases\\n- **SQL
  analytics**: use DuckDB's SQL dialect to query any size of data directly from
  your AI Assistant or IDE\\n- **Serverless architecture**: run analytics
  without needing to configure instances or clusters\\n\\n## Components\\n\\n###
  Prompts\\n\\nThe server provides one prompt:\\n\\n-
  `duckdb-motherduck-initial-prompt`: A prompt to initialize a connection to
  DuckDB or MotherDuck and start working with it\\n\\n### Tools\\n\\nThe server
  offers one tool:\\n\\n- `query`: Execute a SQL query on the DuckDB or
  MotherDuck database\\n  - **Inputs**:\\n    - `query` (string, required): The
  SQL query to execute\\n\\nAll interactions with both DuckDB and MotherDuck are
  done through writing SQL queries.\\n\\n## Command Line Parameters\\n\\nThe MCP
  server supports the following parameters:\\n\\n| Parameter | Type | Default |
  Description                                                                                                                                                                                                                                                    \
  |\\n|-----------|------|---------|-------------------------------------------\
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------|\\n| `--transport`
  | Choice | `stdio` | Transport type. Options: `stdio`, `sse`,
  `stream`                                                                                                                                                                                                              \
  |\\n| `--port` | Integer | `8000` | Port to listen on for sse and stream
  transport
  mode                                                                                                                                                                                                            \
  |\\n| `--db-path` | String | `md:` | Path to local DuckDB database file or
  MotherDuck
  database                                                                                                                                                                                                      \
  |\\n| `--motherduck-token` | String | `None` | Access token to use for
  MotherDuck database connections (uses `motherduck_token` env var by
  default)                                                                                                                                                           \
  |\\n| `--read-only` | Flag | `False` | Flag for connecting to DuckDB or
  MotherDuck in read-only mode. For DuckDB it uses short-lived connections to
  enable concurrent
  access                                                                                                                          \
  |\\n| `--home-dir` | String | `None` | Home directory for DuckDB (uses `HOME`
  env var by
  default)                                                                                                                                                                                                     \
  |\\n| `--saas-mode` | Flag | `False` | Flag for connecting to MotherDuck in
  [SaaS
  mode](https://motherduck.com/docs/key-tasks/authenticating-and-connecting-to-\
  motherduck/authenticating-to-motherduck/#authentication-using-saas-mode).
  (disables filesystem and write permissions for local DuckDB) |\\n|
  `--json-response` | Flag | `False` | Enable JSON responses for HTTP stream.
  Only supported for `stream`
  transport                                                                                                                                                                                   \
  |\\n\\n### Quick Usage Examples\\n\\n```bash\\n# Connect to local DuckDB file
  in read-only mode with stream transport mode\\nuvx mcp-server-motherduck
  --transport stream --db-path /path/to/local.db --read-only\\n\\n# Connect to
  MotherDuck with token with stream transport mode\\nuvx mcp-server-motherduck
  --transport stream --db-path md: --motherduck-token YOUR_TOKEN\\n\\n# Connect
  to local DuckDB file in read-only mode with stream transport mode\\nuvx
  mcp-server-motherduck --transport stream --db-path /path/to/local.db
  --read-only\\n\\n# Connect to MotherDuck in SaaS mode for enhanced security
  with stream transport mode\\nuvx mcp-server-motherduck --transport stream
  --db-path md: --motherduck-token YOUR_TOKEN --saas-mode\\n```\\n\\n## Getting
  Started\\n\\n### General Prerequisites\\n\\n- `uv` installed, you can install
  it using `pip install uv` or `brew install uv`\\n\\nIf you plan to use the MCP
  with Claude Desktop or any other MCP comptabile client, the client need to be
  installed.\\n\\n### Prerequisites for DuckDB\\n\\n- No prerequisites. The MCP
  server can create an in-memory database on-the-fly\\n- Or connect to an
  existing local DuckDB database file , or one stored on remote object storage
  (e.g., AWS S3).\\n\\nSee [Connect to local
  DuckDB](#connect-to-local-duckdb).\\n\\n### Prerequisites for
  MotherDuck\\n\\n- Sign up for a [MotherDuck
  account](https://app.motherduck.com/?auth_flow=signup)\\n- Generate an access
  token via the [MotherDuck
  UI](https://app.motherduck.com/settings/tokens?auth_flow=signup)\\n- Store the
  token securely for use in the configuration\\n\\n### Usage with Cursor\\n\\n1.
  Install Cursor from [cursor.com/downloads](https://www.cursor.com/downloads)
  if you haven't already\\n\\n2. Open Cursor:\\n\\n- To set it up globally for
  the first time, go to Settings->MCP and click on \\\"+ Add new global MCP
  server\\\".\\n- This will open a `mcp.json` file to which you add the
  following configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"md:\\\",\\n        \\\"--motherduck-token\\\",\\n        \\\"<YOUR_MOTHER\
  DUCK_TOKEN_HERE>\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### Usage with VS
  Code\\n\\n[![Install with UV in VS
  Code](https://img.shields.io/badge/VS_Code-Install_with_UV-0098FF?style=plast\
  ic)](https://insiders.vscode.dev/redirect/mcp/install?name=mcp-server-motherd\
  uck&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22mcp-server-mothe\
  rduck%22%2C%22--db-path%22%2C%22md%3A%22%2C%22--motherduck-token%22%2C%22%24%\
  7Binput%3Amotherduck_token%7D%22%5D%7D&inputs=%5B%7B%22type%22%3A%22promptStr\
  ing%22%2C%22id%22%3A%22motherduck_token%22%2C%22description%22%3A%22MotherDuc\
  k+Token%22%2C%22password%22%3Atrue%7D%5D) [![Install with UV in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_with_UV-24bfa\
  5?style=plastic&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/in\
  stall?name=mcp-server-motherduck&config=%7B%22command%22%3A%22uvx%22%2C%22arg\
  s%22%3A%5B%22mcp-server-motherduck%22%2C%22--db-path%22%2C%22md%3A%22%2C%22--\
  motherduck-token%22%2C%22%24%7Binput%3Amotherduck_token%7D%22%5D%7D&inputs=%5\
  B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22motherduck_token%22%2C%22\
  description%22%3A%22MotherDuck+Token%22%2C%22password%22%3Atrue%7D%5D&quality\
  =insiders)\\n\\nFor the quickest installation, click one of the \\\"Install
  with UV\\\" buttons at the top.\\n\\n#### Manual Installation\\n\\nAdd the
  following JSON block to your User Settings (JSON) file in VS Code. You can do
  this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User
  Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"motherduck_token\\\",\\n        \\\"description\\\": \\\"MotherDuck
  Token\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"motherduck\\\":
  {\\n        \\\"command\\\": \\\"uvx\\\",\\n        \\\"args\\\":
  [\\n          \\\"mcp-server-motherduck\\\",\\n          \\\"--db-path\\\",\\\
  n          \\\"md:\\\",\\n          \\\"--motherduck-token\\\",\\n          \\\
  \"${input:motherduck_token}\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nOptionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace. This will allow you to share the configuration with
  others.\\n\\n```json\\n{\\n  \\\"inputs\\\": [\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"motherduck_token\\\",\\n      \\\"description\\\": \\\"MotherDuck
  Token\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\":
  {\\n    \\\"motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"md:\\\",\\n        \\\"--motherduck-token\\\",\\n        \\\"${input:moth\
  erduck_token}\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### Usage with Claude
  Desktop\\n\\n1. Install Claude Desktop from
  [claude.ai/download](https://claude.ai/download) if you haven't
  already\\n\\n2. Open the Claude Desktop configuration file:\\n\\n- To quickly
  access it or create it the first time, open the Claude Desktop app, select
  Settings, and click on the \\\"Developer\\\" tab, finally click on the
  \\\"Edit Config\\\" button.\\n- Add the following configuration to your
  `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"md:\\\",\\n        \\\"--motherduck-token\\\",\\n        \\\"<YOUR_MOTHER\
  DUCK_TOKEN_HERE>\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n**Important
  Notes**:\\n\\n- Replace `YOUR_MOTHERDUCK_TOKEN_HERE` with your actual
  MotherDuck token\\n\\n## Securing your MCP Server when querying
  MotherDuck\\n\\nIf the MCP server is exposed to third parties and should only
  have read access to data, we recommend using a read scaling token and running
  the MCP server in SaaS mode.\\n\\n**Read Scaling Tokens** are special access
  tokens that enable scalable read operations by allowing up to 4 concurrent
  read replicas, improving performance for multiple end users while *restricting
  write capabilities*.\\nRefer to the [Read Scaling
  documentation](https://motherduck.com/docs/key-tasks/authenticating-and-conne\
  cting-to-motherduck/read-scaling/#creating-a-read-scaling-token) to learn how
  to create a read-scaling token.\\n\\n**SaaS Mode** in MotherDuck enhances
  security by restricting it's access to local files, databases, extensions, and
  configurations, making it ideal for third-party tools that require stricter
  environment protection. Learn more about it in the [SaaS Mode
  documentation](https://motherduck.com/docs/key-tasks/authenticating-and-conne\
  cting-to-motherduck/authenticating-to-motherduck/#authentication-using-saas-m\
  ode).\\n\\n**Secure Configuration**\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"md:\\\",\\n        \\\"--motherduck-token\\\",\\n        \\\"<YOUR_READ_S\
  CALING_TOKEN_HERE>\\\",\\n        \\\"--saas-mode\\\"\\n      ]\\n    }\\n  }\
  \\n}\\n```\\n\\n## Connect to local DuckDB\\n\\nTo connect to a local DuckDB,
  instead of using the MotherDuck token, specify the path to your local DuckDB
  database file or use `:memory:` for an in-memory database.\\n\\nIn-memory
  database:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\":memory:\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nLocal DuckDB
  file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-motherduck\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"/path/to/your/local.db\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nLocal
  DuckDB file in [readonly
  mode](https://duckdb.org/docs/stable/connect/concurrency.html):\\n\\n```json\
  \\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-server-motherduck\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"mcp-server-motherduck\\\",\\n        \\\"--db-path\\\",\\n        \
  \\\"/path/to/your/local.db\\\",\\n        \\\"--read-only\\\"\\n      ]\\n    \
  }\\n  }\\n}\\n```\\n\\n**Note**: readonly mode for local file-backed DuckDB
  connections also makes use of\\nshort lived connections. Each time the query
  MCP tool is used a temporary,\\nreaodnly connection is created + query is
  executed + connection is closed. This\\nfeature was motivated by a workflow
  where [DBT](https://www.getdbt.com) was for\\nmodeling data within duckdb and
  then an MCP client (Windsurf/Cline/Claude/Cursor)\\nwas used for exploring the
  database. The short lived connections allow each tool\\nto run and then
  release their connection, allowing the next tool to connect.\\n\\n## Example
  Queries\\n\\nOnce configured, you can e.g. ask Claude to run queries
  like:\\n\\n- \\\"Create a new database and table in MotherDuck\\\"\\n-
  \\\"Query data from my local CSV file\\\"\\n- \\\"Join data from my local
  DuckDB database with a table in MotherDuck\\\"\\n- \\\"Analyze data stored in
  Amazon S3\\\"\\n\\n## Running in SSE mode\\n\\nThe server can run in SSE mode
  in two ways:\\n\\n### Direct SSE mode\\n\\nRun the server directly in SSE mode
  using the `--transport sse` flag:\\n\\n```bash\\nuvx mcp-server-motherduck
  --transport sse --port 8000 --db-path md: --motherduck-token
  <your_motherduck_token>\\n```\\n\\nThis will start the server listening on the
  specified port (default 8000) and you can point your clients directly to this
  endpoint.\\n\\n### Using supergateway\\n\\nAlternatively, you can run SSE mode
  using `supergateway`:\\n\\n```bash\\nnpx -y supergateway --stdio \\\"uvx
  mcp-server-motherduck --db-path md: --motherduck-token
  <your_motherduck_token>\\\"\\n```\\n\\nBoth methods allow you to point your
  clients such as Claude Desktop, Cursor to the SSE endpoint.\\n\\n##
  Development configuration\\n\\nTo run the server from a local development
  environment, use the following configuration:\\n\\n```json\\n
  {\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-server-motherduck\\\":
  {\\n      \\\"command\\\": \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/path/to/your/local/mcp-server\
  -motherduck\\\",\\n        \\\"run\\\",\\n        \\\"mcp-server-motherduck\\\
  \",\\n        \\\"--db-path\\\",\\n        \\\"md:\\\",\\n        \\\"--mothe\
  rduck-token\\\",\\n        \\\"<YOUR_MOTHERDUCK_TOKEN_HERE>\\\"\\n      ]\\n    \
  }\\n  }\\n}\\n```\\n\\n## Troubleshooting\\n\\n- If you encounter connection
  issues, verify your MotherDuck token is correct\\n- For local file access
  problems, ensure the `--home-dir` parameter is set correctly\\n- Check that
  the `uvx` command is available in your PATH\\n- If you encounter [`spawn uvx
  ENOENT`](https://github.com/motherduckdb/mcp-server-motherduck/issues/6)
  errors, try specifying the full path to `uvx` (output of `which uvx`)\\n- In
  version previous for v0.4.0 we used environment variables, now we use
  parameters\\n\\n## License\\n\\nThis MCP server is licensed under the MIT
  License. This means you are free to use, modify, and distribute the software,
  subject to the terms and conditions of the MIT License. For more details,
  please see the LICENSE file in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":231,\"downloadCount\"\
  :290,\"createdAt\":\"2025-02-18T06:08:00.70702Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T12:27:48.205953Z\"},{\"mcp\
  Id\":\"github.com/browserbase/mcp-server-browserbase\",\"githubUrl\":\"https:\
  //github.com/browserbase/mcp-server-browserbase\",\"name\":\"Browserbase\",\"\
  author\":\"browserbase\",\"description\":\"Cloud browser automation server
  enabling LLMs to interact with web pages, take screenshots, extract data, and
  execute JavaScript using Browserbase and
  Puppeteer.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/browserbase.png\",\"category\":\"browser-automat\
  ion\",\"tags\":[\"web-automation\",\"puppeteer\",\"screenshot-capture\",\"dat\
  a-extraction\",\"javascript-execution\"],\"requiresApiKey\":false,\"readmeCon\
  tent\":\"# Browserbase MCP Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/@browserbasehq/mcp-browserbase)](https://smi\
  thery.ai/server/@browserbasehq/mcp-browserbase)\\n\\n![cover](assets/cover-mc\
  p.png)\\n\\n[The Model Context Protocol
  (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that
  enables seamless integration between LLM applications and external data
  sources and tools. Whether youre building an AI-powered IDE, enhancing a chat
  interface, or creating custom AI workflows, MCP provides a standardized way to
  connect LLMs with the context they need.\\n\\nThis server provides cloud
  browser automation capabilities using
  [Browserbase](https://www.browserbase.com/) and
  [Stagehand](https://github.com/browserbase/stagehand). This server enables
  LLMs to interact with web pages, take screenshots, and execute JavaScript in a
  cloud browser environment.\\n\\nTo learn to get started with Browserbase,
  check out [Browserbase MCP](./browserbase/README.md) or [Stagehand
  MCP](./stagehand/README.md).\\n\\n## Getting Started with available
  MCPs\\n\\n **Browserbase MCP** - Located in
  [`browserbase/`](./browserbase/)\\n\\n| Feature            |
  Description                               |\\n| ------------------ |
  ----------------------------------------- |\\n| Browser Automation | Control
  and orchestrate cloud browsers    |\\n| Data Extraction    | Extract
  structured data from any webpage  |\\n| Console Monitoring | Track and analyze
  browser console logs    |\\n| Screenshots        | Capture full-page and
  element screenshots |\\n| Web Interaction    | Navigate, click, and fill forms
  with ease |\\n\\n **Stagehand MCP** - Located in
  [`stagehand/`](./stagehand/)\\n\\n| Feature             |
  Description                                                                                                                                                    \
  |\\n| ------------------- |
  -----------------------------------------------------------------------------\
  -----------------------------------------------------------------------------\
  ---- |\\n| Atomic Instructions | Execute precise actions like `act(\\\"click
  the login button\\\")` or `extract(\\\"find the red
  shoes\\\")`                                                                |\
  \\n| Model Flexibility   | Supports multiple models, including OpenAI's GPT-4
  and Anthropic's Claude-3.7
  Sonnet                                                                           \
  |\\n| Modular Design      | Easily integrate new models with minimal
  changes                                                                                                               \
  |\\n| Vision Support      | Use annotated screenshots for complex
  DOMs                                                                                                                     \
  |\\n| Open Source         | Contribute to the project and join the [Slack
  community](https://join.slack.com/t/stagehand-dev/shared_invite/zt-2uvuobu50-\
  ~wVSx2Si75CPa3332hwVEw) for support |\\n\\n### Alternative Installation
  Methods\\n\\n[Smithery](https://smithery.ai/server/@browserbasehq/mcp-browser\
  base)\\n\\n### Credits\\n\\nHuge thanks and shoutout to the Playwright team
  for their contributions to the framework, and their work on the [Playwright
  MCP
  Server](https://github.com/microsoft/playwright-mcp)\",\"isRecommended\":true,\
  \"githubStars\":2116,\"downloadCount\":2542,\"createdAt\":\"2025-02-18T06:27:\
  48.955864Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\
  \"2025-07-04T11:26:38.267965Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/mai\
  n/src/aws-diagram-mcp-server\",\"githubUrl\":\"https://github.com/awslabs/mcp\
  /tree/main/src/aws-diagram-mcp-server\",\"name\":\"AWS
  Diagrams\",\"author\":\"awslabs\",\"description\":\"Creates professional AWS
  architecture diagrams, sequence diagrams, flow charts, and class diagrams
  using Python code and the Diagrams package
  DSL.\",\"codiconIcon\":\"symbol-structure\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/aws.png\",\"category\":\"developer-tools\",\"\
  tags\":[\"diagrams\",\"aws-architecture\",\"visualization\",\"documentation\",\
  \"python\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Diagram MCP
  Server\\n\\nModel Context Protocol (MCP) server for AWS Diagrams\\n\\nThis MCP
  server that seamlessly creates [diagrams](https://diagrams.mingrammer.com/)
  using the Python diagrams package DSL. This server allows you to generate AWS
  diagrams, sequence diagrams, flow diagrams, and class diagrams using Python
  code.\\n\\n[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.s\
  vg)](tests/)\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Install GraphViz
  https://www.graphviz.org/\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.aws-diagram-mcp-server&config=eyJjb21tYW5kIjoidXZ4\
  IGF3c2xhYnMuYXdzLWRpYWdyYW0tbWNwLXNlcnZlciIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFT\
  CI6IkVSUk9SIn0sImF1dG9BcHByb3ZlIjpbXSwiZGlzYWJsZWQiOmZhbHNlfQ%3D%3D)\\n\\nCon\
  figure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-diagram-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.aws-diagram-mcp-server\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"autoApprove\\\":
  [],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/aws-diagram-mcp-server
  .`:\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.aws-diagram-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"awslabs/aws-diagram-mcp-server:latest\\\"\\n        ],\
  \\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n\\n##
  Features\\n\\nThe Diagrams MCP Server provides the following
  capabilities:\\n\\n1. **Generate Diagrams**: Create professional diagrams
  using Python code\\n2. **Multiple Diagram Types**: Support for AWS
  architecture, sequence diagrams, flow charts, class diagrams, and more\\n3.
  **Customization**: Customize diagram appearance, layout, and styling\\n4.
  **Security**: Code scanning to ensure secure diagram generation\\n\\n## Quick
  Example\\n\\n```python\\nfrom diagrams import Diagram\\nfrom
  diagrams.aws.compute import Lambda\\nfrom diagrams.aws.database import
  Dynamodb\\nfrom diagrams.aws.network import APIGateway\\n\\nwith
  Diagram(\\\"Serverless Application\\\", show=False):\\n    api =
  APIGateway(\\\"API Gateway\\\")\\n    function =
  Lambda(\\\"Function\\\")\\n    database =
  Dynamodb(\\\"DynamoDB\\\")\\n\\n    api >> function >> database\\n```\\n\\n##
  Development\\n\\n### Testing\\n\\nThe project includes a comprehensive test
  suite to ensure the functionality of the MCP server. The tests are organized
  by module and cover all aspects of the server's functionality.\\n\\nTo run the
  tests, use the provided script:\\n\\n```bash\\n./run_tests.sh\\n```\\n\\nThis
  script will automatically install pytest and its dependencies if they're not
  already installed.\\n\\nOr run pytest directly (if you have pytest
  installed):\\n\\n```bash\\npytest -xvs tests/\\n```\\n\\nTo run with
  coverage:\\n\\n```bash\\npytest --cov=awslabs.aws_diagram_mcp_server
  --cov-report=term-missing tests/\\n```\\n\\nFor more information about the
  tests, see the [tests README](tests/README.md).\\n\\n### Development
  Dependencies\\n\\nTo set up the development environment, install the
  development dependencies:\\n\\n```bash\\nuv pip install -e
  \\\".[dev]\\\"\\n```\\n\\nThis will install the required dependencies for
  development, including pytest, pytest-asyncio, and
  pytest-cov.\\n\",\"isRecommended\":false,\"githubStars\":4358,\"downloadCount\
  \":4231,\"createdAt\":\"2025-04-24T06:33:05.379596Z\",\"updatedAt\":\"2025-07\
  -08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T14:54:16.014868Z\"},{\
  \"mcpId\":\"github.com/pashpashpash/mcp-dice\",\"githubUrl\":\"https://github\
  .com/pashpashpash/mcp-dice\",\"name\":\"Dice
  Roller\",\"author\":\"pashpashpash\",\"description\":\"A server for rolling
  dice using standard dice notation, providing individual rolls, sums, and
  modifiers with timestamp
  tracking.\",\"codiconIcon\":\"symbol-number\",\"logoUrl\":\"https://storage.g\
  oogleapis.com/cline_public_images/dice-roller.png\",\"category\":\"entertainm\
  ent-media\",\"tags\":[\"dice-rolling\",\"random-generation\",\"gaming\",\"pro\
  bability\",\"tabletop\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  mcp-dice: A MCP Server for Rolling Dice\\n\\nA Model Context Protocol (MCP)
  server that enables Large Language Models (LLMs) to roll dice. It accepts
  standard dice notation (e.g., `1d20`) and returns both individual rolls and
  their
  sum.\\n\\n![screenshot](https://github.com/user-attachments/assets/ff7615b8-4\
  6ba-4be5-8287-8e1bf348ae28)\\n\\n## Features\\n- Supports standard dice
  notation (e.g., `1d20`, `3d6`, `2d8+1`)\\n- Returns both individual rolls and
  the total sum\\n- Easy integration with Claude Desktop\\n- Compatible with MCP
  Inspector for debugging\\n\\n## Installation\\n\\n1. **Clone the
  Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-dice.git\\n   cd mcp-dice\\n   ```\\n\\n2.
  **Set up Python Environment**:\\n   ```bash\\n   python -m venv
  venv\\n   source venv/bin/activate  # On Windows, use:
  venv\\\\Scripts\\\\activate\\n   ```\\n\\n3. **Install
  Dependencies**:\\n   ```bash\\n   pip install -e .\\n   ```\\n\\n4. **Install
  Development Dependencies** (optional):\\n   ```bash\\n   pip install -e
  \\\".[dev]\\\"\\n   ```\\n\\n## Usage\\n\\n### Input Format\\nThe server
  accepts a JSON object with a `notation`
  field:\\n```json\\n{\\n  \\\"notation\\\":
  \\\"2d6+3\\\"\\n}\\n```\\n\\nExample
  responses:\\n```json\\n{\\n  \\\"rolls\\\":
  [\\n    3,\\n    1\\n  ],\\n  \\\"sum\\\": 4,\\n  \\\"modifier\\\":
  3,\\n  \\\"total\\\": 7,\\n  \\\"notation\\\":
  \\\"2d6+3\\\",\\n  \\\"timestamp\\\":
  \\\"2024-12-03T16:36:38.926452\\\"\\n}\\n```\\n\\n## Claude Desktop
  Configuration\\n\\n### Configuration File Location\\n- macOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n### Basic
  Configuration\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"dice\\\":
  {\\n      \\\"command\\\": \\\"python\\\",\\n      \\\"args\\\": [\\\"-m\\\",
  \\\"mcp_dice\\\"],\\n      \\\"cwd\\\":
  \\\"path/to/mcp-dice\\\"\\n    }\\n  }\\n}\\n```\\nNote: Replace
  \\\"path/to/mcp-dice\\\" with the actual path to your cloned
  repository.\\n\\n### WSL
  Configuration\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"dice\\\":
  {\\n      \\\"command\\\": \\\"wsl\\\",\\n      \\\"args\\\":
  [\\n        \\\"-e\\\",\\n        \\\"python\\\",\\n        \\\"-m\\\",\\n        \
  \\\"mcp_dice\\\"\\n      ],\\n      \\\"cwd\\\":
  \\\"path/to/mcp-dice\\\"\\n    }\\n  }\\n}\\n```\\nNote: Adjust the path
  according to your WSL filesystem.\\n\\n## Development and Debugging\\n\\n###
  Running Tests\\n```bash\\npytest\\n```\\n\\n### Using MCP Inspector\\nThe [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector) is a useful tool
  for debugging your MCP server:\\n\\n```bash\\ncd path/to/mcp-dice\\nnpx
  @modelcontextprotocol/inspector python -m mcp_dice\\n```\\n\\nView logs
  with:\\n```bash\\ntail -n 20 -f ~/Library/Logs/Claude/mcp*.log\\n```\\n\\n##
  License\\n\\nLicensed under MIT - see [LICENSE](LICENSE)
  file.\\n\\n---\\nNote: This is a fork of the [original mcp-dice
  repository](https://github.com/yamaton/mcp-dice).\\n\",\"isRecommended\":fals\
  e,\"githubStars\":1,\"downloadCount\":180,\"createdAt\":\"2025-02-18T23:04:46\
  .967859Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\
  \"2025-06-23T15:31:08.320984Z\"},{\"mcpId\":\"github.com/pashpashpash/mcp-dis\
  cord\",\"githubUrl\":\"https://github.com/pashpashpash/mcp-discord\",\"name\":\
  \"Discord\",\"author\":\"pashpashpash\",\"description\":\"Provides
  comprehensive Discord server management capabilities including message
  handling, channel management, role administration, and webhook
  integration.\",\"codiconIcon\":\"comment-discussion\",\"logoUrl\":\"https://s\
  torage.googleapis.com/cline_public_images/discord.png\",\"category\":\"commun\
  ication\",\"tags\":[\"discord\",\"chat\",\"server-management\",\"webhooks\",\
  \"messaging\"],\"requiresApiKey\":false,\"readmeContent\":\"# Discord MCP
  Server\\n\\nA Model Context Protocol (MCP) server that provides Discord
  integration capabilities to MCP clients like Claude Desktop.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/wvwjgcnppa\\\"><img width=\\\"380\\\"
  height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/wvwjgcnppa/badge\\\"
  alt=\\\"mcp-discord MCP server\\\" /></a>\\n\\n## Features\\n\\n### Server
  Information\\n- `get_server_info`: Get detailed server information\\n-
  `list_members`: List server members and their roles\\n\\n### Message
  Management\\n- `send_message`: Send a message to a channel\\n-
  `read_messages`: Read recent message history\\n- `add_reaction`: Add a
  reaction to a message\\n- `add_multiple_reactions`: Add multiple reactions to
  a message\\n- `remove_reaction`: Remove a reaction from a message\\n-
  `moderate_message`: Delete messages and timeout users\\n\\n### Channel
  Management\\n- `create_text_channel`: Create a new text channel\\n-
  `delete_channel`: Delete an existing channel\\n\\n### Role Management\\n-
  `add_role`: Add a role to a user\\n- `remove_role`: Remove a role from a
  user\\n\\n### Webhook Management\\n- `create_webhook`: Create a new
  webhook\\n- `list_webhooks`: List webhooks in a channel\\n-
  `send_webhook_message`: Send messages via webhook\\n- `modify_webhook`: Update
  webhook settings\\n- `delete_webhook`: Delete a webhook\\n\\n##
  Prerequisites\\n\\n1. **Set up your Discord bot**:\\n   - Create a new
  application at [Discord Developer
  Portal](https://discord.com/developers/applications)\\n   - Create a bot and
  copy the token\\n   - Enable required privileged intents:\\n     - MESSAGE
  CONTENT INTENT\\n     - PRESENCE INTENT\\n     - SERVER MEMBERS INTENT\\n   -
  Invite the bot to your server using OAuth2 URL Generator\\n\\n2. **Python
  Requirements**:\\n   - Python 3.8 or higher\\n   - pip (Python package
  installer)\\n\\n## Installation\\n\\n1. **Clone the
  Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-discord.git\\n   cd
  mcp-discord\\n   ```\\n\\n2. **Create and Activate Virtual
  Environment**:\\n   ```bash\\n   # On Windows\\n   python -m venv
  venv\\n   venv\\\\Scripts\\\\activate\\n\\n   # On macOS/Linux\\n   python -m
  venv venv\\n   source venv/bin/activate\\n   ```\\n\\n3. **Install
  Dependencies**:\\n   ```bash\\n   pip install -e .\\n   ```\\n   Note: If
  using Python 3.13+, also install audioop: `pip install audioop-lts`\\n\\n4.
  **Configure Claude Desktop**:\\n\\nAdd this to your
  claude_desktop_config.json:\\n- macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"discord\\\": {\\n      \\\"command\\\":
  \\\"python\\\",\\n      \\\"args\\\": [\\\"-m\\\",
  \\\"mcp-discord\\\"],\\n      \\\"cwd\\\":
  \\\"path/to/mcp-discord\\\",\\n      \\\"env\\\":
  {\\n        \\\"DISCORD_TOKEN\\\":
  \\\"your_bot_token\\\"\\n      }\\n    }\\n  }\\n}\\n```\\nNote: \\n- Replace
  \\\"path/to/mcp-discord\\\" with the actual path to your cloned repository\\n-
  Replace \\\"your_bot_token\\\" with your Discord bot token\\n\\n##
  Debugging\\n\\nIf you run into issues, check Claude Desktop's MCP
  logs:\\n```bash\\ntail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n```\\n\\nCommon issues:\\n1. **Token
  Errors**:\\n   - Verify your Discord bot token is correct\\n   - Check that
  all required intents are enabled\\n\\n2. **Permission Issues**:\\n   - Ensure
  the bot has proper permissions in your Discord server\\n   - Verify the bot's
  role hierarchy for role management commands\\n\\n3. **Installation
  Issues**:\\n   - Make sure you're using the correct Python version\\n   - Try
  recreating the virtual environment\\n   - Check that all dependencies are
  installed correctly\\n\\n## License\\n\\nMIT License - see LICENSE file for
  details.\\n\\n---\\nNote: This is a fork of the [original mcp-discord
  repository](https://github.com/hanweg/mcp-discord).\\n\",\"isRecommended\":fa\
  lse,\"githubStars\":8,\"downloadCount\":1078,\"createdAt\":\"2025-02-19T01:25\
  :52.857709Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\
  \":\"2025-07-06T14:03:50.285159Z\"},{\"mcpId\":\"github.com/modelcontextproto\
  col/servers/tree/main/src/gitlab\",\"githubUrl\":\"https://github.com/modelco\
  ntextprotocol/servers/tree/main/src/gitlab\",\"name\":\"GitLab\",\"author\":\
  \"modelcontextprotocol\",\"description\":\"Enables comprehensive GitLab
  project management including file operations, issue tracking, merge requests,
  and repository management through the GitLab
  API.\",\"codiconIcon\":\"git-merge\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/gitlab.png\",\"category\":\"version-control\",\"tags\
  \":[\"gitlab\",\"git\",\"repository-management\",\"collaboration\",\"ci-cd\"],\
  \"requiresApiKey\":false,\"isRecommended\":true,\"githubStars\":57042,\"downl\
  oadCount\":5263,\"createdAt\":\"2025-02-17T22:46:26.88278Z\",\"updatedAt\":\"\
  2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T14:12:03.839026Z\
  \"},{\"mcpId\":\"github.com/modelcontextprotocol/servers/tree/main/src/filesy\
  stem\",\"githubUrl\":\"https://github.com/modelcontextprotocol/servers/tree/m\
  ain/src/filesystem\",\"name\":\"File
  System\",\"author\":\"modelcontextprotocol\",\"description\":\"Provides
  comprehensive filesystem operations including reading, writing, moving files,
  directory management, and advanced file editing with pattern matching and
  formatting
  capabilities.\",\"codiconIcon\":\"folder\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/file-system.png\",\"category\":\"file-systems\
  \",\"tags\":[\"filesystem\",\"file-management\",\"directory-operations\",\"fi\
  le-search\",\"file-editing\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Filesystem MCP Server\\n\\nNode.js server implementing Model Context Protocol
  (MCP) for filesystem operations.\\n\\n## Features\\n\\n- Read/write files\\n-
  Create/list/delete directories\\n- Move files/directories\\n- Search files\\n-
  Get file metadata\\n- Dynamic directory access control via
  [Roots](https://modelcontextprotocol.io/docs/concepts/roots)\\n\\n## Directory
  Access Control\\n\\nThe server uses a flexible directory access control
  system. Directories can be specified via command-line arguments or dynamically
  via [Roots](https://modelcontextprotocol.io/docs/concepts/roots).\\n\\n###
  Method 1: Command-line Arguments\\nSpecify Allowed directories when starting
  the server:\\n```bash\\nmcp-server-filesystem /path/to/dir1
  /path/to/dir2\\n```\\n\\n### Method 2: MCP Roots (Recommended)\\nMCP clients
  that support [Roots](https://modelcontextprotocol.io/docs/concepts/roots) can
  dynamically update the Allowed directories. \\n\\nRoots notified by Client to
  Server, completely replace any server-side Allowed directories when
  provided.\\n\\n**Important**: If server starts without command-line arguments
  AND client doesn't support roots protocol (or provides empty roots), the
  server will throw an error during initialization.\\n\\nThis is the recommended
  method, as this enables runtime directory updates via `roots/list_changed`
  notifications without server restart, providing a more flexible and modern
  integration experience.\\n\\n### How It Works\\n\\nThe server's directory
  access control follows this flow:\\n\\n1. **Server Startup**\\n   - Server
  starts with directories from command-line arguments (if provided)\\n   - If no
  arguments provided, server starts with empty allowed directories\\n\\n2.
  **Client Connection & Initialization**\\n   - Client connects and sends
  `initialize` request with capabilities\\n   - Server checks if client supports
  roots protocol (`capabilities.roots`)\\n   \\n3. **Roots Protocol Handling**
  (if client supports roots)\\n   - **On initialization**: Server requests roots
  from client via `roots/list`\\n   - Client responds with its configured
  roots\\n   - Server replaces ALL allowed directories with client's
  roots\\n   - **On runtime updates**: Client can send
  `notifications/roots/list_changed`\\n   - Server requests updated roots and
  replaces allowed directories again\\n\\n4. **Fallback Behavior** (if client
  doesn't support roots)\\n   - Server continues using command-line directories
  only\\n   - No dynamic updates possible\\n\\n5. **Access Control**\\n   - All
  filesystem operations are restricted to allowed directories\\n   - Use
  `list_allowed_directories` tool to see current directories\\n   - Server
  requires at least ONE allowed directory to operate\\n\\n**Note**: The server
  will only allow operations within directories specified either via `args` or
  via Roots.\\n\\n\\n\\n## API\\n\\n### Resources\\n\\n- `file://system`: File
  system operations interface\\n\\n### Tools\\n\\n- **read_file**\\n  - Read
  complete contents of a file\\n  - Input: `path` (string)\\n  - Reads complete
  file contents with UTF-8 encoding\\n\\n- **read_multiple_files**\\n  - Read
  multiple files simultaneously\\n  - Input: `paths` (string[])\\n  - Failed
  reads won't stop the entire operation\\n\\n- **write_file**\\n  - Create new
  file or overwrite existing (exercise caution with this)\\n  - Inputs:\\n    -
  `path` (string): File location\\n    - `content` (string): File content\\n\\n-
  **edit_file**\\n  - Make selective edits using advanced pattern matching and
  formatting\\n  - Features:\\n    - Line-based and multi-line content
  matching\\n    - Whitespace normalization with indentation
  preservation\\n    - Multiple simultaneous edits with correct
  positioning\\n    - Indentation style detection and preservation\\n    -
  Git-style diff output with context\\n    - Preview changes with dry run
  mode\\n  - Inputs:\\n    - `path` (string): File to edit\\n    - `edits`
  (array): List of edit operations\\n      - `oldText` (string): Text to search
  for (can be substring)\\n      - `newText` (string): Text to replace
  with\\n    - `dryRun` (boolean): Preview changes without applying (default:
  false)\\n  - Returns detailed diff and match information for dry runs,
  otherwise applies changes\\n  - Best Practice: Always use dryRun first to
  preview changes before applying them\\n\\n- **create_directory**\\n  - Create
  new directory or ensure it exists\\n  - Input: `path` (string)\\n  - Creates
  parent directories if needed\\n  - Succeeds silently if directory
  exists\\n\\n- **list_directory**\\n  - List directory contents with [FILE] or
  [DIR] prefixes\\n  - Input: `path` (string)\\n\\n- **move_file**\\n  - Move or
  rename files and directories\\n  - Inputs:\\n    - `source` (string)\\n    -
  `destination` (string)\\n  - Fails if destination exists\\n\\n-
  **search_files**\\n  - Recursively search for files/directories\\n  -
  Inputs:\\n    - `path` (string): Starting directory\\n    - `pattern`
  (string): Search pattern\\n    - `excludePatterns` (string[]): Exclude any
  patterns. Glob formats are supported.\\n  - Case-insensitive matching\\n  -
  Returns full paths to matches\\n\\n- **get_file_info**\\n  - Get detailed
  file/directory metadata\\n  - Input: `path` (string)\\n  - Returns:\\n    -
  Size\\n    - Creation time\\n    - Modified time\\n    - Access time\\n    -
  Type (file/directory)\\n    - Permissions\\n\\n-
  **list_allowed_directories**\\n  - List all directories the server is allowed
  to access\\n  - No input required\\n  - Returns:\\n    - Directories that this
  server can read/write from\\n\\n## Usage with Claude Desktop\\nAdd this to
  your `claude_desktop_config.json`:\\n\\nNote: you can provide sandboxed
  directories to the server by mounting them to `/projects`. Adding the `ro`
  flag will make the directory readonly by the server.\\n\\n### Docker\\nNote:
  all directories must be mounted to `/projects` by
  default.\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"filesystem\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"--mount\\\",
  \\\"type=bind,src=/Users/username/Desktop,dst=/projects/Desktop\\\",\\n        \
  \\\"--mount\\\",
  \\\"type=bind,src=/path/to/other/allowed/dir,dst=/projects/other/allowed/dir,\
  ro\\\",\\n        \\\"--mount\\\",
  \\\"type=bind,src=/path/to/file.txt,dst=/projects/path/to/file.txt\\\",\\n        \
  \\\"mcp/filesystem\\\",\\n        \\\"/projects\\\"\\n      ]\\n    }\\n  }\\\
  n}\\n```\\n\\n### NPX\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"filesystem\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@modelcontextprotocol/server-filesystem\
  \\\",\\n        \\\"/Users/username/Desktop\\\",\\n        \\\"/path/to/other\
  /allowed/dir\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Usage with VS
  Code\\n\\nFor quick installation, click the installation buttons
  below...\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=filesystem&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B\
  %22-y%22%2C%22%40modelcontextprotocol%2Fserver-filesystem%22%2C%22%24%7Bworks\
  paceFolder%7D%22%5D%7D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=filesystem&config=%7B%22command%22%3A%22npx%22%2C%22\
  args%22%3A%5B%22-y%22%2C%22%40modelcontextprotocol%2Fserver-filesystem%22%2C%\
  22%24%7BworkspaceFolder%7D%22%5D%7D&quality=insiders)\\n\\n[![Install with
  Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=filesystem&config=%7B%22command%22%3A%22docker%22%2C%22args%22\
  %3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22--mount%22%2C%22type%3Dbind%2Csr\
  c%3D%24%7BworkspaceFolder%7D%2Cdst%3D%2Fprojects%2Fworkspace%22%2C%22mcp%2Ffi\
  lesystem%22%2C%22%2Fprojects%22%5D%7D) [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=filesystem&config=%7B%22command%22%3A%22docker%22\
  %2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22--mount%22%2C%22typ\
  e%3Dbind%2Csrc%3D%24%7BworkspaceFolder%7D%2Cdst%3D%2Fprojects%2Fworkspace%22%\
  2C%22mcp%2Ffilesystem%22%2C%22%2Fprojects%22%5D%7D&quality=insiders)\\n\\nFor
  manual installation, add the following JSON block to your User Settings (JSON)
  file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing
  `Preferences: Open Settings (JSON)`.\\n\\nOptionally, you can add it to a file
  called `.vscode/mcp.json` in your workspace. This will allow you to share the
  configuration with others.\\n\\n> Note that the `mcp` key is not needed in the
  `.vscode/mcp.json` file.\\n\\nYou can provide sandboxed directories to the
  server by mounting them to `/projects`. Adding the `ro` flag will make the
  directory readonly by the server.\\n\\n### Docker\\nNote: all directories must
  be mounted to `/projects` by default. \\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"filesystem\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"-i\\\",\\n          \\\"--rm\\\",\
  \\n          \\\"--mount\\\",
  \\\"type=bind,src=${workspaceFolder},dst=/projects/workspace\\\",\\n          \
  \\\"mcp/filesystem\\\",\\n          \\\"/projects\\\"\\n        ]\\n      }\\\
  n    }\\n  }\\n}\\n```\\n\\n### NPX\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"filesystem\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\":
  [\\n          \\\"-y\\\",\\n          \\\"@modelcontextprotocol/server-filesy\
  stem\\\",\\n          \\\"${workspaceFolder}\\\"\\n        ]\\n      }\\n    }\
  \\n  }\\n}\\n```\\n\\n## Build\\n\\nDocker build:\\n\\n```bash\\ndocker build
  -t mcp/filesystem -f src/filesystem/Dockerfile .\\n```\\n\\n##
  License\\n\\nThis MCP server is licensed under the MIT License. This means you
  are free to use, modify, and distribute the software, subject to the terms and
  conditions of the MIT License. For more details, please see the LICENSE file
  in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":58210,\"downloadCount\
  \":87446,\"createdAt\":\"2025-02-17T22:22:00.256588Z\",\"updatedAt\":\"2025-0\
  7-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-08T00:28:14.570834Z\"},{\
  \"mcpId\":\"github.com/pashpashpash/google-calendar-mcp\",\"githubUrl\":\"htt\
  ps://github.com/pashpashpash/google-calendar-mcp\",\"name\":\"Google
  Calendar\",\"author\":\"pashpashpash\",\"description\":\"Enables AI assistants
  to read, create, and manage Google Calendar events, including processing
  events from screenshots and coordinating schedules across multiple
  calendars.\",\"codiconIcon\":\"calendar\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/google-calendar.png\",\"category\":\"calendar-m\
  anagement\",\"tags\":[\"google-calendar\",\"scheduling\",\"event-management\",\
  \"calendar-automation\",\"oauth\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"# Google Calendar MCP Server\\n\\nThis is a Model Context Protocol (MCP)
  server that provides integration with Google Calendar. It allows LLMs to read,
  create, and manage calendar events through a standardized interface.\\n\\n##
  Features\\n\\n- List available calendars\\n- List events from a calendar\\n-
  Create new calendar events\\n- Update existing events\\n- Delete events\\n-
  Process events from screenshots and images \\n\\n## Requirements\\n\\n-
  Node.js 16 or higher\\n- TypeScript 5.3 or higher\\n- A Google Cloud project
  with the Calendar API enabled\\n- OAuth 2.0 credentials (Client ID and Client
  Secret)\\n\\n## Project Structure\\n\\n```\\ngoogle-calendar-mcp/\\n
  src/           # TypeScript source files\\n build/         # Compiled
  JavaScript output\\n llm/           # LLM-specific configurations and
  prompts\\n package.json   # Project dependencies and scripts\\n
  tsconfig.json  # TypeScript configuration\\n```\\n\\n## Google Cloud
  Setup\\n\\n1. Go to the [Google Cloud
  Console](https://console.cloud.google.com)\\n2. Create a new project or select
  an existing one.\\n3. Enable the [Google Calendar
  API](https://console.cloud.google.com/apis/library/calendar-json.googleapis.c\
  om).\\n4. Create OAuth 2.0 credentials:\\n   - Go to **Credentials**\\n   -
  Click **\\\"Create Credentials\\\" > \\\"OAuth client ID\\\"**\\n   - Choose
  **\\\"User data\\\"** as the type of data the app will be accessing.\\n   -
  Add your app name and contact information.\\n   - Add the following scope
  (optional):\\n     - `https://www.googleapis.com/auth/calendar.events`\\n   -
  Select **\\\"Desktop app\\\"** as the application type.\\n   - Add your email
  address as a test user under the [OAuth Consent
  screen](https://console.cloud.google.com/apis/credentials/consent).\\n     -
  **Note:** It may take a few minutes for the test user to propagate.\\n\\n##
  Installation\\n\\n1. Clone the repository:\\n   ```sh\\n   git clone
  https://github.com/pashpashpash/google-calendar-mcp.git\\n   cd
  google-calendar-mcp\\n   ```\\n2. Install dependencies:\\n   ```sh\\n   npm
  install\\n   ```\\n3. Build the TypeScript code:\\n   ```sh\\n   npm run
  build\\n   ```\\n4. Download your Google OAuth credentials from the Google
  Cloud Console.\\n   - Rename the file to `gcp-oauth.keys.json`\\n   - Place it
  in the root directory of the project.\\n\\n5. Run the
  server:\\n   ```sh\\n   node build/index.js\\n   ```\\n\\n## Available
  Scripts\\n\\n- `npm run build` - Build the TypeScript code.\\n- `npm run
  build:watch` - Build TypeScript in watch mode for development.\\n- `npm run
  dev` - Start the server in development mode using ts-node.\\n- `npm run auth`
  - Start the authentication server for Google OAuth flow.\\n\\n##
  Authentication Setup\\n\\n### Automatic Authentication (Recommended)\\n\\n1.
  Ensure your OAuth credentials are in `gcp-oauth.keys.json`\\n2. Start the MCP
  server:\\n   ```sh\\n   npm start\\n   ```\\n3. If no authentication tokens
  are found, the server will:\\n   - Start an authentication server (on ports
  3000-3004).\\n   - Open a **browser window** for OAuth authentication.\\n   -
  Save the authentication tokens securely.\\n   - Shut down the authentication
  server and continue normal operation.\\n\\n### Manual Authentication\\n\\nIf
  you prefer to **manually authenticate**, run:\\n```sh\\nnpm run auth\\n```\\n-
  This starts an authentication server, opens a browser for OAuth, and saves the
  tokens.\\n\\n### Security Notes\\n\\n- OAuth credentials are stored in
  `gcp-oauth.keys.json`\\n- Authentication tokens are stored in
  `.gcp-saved-tokens.json` with 600 permissions.\\n- Tokens **refresh
  automatically** before expiration.\\n- If token refresh fails, youll be
  prompted to re-authenticate.\\n- **Never commit OAuth credentials or token
  files to version control.**\\n\\n## Usage\\n\\nThe server provides the
  following tools:\\n\\n| Tool            | Description
  |\\n|----------------|-------------|\\n| `list-calendars` | List all available
  calendars |\\n| `list-events`   | List events from a calendar |\\n|
  `create-event`  | Create a new calendar event |\\n| `update-event`  | Update
  an existing calendar event |\\n| `delete-event`  | Delete a calendar event
  |\\n\\n## Using with Claude Desktop\\n\\n1. Modify your Claude Desktop config
  file (e.g., `/Users/<user>/Library/Application
  Support/Claude/claude_desktop_config.json`):\\n   ```json\\n   {\\n     \\\"m\
  cpServers\\\": {\\n       \\\"google-calendar\\\":
  {\\n         \\\"command\\\": \\\"node\\\",\\n         \\\"args\\\":
  [\\\"path/to/build/index.js\\\"]\\n       }\\n     }\\n   }\\n   ```\\n2.
  Restart Claude Desktop.\\n\\n## Example Use Cases\\n\\n###  Add events from
  screenshots and images\\n```\\nAdd this event to my calendar based on the
  attached screenshot.\\n```\\n **Supported formats**: PNG, JPEG, GIF  \\n
  Extracts details like **date, time, location, description**  \\n\\n### 
  Check attendance\\n```\\nWhich events tomorrow have attendees who haven't
  accepted the invitation?\\n```\\n\\n###  Auto-schedule
  meetings\\n```\\nHere's availability from someone I'm interviewing. Find a
  time that works on my work calendar.\\n```\\n\\n###  Find free time across
  calendars\\n```\\nShow my available time slots for next week. Consider both my
  personal and work calendar.\\n```\\n\\n## Troubleshooting\\n\\n|
  Issue                        | Solution
  |\\n|------------------------------|-------------|\\n| OAuth token expires
  after 7 days | You must **re-authenticate** if the app is in testing mode.
  |\\n| OAuth token errors | Ensure `gcp-oauth.keys.json` is formatted
  correctly. |\\n| TypeScript build errors | Run `npm install` and `npm run
  build`. |\\n| Image processing issues | Ensure the image format is **PNG,
  JPEG, or GIF**. |\\n\\n## Security Notes\\n\\n- The server runs **locally**
  and requires **OAuth authentication**.\\n- OAuth credentials must be stored in
  `gcp-oauth.keys.json` in the project root.\\n- **Tokens refresh
  automatically** when expired.\\n- **DO NOT** commit credentials or tokens to
  version control.\\n- For **production use**, get your OAuth app verified by
  Google.\\n\\n## License\\n\\nThis project is licensed under the **MIT
  License**. See the [LICENSE](LICENSE) file for details.\\n\\n##
  Contributing\\n\\nWant to contribute?\\n\\n1. Fork the repository.\\n2. Create
  a new branch:\\n   ```sh\\n   git checkout -b feature-branch\\n   ```\\n3.
  Make changes & commit:\\n   ```sh\\n   git commit -m \\\"Added new
  feature\\\"\\n   ```\\n4. Push and open a **pull
  request**:\\n   ```sh\\n   git push origin feature-branch\\n   ```\\n\\n##
  Attribution\\n\\nThis project is a fork of the original
  **[nspady/google-calendar-mcp](https://github.com/nspady/google-calendar-mcp)\
  ** repository.\\n\\n## Stay Updated\\n\\n **[GitHub:
  pashpashpash/google-calendar-mcp](https://github.com/pashpashpash/google-cale\
  ndar-mcp)**\\n\\n---\\n\\n### TL;DR Setup\\n```sh\\ngit clone
  https://github.com/pashpashpash/google-calendar-mcp.git\\ncd
  google-calendar-mcp\\nnpm install\\nnpm run build\\nnode
  build/index.js\\n```\\nThen **connect your Notion integration and you're good
  to go!
  **\\n\",\"isRecommended\":false,\"githubStars\":20,\"downloadCount\":3158,\
  \"createdAt\":\"2025-02-19T01:25:47.301582Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-04T01:45:15.000643Z\"},{\"mcpId\":\
  \"github.com/browserbase/mcp-server-browserbase/tree/main/stagehand\",\"githu\
  bUrl\":\"https://github.com/browserbase/mcp-server-browserbase/tree/main/stag\
  ehand\",\"name\":\"Stagehand\",\"author\":\"browserbase\",\"description\":\"P\
  rovides AI-powered web automation capabilities using a real browser
  environment, enabling interaction with web pages, action performance, data
  extraction, and action
  observation.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/stagehand.png\",\"category\":\"browser-automat\
  ion\",\"tags\":[\"web-automation\",\"browser-control\",\"data-extraction\",\"\
  web-interaction\",\"screenshots\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"# Stagehand MCP Server\\n\\n![cover](../assets/stagehand-mcp.png)\\n\\nA
  Model Context Protocol (MCP) server that provides AI-powered web automation
  capabilities using [Stagehand](https://github.com/browserbase/stagehand). This
  server enables LLMs to interact with web pages, perform actions, extract data,
  and observe possible actions in a real browser environment.\\n\\n## Get
  Started\\n\\n1. Run `npm install` to install the necessary dependencies, then
  run `npm run build` to get `dist/index.js`.\\n\\n2. Set up your Claude Desktop
  configuration to use the server.  \\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"stagehand\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/mcp-server-browserbase/stagehand/dist/index.js\\\"],\\n      \\\
  \"env\\\": {\\n        \\\"BROWSERBASE_API_KEY\\\":
  \\\"<YOUR_BROWSERBASE_API_KEY>\\\",\\n        \\\"BROWSERBASE_PROJECT_ID\\\":
  \\\"<YOUR_BROWSERBASE_PROJECT_ID>\\\",\\n        \\\"OPENAI_API_KEY\\\":
  \\\"<YOUR_OPENAI_API_KEY>\\\",\\n        \\\"CONTEXT_ID\\\":
  \\\"<YOUR_CONTEXT_ID>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\nor, for running
  locally, first [**open Chrome in debug
  mode**](https://docs.stagehand.dev/examples/customize_browser#use-your-person\
  al-browser) like so:\\n\\n`open -a \\\"Google Chrome\\\" --args
  --remote-debugging-port=9222`\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"stagehand\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/mcp-server-browserbase/stagehand/dist/index.js\\\"],\\n      \\\
  \"env\\\": {\\n        \\\"OPENAI_API_KEY\\\":
  \\\"<YOUR_OPENAI_API_KEY>\\\",\\n        \\\"LOCAL_CDP_URL\\\":
  \\\"http://localhost:9222\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n>  Check
  out our
  [documentation](https://docs.stagehand.dev/examples/customize_browser#use-you\
  r-personal-browser) for getting your local CDP url!\\n\\n3. Restart your
  Claude Desktop app and you should see the tools available clicking the 
  icon.\\n\\n4. Start using the tools! Below is a demo video of Claude doing a
  Google search for OpenAI using stagehand MCP server and Browserbase for a
  remote headless browser.\\n\\n<div>\\n    <a
  href=\\\"https://www.loom.com/share/9fe52fd9ab24421191223645366ec1c5\\\">\\n      \
  <p>Stagehand MCP Server demo - Watch Video</p>\\n    </a>\\n    <a
  href=\\\"https://www.loom.com/share/9fe52fd9ab24421191223645366ec1c5\\\">\\n      \
  <img style=\\\"max-width:300px;\\\"
  src=\\\"https://cdn.loom.com/sessions/thumbnails/9fe52fd9ab24421191223645366e\
  c1c5-f1a228ffe52d8065-full-play.gif\\\">\\n    </a>\\n  </div>\\n\\n##
  Tools\\n\\n### Stagehand commands\\n\\n- **stagehand_navigate**\\n  - Navigate
  to any URL in the browser\\n  - Input:\\n    - `url` (string): The URL to
  navigate to\\n\\n- **stagehand_act**\\n  - Perform an action on the web
  page\\n  - Inputs:\\n    - `action` (string): The action to perform (e.g.,
  \\\"click the login button\\\")\\n    - `variables` (object, optional):
  Variables used in the action template\\n\\n- **stagehand_extract**\\n  -
  Extract data from the web page \\n\\n- **stagehand_observe**\\n  - Observe
  actions that can be performed on the web page\\n  - Input:\\n    -
  `instruction` (string, optional): Instruction for observation\\n\\n###
  Resources\\n\\nThe server provides access to one resource:\\n\\n1. **Console
  Logs** (`console://logs`)\\n\\n   - Browser console output in text
  format\\n   - Includes all console messages from the browser\\n\\n2.
  **Screenshots** (`screenshot://<n>`)\\n   - PNG images of captured
  screenshots\\n   - Accessible via the screenshot name specified during
  capture\\n\\n## File Structure\\n\\nThe codebase is organized into the
  following modules:\\n\\n- **index.ts**: Entry point that initializes and runs
  the server.\\n- **server.ts**: Core server logic, including server creation,
  configuration, and request handling.\\n- **tools.ts**: Definitions and
  implementations of tools that can be called by MCP clients.\\n-
  **prompts.ts**: Prompt templates that can be used by MCP clients.\\n-
  **resources.ts**: Resource definitions and handlers for resource-related
  requests.\\n- **logging.ts**: Comprehensive logging system with rotation and
  formatting capabilities.\\n- **utils.ts**: Utility functions including JSON
  Schema to Zod schema conversion and message sanitization.\\n\\n## Module
  Descriptions\\n\\n### index.ts\\n\\nThe main entry point for the application.
  It:\\n- Initializes the logging system\\n- Creates the server instance\\n-
  Connects to the stdio transport to receive and respond to requests\\n\\n###
  server.ts\\n\\nContains core server functionality:\\n- Creates and configures
  the MCP server\\n- Defines Stagehand configuration\\n- Sets up request
  handlers for all MCP operations\\n- Manages the Stagehand browser
  instance\\n\\n### tools.ts\\n\\nImplements the tools that can be called by MCP
  clients:\\n- `stagehand_navigate`: Navigate to URLs\\n- `stagehand_act`:
  Perform actions on web elements\\n- `stagehand_extract`: Extract structured
  data from web pages\\n- `stagehand_observe`: Observe elements on the page\\n-
  `screenshot`: Take screenshots of the current page\\n\\n###
  prompts.ts\\n\\nDefines prompt templates for MCP clients:\\n-
  `click_search_button`: Template for clicking search buttons\\n\\n###
  resources.ts\\n\\nManages resources in the MCP protocol:\\n- Currently
  provides empty resource and resource template lists\\n\\n###
  logging.ts\\n\\nImplements a comprehensive logging system:\\n- File-based
  logging with rotation\\n- In-memory operation logs\\n- Log formatting and
  sanitization\\n- Console logging for debugging\\n\\n### utils.ts\\n\\nProvides
  utility functions:\\n- `jsonSchemaToZod`: Converts JSON Schema to Zod schema
  for validation\\n- `sanitizeMessage`: Ensures messages are properly formatted
  JSON\\n\\n## Key Features\\n\\n- AI-powered web automation\\n- Perform actions
  on web pages\\n- Extract structured data from web pages\\n- Observe possible
  actions on web pages\\n- Simple and extensible API\\n- Model-agnostic support
  for various LLM providers\\n\\n## Environment Variables\\n\\n-
  `BROWSERBASE_API_KEY`: API key for BrowserBase authentication\\n-
  `BROWSERBASE_PROJECT_ID`: Project ID for BrowserBase\\n- `OPENAI_API_KEY`: API
  key for OpenAI (used by Stagehand)\\n- `DEBUG`: Enable debug logging\\n\\n##
  MCP Capabilities\\n\\nThis server implements the following MCP
  capabilities:\\n\\n- **Tools**: Allows clients to call tools that control a
  browser instance\\n- **Prompts**: Provides prompt templates for common
  operations\\n- **Resources**: (Currently empty but structured for future
  expansion)\\n- **Logging**: Provides detailed logging capabilities\\n\\nFor
  more information about the Model Context Protocol, visit:\\n- [MCP
  Documentation](https://modelcontextprotocol.io/docs)\\n- [MCP
  Specification](https://spec.modelcontextprotocol.io/)\\n\\n##
  License\\n\\nLicensed under the MIT License.\\n\\nCopyright 2024 Browserbase,
  Inc.\\n\",\"isRecommended\":false,\"githubStars\":2132,\"downloadCount\":3720,\
  \"createdAt\":\"2025-03-28T18:55:55.022866Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-07T04:59:40.229429Z\"},{\"mcpId\":\
  \"github.com/NightTrek/Software-planning-mcp\",\"githubUrl\":\"https://github\
  .com/NightTrek/Software-planning-mcp\",\"name\":\"Software
  Planning\",\"author\":\"NightTrek\",\"description\":\"Interactive tool for
  breaking down software projects into manageable tasks, tracking implementation
  progress, and maintaining detailed development plans with complexity scoring
  and code
  examples.\",\"codiconIcon\":\"project\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/software-planning.png\",\"category\":\"developer-\
  tools\",\"tags\":[\"project-planning\",\"task-management\",\"software-develop\
  ment\",\"todo-tracking\",\"documentation\"],\"requiresApiKey\":false,\"readme\
  Content\":\"# Software Planning Tool \\n[![smithery
  badge](https://smithery.ai/badge/@NightTrek/Software-planning-mcp)](https://s\
  mithery.ai/server/@NightTrek/Software-planning-mcp)\\n\\nA Model Context
  Protocol (MCP) server designed to facilitate software development planning
  through an interactive, structured approach. This tool helps break down
  complex software projects into manageable tasks, track implementation
  progress, and maintain detailed development plans.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/a35c7qc7ie\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/a35c7qc7ie/badge\\\" alt=\\\"Software
  Planning Tool MCP server\\\" />\\n</a>\\n\\n## Features \\n\\n- **Interactive
  Planning Sessions**: Start and manage development planning sessions\\n- **Todo
  Management**: Create, update, and track development tasks\\n- **Complexity
  Scoring**: Assign complexity scores to tasks for better estimation\\n- **Code
  Examples**: Include relevant code snippets in task descriptions\\n-
  **Implementation Plans**: Save and manage detailed implementation
  plans\\n\\n## Installation \\n\\n### Installing via Smithery\\n\\nTo
  install Software Planning Tool for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@NightTrek/Software-planning-mcp):\\n\\\
  n```bash\\nnpx -y @smithery/cli install @NightTrek/Software-planning-mcp
  --client claude\\n```\\n\\n### Manual Installation\\n1. Clone the
  repository\\n2. Install dependencies:\\n```bash\\npnpm install\\n```\\n3.
  Build the project:\\n```bash\\npnpm run build\\n```\\n4. Add to your MCP
  settings configuration (typically located at `~/Library/Application
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json`):\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"software-planning-tool\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\n        \\\"/path/to/software-planning-tool/build/index.js\\\"\\n      ],\
  \\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n## Available Tools \\n\\n###
  start_planning\\nStart a new planning session with a specific
  goal.\\n```typescript\\n{\\n  goal: string  // The software development goal
  to plan\\n}\\n```\\n\\n### add_todo\\nAdd a new todo item to the current
  plan.\\n```typescript\\n{\\n  title: string,         // Title of the todo
  item\\n  description: string,   // Detailed description\\n  complexity:
  number,    // Complexity score (0-10)\\n  codeExample?: string  // Optional
  code example\\n}\\n```\\n\\n### get_todos\\nRetrieve all todos in the current
  plan.\\n```typescript\\n// No parameters required\\n```\\n\\n###
  update_todo_status\\nUpdate the completion status of a todo
  item.\\n```typescript\\n{\\n  todoId: string,     // ID of the todo
  item\\n  isComplete: boolean // New completion status\\n}\\n```\\n\\n###
  save_plan\\nSave the current implementation
  plan.\\n```typescript\\n{\\n  plan: string  // The implementation plan
  text\\n}\\n```\\n\\n### remove_todo\\nRemove a todo item from the current
  plan.\\n```typescript\\n{\\n  todoId: string  // ID of the todo item to
  remove\\n}\\n```\\n\\n## Example Usage \\n\\nHere's a complete example of
  using the software planning tool:\\n\\n1. Start a planning
  session:\\n```typescript\\nawait
  client.callTool(\\\"software-planning-tool\\\", \\\"start_planning\\\",
  {\\n  goal: \\\"Create a React-based dashboard
  application\\\"\\n});\\n```\\n\\n2. Add a todo item:\\n```typescript\\nconst
  todo = await client.callTool(\\\"software-planning-tool\\\", \\\"add_todo\\\",
  {\\n  title: \\\"Set up project structure\\\",\\n  description: \\\"Initialize
  React project with necessary dependencies\\\",\\n  complexity:
  3,\\n  codeExample: `\\nnpx create-react-app dashboard\\ncd dashboard\\nnpm
  install @material-ui/core @material-ui/icons\\n  `\\n});\\n```\\n\\n3. Update
  todo status:\\n```typescript\\nawait
  client.callTool(\\\"software-planning-tool\\\", \\\"update_todo_status\\\",
  {\\n  todoId: todo.id,\\n  isComplete: true\\n});\\n```\\n\\n4. Save the
  implementation plan:\\n```typescript\\nawait
  client.callTool(\\\"software-planning-tool\\\", \\\"save_plan\\\", {\\n  plan:
  `\\n# Dashboard Implementation Plan\\n\\n## Phase 1: Setup (Complexity: 3)\\n-
  Initialize React project\\n- Install dependencies\\n- Set up routing\\n\\n##
  Phase 2: Core Features (Complexity: 5)\\n- Implement authentication\\n- Create
  dashboard layout\\n- Add data visualization
  components\\n  `\\n});\\n```\\n\\n## Development \\n\\n### Project
  Structure\\n```\\nsoftware-planning-tool/\\n   src/\\n     
  index.ts        # Main server implementation\\n      prompts.ts      #
  Planning prompts and templates\\n      storage.ts      # Data
  persistence\\n      types.ts        # TypeScript type definitions\\n  
  build/              # Compiled JavaScript\\n   package.json\\n  
  tsconfig.json\\n```\\n\\n### Building\\n```bash\\npnpm run
  build\\n```\\n\\n### Testing\\nTest all features using the MCP
  inspector:\\n```bash\\npnpm run inspector\\n```\\n\\n## License
  \\n\\nMIT\\n\\n---\\n\\nMade with  using the Model Context
  Protocol\",\"isRecommended\":false,\"githubStars\":300,\"downloadCount\":6371,\
  \"createdAt\":\"2025-02-18T23:03:50.971515Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-02T11:17:51.848006Z\"},{\"mcpId\":\
  \"github.com/ahujasid/ableton-mcp\",\"githubUrl\":\"https://github.com/ahujas\
  id/ableton-mcp\",\"name\":\"Ableton
  Live\",\"author\":\"ahujasid\",\"description\":\"Controls Ableton Live through
  socket-based communication, enabling AI-assisted music production with
  features like track creation, MIDI manipulation, instrument selection, and
  session
  control.\",\"codiconIcon\":\"music\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/ableton-live.png\",\"category\":\"entertainment-media\
  \",\"tags\":[\"music-production\",\"midi\",\"audio-editing\",\"daw-control\",\
  \"ableton\"],\"requiresApiKey\":false,\"readmeContent\":\"# AbletonMCP -
  Ableton Live Model Context Protocol Integration\\n[![smithery
  badge](https://smithery.ai/badge/@ahujasid/ableton-mcp)](https://smithery.ai/\
  server/@ahujasid/ableton-mcp)\\n\\nAbletonMCP connects Ableton Live to Claude
  AI through the Model Context Protocol (MCP), allowing Claude to directly
  interact with and control Ableton Live. This integration enables
  prompt-assisted music production, track creation, and Live session
  manipulation.\\n\\n### Join the Community\\n\\nGive feedback, get inspired,
  and build on top of the MCP: [Discord](https://discord.gg/3ZrMyGKnaU). Made by
  [Siddharth](https://x.com/sidahuj)\\n\\n## Features\\n\\n- **Two-way
  communication**: Connect Claude AI to Ableton Live through a socket-based
  server\\n- **Track manipulation**: Create, modify, and manipulate MIDI and
  audio tracks\\n- **Instrument and effect selection**: Claude can access and
  load the right instruments, effects and sounds from Ableton's library\\n-
  **Clip creation**: Create and edit MIDI clips with notes\\n- **Session
  control**: Start and stop playback, fire clips, and control transport\\n\\n##
  Components\\n\\nThe system consists of two main components:\\n\\n1. **Ableton
  Remote Script** (`Ableton_Remote_Script/__init__.py`): A MIDI Remote Script
  for Ableton Live that creates a socket server to receive and execute
  commands\\n2. **MCP Server** (`server.py`): A Python server that implements
  the Model Context Protocol and connects to the Ableton Remote Script\\n\\n##
  Installation\\n\\n### Installing via Smithery\\n\\nTo install Ableton Live
  Integration for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@ahujasid/ableton-mcp):\\n\\n```bash\\n\
  npx -y @smithery/cli install @ahujasid/ableton-mcp --client
  claude\\n```\\n\\n### Prerequisites\\n\\n- Ableton Live 10 or newer\\n- Python
  3.8 or newer\\n- [uv package manager](https://astral.sh/uv)\\n\\nIf you're on
  Mac, please install uv as:\\n```\\nbrew install uv\\n```\\n\\nOtherwise,
  install from [uv's official
  website][https://docs.astral.sh/uv/getting-started/installation/]\\n\\n Do
  not proceed before installing UV\\n\\n### Claude for Desktop
  Integration\\n\\n[Follow along with the setup instructions
  video](https://youtu.be/iJWJqyVuPS8)\\n\\n1. Go to Claude > Settings >
  Developer > Edit Config > claude_desktop_config.json to include the
  following:\\n\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n        \\\"AbletonMCP\\\": {\\n            \\\"command\\\":
  \\\"uvx\\\",\\n            \\\"args\\\":
  [\\n                \\\"ableton-mcp\\\"\\n            ]\\n        }\\n    }\\\
  n}\\n```\\n\\n### Cursor Integration\\n\\nRun ableton-mcp without installing
  it permanently through uvx. Go to Cursor Settings > MCP and paste this as a
  command:\\n\\n```\\nuvx ableton-mcp\\n```\\n\\n Only run one instance of the
  MCP server (either on Cursor or Claude Desktop), not both\\n\\n### Installing
  the Ableton Remote Script\\n\\n[Follow along with the setup instructions
  video](https://youtu.be/iJWJqyVuPS8)\\n\\n1. Download the
  `AbletonMCP_Remote_Script/__init__.py` file from this repo\\n\\n2. Copy the
  folder to Ableton's MIDI Remote Scripts directory. Different OS and versions
  have different locations. **One of these should work, you might have to
  look**:\\n\\n   **For macOS:**\\n   - Method 1: Go to Applications >
  Right-click on Ableton Live app  Show Package Contents  Navigate
  to:\\n     `Contents/App-Resources/MIDI Remote Scripts/`\\n   - Method 2: If
  it's not there in the first method, use the direct path (replace XX with your
  version number):\\n     `/Users/[Username]/Library/Preferences/Ableton/Live
  XX/User Remote Scripts`\\n   \\n   **For Windows:**\\n   - Method
  1:\\n     C:\\\\Users\\\\[Username]\\\\AppData\\\\Roaming\\\\Ableton\\\\Live
  x.x.x\\\\Preferences\\\\User Remote Scripts \\n   - Method
  2:\\n     `C:\\\\ProgramData\\\\Ableton\\\\Live XX\\\\Resources\\\\MIDI Remote
  Scripts\\\\`\\n   - Method 3:\\n     `C:\\\\Program Files\\\\Ableton\\\\Live
  XX\\\\Resources\\\\MIDI Remote Scripts\\\\`\\n   *Note: Replace XX with your
  Ableton version number (e.g., 10, 11, 12)*\\n\\n4. Create a folder called
  'AbletonMCP' in the Remote Scripts directory and paste the downloaded
  '\\\\_\\\\_init\\\\_\\\\_.py' file\\n\\n3. Launch Ableton Live\\n\\n4. Go to
  Settings/Preferences  Link, Tempo & MIDI\\n\\n5. In the Control Surface
  dropdown, select \\\"AbletonMCP\\\"\\n\\n6. Set Input and Output to
  \\\"None\\\"\\n\\n## Usage\\n\\n### Starting the Connection\\n\\n1. Ensure the
  Ableton Remote Script is loaded in Ableton Live\\n2. Make sure the MCP server
  is configured in Claude Desktop or Cursor\\n3. The connection should be
  established automatically when you interact with Claude\\n\\n### Using with
  Claude\\n\\nOnce the config file has been set on Claude, and the remote script
  is running in Ableton, you will see a hammer icon with tools for the Ableton
  MCP.\\n\\n## Capabilities\\n\\n- Get session and track information\\n- Create
  and modify MIDI and audio tracks\\n- Create, edit, and trigger clips\\n-
  Control playback\\n- Load instruments and effects from Ableton's browser\\n-
  Add notes to MIDI clips\\n- Change tempo and other session parameters\\n\\n##
  Example Commands\\n\\nHere are some examples of what you can ask Claude to
  do:\\n\\n- \\\"Create an 80s synthwave track\\\"
  [Demo](https://youtu.be/VH9g66e42XA)\\n- \\\"Create a Metro Boomin style
  hip-hop beat\\\"\\n- \\\"Create a new MIDI track with a synth bass
  instrument\\\"\\n- \\\"Add reverb to my drums\\\"\\n- \\\"Create a 4-bar MIDI
  clip with a simple melody\\\"\\n- \\\"Get information about the current
  Ableton session\\\"\\n- \\\"Load a 808 drum rack into the selected
  track\\\"\\n- \\\"Add a jazz chord progression to the clip in track 1\\\"\\n-
  \\\"Set the tempo to 120 BPM\\\"\\n- \\\"Play the clip in track
  2\\\"\\n\\n\\n## Troubleshooting\\n\\n- **Connection issues**: Make sure the
  Ableton Remote Script is loaded, and the MCP server is configured on
  Claude\\n- **Timeout errors**: Try simplifying your requests or breaking them
  into smaller steps\\n- **Have you tried turning it off and on again?**: If
  you're still having connection errors, try restarting both Claude and Ableton
  Live\\n\\n## Technical Details\\n\\n### Communication Protocol\\n\\nThe system
  uses a simple JSON-based protocol over TCP sockets:\\n\\n- Commands are sent
  as JSON objects with a `type` and optional `params`\\n- Responses are JSON
  objects with a `status` and `result` or `message`\\n\\n### Limitations &
  Security Considerations\\n\\n- Creating complex musical arrangements might
  need to be broken down into smaller steps\\n- The tool is designed to work
  with Ableton's default devices and browser items\\n- Always save your work
  before extensive experimentation\\n\\n## Contributing\\n\\nContributions are
  welcome! Please feel free to submit a Pull Request.\\n\\n##
  Disclaimer\\n\\nThis is a third-party integration and not made by
  Ableton.\\n\",\"isRecommended\":false,\"githubStars\":1736,\"downloadCount\":\
  728,\"createdAt\":\"2025-03-27T20:04:05.827143Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T07:38:24.65385Z\"},{\"mcpId\
  \":\"github.com/supabase-community/supabase-mcp\",\"githubUrl\":\"https://git\
  hub.com/supabase-community/supabase-mcp\",\"name\":\"Supabase\",\"author\":\"\
  supabase-community\",\"description\":\"Enables AI assistants to interact with
  Supabase projects, providing tools for database management, project
  configuration, migrations, and TypeScript type
  generation.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/supabase.png\",\"category\":\"databases\",\"ta\
  gs\":[\"supabase\",\"postgresql\",\"database-management\",\"migrations\",\"pr\
  oject-management\"],\"requiresApiKey\":false,\"readmeContent\":\"# Supabase
  MCP Server\\n\\n> Connect your Supabase projects to Cursor, Claude, Windsurf,
  and other AI
  assistants.\\n\\n![supabase-mcp-demo](https://github.com/user-attachments/ass\
  ets/3fce101a-b7d4-482f-9182-0be70ed1ad56)\\n\\nThe [Model Context
  Protocol](https://modelcontextprotocol.io/introduction) (MCP) standardizes how
  Large Language Models (LLMs) talk to external services like Supabase. It
  connects AI assistants directly with your Supabase project and allows them to
  perform tasks like managing tables, fetching config, and querying data. See
  the [full list of tools](#tools).\\n\\n## Prerequisites\\n\\nYou will need
  Node.js installed on your machine. You can check this by
  running:\\n\\n```shell\\nnode -v\\n```\\n\\nIf you don't have Node.js
  installed, you can download it from [nodejs.org](https://nodejs.org/).\\n\\n##
  Setup\\n\\n### 1. Personal access token (PAT)\\n\\nFirst, go to your [Supabase
  settings](https://supabase.com/dashboard/account/tokens) and create a personal
  access token. Give it a name that describes its purpose, like \\\"Cursor MCP
  Server\\\".\\n\\nThis will be used to authenticate the MCP server with your
  Supabase account. Make sure to copy the token, as you won't be able to see it
  again.\\n\\n### 2. Configure MCP client\\n\\nNext, configure your MCP client
  (such as Cursor) to use this server. Most MCP clients store the configuration
  as JSON in the following format:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"supabase\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@supabase/mcp-server-supabase@latest\\\
  \",\\n        \\\"--read-only\\\",\\n        \\\"--project-ref=<project-ref>\\\
  \"\\n      ],\\n      \\\"env\\\": {\\n        \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"<personal-access-token>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nReplace
  `<personal-access-token>` with the token you created in step 1. Alternatively
  you can omit `SUPABASE_ACCESS_TOKEN` in this config and instead set it
  globally on your machine. This allows you to keep your token out of version
  control if you plan on committing this configuration to a repository.\\n\\nThe
  following options are available:\\n\\n- `--read-only`: Used to restrict the
  server to read-only queries. Recommended by default. See [read-only
  mode](#read-only-mode).\\n- `--project-ref`: Used to scope the server to a
  specific project. Recommended by default. If you omit this, the server will
  have access to all projects in your Supabase account. See [project scoped
  mode](#project-scoped-mode).\\n- `--features`: Used to specify which tool
  groups to enable. See [feature groups](#feature-groups).\\n\\nIf you are on
  Windows, you will need to [prefix the command](#windows). If your MCP client
  doesn't accept JSON, the direct CLI command is:\\n\\n```shell\\nnpx -y
  @supabase/mcp-server-supabase@latest --read-only
  --project-ref=<project-ref>\\n```\\n\\n> Note: Do not run this command
  directly - this is meant to be executed by your MCP client in order to start
  the server. `npx` automatically downloads the latest version of the MCP server
  from `npm` and runs it in a single command.\\n\\n#### Windows\\n\\nOn Windows,
  you will need to prefix the command with `cmd
  /c`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"supabase\\\":
  {\\n      \\\"command\\\": \\\"cmd\\\",\\n      \\\"args\\\":
  [\\n        \\\"/c\\\",\\n        \\\"npx\\\",\\n        \\\"-y\\\",\\n        \
  \\\"@supabase/mcp-server-supabase@latest\\\",\\n        \\\"--read-only\\\",\
  \\n        \\\"--project-ref=<project-ref>\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"<personal-access-token>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nor with
  `wsl` if you are running Node.js inside
  WSL:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"supabase\\\":
  {\\n      \\\"command\\\": \\\"wsl\\\",\\n      \\\"args\\\":
  [\\n        \\\"npx\\\",\\n        \\\"-y\\\",\\n        \\\"@supabase/mcp-se\
  rver-supabase@latest\\\",\\n        \\\"--read-only\\\",\\n        \\\"--proj\
  ect-ref=<project-ref>\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"<personal-access-token>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nMake
  sure Node.js is available in your system `PATH` environment variable. If you
  are running Node.js natively on Windows, you can set this by running the
  following commands in your terminal.\\n\\n1. Get the path to
  `npm`:\\n\\n   ```shell\\n   npm config get prefix\\n   ```\\n\\n2. Add the
  directory to your PATH:\\n\\n   ```shell\\n   setx PATH
  \\\"%PATH%;<path-to-dir>\\\"\\n   ```\\n\\n3. Restart your MCP
  client.\\n\\n### Project scoped mode\\n\\nWithout project scoping, the MCP
  server will have access to all organizations and projects in your Supabase
  account. We recommend you restrict the server to a specific project by setting
  the `--project-ref` flag on the CLI command:\\n\\n```shell\\nnpx -y
  @supabase/mcp-server-supabase@latest
  --project-ref=<project-ref>\\n```\\n\\nReplace `<project-ref>` with the ID of
  your project. You can find this under **Project ID** in your Supabase [project
  settings](https://supabase.com/dashboard/project/_/settings/general).\\n\\nAf\
  ter scoping the server to a project, [account-level](#project-management)
  tools like `list_projects` and `list_organizations` will no longer be
  available. The server will only have access to the specified project and its
  resources.\\n\\n### Read-only mode\\n\\nTo restrict the Supabase MCP server to
  read-only queries, set the `--read-only` flag on the CLI
  command:\\n\\n```shell\\nnpx -y @supabase/mcp-server-supabase@latest
  --read-only\\n```\\n\\nWe recommend you enable this by default. This prevents
  write operations on any of your databases by executing SQL as a read-only
  Postgres user. Note that this flag only applies to database tools
  (`execute_sql` and `apply_migration`) and not to other tools like
  `create_project` or `create_branch`.\\n\\n### Feature groups\\n\\nYou can
  enable or disable specific tool groups by passing the `--features` flag to the
  MCP server. This allows you to customize which tools are available to the LLM.
  For example, to enable only the [database](#database) and
  [docs](#knowledge-base) tools, you would run:\\n\\n```shell\\nnpx -y
  @supabase/mcp-server-supabase@latest
  --features=database,docs\\n```\\n\\nAvailable groups are:
  [`account`](#account), [`docs`](#knowledge-base), [`database`](#database),
  [`debug`](#debug), [`development`](#development),
  [`functions`](#edge-functions), [`storage`](#storage), and
  [`branching`](#branching-experimental-requires-a-paid-plan).\\n\\nIf this flag
  is not passed, the default feature groups are: `account`, `database`, `debug`,
  `development`, `docs`, `functions`, and `branching`.\\n\\n##
  Tools\\n\\n_**Note:** This server is pre-1.0, so expect some breaking changes
  between versions. Since LLMs will automatically adapt to the tools available,
  this shouldn't affect most users._\\n\\nThe following Supabase tools are
  available to the LLM, [grouped by feature](#feature-groups).\\n\\n####
  Account\\n\\nEnabled by default when no `--project-ref` is passed. Use
  `account` to target this group of tools with the
  [`--features`](#feature-groups) option.\\n\\n_**Note:** these tools will be
  unavailable if the server is [scoped to a
  project](#project-scoped-mode)._\\n\\n- `list_projects`: Lists all Supabase
  projects for the user.\\n- `get_project`: Gets details for a project.\\n-
  `create_project`: Creates a new Supabase project.\\n- `pause_project`: Pauses
  a project.\\n- `restore_project`: Restores a project.\\n-
  `list_organizations`: Lists all organizations that the user is a member
  of.\\n- `get_organization`: Gets details for an organization.\\n- `get_cost`:
  Gets the cost of a new project or branch for an organization.\\n-
  `confirm_cost`: Confirms the user's understanding of new project or branch
  costs. This is required to create a new project or branch.\\n\\n#### Knowledge
  Base\\n\\nEnabled by default. Use `docs` to target this group of tools with
  the [`--features`](#feature-groups) option.\\n\\n- `search_docs`: Searches the
  Supabase documentation for up-to-date information. LLMs can use this to find
  answers to questions or learn how to use specific features.\\n\\n####
  Database\\n\\nEnabled by default. Use `database` to target this group of tools
  with the [`--features`](#feature-groups) option.\\n\\n- `list_tables`: Lists
  all tables within the specified schemas.\\n- `list_extensions`: Lists all
  extensions in the database.\\n- `list_migrations`: Lists all migrations in the
  database.\\n- `apply_migration`: Applies a SQL migration to the database. SQL
  passed to this tool will be tracked within the database, so LLMs should use
  this for DDL operations (schema changes).\\n- `execute_sql`: Executes raw SQL
  in the database. LLMs should use this for regular queries that don't change
  the schema.\\n\\n#### Debug\\n\\nEnabled by default. Use `debug` to target
  this group of tools with the [`--features`](#feature-groups) option.\\n\\n-
  `get_logs`: Gets logs for a Supabase project by service type (api, postgres,
  edge functions, auth, storage, realtime). LLMs can use this to help with
  debugging and monitoring service performance.\\n- `get_advisors`: Gets a list
  of advisory notices for a Supabase project. LLMs can use this to check for
  security vulnerabilities or performance issues.\\n\\n####
  Development\\n\\nEnabled by default. Use `development` to target this group of
  tools with the [`--features`](#feature-groups) option.\\n\\n-
  `get_project_url`: Gets the API URL for a project.\\n- `get_anon_key`: Gets
  the anonymous API key for a project.\\n- `generate_typescript_types`:
  Generates TypeScript types based on the database schema. LLMs can save this to
  a file and use it in their code.\\n\\n#### Edge Functions\\n\\nEnabled by
  default. Use `functions` to target this group of tools with the
  [`--features`](#feature-groups) option.\\n\\n- `list_edge_functions`: Lists
  all Edge Functions in a Supabase project.\\n- `deploy_edge_function`: Deploys
  a new Edge Function to a Supabase project. LLMs can use this to deploy new
  functions or update existing ones.\\n\\n#### Branching (Experimental, requires
  a paid plan)\\n\\nEnabled by default. Use `branching` to target this group of
  tools with the [`--features`](#feature-groups) option.\\n\\n- `create_branch`:
  Creates a development branch with migrations from production branch.\\n-
  `list_branches`: Lists all development branches.\\n- `delete_branch`: Deletes
  a development branch.\\n- `merge_branch`: Merges migrations and edge functions
  from a development branch to production.\\n- `reset_branch`: Resets migrations
  of a development branch to a prior version.\\n- `rebase_branch`: Rebases
  development branch on production to handle migration drift.\\n\\n####
  Storage\\n\\nDisabled by default to reduce tool count. Use `storage` to target
  this group of tools with the [`--features`](#feature-groups) option.\\n\\n-
  `list_storage_buckets`: Lists all storage buckets in a Supabase project.\\n-
  `get_storage_config`: Gets the storage config for a Supabase project.\\n-
  `update_storage_config`: Updates the storage config for a Supabase project
  (requires a paid plan).\\n\\n## Other MCP servers\\n\\n###
  `@supabase/mcp-server-postgrest`\\n\\nThe PostgREST MCP server allows you to
  connect your own users to your app via REST API. See more details on its
  [project README](./packages/mcp-server-postgrest).\\n\\n## Resources\\n\\n-
  [**Model Context Protocol**](https://modelcontextprotocol.io/introduction):
  Learn more about MCP and its capabilities.\\n- [**From development to
  production**](/docs/production.md): Learn how to safely promote changes to
  production environments.\\n\\n## For developers\\n\\nThis repo uses npm for
  package management, and the latest LTS version of Node.js.\\n\\nClone the repo
  and run:\\n\\n```\\nnpm install --ignore-scripts\\n```\\n\\n> [!NOTE]\\n> On
  recent versions of MacOS, you may have trouble installing the `libpg-query`
  transient dependency without the `--ignore-scripts` flag.\\n\\n##
  License\\n\\nThis project is licensed under Apache 2.0. See the
  [LICENSE](./LICENSE) file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":1725,\"downloadCount\":\
  9093,\"createdAt\":\"2025-04-04T16:08:19.129363Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T22:10:23.969996Z\"},{\"mc\
  pId\":\"github.com/awslabs/mcp/tree/main/src/stepfunctions-tool-mcp-server\",\
  \"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/stepfunctions-to\
  ol-mcp-server\",\"name\":\"Step
  Functions\",\"author\":\"awslabs\",\"description\":\"Enables AI models to
  execute and manage AWS Step Functions state machines as tools, supporting both
  Standard and Express workflows with input validation via EventBridge Schema
  Registry.\",\"codiconIcon\":\"workflow\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\
  \":[\"aws\",\"workflows\",\"automation\",\"state-machines\",\"serverless\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"# AWS Step Functions Tool MCP
  Server\\n\\nA Model Context Protocol (MCP) server for AWS Step Functions to
  select and run state machines as MCP tools without code changes.\\n\\n##
  Features\\n\\nThis MCP server acts as a **bridge** between MCP clients and AWS
  Step Functions state machines, allowing generative AI models to access and run
  state machines as tools. This enables seamless integration with existing Step
  Function workflows without requiring any modifications to their definitions.
  Through this bridge, AI models can execute and manage complex, multi-step
  business processes that coordinate operations across multiple AWS
  services.\\n\\nThe server supports both Standard and Express workflows,
  adapting to different execution needs. Standard workflows excel at
  long-running processes where status tracking is essential, while Express
  workflows handle high-volume, short-duration tasks with synchronous execution.
  This flexibility ensures optimal handling of various workflow patterns and
  requirements.\\n\\nTo ensure data quality and provide clear documentation, the
  server integrates with EventBridge Schema Registry for input validation. It
  combines schema information with state machine definitions to generate
  comprehensive tool documentation, helping AI models understand both the
  purpose and technical requirements of each workflow.\\n\\nFrom a security
  perspective, the server implements IAM-based authentication and authorization,
  creating a clear separation of duties. While models can invoke state machines
  through the MCP server, they don't have direct access to other AWS services.
  Instead, the state machines themselves handle AWS service interactions using
  their own IAM roles, maintaining robust security boundaries while enabling
  powerful workflow capabilities.\\n\\n```mermaid\\ngraph LR\\n    A[Model] <-->
  B[MCP Client]\\n    B <--> C[\\\"MCP2StepFunctions<br>(MCP
  Server)\\\"]\\n    C <--> D[State Machine]\\n    D <--> E[Other AWS
  Services]\\n    D <--> F[Internet]\\n    D <--> G[VPC]\\n\\n    style A
  fill:#f9f,stroke:#333,stroke-width:2px\\n    style B
  fill:#bbf,stroke:#333,stroke-width:2px\\n    style C
  fill:#bfb,stroke:#333,stroke-width:4px\\n    style D
  fill:#fbb,stroke:#333,stroke-width:2px\\n    style E
  fill:#fbf,stroke:#333,stroke-width:2px\\n    style F
  fill:#dff,stroke:#333,stroke-width:2px\\n    style G
  fill:#ffd,stroke:#333,stroke-width:2px\\n```\\n\\n## Prerequisites\\n\\n1.
  Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.stepfunctions-tool-mcp-server&config=eyJjb21tYW5kI\
  joidXZ4IGF3c2xhYnMuc3RlcGZ1bmN0aW9ucy10b29sLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ij\
  p7IkFXU19QUk9GSUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTE\
  iLCJTVEFURV9NQUNISU5FX1BSRUZJWCI6InlvdXItc3RhdGUtbWFjaGluZS1wcmVmaXgiLCJTVEFU\
  RV9NQUNISU5FX0xJU1QiOiJ5b3VyLWZpcnN0LXN0YXRlLW1hY2hpbmUsIHlvdXItc2Vjb25kLXN0Y\
  XRlLW1hY2hpbmUiLCJTVEFURV9NQUNISU5FX1RBR19LRVkiOiJ5b3VyLXRhZy1rZXkiLCJTVEFURV\
  9NQUNISU5FX1RBR19WQUxVRSI6InlvdXItdGFnLXZhbHVlIiwiU1RBVEVfTUFDSElORV9JTlBVVF9\
  TQ0hFTUFfQVJOX1RBR19LRVkiOiJ5b3VyLXN0YXRlLW1hY2hpbmUtdGFnLWZvci1pbnB1dC1zY2hl\
  bWEifX0%3D)\\n\\nConfigure the MCP server in your MCP client configuration
  (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.stepfunctions-tool-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.stepfunctions-tool-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"STATE_MACHINE_PREFIX\\\":
  \\\"your-state-machine-prefix\\\",\\n        \\\"STATE_MACHINE_LIST\\\":
  \\\"your-first-state-machine,
  your-second-state-machine\\\",\\n        \\\"STATE_MACHINE_TAG_KEY\\\":
  \\\"your-tag-key\\\",\\n        \\\"STATE_MACHINE_TAG_VALUE\\\":
  \\\"your-tag-value\\\",\\n        \\\"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\\\
  \":
  \\\"your-state-machine-tag-for-input-schema\\\"\\n      }\\n    }\\n  }\\n}\\\
  n```\\n\\nor docker after a successful `docker build -t
  awslabs/stepfunctions-tool-mcp-server .`:\\n\\n```file\\n# fictitious `.env`
  file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.stepfunctions-tool-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"AWS_REGION=us-east-1\\\
  \",\\n          \\\"--env\\\",\\n          \\\"STATE_MACHINE_PREFIX=your-stat\
  e-machine-prefix\\\",\\n          \\\"--env\\\",\\n          \\\"STATE_MACHIN\
  E_LIST=your-first-state-machine,your-second-state-machine\\\",\\n          \\\
  \"--env\\\",\\n          \\\"STATE_MACHINE_TAG_KEY=your-tag-key\\\",\\n          \
  \\\"--env\\\",\\n          \\\"STATE_MACHINE_TAG_VALUE=your-tag-value\\\",\\n          \
  \\\"--env\\\",\\n          \\\"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY=your-st\
  ate-machine-tag-for-input-schema\\\",\\n          \\\"--env-file\\\",\\n          \
  \\\"/full/path/to/file/above/.env\\\",\\n          \\\"awslabs/stepfunctions-\
  tool-mcp-server:latest\\\"\\n        ],\\n        \\\"env\\\":
  {},\\n        \\\"disabled\\\": false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\nThe `AWS_PROFILE` and the `AWS_REGION` are
  optional, their default values are `default` and `us-east-1`.\\n\\nYou can
  specify `STATE_MACHINE_PREFIX`, `STATE_MACHINE_LIST`, or both. If both are
  empty, all state machines pass the name check.\\nAfter the name check, if both
  `STATE_MACHINE_TAG_KEY` and `STATE_MACHINE_TAG_VALUE` are set, state machines
  are further filtered by tag (with key=value).\\nIf only one of
  `STATE_MACHINE_TAG_KEY` and `STATE_MACHINE_TAG_VALUE`, then no state machine
  is selected and a warning is displayed.\\n\\n## Tool Documentation\\n\\nThe
  MCP server builds comprehensive tool documentation by combining multiple
  sources of information to help AI models understand and use state machines
  effectively.\\n\\n1. **State Machine Description**: The state machine's
  description field provides the base tool description. For
  example:\\n   ```plaintext\\n   Retrieve customer status on the CRM system
  based on { 'customerId' } or { 'customerEmail' }\\n   ```\\n\\n2. **Workflow
  Description**: The Comment field from the state machine definition adds
  workflow context. For example:\\n   ```json\\n   {\\n     \\\"Comment\\\":
  \\\"This workflow first looks up a customer ID from email, then retrieves
  their info\\\",\\n     \\\"StartAt\\\":
  \\\"GetCustomerId\\\",\\n     \\\"States\\\": { ... }\\n   }\\n   ```\\n\\n3.
  **Input Schema**: The server integrates with EventBridge Schema Registry to
  provide formal JSON Schema documentation for state machine inputs. To enable
  schema support:\\n   - Create your schema in EventBridge Schema
  Registry\\n   - Tag your state machine with the schema
  ARN:\\n     ```plaintext\\n     Key: STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY
  (configurable)\\n     Value:
  arn:aws:schemas:region:account:schema/registry-name/schema-name\\n     ```\\n   \
  - Configure the MCP server:\\n     ```json\\n     {\\n       \\\"env\\\":
  {\\n         \\\"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\\\":
  \\\"your-schema-arn-tag-key\\\"\\n       }\\n     }\\n     ```\\n\\nThe server
  combines these sources into a unified documentation
  format:\\n```plaintext\\n[State Machine Description]\\n\\nWorkflow
  Description: [Comment from state machine definition]\\n\\nInput
  Schema:\\n[JSON Schema from EventBridge Schema Registry]\\n```\\n\\nThis
  comprehensive documentation helps AI models understand both the purpose and
  technical requirements of each state machine, with formal schema support
  ensuring correct input formatting.\\n\\n## Best practices\\n\\n- Use the
  `STATE_MACHINE_LIST` to specify the state machines that are available as MCP
  tools.\\n- Use the `STATE_MACHINE_PREFIX` to specify the prefix of the state
  machines that are available as MCP tools.\\n- Use the `STATE_MACHINE_TAG_KEY`
  and `STATE_MACHINE_TAG_VALUE` to specify the tag key and value of the state
  machines that are available as MCP tools.\\n- AWS Step Functions `Description`
  property: the description of the state machine is used as MCP tool
  description, so it should be very detailed to help the model understand when
  and how to use the state machine\\n- Add workflow documentation using the
  `Comment` field in state machine definitions:\\n  - Describe the workflow's
  purpose and steps\\n  - Explain any important logic or conditions\\n  -
  Document expected inputs and outputs\\n- Use EventBridge Schema Registry to
  provide formal input definition:\\n  - Create JSON Schema definitions for your
  state machine inputs\\n  - Tag state machines with their schema ARNs\\n  -
  Configure `STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY` in the MCP server\\n\\n##
  Security Considerations\\n\\nWhen using this MCP server, you should
  consider:\\n\\n- Only state machines that are in the provided list or with a
  name starting with the prefix are imported as MCP tools.\\n- The MCP server
  needs permissions to invoke the state machines.\\n- Each state machine has its
  own permissions to optionally access other AWS
  resources.\\n\",\"isRecommended\":false,\"githubStars\":4404,\"downloadCount\
  \":38,\"createdAt\":\"2025-06-21T01:37:24.720466Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T22:29:50.560224Z\"},{\"m\
  cpId\":\"github.com/neondatabase/mcp-server-neon\",\"githubUrl\":\"https://gi\
  thub.com/neondatabase/mcp-server-neon\",\"name\":\"Neon
  Database\",\"author\":\"neondatabase\",\"description\":\"Enables natural
  language interaction with Neon PostgreSQL databases, supporting project
  management, schema migrations, SQL queries, and database operations through
  the Neon
  API.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/neon-logo.png\",\"category\":\"databases\",\"tags\":[\
  \"postgresql\",\"database-management\",\"migrations\",\"sql\",\"neon-api\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"<img width=\\\"250px\\\"
  src=\\\"https://neon.tech/brand/neon-logo-dark-color.svg\\\" />\\n\\n# Neon
  MCP Server\\n\\n[![Install MCP Server in
  Cursor](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=Neon&config=eyJ1cmwiOiJodHRwczovL21jcC5uZW9uLnRlY2gvc3NlIn0\
  %3D)\\n\\n**Neon MCP Server** is an open-source tool that lets you interact
  with your Neon Postgres databases in **natural language**.\\n\\n[![npm
  version](https://img.shields.io/npm/v/@neondatabase/mcp-server-neon)](https:/\
  /www.npmjs.com/package/@neondatabase/mcp-server-neon)\\n[![npm
  downloads](https://img.shields.io/npm/dt/@neondatabase/mcp-server-neon)](http\
  s://www.npmjs.com/package/@neondatabase/mcp-server-neon)\\n[![License:
  MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource\
  .org/licenses/MIT)\\n[![smithery
  badge](https://smithery.ai/badge/neon)](https://smithery.ai/server/neon)\\n\\\
  nThe Model Context Protocol (MCP) is a [new, standardized
  protocol](https://modelcontextprotocol.io/introduction) designed to manage
  context between large language models (LLMs) and external systems. This
  repository offers an installer and an MCP Server for
  [Neon](https://neon.tech).\\n\\nNeon's MCP server acts as a bridge between
  natural language requests and the [Neon
  API](https://api-docs.neon.tech/reference/getting-started-with-neon-api).
  Built upon MCP, it translates your requests into the necessary API calls,
  enabling you to manage tasks such as creating projects and branches, running
  queries, and performing database migrations seamlessly.\\n\\nSome of the key
  features of the Neon MCP server include:\\n\\n- **Natural language
  interaction:** Manage Neon databases using intuitive, conversational
  commands.\\n- **Simplified database management:** Perform complex actions
  without writing SQL or directly using the Neon API.\\n- **Accessibility for
  non-developers:** Empower users with varying technical backgrounds to interact
  with Neon databases.\\n- **Database migration support:** Leverage Neon's
  branching capabilities for database schema changes initiated via natural
  language.\\n\\nFor example, in Claude Desktop, or any MCP Client, you can use
  natural language to accomplish things with Neon, such as:\\n\\n- `Let's create
  a new Postgres database, and call it \\\"my-database\\\". Let's then create a
  table called users with the following columns: id, name, email, and
  password.`\\n- `I want to run a migration on my project called
  \\\"my-project\\\" that alters the users table to add a new column called
  \\\"created_at\\\".`\\n- `Can you give me a summary of all of my Neon projects
  and what data is in each one?`\\n\\n> [!NOTE]  \\n> The Neon MCP server grants
  powerful database management capabilities through natural language requests.
  **Always review and authorize actions** requested by the LLM before execution.
  Ensure that only authorized users and applications have access to the Neon MCP
  server and Neon API keys.\\n\\n## Setting up Neon MCP Server\\n\\nYou have two
  options for connecting your MCP client to Neon:\\n\\n1. **Remote MCP Server
  (Preview):** Connect to Neon's managed MCP server using OAuth for
  authentication. This method is more convenient as it eliminates the need to
  manage API keys. Additionally, you will automatically receive the latest
  features and improvements as soon as they are released.\\n\\n2. **Local MCP
  Server:** Run the Neon MCP server locally on your machine, authenticating with
  a Neon API key.\\n\\n## Prerequisites\\n\\n- An MCP Client application.\\n- A
  [Neon account](https://console.neon.tech/signup).\\n- **Node.js (>= v18.0.0)
  and npm:** Download from [nodejs.org](https://nodejs.org).\\n\\nFor Local MCP
  Server setup, you also need a Neon API key. See [Neon API Keys
  documentation](https://neon.tech/docs/manage/api-keys) for instructions on
  generating one.\\n\\n### Option 1. Remote Hosted MCP Server
  (Preview)\\n\\nConnect to Neon's managed MCP server using OAuth for
  authentication. This is the easiest setup, requires no local installation of
  this server, and doesn't need a Neon API key configured in the client.\\n\\n-
  Add the following \\\"Neon\\\" entry to your client's MCP server configuration
  file (e.g., `mcp.json`,
  `mcp_config.json`):\\n\\n  ```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"Neon\\\": {\\n        \\\"command\\\":
  \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\", \\\"mcp-remote\\\",
  \\\"https://mcp.neon.tech/sse\\\"]\\n      }\\n    }\\n  }\\n  ```\\n\\n- Save
  the configuration file.\\n- Restart or refresh your MCP client.\\n- An OAuth
  window will open in your browser. Follow the prompts to authorize your MCP
  client to access your Neon account.\\n\\n### Option 2. Local MCP
  Server\\n\\nRun the Neon MCP server on your local machine.\\n\\n**Setup via
  Smithery:**\\n\\n```bash\\nnpx -y @smithery/cli@latest install neon --client
  <client_name>\\n```\\n\\nYou will be prompted to enter your Neon API key.
  Enter the API key which you obtained from the [prerequisites](#prerequisites)
  section\\nReplace `<client_name>` with the name of your MCP client
  application. Supported client names include:\\n\\n- `claude` for [Claude
  Desktop](https://claude.ai/download)\\n- `cursor` for
  [Cursor](https://cursor.com) (Installing via `smithery` makes the MCP server a
  global MCP server in Cursor)\\n- `windsurf` for [Windsurf
  Editor](https://codeium.com/windsurf)\\n- `roo-cline` for [Roo Cline VS Code
  extension](https://github.com/RooVetGit/Roo-Code)\\n- `witsy` for
  [Witsy](https://witsyai.com/)\\n- `enconvo` for
  [Enconvo](https://www.enconvo.com/)\\n- `vscode` for [Visual Studio
  Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers)\\n\\nResta\
  rt your MCP client after installation.\\n\\n**Setup via npm**\\n\\nIf your MCP
  client is not listed here, you can manually add the Neon MCP Server details to
  your client's `mcp_config` file.\\n\\nAdd the following JSON configuration
  within the `mcpServers` section of your client's `mcp_config` file, replacing
  `<YOUR_NEON_API_KEY>` with your actual Neon API
  key:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"neon\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@neondatabase/mcp-server-neon\\\",\\n        \
  \\\"start\\\",\\n        \\\"<YOUR_NEON_API_KEY>\\\"\\n      ]\\n    }\\n  }\
  \\n}\\n```\\n\\n### Troubleshooting\\n\\nIf your client does not use `JSON`
  for configuration of MCP servers (such as older versions of Cursor), you can
  use the following command when prompted:\\n\\n```bash\\nnpx -y
  @neondatabase/mcp-server-neon start <YOUR_NEON_API_KEY>\\n```\\n\\n####
  Troubleshooting on Windows\\n\\nIf you are using Windows and encounter issues
  while adding the MCP server, you might need to use the Command Prompt (`cmd`)
  or Windows Subsystem for Linux (`wsl`) to run the necessary commands. Your
  configuration setup may resemble the
  following:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"neon\\\":
  {\\n      \\\"command\\\": \\\"cmd\\\",\\n      \\\"args\\\":
  [\\n        \\\"/c\\\",\\n        \\\"npx\\\",\\n        \\\"-y\\\",\\n        \
  \\\"@neondatabase/mcp-server-neon\\\",\\n        \\\"start\\\",\\n        \\\
  \"<YOUR_NEON_API_KEY>\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n```json\\n{\
  \\n  \\\"mcpServers\\\": {\\n    \\\"neon\\\": {\\n      \\\"command\\\":
  \\\"wsl\\\",\\n      \\\"args\\\":
  [\\n        \\\"npx\\\",\\n        \\\"-y\\\",\\n        \\\"@neondatabase/mc\
  p-server-neon\\\",\\n        \\\"start\\\",\\n        \\\"<YOUR_NEON_API_KEY>\
  \\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Guides\\n\\n- [Neon MCP Server
  Guide](https://neon.tech/docs/ai/neon-mcp-server)\\n- [Connect MCP Clients to
  Neon](https://neon.tech/docs/ai/connect-mcp-clients-to-neon)\\n- [Cursor with
  Neon MCP Server](https://neon.tech/guides/cursor-mcp-neon)\\n- [Claude Desktop
  with Neon MCP Server](https://neon.tech/guides/neon-mcp-server)\\n- [Cline
  with Neon MCP Server](https://neon.tech/guides/cline-mcp-neon)\\n- [Windsurf
  with Neon MCP Server](https://neon.tech/guides/windsurf-mcp-neon)\\n- [Zed
  with Neon MCP Server](https://neon.tech/guides/zed-mcp-neon)\\n\\n#
  Features\\n\\n## Supported Tools\\n\\nThe Neon MCP Server provides the
  following actions, which are exposed as \\\"tools\\\" to MCP Clients. You can
  use these tools to interact with your Neon projects and databases using
  natural language commands.\\n\\n**Project Management:**\\n\\n-
  **`list_projects`**: Lists the first 10 Neon projects in your account,
  providing a summary of each project. If you can't find a specific project,
  increase the limit by passing a higher value to the `limit` parameter.\\n-
  **`describe_project`**: Fetches detailed information about a specific Neon
  project, including its ID, name, and associated branches and databases.\\n-
  **`create_project`**: Creates a new Neon project in your Neon account. A
  project acts as a container for branches, databases, roles, and computes.\\n-
  **`delete_project`**: Deletes an existing Neon project and all its associated
  resources.\\n\\n**Branch Management:**\\n\\n- **`create_branch`**: Creates a
  new branch within a specified Neon project. Leverages [Neon's
  branching](/docs/introduction/branching) feature for development, testing, or
  migrations.\\n- **`delete_branch`**: Deletes an existing branch from a Neon
  project.\\n- **`describe_branch`**: Retrieves details about a specific branch,
  such as its name, ID, and parent branch.\\n- **`list_branch_computes`**: Lists
  compute endpoints for a project or specific branch, including compute ID,
  type, size, and autoscaling information.\\n\\n**SQL Query Execution:**\\n\\n-
  **`get_connection_string`**: Returns your database connection string.\\n-
  **`run_sql`**: Executes a single SQL query against a specified Neon database.
  Supports both read and write operations.\\n- **`run_sql_transaction`**:
  Executes a series of SQL queries within a single transaction against a Neon
  database.\\n- **`get_database_tables`**: Lists all tables within a specified
  Neon database.\\n- **`describe_table_schema`**: Retrieves the schema
  definition of a specific table, detailing columns, data types, and
  constraints.\\n- **`list_slow_queries`**: Identifies performance bottlenecks
  by finding the slowest queries in a database. Requires the pg_stat_statements
  extension.\\n\\n**Database Migrations (Schema Changes):**\\n\\n-
  **`prepare_database_migration`**: Initiates a database migration process.
  Critically, it creates a temporary branch to apply and test the migration
  safely before affecting the main branch.\\n-
  **`complete_database_migration`**: Finalizes and applies a prepared database
  migration to the main branch. This action merges changes from the temporary
  migration branch and cleans up temporary resources.\\n\\n**Query Performance
  Optimization:**\\n\\n- **`explain_sql_statement`**: Provides detailed
  execution plans for SQL queries to help identify performance bottlenecks.\\n-
  **`prepare_query_tuning`**: Analyzes query performance and suggests
  optimizations like index creation. Creates a temporary branch for safely
  testing these optimizations.\\n- **`complete_query_tuning`**: Applies or
  discards query optimizations after testing. Can merge changes from the
  temporary branch to the main branch.\\n- **`list_slow_queries`**: Identifies
  and analyzes slow-performing queries in your database. Requires the
  `pg_stat_statements` extension.\\n\\n**Compute Management:**\\n\\n-
  **`list_branch_computes`**: Lists compute endpoints for a project or specific
  branch, showing details like compute ID, type, size, and last active
  time.\\n\\n**Neon Auth:**\\n\\n- **`provision_neon_auth`**: Provisions Neon
  Auth for a Neon project. It allows developers to easily set up authentication
  infrastructure by creating an integration with Stack Auth
  (`@stackframe/stack`).\\n\\n  **Query Performance Tuning:**\\n\\n-
  **`explain_sql_statement`**: Analyzes a SQL query and returns detailed
  execution plan information to help understand query performance.\\n-
  **`prepare_query_tuning`**: Identifies potential performance issues in a SQL
  query and suggests optimizations. Creates a temporary branch for testing
  improvements.\\n- **`complete_query_tuning`**: Finalizes and applies query
  optimizations after testing. Merges changes from the temporary tuning branch
  to the main branch.\\n\\n**Neon Auth:**\\n\\n- **`provision_neon_auth`**:
  Action to provision Neon Auth for a Neon project. It allows developers to
  easily setup authentication infrastructure by creating a integration with
  Stack Auth (`@stackframe/stack`).\\n\\n## Migrations\\n\\nMigrations are a way
  to manage changes to your database schema over time. With the Neon MCP server,
  LLMs are empowered to do migrations safely with separate \\\"Start\\\"
  (`prepare_database_migration`) and \\\"Commit\\\"
  (`complete_database_migration`) commands.\\n\\nThe \\\"Start\\\" command
  accepts a migration and runs it in a new temporary branch. Upon returning,
  this command hints to the LLM that it should test the migration on this
  branch. The LLM can then run the \\\"Commit\\\" command to apply the migration
  to the original branch.\\n\\n# Development\\n\\n## Development with MCP CLI
  Client\\n\\nThe easiest way to iterate on the MCP Server is using the
  `mcp-client/`. Learn more in `mcp-client/README.md`.\\n\\n```bash\\nnpm
  install\\nnpm run build\\nnpm run watch # You can keep this open.\\ncd
  mcp-client/ && NEON_API_KEY=... npm run start:mcp-server-neon\\n```\\n\\n##
  Development with Claude Desktop (Local MCP Server)\\n\\n```bash\\nnpm
  install\\nnpm run build\\nnpm run watch # You can keep this open.\\nnode
  dist/index.js init $NEON_API_KEY\\n```\\n\\nThen, **restart Claude** each time
  you want to test changes.\\n\\n# Testing\\n\\nTo run the tests you need to
  setup the `.env` file according to the `.env.example` file.\\n\\n```bash\\nnpm
  run
  test\\n```\\n\",\"isRecommended\":true,\"githubStars\":349,\"downloadCount\":\
  897,\"createdAt\":\"2025-02-18T06:28:23.454334Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T10:37:31.673944Z\"},{\"mcp\
  Id\":\"github.com/Azure/azure-mcp\",\"githubUrl\":\"https://github.com/Azure/\
  azure-mcp\",\"name\":\"Azure
  Services\",\"author\":\"Azure\",\"description\":\"Comprehensive management
  interface for Azure cloud services, providing tools for storage, databases,
  monitoring, security, and resource management through the Model Context
  Protocol.\",\"codiconIcon\":\"azure\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/azure-services.png\",\"category\":\"cloud-platforms\
  \",\"tags\":[\"azure\",\"cloud-management\",\"infrastructure\",\"devops\",\"m\
  onitoring\"],\"requiresApiKey\":false,\"readmeContent\":\"#  Azure MCP
  Server\\n\\nThe Azure MCP Server implements the [MCP
  specification](https://modelcontextprotocol.io) to create a seamless
  connection between AI agents and Azure services.  Azure MCP Server can be used
  alone or with the [GitHub Copilot for Azure
  extension](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.\
  vscode-azure-github-copilot) in VS Code.  This project is in Public Preview
  and implementation may significantly change prior to our General
  Availability.\\n\\nHere's a short (16 seconds) video to help you get the Azure
  MCP Server installed in VS Code.\\n<video
  src=\\\"https://github.com/user-attachments/assets/535f393c-0ed2-479d-9b24-5c\
  a933293c92\\\" width=\\\"1080\\\" height=\\\"1920\\\"
  controls></video>\\n\\n###  VS Code Install Steps (Recommended)\\n1. Install
  either the stable or Insiders release of VS Code:\\n   * [ Stable
  release](https://code.visualstudio.com/download)\\n   * [ Insiders
  release](https://code.visualstudio.com/insiders)\\n2. Install the [GitHub
  Copilot](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot)
  and [GitHub Copilot
  Chat](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat)
  extensions\\n3. Install [Node.js](https://nodejs.org/en/download) 20 or
  later\\n   * Ensure `node` and `npm` are in your path\\n4. Open VS Code in an
  empty folder\\n5. Install any of the available Azure MCP Server(s) for either
  the stable or Insiders release of VS Code\\n6. Open GitHub Copilot in VS Code
  and [switch to Agent
  mode](https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode)\\n7.
  Click `refresh` on the tools list.\\n\\n####  Available Azure MCP
  Servers\\n\\n| Name         |
  Description                                                                                   \
  | All Tools | Read Only
  |\\n|--------------|---------------------------------------------------------\
  --------------------------------------|-----------|-----------|\\n| All | All
  Azure tools in a single MCP server | [![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-Install_all-0098FF?style=flat-squa\
  re&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redire\
  ct/mcp/install?name=Azure%20Server&config=%7B%22command%22%3A%22npx%22%2C%22a\
  rgs%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C%22start%\
  22%5D%7D) | [![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-Install_all-24bfa5?style=flat-squa\
  re&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redire\
  ct/mcp/install?name=Azure%20Server%20Read%20Only&config=%7B%22command%22%3A%2\
  2npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%\
  22%2C%22start%22%2C%22--read-only%22%5D%7D) |\\n| App Configuration | App
  Configuration operations - Manage App Configuration stores. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_appconfig-0098FF?sty\
  le=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscod\
  e.dev/redirect/mcp/install?name=Azure%20App%20Config&config=%7B%22command%22%\
  3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22ser\
  ver%22%2C%22start%22%2C%22--service%22%2C%22appconfig%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_appconfig-24bfa5?sty\
  le=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscod\
  e.dev/redirect/mcp/install?name=Azure%20App%20Config%20Read%20Only&config=%7B\
  %22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40late\
  st%22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22appconfig%22%2C%22-\
  -read-only%22%5D%7D) |\\n| Best Practices | Returns secure, production-grade
  Azure SDK best practices. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_bestpractices-0098FF\
  ?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.v\
  scode.dev/redirect/mcp/install?name=Azure%20Best%20Practices&config=%7B%22com\
  mand%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%\
  2C%22server%22%2C%22start%22%2C%22--service%22%2C%22bestpractices%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_bestpractices-24bfa5\
  ?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.v\
  scode.dev/redirect/mcp/install?name=Azure%20Best%20Practices%20Read%20Only&co\
  nfig=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmc\
  p%40latest%22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22bestpractic\
  es%22%2C%22--read-only%22%5D%7D) |\\n| Cosmos DB    | Cosmos DB operations -
  Manage/query Cosmos DB resources. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_cosmos-0098FF?style=\
  flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.d\
  ev/redirect/mcp/install?name=Azure%20Cosmos&config=%7B%22command%22%3A%22npx%\
  22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C\
  %22start%22%2C%22--service%22%2C%22cosmos%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_cosmos-24bfa5?style=\
  flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.d\
  ev/redirect/mcp/install?name=Azure%20Cosmos%20Read%20Only&config=%7B%22comman\
  d%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%\
  22server%22%2C%22start%22%2C%22--service%22%2C%22cosmos%22%2C%22--read-only%2\
  2%5D%7D) |\\n| Foundry       | AI Foundry operations - List models, deploy
  models and list model deployments. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_foundry-0098FF?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%Foundry&config=%7B%22command%22%3A%22npx%\
  22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C\
  %22start%22%2C%22--service%22%2C%22foundry%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_foundry-24bfa5?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%20Foundry%20Read%20Only&config=%7B%22comm\
  and%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2\
  C%22server%22%2C%22start%22%2C%22--service%22%2C%22foundry%22%2C%22--read-onl\
  y%22%5D%7D) |\\n| Key Vault    | Key Vault operations - Manage/access Azure
  Key Vault resources. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_keyvault-0098FF?styl\
  e=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode\
  .dev/redirect/mcp/install?name=Azure%20Key%20Vault&config=%7B%22command%22%3A\
  %22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22serve\
  r%22%2C%22start%22%2C%22--service%22%2C%22keyvault%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_keyvault-24bfa5?styl\
  e=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode\
  .dev/redirect/mcp/install?name=Azure%20Key%20Vault%20Read%20Only&config=%7B%2\
  2command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest\
  %22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22keyvault%22%2C%22--re\
  ad-only%22%5D%7D) |\\n| Azure Data Explorer        | Azure Data Explorer
  operations - Manage/query Azure Data Explorer clusters. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_kusto-0098FF?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Kusto&config=%7B%22command%22%3A%22npx%22\
  %2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C%2\
  2start%22%2C%22--service%22%2C%22kusto%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_kusto-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Kusto%20Read%20Only&config=%7B%22command%\
  22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22\
  server%22%2C%22start%22%2C%22--service%22%2C%22kusto%22%2C%22--read-only%22%5\
  D%7D) |\\n| Monitor      | Azure Monitor operations - Query/analyze logs and
  metrics. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_monitor-0098FF?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%20Monitor&config=%7B%22command%22%3A%22np\
  x%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%\
  2C%22start%22%2C%22--service%22%2C%22monitor%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_monitor-24bfa5?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%20Monitor%20Read%20Only&config=%7B%22comm\
  and%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2\
  C%22server%22%2C%22start%22%2C%22--service%22%2C%22monitor%22%2C%22--read-onl\
  y%22%5D%7D) |\\n| PostgreSQL   | PostgreSQL operations - Manage Azure Database
  for PostgreSQL - Flexible server. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_postgres-0098FF?styl\
  e=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode\
  .dev/redirect/mcp/install?name=Azure%20PostgreSQL&config=%7B%22command%22%3A%\
  22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server\
  %22%2C%22start%22%2C%22--service%22%2C%22postgres%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_postgres-24bfa5?styl\
  e=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode\
  .dev/redirect/mcp/install?name=Azure%20PostgreSQL%20Read%20Only&config=%7B%22\
  command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%\
  22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22postgres%22%2C%22--rea\
  d-only%22%5D%7D) |\\n| Role Based Access Control  | Azure RBAC Operations -
  List Azure RBAC role assignments. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_rbac-0098FF?style=fl\
  at-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev\
  /redirect/mcp/install?name=Azure%20RBAC&config=%7B%22command%22%3A%22npx%22%2\
  C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C%22s\
  tart%22%2C%22--service%22%2C%22role%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_rbac-24bfa5?style=fl\
  at-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev\
  /redirect/mcp/install?name=Azure%20RBAC%20Read%20Only&config=%7B%22command%22\
  %3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22se\
  rver%22%2C%22start%22%2C%22--service%22%2C%22role%22%2C%22--read-only%22%5D%7\
  D) |\\n| Redis Cache  | Redis Cache operations - Manage/access Azure Redis
  Cache resources. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_redis-0098FF?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Redis%20Cache&config=%7B%22command%22%3A%\
  22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server\
  %22%2C%22start%22%2C%22--service%22%2C%22redis%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_redis-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Redis%20Cache%20Read%20Only&config=%7B%22\
  command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%\
  22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22redis%22%2C%22--read-o\
  nly%22%5D%7D) |\\n| Resource Group | Resource group operations - List/manage
  Azure resource groups. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_group-0098FF?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Resource%20Group&config=%7B%22command%22%\
  3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22ser\
  ver%22%2C%22start%22%2C%22--service%22%2C%22group%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_group-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=Azure%20Resource%20Group%20Read%20Only&config=%7B\
  %22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40late\
  st%22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22group%22%2C%22--rea\
  d-only%22%5D%7D) |\\n| Search       | Search operations - List/query Azure AI
  Search services. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_search-0098FF?style=\
  flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.d\
  ev/redirect/mcp/install?name=Azure%20Search&config=%7B%22command%22%3A%22npx%\
  22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%2C\
  %22start%22%2C%22--service%22%2C%22search%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_search-24bfa5?style=\
  flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.d\
  ev/redirect/mcp/install?name=Azure%20Search%20Read%20Only&config=%7B%22comman\
  d%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%\
  22server%22%2C%22start%22%2C%22--service%22%2C%22search%22%2C%22--read-only%2\
  2%5D%7D) |\\n| Service Bus  | Service Bus operations - Manage Azure Service
  Bus resources. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_servicebus-0098FF?st\
  yle=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vsco\
  de.dev/redirect/mcp/install?name=Azure%20Service%20Bus&config=%7B%22command%2\
  2%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22s\
  erver%22%2C%22start%22%2C%22--service%22%2C%22servicebus%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_servicebus-24bfa5?st\
  yle=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vsco\
  de.dev/redirect/mcp/install?name=Azure%20Service%20Bus%20Read%20Only&config=%\
  7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40la\
  test%22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22servicebus%22%2C%\
  22--read-only%22%5D%7D) |\\n| SQL Database | Azure SQL Database operations -
  Manage Azure SQL Database servers and databases. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_sql-0098FF?style=fla\
  t-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/\
  redirect/mcp/install?name=Azure%20SQL%20Database&config=%7B%22command%22%3A%2\
  2npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%\
  22%2C%22start%22%2C%22--service%22%2C%22sql%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_sql-24bfa5?style=fla\
  t-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/\
  redirect/mcp/install?name=Azure%20SQL%20Database%20Read%20Only&config=%7B%22c\
  ommand%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%2\
  2%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22sql%22%2C%22--read-only\
  %22%5D%7D) |\\n| Storage      | Storage operations - Manage/access Azure
  Storage resources. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_storage-0098FF?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%20Storage&config=%7B%22command%22%3A%22np\
  x%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22server%22%\
  2C%22start%22%2C%22--service%22%2C%22storage%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_storage-24bfa5?style\
  =flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.\
  dev/redirect/mcp/install?name=Azure%20Storage%20Read%20Only&config=%7B%22comm\
  and%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2\
  C%22server%22%2C%22start%22%2C%22--service%22%2C%22storage%22%2C%22--read-onl\
  y%22%5D%7D) |\\n| Subscription | Azure subscription operations - List/manage
  Azure subscriptions. |
  [![Install](https://img.shields.io/badge/VS_Code-Install_subscription-0098FF?\
  style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vs\
  code.dev/redirect/mcp/install?name=Azure%20Subscription&config=%7B%22command%\
  22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40latest%22%2C%22\
  server%22%2C%22start%22%2C%22--service%22%2C%22subscription%22%5D%7D) |
  [![Install](https://img.shields.io/badge/VS_Code-Install_subscription-24bfa5?\
  style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vs\
  code.dev/redirect/mcp/install?name=Azure%20Subscription%20Read%20Only&config=\
  %7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22@azure%2Fmcp%40l\
  atest%22%2C%22server%22%2C%22start%22%2C%22--service%22%2C%22subscription%22%\
  2C%22--read-only%22%5D%7D) |\\n\\n###   Getting Started\\n1. Open GitHub
  Copilot in VS Code and [switch to Agent
  mode](https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode)\\n2.
  You should see the Azure MCP Server in the list of tools\\n3. Try a prompt
  that tells the agent to use the Azure MCP Server, such as \\\"List my Azure
  Storage containers\\\"\\n4. The agent should be able to use the Azure MCP
  Server tools to complete your query\\n5. For help with common issues see
  [Troubleshooting
  guide](https://github.com/Azure/azure-mcp/blob/main/TROUBLESHOOTING.md#128-to\
  ol-limit-issue)\\n\\n##  What can you do with the Azure MCP Server?\\n\\nThe
  Azure MCP Server supercharges your agents with Azure context. Here are some
  cool prompts you can try:\\n\\n###  Explore Your Azure Resources\\n\\n-
  \\\"List my Azure storage accounts\\\"\\n- \\\"Show me all my Cosmos DB
  databases\\\"\\n- \\\"What indexes do I have in my Azure AI Search service
  'mysvc'?\\\"\\n- \\\"List my resource groups\\\"\\n- \\\"Show me the tables in
  my Storage account\\\"\\n- \\\"List containers in my Cosmos DB
  database\\\"\\n- \\\"Get details about my Storage container\\\"\\n- \\\"Get
  Azure Data Explorer databases in cluster 'mycluster'\\\"\\n- \\\"Sample 10
  rows from table 'StormEvents' in Azure Data Explorer database 'db1'\\\"\\n-
  \\\"Show me details about my Azure SQL database 'mydb'\\\"\\n\\n###  Query &
  Analyze\\n- \\\"Query my Log Analytics workspace\\\"\\n- \\\"Let's search this
  index for 'my search query'\\\"\\n\\n###  Manage Configuration\\n\\n-
  \\\"List my App Configuration stores\\\"\\n- \\\"Show my key-value pairs in
  App Config\\\"\\n\\n###  Advanced Azure Operations\\n\\n- \\\"List my Azure
  CDN endpoints\\\"\\n- \\\"Help me build an Azure application using
  Node.js\\\"\\n\\n\\n##  Currently Supported
  Tools\\n<details>\\n<summary>The Azure MCP Server provides tools for
  interacting with the following Azure services</summary>\\n\\n###  Azure AI
  Search (search engine/vector database)\\n- List Azure AI Search services\\n-
  List indexes and look at their schema and configuration\\n- Query search
  indexes\\n\\n###  Azure Cosmos DB (NoSQL Databases)\\n- List Cosmos DB
  accounts\\n- List and query databases\\n- Manage containers and items\\n-
  Execute SQL queries against containers\\n\\n###  Azure Database for
  PostgreSQL - Flexible Server\\n- List and query databases.\\n- List and get
  schema for tables.\\n- List, get configuration and get parameters for
  servers.\\n\\n###  Azure SQL Database\\n- Show database details and
  properties\\n\\n###  Azure Data Explorer\\n- List Azure Data Explorer
  clusters\\n- List databases\\n- List tables\\n- Get schema for a table\\n-
  Sample rows from a table\\n- Query using KQL\\n\\n- ###  Azure Foundry\\n-
  List Azure Foundry models\\n- Deploy foundry models\\n- List foundry model
  deployments\\n\\n###  Azure Storage\\n- List Storage accounts\\n- Manage
  blob containers and blobs\\n- List and query Storage tables\\n- Get container
  properties and metadata\\n\\n###  Azure Monitor\\n#### Log Analytics\\n-
  List Log Analytics workspaces\\n- Query logs using KQL\\n- List available
  tables\\n\\n#### Health Models\\n- Get health of an entity\\n\\n####
  Metrics\\n- Query Azure Monitor metrics for resources with time series
  data\\n- List available metric definitions for resources\\n\\n###  Azure App
  Configuration\\n- List App Configuration stores\\n- Manage key-value pairs\\n-
  Handle labeled configurations\\n- Lock/unlock configuration settings\\n\\n###
   Azure Key Vault\\n- List, create, and get keys\\n\\n###  Azure Role-Based
  Access Control (RBAC)\\n- List role assignments\\n\\n###  Azure Resource
  Groups\\n- List resource groups\\n\\n###  Azure Service Bus\\n- Examine
  properties and runtime information about queues, topics, and
  subscriptions\\n\\n###  Azure Native ISV Services\\n- List Monitored
  Resources in a Datadog Monitor\\n\\n###  Azure CLI Extension\\n- Execute
  Azure CLI commands directly\\n- Support for all Azure CLI functionality\\n-
  JSON output formatting\\n- Cross-platform compatibility\\n\\n###  Azure
  Developer CLI (azd) Extension\\n- Execute Azure Developer CLI commands
  directly\\n- Support for template discovery, template initialization,
  provisioning and deployment\\n- Cross-platform compatibility\\n\\nAgents and
  models can discover and learn best practices and usage guidelines for the
  `azd` MCP tool. For more information, see [AZD Best
  Practices](https://github.com/Azure/azure-mcp/tree/main/src/Areas/Extension/R\
  esources/azd-best-practices.txt).\\n\\n###  Azure Best Practices\\n- Get
  secure, production-grade Azure SDK best practices for effective code
  generation.\\n</details>\\n\\nFor detailed command documentation and examples,
  see [Azure MCP
  Commands](https://github.com/Azure/azure-mcp/blob/main/docs/azmcp-commands.md\
  ).\\n\\n##  Upgrading Existing Installs to the Latest
  Version\\n\\n<details>\\n<summary>How to stay current with releases of Azure
  MCP Server</summary>\\n\\n#### NPX\\n\\nIf you use the default package spec of
  `@azure/mcp@latest`, npx will look for a new version on each server start. If
  you use just `@azure/mcp`, npx will continue to use its cached version until
  its cache is cleared.\\n\\n#### NPM\\n\\nIf you globally install the cli via
  `npm install -g @azure/mcp` it will use the installed version until you
  manually update it with `npm update -g @azure/mcp`.\\n\\n####
  Docker\\n\\nThere is no version update built into the docker image.  To
  update, just pull the latest from the repo and repeat the [docker installation
  instructions](#docker-install).\\n\\n#### VS Code\\n\\nInstallation in VS Code
  should be in one of the previous forms and the update instructions are the
  same. If you installed the mcp server with the `npx` command and  `-y
  @azure/mcp@latest` args, npx will check for package updates each time VS Code
  starts the server. Using a docker container in VS Code has the same no-update
  limitation described above.\\n</details>\\n\\n##  Advanced Install Scenarios
  (Optional)\\n<details>\\n<summary>Docker containers, custom MCP clients, and
  manual install options</summary>\\n\\n####  Docker Install Steps
  (Optional)\\nFor a step-by-step Docker installation, follow these
  instructions:\\n\\n1. Clone repository\\n2. From repository root, build Docker
  image: `docker build -t azure/azuremcp .`\\n3. Create an `.env` file with
  environment variables that [match one of the
  `EnvironmentCredential`](https://learn.microsoft.com/dotnet/api/azure.identit\
  y.environmentcredential) sets.  For example, a `.env` file using a service
  principal could look
  like:\\n```json\\nAZURE_TENANT_ID={YOUR_AZURE_TENANT_ID}\\nAZURE_CLIENT_ID={Y\
  OUR_AZURE_CLIENT_ID}\\nAZURE_CLIENT_SECRET={YOUR_AZURE_CLIENT_SECRET}\\n```\\\
  n4. Add `.vscode/mcp.json` or update existing MCP configuration. Replace
  `/full/path/to/.env` with a path to your `.env`
  file.\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"Azure MCP Server\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"--env-file\\\",\\n        \\\"/full/path/to/.env\\\"\\n        \\\"azure/\
  azuremcp\\\",\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nOptionally, customers can
  use `--env` or `--volume` to pass authentication values.\\n\\n####  Custom
  MCP Client Install Steps (Optional)\\nYou can easily configure your MCP client
  to use the Azure MCP Server. Have your client run the following command and
  access it via standard IO or SSE.\\n\\n####  Manual Install Steps
  (Optional)\\nFor a step-by-step installation, follow these
  instructions:\\n\\n1. Add
  `.vscode/mcp.json`:\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"Azure MCP
  Server\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@azure/mcp@latest\\\",\\n        \\\"se\
  rver\\\",\\n        \\\"start\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYou
  can optionally set the `--service <service>` flag to install tools for the
  specified Azure product or service.\\n\\n1. Add
  `.vscode/mcp.json`:\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"Azure Best
  Practices\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@azure/mcp@latest\\\",\\n        \\\"se\
  rver\\\",\\n        \\\"start\\\",\\n        \\\"--service\\\",\\n        \\\
  \"bestpractices\\\" // Any of the available MCP servers can be referenced
  here.\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### Using standard
  IO\\n\\nConfigure the MCP client to execute: `npx -y @azure/mcp@latest server
  start`. For instructions on using , follow instructions in [Quick install with
  VS Code](#-quick-install-with-vs-code) or [Manual
  Install](#-manual-install).\\n\\n### Using SSE\\n\\n1. Open a terminal window
  and execute: `npx -y @azure/mcp@latest server start --transport sse`\\n2. The
  server starts up and is hosted at: http://localhost:5008.  To use another
  port, append `--port {YOUR-PORT-NUMBER}`.\\n3. Open your MCP client and add
  the SSE configuration value.  This may differ between MCP clients.  In VS
  Code, it will look like:\\n   ```json\\n   {\\n      \\\"servers\\\":
  {\\n        \\\"Azure MCP Server\\\": {\\n          \\\"type\\\":
  \\\"sse\\\",\\n          \\\"url\\\":
  \\\"http://localhost:5008/sse\\\"\\n        }\\n      }\\n    }\\n   ```\\n\\\
  nMore end-to-end MCP client/agent guides are coming soon!\\n</details>\\n\\n##
  Data Collection\\n\\nThe software may collect information about you and your
  use of the software and send it to Microsoft. Microsoft may use this
  information to provide services and improve our products and services. You may
  turn off the telemetry as described in the repository. There are also some
  features in the software that may enable you and Microsoft to collect data
  from users of your applications. If you use these features, you must comply
  with applicable law, including providing appropriate notices to users of your
  applications together with a copy of Microsoft's privacy statement. Our
  privacy statement is located at
  https://go.microsoft.com/fwlink/?LinkId=521839. You can learn more about data
  collection and use in the help documentation and our privacy statement. Your
  use of the software operates as your consent to these practices.\\n\\n###
  Telemetry Configuration\\n\\nTelemetry collection is on by default.\\n\\nTo
  opt out, set the environment variable `AZURE_MCP_COLLECT_TELEMETRY` to `false`
  in your environment.\\n\\n##  Troubleshooting\\n\\nSee [Troubleshooting
  guide](https://github.com/Azure/azure-mcp/blob/main/TROUBLESHOOTING.md#128-to\
  ol-limit-issue) for help with common issues and logging.\\n\\n### 
  Authentication\\n\\n<details>\\n<summary>Authentication options including
  DefaultAzureCredential flow, RBAC permissions, troubleshooting, and production
  credentials</summary>\\n\\nThe Azure MCP Server uses the Azure Identity
  library for .NET to authenticate to Microsoft Entra ID. For detailed
  information, see [Authentication
  Fundamentals](https://github.com/Azure/azure-mcp/blob/main/docs/Authenticatio\
  n.md#authentication-fundamentals).\\n\\nIf you're running into any issues with
  authentication, visit our [troubleshooting
  guide](https://github.com/Azure/azure-mcp/blob/main/TROUBLESHOOTING.md#authen\
  tication).\\n\\nFor enterprise authentication scenarios, including network
  restrictions, security policies, and protected resources, see [Authentication
  Scenarios in Enterprise
  Environments](https://github.com/Azure/azure-mcp/blob/main/docs/Authenticatio\
  n.md#authentication-scenarios-in-enterprise-environments).\\n</details>\\n\\n\
  ##  Security Note\\n\\nYour credentials are always handled securely through
  the official [Azure Identity
  SDK](https://github.com/Azure/azure-sdk-for-net/blob/main/sdk/identity/Azure.\
  Identity/README.md) - **we never store or manage tokens directly**.\\n\\nMCP
  as a phenomenon is very novel and cutting-edge. As with all new technology
  standards, consider doing a security review to ensure any systems that
  integrate with MCP servers follow all regulations and standards your system is
  expected to adhere to. This includes not only the Azure MCP Server, but any
  MCP client/agent that you choose to implement down to the model
  provider.\\n\\n##  Contributing\\nWe welcome contributions to the Azure MCP
  Server! Whether you're fixing bugs, adding new features, or improving
  documentation, your contributions are welcome.\\n\\nPlease read our
  [Contributing
  Guide](https://github.com/Azure/azure-mcp/blob/main/CONTRIBUTING.md) for
  guidelines on:\\n\\n-  Setting up your development environment\\n-  Adding
  new commands\\n-  Code style and testing requirements\\n-  Making pull
  requests\\n\\n##  Feedback\\n\\nWe're building this in the open.  Your
  feedback is much appreciated, and will help us shape the future of the Azure
  MCP server.\\n\\n [Open an issue in the public
  repository](https://github.com/Azure/azure-mcp/issues/new/choose).\\n\\n## 
  Code of Conduct\\n\\nThis project has adopted the\\n[Microsoft Open Source
  Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more
  information, see the\\n[Code of Conduct
  FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\\nor contact
  [open@microsoft.com](mailto:open@microsoft.com)\\nwith any additional
  questions or comments.\\n\",\"llmsInstallationContent\":\"# Azure MCP Server
  Installation Guide\\n\\nThis guide is specifically designed to help AI agents
  install and configure the Azure MCP Server.\\n\\n## Prerequisites\\n\\n1.
  Node.js (Latest LTS version)\\n\\n## Installation Steps\\n\\n### 1.
  Configuration Setup\\n\\nThe Azure MCP Server requires configuration based on
  the client type. Below are the setup instructions for each supported
  client:\\n\\n#### For VS Code\\n\\n1. Create or modify the MCP configuration
  file, `mcp.json`, in your `.vscode`
  folder.\\n\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"Azure MCP
  Server\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@azure/mcp@latest\\\",\\n        \\\"se\
  rver\\\",\\n        \\\"start\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n####
  For Windsurf\\n\\n1. Create or modify the configuration file at
  `~/.codeium/windsurf/mcp_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\
  \": {\\n    \\\"Azure MCP Server\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@azure/mcp@latest\\\",\\n        \\\"se\
  rver\\\",\\n        \\\"start\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\",\"is\
  Recommended\":false,\"githubStars\":906,\"downloadCount\":1662,\"createdAt\":\
  \"2025-06-23T19:18:25.83627Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\
  \"lastGithubSync\":\"2025-07-07T21:09:18.672197Z\"},{\"mcpId\":\"github.com/P\
  ixVerseAI/PixVerse-MCP\",\"githubUrl\":\"https://github.com/PixVerseAI/PixVer\
  se-MCP\",\"name\":\"PixVerse\",\"author\":\"PixVerseAI\",\"description\":\"Ge\
  nerate high-quality videos from text descriptions using PixVerse's video
  generation models, supporting customizable parameters like quality, duration,
  and aspect
  ratio.\",\"codiconIcon\":\"play-circle\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/pixverse.png\",\"category\":\"image-video-proces\
  sing\",\"tags\":[\"video-generation\",\"text-to-video\",\"ai-video\",\"creati\
  ve-tools\",\"media-creation\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  PixVerse MCP\\n<div align=\\\"left\\\">\\n<a
  href=\\\"https://app.pixverse.ai\\\" style=\\\"margin: 2px\\\">\\n<img
  alt=\\\"Webapp\\\"
  src=\\\"https://img.shields.io/badge/PixVerse-Web-3961F1?style=flat-square&la\
  belColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n</a>\\n<a
  href=\\\"https://platform.pixverse.ai?utm_source=github&utm_medium=readme&utm\
  _campaign=mcp\\\" style=\\\"margin: 2px\\\">\\n<img alt=\\\"API\\\"
  src=\\\"https://img.shields.io/badge/PixVerse-API-3961F1?style=flat-square&la\
  belColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align:
  middle;\\\"/>\\n</a>\\n</div>\\n\\nA tool that allows you to access PixVerse's
  latest video generation models via applications that support the Model Context
  Protocol (MCP), such as Claude or
  Cursor.\\n\\n[](https://github.com/PixVerseAI/PixVerse-MCP/blob/main/READ\
  ME-CN.md)\\n\\n\\nhttps://github.com/user-attachments/assets/08ce90b7-2591-42\
  56-aff2-9cc51e156d00\\n\\n\\n## Overview\\n\\nPixVerse MCP is a tool that
  allows you to access PixVerse's latest video generation models via
  applications that support the Model Context Protocol (MCP), such as Claude or
  Cursor. This integration enables you to generate high-quality videos anytime,
  anywhere  including text-to-video, image-to-video, and more.\\n\\n## Key
  Features\\n\\n- **Text-to-Video Generation**: Generate creative videos using
  text prompts\\n- **Flexible Parameter Control**: Adjust video quality, length,
  aspect ratio, and more\\n- **Co-Creation with AI Assistants**: Collaborate
  with AI models like Claude to enhance your creative workflow\\n\\n## System
  Components\\n\\nThe system consists of two main components:\\n\\n1. **UVX MCP
  Server**\\n   - Python-based cloud server\\n   - Communicates directly with
  the PixVerse API\\n   - Provides full video generation capabilities\\n\\n##
  Installation & Configuration\\n\\n### Prerequisites\\n\\n1. Python 3.10 or
  higher\\n2. UV/UVX\\n3. PixVerse API Key: Obtain from PixVerse Platform (This
  feature requires API Credits, which must be purchased separately on [PixVerse
  Platform](https://platform.pixverse.ai?utm_source=github&utm_medium=readme&ut\
  m_campaign=mcp)\\n\\n\\n### Get Dependencies\\n\\n1. **Python**:\\n   -
  Download and install from the official Python website\\n   - Ensure Python is
  added to your system path\\n\\n2. **UV/UVX**:\\n   - Install uv and set up our
  Python project and environment:\\n\\n#### Mac/Linux\\n```\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n```\\n\\n####
  Windows\\n```\\npowershell -ExecutionPolicy ByPass -c \\\"irm
  https://astral.sh/uv/install.ps1 | iex\\\"\\n```\\n\\n## How to Use MCP
  Server\\n\\n### 1. Get PixVerse API Key\\n- Visit the [PixVerse
  Platform](https://platform.pixverse.ai?utm_source=github&utm_medium=readme&ut\
  m_campaign=mcp)\\n- Register or log into your account\\n- Create and copy your
  API key from the account settings\\n- [API key generation
  guide](https://docs.platform.pixverse.ai/how-to-get-api-key-882968m0)\\n\\n###
  2. Download Required Dependencies\\n- **Python**: Install Python 3.10 or
  above\\n- **UV/UVX**: Install the latest stable version of UV & UVX\\n\\n###
  3. Configure MCP Client\\n- Open your MCP client (e.g., Claude for Desktop or
  Cursor)\\n- Locate the client settings\\n- Open mcp_config.json (or relevant
  config file)\\n- Add the configuration based on the method you
  use:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"PixVerse\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"pixverse-mcp\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"PIXVERSE_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n- Add the API
  key obtained from platform.pixverse.ai under `\\\"PIXVERSE_API_KEY\\\":
  \\\"xxxx\\\"`\\n- Save the config file\\n\\n### 5. Restart MCP Client or
  Refresh MCP Server\\n- Fully close and reopen your MCP client\\n- Or use the
  \\\"Refresh MCP Server\\\" option if supported\\n\\n## Client-specific
  Configuration\\n\\n### Claude for Desktop\\n\\n1. Open the Claude
  application\\n2. Navigate to Claude > Settings > Developer > Edit Config\\n3.
  Open the claude_desktop_config.json file\\n   - Windows\\n   - Mac :
  ~/Library/Application\\\\ Support/Claude/claude_desktop_config.json\\n4. Add
  the configuration above and save\\n5. Restart Claude\\n   - If connected
  successfully: the homepage will not show any error and the MCP status will be
  green\\n   - If connection fails: an error message will be shown on the
  homepage\\n\\n### Cursor\\n\\n1. Open the Cursor application\\n2. Go to
  Settings > Model Context Protocol\\n3. Add a new server\\n4. Fill in the
  server details as in the JSON config above\\n5. Save and restart or refresh
  the MCP server\\n\\n## Usage Examples\\n\\n### Text-to-Video\\n\\nUse natural
  language prompts via Claude or Cursor to generate videos.\\n\\n**Basic
  Example**:\\n```\\nGenerate a video of a sunset over the ocean. Golden
  sunlight reflects on the water as waves gently hit the
  shore.\\n```\\n\\n**Advanced Example with Parameters**:\\n```\\nGenerate a
  night cityscape video with the following parameters:\\nContent: Skyscraper
  lights twinkling under the night sky, with car lights forming streaks on the
  road\\nAspect Ratio: 16:9\\nQuality: 540p\\nDuration: 5 seconds\\nMotion Mode:
  normal\\nNegative Prompts: blur, shaking, text\\n```\\n\\n**Supported
  Parameters**:\\n- Aspect Ratio: 16:9, 4:3, 1:1, 3:4, 9:16\\n- Duration: 5s or
  8s\\n- Quality: 360p, 540p, 720p, 1080p\\n- Motion Mode: normal or
  fast\\n\\n### Script + Video\\n\\nUse detailed scene descriptions or shot
  lists to create more structured videos.\\n\\n**Scene Description
  Example**:\\n```\\nScene: A beach in the early morning.\\nThe sun is rising,
  casting golden reflections on the sea.\\nFootprints stretch across the
  sand.\\nGentle waves leave white foam as they retreat.\\nA small boat slowly
  sails across the calm sea in the distance.\\nAspect Ratio: 16:9, Quality:
  540p, Duration: 5 seconds.\\n```\\n\\n**Shot-by-Shot
  Example**:\\n```\\nGenerate a video based on this storyboard:\\n- Start:
  Top-down shot of a coffee cup with steam rising\\n- Close-up: Ripples and
  texture on the coffee surface\\n- Transition: Stirring creates a vortex\\n-
  End: An open book and glasses next to the cup\\nFormat: 1:1 square, Quality:
  540p, Motion: fast\\n```\\n- Claude Desktop also supports storyboard image
  input.\\n\\n### One-Click Video\\n\\nQuickly generate videos of specific
  themes or styles without detailed descriptions.\\n\\n**Theme
  Example**:\\n```\\nGenerate a video with a futuristic technology theme,
  including neon lights and holographic projections.\\n```\\n\\n**Style
  Example**:\\n```\\nGenerate a watercolor-style video of blooming flowers with
  bright, dreamy colors.\\n```\\n\\n### Creative + Video\\n\\nCombine AI's
  creativity with video generation.\\n\\n**Style Transfer
  Example**:\\n```\\nThis is a photo of a cityscape. Reinterpret it with a retro
  style and provide a video prompt.\\n```\\n\\n**Story Prompt
  Example**:\\n```\\nIf this street photo is the opening scene of a movie, what
  happens next? Provide a short video concept.\\n```\\n\\n**Emotional Scene
  Example**:\\n```\\nLook at this forest path photo and design a short video
  concept, either a micro-story or a scene with emotional
  progression.\\n```\\n\\n## FAQ\\n\\n**How do I get a PixVerse API key?**\\n-
  Register at the PixVerse Platform and generate it under \\\"API-KEY\\\" in
  your account.\\n\\n**What should I do if the server doesn't respond?**\\n1.
  Check whether your API key is valid\\n2. Ensure the configuration file path is
  correct\\n3. View error logs (typically in the log folders of Claude or
  Cursor)\\n\\n**Does MCP support image-to-video or keyframe features?**\\n- Not
  yet. These features are only available via the PixVerse API. [API
  Docs](https://docs.platform.pixverse.ai)\\n\\n**How to obtain credits?**\\n-
  If you haven't topped up on the API platform yet, please do so first.
  [PixVerse
  Platform](https://platform.pixverse.ai/billing?utm_source=github&utm_medium=r\
  eadme&utm_campaign=mcp)\\n\\n**What video formats and sizes are
  supported?**\\n- PixVerse supports resolutions from 360p to 1080p, and aspect
  ratios from 9:16 (portrait) to 16:9 (landscape).\\n- We recommend starting
  with 540p and 5-second videos to test the output quality.\\n\\n**Where can I
  find the generated video?**\\n- You will receive a URL link to view, download,
  or share the video.\\n\\n**How long does video generation take?**\\n-
  Typically 30 seconds to 2 minutes depending on complexity, server load, and
  network conditions.\\n\\n**What to do if you encounter a spawn uvx ENOENT
  error?**\\n- This error is typically caused by incorrect UV/UVX installation
  paths. You can resolve it as follows:\\n\\nFor Mac/Linux:\\n```\\nsudo cp
  ./uvx /usr/local/bin\\n```\\n\\nFor Windows:\\n1. Identify the installation
  path of UV/UVX by running the following command in the terminal:\\n```\\nwhere
  uvx\\n```\\n2. Open File Explorer and locate the uvx/uv files.\\n3. Move the
  files to one of the following directories:\\n   - C:\\\\Program Files (x86) or
  C:\\\\Program Files\\n\\n## Community & Support\\n### Community\\n- Join our
  [Discord server](https://discord.gg/pixverse) to receive updates, share
  creations, get help, or give feedback.\\n\\n### Technical Support\\n- Email:
  api@pixverse.ai\\n- Website: https://platform.pixverse.ai\\n\\n## Release
  Notes\\nv1.0.0\\n- Supports text-to-video generation via MCP\\n- Enables video
  link retrieval\\n- Integrates with Claude and Cursor for enhanced
  workflows\\n- Supports Cloud based Python MCP
  servers\\n\",\"isRecommended\":false,\"githubStars\":24,\"downloadCount\":134,\
  \"createdAt\":\"2025-04-24T06:25:04.896697Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-07T15:25:49.985266Z\"},{\"mcpId\":\
  \"github.com/posthog/mcp\",\"githubUrl\":\"https://github.com/posthog/mcp\",\
  \"name\":\"PostHog\",\"author\":\"posthog\",\"description\":\"Integrates with
  PostHog analytics platform for managing feature flags, tracking errors, and
  analyzing user behavior through natural language
  interactions.\",\"codiconIcon\":\"graph\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/posthog.png\",\"category\":\"monitoring\",\"tags\
  \":[\"analytics\",\"feature-flags\",\"error-tracking\",\"user-behavior\",\"po\
  sthog-api\"],\"requiresApiKey\":false,\"readmeContent\":\"# PostHog
  MCP\\n\\n## Use the MCP Server\\n\\n### Quick install\\n\\nYou can install the
  MCP server automatically into popular clients by running the following
  command:\\n\\n```\\nnpx @posthog/wizard@latest mcp add\\n```\\n\\n### Manual
  install\\n\\n1. Obtain a personal API key using the MCP Server preset
  [here](https://app.posthog.com/settings/user-api-keys?preset=mcp_server).\\n\
  \\n2. Add the MCP configuration to your desktop client (e.g. Cursor, Windsurf,
  Claude Desktop) and add your personal API
  key\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"posthog\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"mcp-remote@latest\\\",\\n        \\\"ht\
  tps://mcp.posthog.com/sse\\\",\\n        \\\"--header\\\",\\n        \\\"Auth\
  orization:${POSTHOG_AUTH_HEADER}\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"POSTHOG_AUTH_HEADER\\\": \\\"Bearer
  {INSERT_YOUR_PERSONAL_API_KEY_HERE}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\
  \\n\\n**Here are some examples of prompts you can use:**\\n- What feature
  flags do I have active?\\n- Add a new feature flag for our homepage
  redesign\\n- What are my most common errors?\\n\\n## Running locally\\n\\n###
  Environment variables\\n\\n- Create `.dev.vars` in the root\\n- Add Inkeep API
  key to enable `docs-search` tool (see `Inkeep API key -
  mcp`)\\n\\n\\n```\\nINKEEP_API_KEY=\\\"...\\\"\\n```\\n\\n\",\"isRecommended\
  \":false,\"githubStars\":60,\"downloadCount\":204,\"createdAt\":\"2025-05-22T\
  06:17:32.388563Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithub\
  Sync\":\"2025-07-07T01:04:51.903053Z\"},{\"mcpId\":\"github.com/antvis/mcp-se\
  rver-chart\",\"githubUrl\":\"https://github.com/antvis/mcp-server-chart\",\"n\
  ame\":\"Chart Generator\",\"author\":\"antvis\",\"description\":\"Creates
  various types of charts and visualizations using AntV, supporting 15+ chart
  types including line, bar, pie, radar, network graphs, and more with
  customizable deployment
  options.\",\"codiconIcon\":\"graph-line\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/chart-generator.png\",\"category\":\"image-vide\
  o-processing\",\"tags\":[\"data-visualization\",\"charts\",\"graphs\",\"antv\
  \",\"image-generation\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP
  Server Chart  ![](https://badge.mcpx.dev?type=server 'MCP
  Server')  [![build](https://github.com/antvis/mcp-server-chart/actions/workfl\
  ows/build.yml/badge.svg)](https://github.com/antvis/mcp-server-chart/actions/\
  workflows/build.yml) [![npm
  Version](https://img.shields.io/npm/v/@antv/mcp-server-chart.svg)](https://ww\
  w.npmjs.com/package/@antv/mcp-server-chart) [![smithery
  badge](https://smithery.ai/badge/@antvis/mcp-server-chart)](https://smithery.\
  ai/server/@antvis/mcp-server-chart) [![npm
  License](https://img.shields.io/npm/l/@antv/mcp-server-chart.svg)](https://ww\
  w.npmjs.com/package/@antv/mcp-server-chart)\\n\\nA Model Context Protocol
  server for generating charts using [AntV](https://github.com/antvis/).\\n\\n<a
  href=\\\"https://www.star-history.com/#antvis/mcp-server-chart&Date\\\">\\n  \
  <img width=\\\"512\\\"
  src=\\\"https://api.star-history.com/svg?repos=antvis/mcp-server-chart&type=D\
  ate\\\" />\\n</a>\\n\\nThis is a TypeScript-based MCP server that provides
  chart generation capabilities. It allows you to create various types of charts
  through MCP tools. You can also use it in
  [Dify](https://marketplace.dify.ai/plugins/antv/visualization).\\n\\n## 
  Table of Contents\\n\\n- [ Features](#-features)\\n- [ Usage](#-usage)\\n-
  [ Run with SSE or Streamable
  transport](#-run-with-sse-or-streamable-transport)\\n- [ CLI
  Options](#-cli-options)\\n- [ Environment
  Variables](#%EF%B8%8F-environment-variables)\\n  -
  [VIS_REQUEST_SERVER](#-private-deployment)\\n  -
  [SERVICE_ID](#%EF%B8%8F-generate-records)\\n  -
  [DISABLED_TOOLS](#%EF%B8%8F-tool-filtering)\\n- [ Private
  Deployment](#-private-deployment)\\n- [ Generate
  Records](#%EF%B8%8F-generate-records)\\n- [ Tool
  Filtering](#%EF%B8%8F-tool-filtering)\\n- [ Development](#-development)\\n-
  [ License](#-license)\\n\\n##  Features\\n\\nNow 25+ charts
  supported.\\n\\n<img width=\\\"768\\\" alt=\\\"mcp-server-chart preview\\\"
  src=\\\"https://mdn.alipayobjects.com/huamei_qa8qxu/afts/img/A*IyIRQIQHyKYAAA\
  AAgCAAAAgAemJ7AQ/fmt.avif\\\" />\\n\\n1. `generate_area_chart`: Generate an
  `area` chart, used to display the trend of data under a continuous independent
  variable, allowing observation of overall data trends.\\n1.
  `generate_bar_chart`: Generate a `bar` chart, used to compare values across
  different categories, suitable for horizontal comparisons.\\n1.
  `generate_boxplot_chart`: Generate a `boxplot`, used to display the
  distribution of data, including the median, quartiles, and outliers.\\n1.
  `generate_column_chart`: Generate a `column` chart, used to compare values
  across different categories, suitable for vertical comparisons.\\n1.
  `generate_district_map` - Generate a `district-map`, used to show
  administrative divisions and data distribution.\\n1.
  `generate_dual_axes_chart`: Generate a `dual-axes` chart, used to display the
  relationship between two variables with different units or ranges.\\n1.
  `generate_fishbone_diagram`: Generate a `fishbone` diagram, also known as an
  Ishikawa diagram, used to identify and display the root causes of a
  problem.\\n1. `generate_flow_diagram`: Generate a `flowchart`, used to display
  the steps and sequence of a process.\\n1. `generate_funnel_chart`: Generate a
  `funnel` chart, used to display data loss at different stages.\\n1.
  `generate_histogram_chart`: Generate a `histogram`, used to display the
  distribution of data by dividing it into intervals and counting the number of
  data points in each interval.\\n1. `generate_line_chart`: Generate a `line`
  chart, used to display the trend of data over time or another continuous
  variable.\\n1. `generate_liquid_chart`: Generate a `liquid` chart, used to
  display the proportion of data, visually representing percentages in the form
  of water-filled spheres.\\n1. `generate_mind_map`: Generate a `mind-map`, used
  to display thought processes and hierarchical information.\\n1.
  `generate_network_graph`: Generate a `network` graph, used to display
  relationships and connections between nodes.\\n1.
  `generate_organization_chart`: Generate an `organizational` chart, used to
  display the structure of an organization and personnel relationships.\\n1.
  `generate_path_map` - Generate a `path-map`, used to display route planning
  results for POIs.\\n1. `generate_pie_chart`: Generate a `pie` chart, used to
  display the proportion of data, dividing it into parts represented by sectors
  showing the percentage of each part.\\n1. `generate_pin_map` - Generate a
  `pin-map`, used to show the distribution of POIs.\\n1. `generate_radar_chart`:
  Generate a `radar` chart, used to display multi-dimensional data
  comprehensively, showing multiple dimensions in a radar-like format.\\n1.
  `generate_sankey_chart`: Generate a `sankey` chart, used to display data flow
  and volume, representing the movement of data between different nodes in a
  Sankey-style format.\\n1. `generate_scatter_chart`: Generate a `scatter` plot,
  used to display the relationship between two variables, showing data points as
  scattered dots on a coordinate system.\\n1. `generate_treemap_chart`: Generate
  a `treemap`, used to display hierarchical data, showing data in rectangular
  forms where the size of rectangles represents the value of the data.\\n1.
  `generate_venn_chart`: Generate a `venn` diagram, used to display
  relationships between sets, including intersections, unions, and
  differences.\\n1. `generate_violin_chart`: Generate a `violin` plot, used to
  display the distribution of data, combining features of boxplots and density
  plots to provide a more detailed view of the data distribution.\\n1.
  `generate_word_cloud_chart`: Generate a `word-cloud`, used to display the
  frequency of words in textual data, with font sizes indicating the frequency
  of each word.\\n\\n> [!NOTE]\\n> The above geographic visualization chart
  generation tool uses [AMap service](https://lbs.amap.com/) and currently only
  supports map generation within China.\\n\\n##  Usage\\n\\nTo use with
  `Desktop APP`, such as Claude, VSCode,
  [Cline](https://cline.bot/mcp-marketplace), Cherry Studio, Cursor, and so on,
  add the MCP server config below. On Mac
  system:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-chart\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@antv/mcp-server-chart\\\"\\n      ]\\n    \
  }\\n  }\\n}\\n```\\n\\nOn Window
  system:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-chart\\\": {\\n      \\\"command\\\":
  \\\"cmd\\\",\\n      \\\"args\\\":
  [\\n        \\\"/c\\\",\\n        \\\"npx\\\",\\n        \\\"-y\\\",\\n        \
  \\\"@antv/mcp-server-chart\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nAlso,
  you can use it on
  [aliyun](https://bailian.console.aliyun.com/?tab=mcp#/mcp-market/detail/antv-\
  visualization-chart),
  [modelscope](https://www.modelscope.cn/mcp/servers/@antvis/mcp-server-chart),
  [glama.ai](https://glama.ai/mcp/servers/@antvis/mcp-server-chart),
  [smithery.ai](https://smithery.ai/server/@antvis/mcp-server-chart) or others
  with HTTP, SSE Protocol.\\n\\n##  Run with SSE or Streamable
  transport\\n\\nInstall the package globally.\\n\\n```bash\\nnpm install -g
  @antv/mcp-server-chart\\n```\\n\\nRun the server with your preferred transport
  option:\\n\\n```bash\\n# For SSE transport (default endpoint:
  /sse)\\nmcp-server-chart --transport sse\\n\\n# For Streamable transport with
  custom endpoint\\nmcp-server-chart --transport streamable\\n```\\n\\nThen you
  can access the server at:\\n\\n- SSE transport:
  `http://localhost:1122/sse`\\n- Streamable transport:
  `http://localhost:1122/mcp`\\n\\n##  CLI Options\\n\\nYou can also use the
  following CLI options when running the MCP server. Command options by run cli
  with `-h`.\\n\\n```plain\\nMCP Server Chart CLI\\n\\nOptions:\\n  --transport,
  -t  Specify the transport protocol: \\\"stdio\\\", \\\"sse\\\", or
  \\\"streamable\\\" (default: \\\"stdio\\\")\\n  --port, -p       Specify the
  port for SSE or streamable transport (default: 1122)\\n  --endpoint,
  -e   Specify the endpoint for the transport:\\n                   - For SSE:
  default is \\\"/sse\\\"\\n                   - For streamable: default is
  \\\"/mcp\\\"\\n  --help, -h       Show this help message\\n```\\n\\n## 
  Environment Variables\\n\\n| Variable | Description | Default | Example
  |\\n|----------|:------------|---------|---------|\\n| `VIS_REQUEST_SERVER` |
  Custom chart generation service URL for private deployment |
  `https://antv-studio.alipay.com/api/gpt-vis` |
  `https://your-server.com/api/chart` |\\n| `SERVICE_ID` | Service identifier
  for chart generation records | - | `your-service-id-123` |\\n|
  `DISABLED_TOOLS` | Comma-separated list of tool names to disable | - |
  `generate_fishbone_diagram,generate_mind_map` |\\n\\n\\n###  Private
  Deployment\\n\\n`MCP Server Chart` provides a free chart generation service by
  default. For users with a need for private deployment, they can try using
  `VIS_REQUEST_SERVER` to customize their own chart generation
  service.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-chart\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@antv/mcp-server-chart\\\"\\n      ],\\\
  n      \\\"env\\\": {\\n        \\\"VIS_REQUEST_SERVER\\\":
  \\\"<YOUR_VIS_REQUEST_SERVER>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nYou
  can use AntV's project
  [GPT-Vis-SSR](https://github.com/antvis/GPT-Vis/tree/main/bindings/gpt-vis-ss\
  r) to deploy an HTTP service in a private environment, and then pass the URL
  address through env `VIS_REQUEST_SERVER`.\\n\\n- **Method**: `POST`\\n-
  **Parameter**: Which will be passed to `GPT-Vis-SSR` for rendering. Such as,
  `{ \\\"type\\\": \\\"line\\\", \\\"data\\\": [{ \\\"time\\\": \\\"2025-05\\\",
  \\\"value\\\": 512 }, { \\\"time\\\": \\\"2025-06\\\", \\\"value\\\": 1024 }]
  }`.\\n- **Return**: The return object of HTTP service.\\n  - **success**:
  `boolean` Whether generate chart image successfully.\\n  - **resultObj**:
  `string` The chart image url.\\n  - **errorMessage**: `string` When `success =
  false`, return the error message.\\n\\n> [!NOTE]\\n> The private deployment
  solution currently does not support geographic visualization chart generation
  include 3 tools: `geographic-district-map`, `geographic-path-map`,
  `geographic-pin-map`.\\n\\n###  Generate Records\\n\\nBy default, users are
  required to save the results themselves, but we also provide a service for
  viewing the chart generation records, which requires users to generate a
  service identifier for themselves and configure it.\\n\\nUse Alipay to scan
  and open the mini program to generate a personal service identifier (click the
  \\\"My\\\" menu below, enter the \\\"My Services\\\" page, click the
  \\\"Generate\\\" button, and click the \\\"Copy\\\" button after
  success):\\n\\n<img alt=\\\"my service identifier website\\\"
  width=\\\"240\\\"
  src=\\\"https://mdn.alipayobjects.com/huamei_dxq8v0/afts/img/dASoTLt6EywAAAAA\
  RqAAAAgADu43AQFr/fmt.webp\\\" />\\n\\nNext, you need to add the `SERVICE_ID`
  environment variable to the MCP server configuration. For example, the
  configuration for Mac is as follows (for Windows systems, just add the `env`
  variable):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"AntV Map\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@antv/mcp-server-chart\\\"\\n      ],\\\
  n      \\\"env\\\": {\\n        \\\"SERVICE_ID\\\":
  \\\"***********************************\\\"\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nAfter updating the MCP Server configuration, you need to restart your AI
  client application and check again whether you have started and connected to
  the MCP Server successfully. Then you can try to generate the map again. After
  the generation is successful, you can go to the \\\"My Map\\\" page of the
  mini program to view your map generation records.\\n\\n<img alt=\\\"my map
  records website\\\" width=\\\"240\\\"
  src=\\\"https://mdn.alipayobjects.com/huamei_dxq8v0/afts/img/RacFR7emR3QAAAAA\
  UkAAAAgADu43AQFr/original\\\" />\\n\\n###  Tool Filtering\\n\\nYou can
  disable specific chart generation tools using the `DISABLED_TOOLS` environment
  variable. This is useful when certain tools have compatibility issues with
  your MCP client or when you want to limit the available
  functionality.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-chart\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@antv/mcp-server-chart\\\"\\n      ],\\\
  n      \\\"env\\\": {\\n        \\\"DISABLED_TOOLS\\\":
  \\\"generate_fishbone_diagram,generate_mind_map\\\"\\n      }\\n    }\\n  }\\\
  n}\\n```\\n\\n**Available tool names for filtering** See the [
  Features](#-features).\\n\\n##  Development\\n\\nInstall
  dependencies:\\n\\n```bash\\nnpm install\\n```\\n\\nBuild the
  server:\\n\\n```bash\\nnpm run build\\n```\\n\\nStart the MCP
  server:\\n\\n```bash\\nnpm run start\\n```\\n\\n## 
  License\\n\\nMIT@[AntV](https://github.com/antvis).\\n\",\"isRecommended\":fa\
  lse,\"githubStars\":1741,\"downloadCount\":1143,\"createdAt\":\"2025-05-18T07\
  :54:49.04534Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\
  \":\"2025-07-06T14:27:00.742762Z\"},{\"mcpId\":\"github.com/paypal/agent-tool\
  kit\",\"githubUrl\":\"https://github.com/paypal/agent-toolkit\",\"name\":\"Pa\
  yPal\",\"author\":\"paypal\",\"description\":\"Enables integration with PayPal
  APIs for creating invoices, managing orders, and handling transactions through
  multiple agent frameworks and function
  calling.\",\"codiconIcon\":\"credit-card\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/paypal.png\",\"category\":\"finance\",\"tags\"\
  :[\"payments\",\"invoicing\",\"transactions\",\"paypal-api\",\"financial-serv\
  ices\"],\"requiresApiKey\":false,\"readmeContent\":\"# PayPal Agent
  Toolkit\\n\\nThe PayPal Agent Toolkit enables popular agent frameworks
  including OpenAI's Agent SDK, LangChain, Vercel's AI SDK, and Model Context
  Protocol (MCP) to integrate with PayPal APIs through function calling. It
  includes support for TypeScript and is built on top of PayPal APIs and the
  PayPal SDKs.\\n\\n\\n## Available tools\\n\\nThe PayPal Agent toolkit provides
  the following tools:\\n\\n**Invoices**\\n\\n- `create_invoice`: Create a new
  invoice in the PayPal system\\n- `list_invoices`: List invoices with optional
  pagination and filtering\\n- `get_invoice`: Retrieve details of a specific
  invoice\\n- `send_invoice`: Send an invoice to recipients\\n-
  `send_invoice_reminder`: Send a reminder for an existing invoice\\n-
  `cancel_sent_invoice`: Cancel a sent invoice\\n- `generate_invoice_qr_code`:
  Generate a QR code for an invoice\\n\\n**Payments**\\n\\n- `create_order`:
  Create an order in PayPal system based on provided details\\n- `get_order`:
  Retrieve the details of an order\\n- `pay_order`: Process payment for an
  authorized order\\n- `create_refund`: Process a refund for a captured
  payment.\\n- `get_refund`: Get the details for a specific
  refund.\\n\\n**Dispute Management**\\n\\n- `list_disputes`: Retrieve a summary
  of all open disputes\\n- `get_dispute`: Retrieve detailed information of a
  specific dispute\\n- `accept_dispute_claim`: Accept a dispute
  claim\\n\\n**Shipment Tracking**\\n\\n- `create_shipment_tracking`: Create a
  shipment tracking record\\n- `get_shipment_tracking`: Retrieve shipment
  tracking information\\n\\n**Catalog Management**\\n\\n- `create_product`:
  Create a new product in the PayPal catalog\\n- `list_products`: List products
  with optional pagination and filtering\\n- `show_product_details`: Retrieve
  details of a specific product\\n\\n**Subscription Management**\\n\\n-
  `create_subscription_plan`: Create a new subscription plan\\n-
  `list_subscription_plans`: List subscription plans\\n-
  `show_subscription_plan_details`: Retrieve details of a specific subscription
  plan\\n- `create_subscription`: Create a new subscription\\n-
  `show_subscription_details`: Retrieve details of a specific subscription\\n-
  `update_subscription`: update an existing subscription\\n-
  `cancel_subscription`: Cancel an active subscription\\n\\n\\n**Reporting and
  Insights**\\n\\n- `list_transactions`: List transactions with optional
  pagination and filtering\\n\\n## TypeScript\\n\\n### Installation\\n\\nYou
  don't need this source code unless you want to modify the package. If you
  just\\nwant to use the package run:\\n\\n```sh\\nnpm install
  @paypal/agent-toolkit\\n```\\n\\n#### Requirements\\n\\n- Node 18+\\n\\n###
  Usage\\n\\nThe library needs to be configured with your account's client id
  and secret which is available in your [PayPal Developer
  Dashboard](https://developer.paypal.com/dashboard/). \\n\\n\\nThe toolkit
  works with Vercel's AI SDK and can be passed as a list of tools. For more
  details, refer our
  [examples](./typescript/examples)\\n\\n```typescript\\nimport {
  PayPalAgentToolkit } from '@paypal/agent-toolkit/ai-sdk';\\nconst
  paypalToolkit = new PayPalAgentToolkit({\\n  clientId:
  process.env.PAYPAL_CLIENT_ID,\\n  clientSecret:
  process.env.PAYPAL_CLIENT_SECRET,\\n  configuration: {\\n    actions:
  {\\n      invoices: {\\n        create: true,\\n        list:
  true,\\n        send: true,\\n        sendReminder: true,\\n        cancel:
  true,\\n        generateQRC: true,\\n      },\\n      products: { create:
  true, list: true, update: true },\\n      subscriptionPlans: { create: true,
  list: true, show: true },\\n      shipment: { create: true, show: true,
  cancel: true },\\n      orders: { create: true, get: true },\\n      disputes:
  { list: true, get: true },\\n    },\\n  },\\n});\\n```\\n\\n### Initializing
  the Workflows\\n\\n```typescript\\nimport { PayPalWorkflows, ALL_TOOLS_ENABLED
  } from '@paypal/agent-toolkit/ai-sdk';\\nconst paypalWorkflows = new
  PayPalWorkflows({\\n  clientId:
  process.env.PAYPAL_CLIENT_ID,\\n  clientSecret:
  process.env.PAYPAL_CLIENT_SECRET,\\n  configuration: {\\n    actions:
  ALL_TOOLS_ENABLED,\\n  },\\n});\\n```\\n\\n## Usage\\n\\n### Using the
  toolkit\\n\\n```typescript\\nconst llm: LanguageModelV1 = getModel(); // The
  model to be used with ai-sdk\\nconst { text: response } = await
  generateText({\\n  model: llm,\\n  tools:
  paypalToolkit.getTools(),\\n  maxSteps: 10,\\n  prompt: `Create an order for
  $50 for custom handcrafted item and get the payment
  link.`,\\n});\\n\\n```\\n\\n## PayPal Model Context Protocol\\n\\nThe PayPal
  [Model Context Protocol](https://modelcontextprotocol.com/) server allows you
  to integrate with PayPal APIs through function calling. This protocol supports
  various tools to interact with different PayPal services.\\n\\n### Running MCP
  Inspector\\n\\nTo run the PayPal MCP server using npx, use the following
  command:\\n\\n```bash\\nnpx -y @paypal/mcp --tools=all
  PAYPAL_ACCESS_TOKEN=\\\"YOUR_ACCESS_TOKEN\\\"
  PAYPAL_ENVIRONMENT=\\\"SANDBOX\\\"\\n```\\n\\nReplace `YOUR_ACCESS_TOKEN` with
  active access token generated using these steps: [PayPal access
  token](#generating-an-access-token). Alternatively, you could set the
  PAYPAL_ACCESS_TOKEN in your environment variables.\\n\\n### Custom MCP
  Server\\nYou can set up your own MCP server. For
  example:\\n\\n```typescript\\nimport { PayPalAgentToolkit } from
  @paypal/agent-toolkit/modelcontextprotocol\\\";\\nimport {
  StdioServerTransport } from
  \\\"@modelcontextprotocol/sdk/server/stdio.js\\\";\\n\\nconst orderSummary =
  await
  paypalWorkflows.generateOrder(\\n  llm,\\n  transactionInfo,\\n  merchantInfo,\
  \\n);\\n\\nconst server = new PayPalAgentToolkit({\\n\\taccessToken:
  process.env.PAYPAL_ACCESS_TOKEN\\n});\\n\\nasync function main() {\\n  const
  transport = new StdioServerTransport();\\n  await
  server.connect(transport);\\n  console.error(\\\"PayPal MCP Server running on
  stdio\\\");\\n}\\n\\nmain().catch((error) => {\\n  console.error(\\\"Fatal
  error in main():\\\", error);\\n  process.exit(1);\\n});\\n```\\n\\n### Usage
  with MCP host (Claude Desktop/Cline/Cursor/Github Co-Pilot)\\n\\nThis guide
  explains how to integrate the PayPal connector with Claude Desktop.\\n\\n##
  Prerequisites\\n- Claude Desktop application installed\\n- installing Node.js
  locally\\n\\n## Installation Steps\\n\\n### 1. Install Node.js\\n\\nNode.js is
  required for the PayPal connector to function:\\n\\n1. Visit the [Node.js
  official website](https://nodejs.org/), download and install it.\\n2.
  Requirements: Node 18+\\n\\n### 2. Configure PayPal Connector with MCP host
  (Claude desktop / Cursor / Cline)\\nWe will show the integration with Claude
  desktop. You can use your favorite MCP host.\\n1. Open Claude Desktop\\n2.
  Navigate to Settings\\n3. Find the Developer or Advanced settings section\\n4.
  Locate the external tools or connectors configuration area\\n5. Add the
  following PayPal connector configuration to this
  ~/Claude/claude_desktop_config.json:\\n\\n```json\\n{\\n   \\\"mcpServers\\\":
  {\\n     \\\"paypal\\\": {\\n       \\\"command\\\":
  \\\"npx\\\",\\n       \\\"args\\\":
  [\\n         \\\"-y\\\",\\n         \\\"@paypal/mcp\\\",\\n         \\\"--too\
  ls=all\\\"\\n       ],\\n       \\\"env\\\":
  {\\n         \\\"PAYPAL_ACCESS_TOKEN\\\":
  \\\"YOUR_PAYPAL_ACCESS_TOKEN\\\",\\n         \\\"PAYPAL_ENVIRONMENT\\\":
  \\\"SANDBOX\\\"\\n       }\\n     }\\n   }\\n}\\n```\\nMake sure to replace
  `YOUR_PAYPAL_ACCESS_TOKEN` with your actual PayPal Access Token.
  Alternatively, you could set the PAYPAL_ACCESS_TOKEN as an environment
  variable. You can also pass it as an argument using --access-token in
  \\\"args\\\"\\nSet `PAYPAL_ENVIRONMENT` value as either `SANDBOX` for stage
  testing and `PRODUCTION` for production environment.\\n\\n6. Save your
  configuration changes\\n\\n### 3. Test the Integration\\n\\n1. Quit and
  restart Claude Desktop to apply changes\\n2. Test the connection by asking
  Claude to perform a PayPal-related task\\n   - Example: \\\\\\\"List my PayPal
  invoices\\\\\\\"\\n\\n## Environment Variables\\n\\nThe following environment
  variables can be used:\\n\\n- `PAYPAL_ACCESS_TOKEN`: Your PayPal Access
  Token\\n- `PAYPAL_ENVIRONMENT`: Set to `SANDBOX` for sandbox mode,
  `PRODUCTION` for production (defaults to `SANDBOX` mode)\\n\\n\\nThis guide
  explains how to generate an access token for PayPal API integration, including
  how to find your client ID and client secret.\\n\\n\\n\\n##
  Prerequisites\\n\\n- PayPal Developer account (for Sandbox)\\n- PayPal
  Business account (for production)\\n\\n## Finding Your Client ID and Client
  Secret\\n\\n1. **Create a PayPal Developer Account**:\\n   - Go to [PayPal
  Developer Dashboard](https://developer.paypal.com/dashboard/)\\n   - Sign up
  or log in with your PayPal credentials\\n\\n2. **Access Your
  Credentials**:\\n   - In the Developer Dashboard, click on **Apps &
  Credentials** in the menu\\n   - Switch between **Sandbox** and **Live** modes
  depending on your needs\\n   \\n3. **Create or View an App**:\\n   - To create
  a new app, click **Create App**\\n   - Give your app a name and select a
  Business account to associate with it\\n   - For existing apps, click on the
  app name to view details\\n\\n4. **Retrieve Credentials**:\\n   - Once your
  app is created or selected, you'll see a screen with your:\\n     - **Client
  ID**: A public identifier for your app\\n     - **Client Secret**: A private
  key (shown after clicking \\\\\\\"Show\\\\\\\")\\n   - Save these credentials
  securely as they are required for generating access tokens\\n\\n## Generating
  an Access Token\\n### Using cURL\\n\\n```bash\\ncurl -v
  https://api-m.sandbox.paypal.com/v1/oauth2/token \\\\\\\\\\n  -H
  \\\\\\\"Accept: application/json\\\\\\\" \\\\\\\\\\n  -H
  \\\\\\\"Accept-Language: en_US\\\\\\\" \\\\\\\\\\n  -u
  \\\\\\\"CLIENT_ID:CLIENT_SECRET\\\\\\\" \\\\\\\\\\n  -d
  \\\\\\\"grant_type=client_credentials\\\\\\\"\\n```\\n\\nReplace `CLIENT_ID`
  and `CLIENT_SECRET` with your actual credentials. For production, use
  `https://api-m.paypal.com` instead of the sandbox URL.\\n\\n\\n### Using
  Postman\\n\\n1. Create a new request to
  `https://api-m.sandbox.paypal.com/v1/oauth2/token`\\n2. Set method to
  **POST**\\n3. Under **Authorization**, select **Basic Auth** and enter your
  Client ID and Client Secret\\n4. Under **Body**, select
  **x-www-form-urlencoded** and add a key `grant_type` with value
  `client_credentials`\\n5. Send the request\\n\\n### Response\\n\\nA successful
  response will look like:\\n\\n```json\\n{\\n  \\\"scope\\\":
  \\\"...\\\",\\n  \\\"access_token\\\": \\\"Your Access
  Token\\\",\\n  \\\"token_type\\\": \\\"Bearer\\\",\\n  \\\"app_id\\\":
  \\\"APP-80W284485P519543T\\\",\\n  \\\"expires_in\\\":
  32400,\\n  \\\"nonce\\\": \\\"...\\\"\\n}\\n```\\n\\nCopy the `access_token`
  value for use in your Claude Desktop integration.\\n\\n## Token Details\\n\\n-
  **Sandbox Tokens**: Valid for 3-8 hours\\n- **Production Tokens**: Valid for 8
  hours\\n- It's recommended to implement token refresh logic before
  expiration\\n\\n## Using the Token with Claude Desktop\\n\\nOnce you have your
  access token, update the `PAYPAL_ACCESS_TOKEN` value in your Claude Desktop
  connector configuration:\\n\\n```json\\n{\\n  \\\"env\\\":
  {\\n    \\\"PAYPAL_ACCESS_TOKEN\\\":
  \\\"YOUR_NEW_ACCESS_TOKEN\\\",\\n    \\\"PAYPAL_ENVIRONMENT\\\":
  \\\"SANDBOX\\\"\\n  }\\n}\\n```\\n\\n## Best Practices\\n\\n1. Store client ID
  and client secret securely\\n2. Implement token refresh logic to handle token
  expiration\\n3. Use environment-specific tokens (sandbox for testing,
  production for real transactions)\\n4. Avoid hardcoding tokens in application
  code\\n\\n## Disclaimer\\n*AI-generated content may be inaccurate or
  incomplete. Users are responsible for independently verifying any information
  before relying on it. PayPal makes no guarantees regarding output accuracy and
  is not liable for any decisions, actions, or consequences resulting from its
  use.*\\n\",\"isRecommended\":false,\"githubStars\":115,\"downloadCount\":440,\
  \"createdAt\":\"2025-04-08T05:48:29.23484Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-07-03T14:45:32.655687Z\"},{\"mcpId\":\
  \"github.com/pashpashpash/mcp-server-asana\",\"githubUrl\":\"https://github.c\
  om/pashpashpash/mcp-server-asana\",\"name\":\"Asana\",\"author\":\"pashpashpa\
  sh\",\"description\":\"Enables AI assistants to interact with Asana
  workspaces, providing comprehensive task and project management capabilities
  including creation, search, updates, and status
  tracking.\",\"codiconIcon\":\"project\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/asana.png\",\"category\":\"developer-tools\",\"ta\
  gs\":[\"project-management\",\"task-tracking\",\"team-collaboration\",\"workf\
  low\",\"asana-api\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP Server
  for Asana\\nA fork of @roychri's MCP (Model Context Protocol) server
  implementation for Asana, allowing you to interact with the Asana API from MCP
  clients such as Anthropic's Claude Desktop Application.\\n\\nMore details on
  MCP here:\\n - https://www.anthropic.com/news/model-context-protocol\\n -
  https://modelcontextprotocol.io/introduction\\n -
  https://github.com/modelcontextprotocol\\n\\n## Usage\\n\\nIn the AI tool of
  your choice (ex: Claude Desktop) ask something about asana tasks, projects,
  workspaces, and/or comments. Mentioning the word \\\"asana\\\" will increase
  the chance of having the LLM pick the right tool.\\n\\nExample:\\n\\n> How
  many unfinished asana tasks do we have in our Sprint 30 project?\\n\\nAnother
  example:\\n\\n![Claude Desktop
  Example](https://raw.githubusercontent.com/pashpashpash/mcp-server-asana/main\
  /mcp-server-asana-claude-example.png)\\n\\n## Tools\\n\\n1.
  `asana_list_workspaces`\\n    * List all available workspaces in Asana\\n    *
  Optional input:\\n        * opt_fields (string): Comma-separated list of
  optional fields to include\\n    * Returns: List of workspaces\\n\\n2.
  `asana_search_projects`\\n    * Search for projects in Asana using name
  pattern matching\\n    * Required input:\\n        * workspace (string): The
  workspace to search in\\n        * name_pattern (string): Regular expression
  pattern to match project names\\n    * Optional input:\\n        * archived
  (boolean): Only return archived projects (default: false)\\n        *
  opt_fields (string): Comma-separated list of optional fields to
  include\\n    * Returns: List of matching projects\\n\\n3.
  `asana_search_tasks`\\n    * Search tasks in a workspace with advanced
  filtering options\\n    * Required input:\\n        * workspace (string): The
  workspace to search in\\n    * Optional input:\\n        * text (string): Text
  to search for in task names and descriptions\\n        * resource_subtype
  (string): Filter by task subtype (e.g. milestone)\\n        * completed
  (boolean): Filter for completed tasks\\n        * is_subtask (boolean): Filter
  for subtasks\\n        * has_attachment (boolean): Filter for tasks with
  attachments\\n        * is_blocked (boolean): Filter for tasks with incomplete
  dependencies\\n        * is_blocking (boolean): Filter for incomplete tasks
  with dependents\\n        * assignee, projects, sections, tags, teams, and
  many other advanced filters\\n        * sort_by (string): Sort by due_date,
  created_at, completed_at, likes, modified_at (default:
  modified_at)\\n        * sort_ascending (boolean): Sort in ascending order
  (default: false)\\n        * opt_fields (string): Comma-separated list of
  optional fields to include\\n        * custom_fields (object): Object
  containing custom field filters\\n    * Returns: List of matching
  tasks\\n\\n4. `asana_get_task`\\n    * Get detailed information about a
  specific task\\n    * Required input:\\n        * task_id (string): The task
  ID to retrieve\\n    * Optional input:\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: Detailed
  task information\\n\\n5. `asana_create_task`\\n    * Create a new task in a
  project\\n    * Required input:\\n        * project_id (string): The project
  to create the task in\\n        * name (string): Name of the task\\n    *
  Optional input:\\n        * notes (string): Description of the
  task\\n        * html_notes (string): HTML-like formatted description of the
  task\\n        * due_on (string): Due date in YYYY-MM-DD format\\n        *
  assignee (string): Assignee (can be 'me' or a user ID)\\n        * followers
  (array of strings): Array of user IDs to add as followers\\n        * parent
  (string): The parent task ID to set this task under\\n        * projects
  (array of strings): Array of project IDs to add this task to\\n    * Returns:
  Created task information\\n\\n6. `asana_get_task_stories`\\n    * Get comments
  and stories for a specific task\\n    * Required input:\\n        * task_id
  (string): The task ID to get stories for\\n    * Optional input:\\n        *
  opt_fields (string): Comma-separated list of optional fields to
  include\\n    * Returns: List of task stories/comments\\n\\n7.
  `asana_update_task`\\n    * Update an existing task's details\\n    * Required
  input:\\n        * task_id (string): The task ID to update\\n    * Optional
  input:\\n        * name (string): New name for the task\\n        * notes
  (string): New description for the task\\n        * due_on (string): New due
  date in YYYY-MM-DD format\\n        * assignee (string): New assignee (can be
  'me' or a user ID)\\n        * completed (boolean): Mark task as completed or
  not\\n    * Returns: Updated task information\\n\\n8.
  `asana_get_project`\\n    * Get detailed information about a specific
  project\\n    * Required input:\\n        * project_id (string): The project
  ID to retrieve\\n    * Optional input:\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: Detailed
  project information\\n\\n9. `asana_get_project_task_counts`\\n    * Get the
  number of tasks in a project\\n    * Required input:\\n        * project_id
  (string): The project ID to get task counts for\\n    * Optional
  input:\\n        * opt_fields (string): Comma-separated list of optional
  fields to include\\n    * Returns: Task count information\\n\\n10.
  `asana_get_project_sections`\\n    * Get sections in a project\\n    *
  Required input:\\n        * project_id (string): The project ID to get
  sections for\\n    * Optional input:\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: List of
  project sections\\n\\n11. `asana_create_task_story`\\n    * Create a comment
  or story on a task\\n    * Required input:\\n        * task_id (string): The
  task ID to add the story to\\n        * text (string): The text content of the
  story/comment\\n    * Optional input:\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: Created
  story information\\n\\n12. `asana_add_task_dependencies`\\n    * Set
  dependencies for a task\\n    * Required input:\\n        * task_id (string):
  The task ID to add dependencies to\\n        * dependencies (array of
  strings): Array of task IDs that this task depends on\\n    * Returns: Updated
  task dependencies\\n\\n13. `asana_add_task_dependents`\\n    * Set dependents
  for a task (tasks that depend on this task)\\n    * Required
  input:\\n        * task_id (string): The task ID to add dependents
  to\\n        * dependents (array of strings): Array of task IDs that depend on
  this task\\n    * Returns: Updated task dependents\\n\\n14.
  `asana_create_subtask`\\n    * Create a new subtask for an existing
  task\\n    * Required input:\\n        * parent_task_id (string): The parent
  task ID to create the subtask under\\n        * name (string): Name of the
  subtask\\n    * Optional input:\\n        * notes (string): Description of the
  subtask\\n        * due_on (string): Due date in YYYY-MM-DD format\\n        *
  assignee (string): Assignee (can be 'me' or a user ID)\\n        * opt_fields
  (string): Comma-separated list of optional fields to include\\n    * Returns:
  Created subtask information\\n\\n15. `asana_get_multiple_tasks_by_gid`\\n    *
  Get detailed information about multiple tasks by their GIDs (maximum 25
  tasks)\\n    * Required input:\\n        * task_ids (array of strings or
  comma-separated string): Task GIDs to retrieve (max 25)\\n    * Optional
  input:\\n        * opt_fields (string): Comma-separated list of optional
  fields to include\\n    * Returns: List of detailed task information\\n\\n16.
  `asana_get_project_status`\\n    * Get a project status update\\n    *
  Required input:\\n        * project_status_gid (string): The project status
  GID to retrieve\\n    * Optional input:\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: Project
  status information\\n\\n17. `asana_get_project_statuses`\\n    * Get all
  status updates for a project\\n    * Required input:\\n        * project_gid
  (string): The project GID to get statuses for\\n    * Optional
  input:\\n        * limit (number): Results per page (1-100)\\n        * offset
  (string): Pagination offset token\\n        * opt_fields (string):
  Comma-separated list of optional fields to include\\n    * Returns: List of
  project status updates\\n\\n18. `asana_create_project_status`\\n    * Create a
  new status update for a project\\n    * Required input:\\n        *
  project_gid (string): The project GID to create the status for\\n        *
  text (string): The text content of the status update\\n    * Optional
  input:\\n        * color (string): The color of the status (green, yellow,
  red)\\n        * title (string): The title of the status update\\n        *
  html_text (string): HTML formatted text for the status update\\n        *
  opt_fields (string): Comma-separated list of optional fields to
  include\\n    * Returns: Created project status information\\n\\n19.
  `asana_delete_project_status`\\n    * Delete a project status update\\n    *
  Required input:\\n        * project_status_gid (string): The project status
  GID to delete\\n    * Returns: Deletion confirmation\\n\\n## Prompts\\n\\n1.
  `task-summary`\\n    * Get a summary and status update for a task based on its
  notes, custom fields and comments\\n    * Required input:\\n        * task_id
  (string): The task ID to get summary for\\n    * Returns: A detailed prompt
  with instructions for generating a task summary\\n\\n## Setup\\n\\n### Local
  Installation\\n\\n1. Clone the repository:\\n```bash\\ngit clone
  https://github.com/pashpashpash/mcp-server-asana.git\\ncd
  mcp-server-asana\\n```\\n\\n2. Install dependencies:\\n```bash\\nnpm
  install\\n```\\n\\n3. Build the project:\\n```bash\\nnpm run
  build\\n```\\n\\n### Alternative Installation\\n\\nYou can also use `npx` to
  run the server directly (not recommended for development).\\n\\n###
  Configuration\\n\\n1. **Create an Asana account**:\\n   - Visit
  [Asana](https://www.asana.com)\\n   - Click \\\"Sign up\\\"\\n\\n2. **Retrieve
  the Asana Access Token**:\\n   - Generate a personal access token from the
  [Asana developer console](https://app.asana.com/0/my-apps)\\n   - More details
  here: https://developers.asana.com/docs/personal-access-token\\n\\n3.
  **Configure Claude Desktop**:\\n   Add the following to your
  `claude_desktop_config.json`:\\n\\n   For local
  installation:\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"asana\\\": {\\n         \\\"command\\\":
  \\\"node\\\",\\n         \\\"args\\\":
  [\\\"path/to/build/index.js\\\"],\\n         \\\"env\\\":
  {\\n           \\\"ASANA_ACCESS_TOKEN\\\":
  \\\"your-asana-access-token\\\"\\n         }\\n       }\\n     }\\n   }\\n   \
  ```\\n\\nNote: Replace \\\"path/to/build/index.js\\\" with the **actual path**
  to your built index.js file. KEEP IN MIND, by default it will be in
  `./dist/index.js` according to
  `tsconfig.json`:\\n\\n```\\n{\\n  \\\"extends\\\":
  \\\"@tsconfig/node20/tsconfig.json\\\",\\n  \\\"compilerOptions\\\":
  {\\n    \\\"target\\\": \\\"ES2022\\\",\\n    \\\"module\\\":
  \\\"NodeNext\\\",\\n    \\\"moduleResolution\\\":
  \\\"NodeNext\\\",\\n    \\\"esModuleInterop\\\": true,\\n    \\\"strict\\\":
  true,\\n    \\\"outDir\\\": \\\"./dist\\\",\\n    \\\"rootDir\\\":
  \\\"./src\\\",\\n    \\\"declaration\\\": true,\\n    \\\"skipLibCheck\\\":
  true\\n  },\\n  \\\"ts-node\\\": {\\n    \\\"esm\\\":
  true,\\n    \\\"experimentalSpecifiers\\\": true\\n  },\\n  \\\"include\\\":
  [\\\"src/**/*\\\"],\\n  \\\"exclude\\\": [\\\"node_modules\\\",
  \\\"dist\\\"]\\n}\\n```\\n\\n## Troubleshooting\\n\\nIf you encounter
  permission errors:\\n\\n1. Ensure the asana plan you have allows API
  access\\n2. Confirm the access token and configuration are correctly set in
  `claude_desktop_config.json`\\n\\n## Development\\n\\n### Testing Locally with
  the MCP Inspector\\n\\nTo test your changes, you can use the MCP
  Inspector:\\n\\n```bash\\nnpm run inspector\\n```\\n\\nThis will expose the
  client to port `5173` and server to port `3000`.\\n\\nIf those ports are
  already used by something else, you can use:\\n\\n```bash\\nCLIENT_PORT=5009
  SERVER_PORT=3009 npm run inspector\\n```\\n\\n## License\\n\\nThis MCP server
  is licensed under the MIT License. This means you are free to use, modify, and
  distribute the software, subject to the terms and conditions of the MIT
  License. For more details, please see the LICENSE file in the project
  repository.\\n\",\"isRecommended\":false,\"githubStars\":5,\"downloadCount\":\
  400,\"createdAt\":\"2025-02-18T23:04:35.990279Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T02:55:06.789642Z\"},{\"mcp\
  Id\":\"github.com/magnitudedev/magnitude/tree/main/packages/magnitude-mcp\",\
  \"githubUrl\":\"https://github.com/magnitudedev/magnitude/tree/main/packages/\
  magnitude-mcp\",\"name\":\"Magnitude\",\"author\":\"magnitudedev\",\"descript\
  ion\":\"Users will leave if your app keeps breaking - Magnitude enables
  effortless end-to-end testing with visual AI agents that find bugs by
  navigating your app like real
  users.\",\"codiconIcon\":\"beaker\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/magnitude.png\",\"category\":\"quality\",\"tags\":[\"\
  testing\",\"automation\",\"quality-assurance\",\"cli-integration\",\"test-cas\
  es\"],\"requiresApiKey\":false,\"readmeContent\":\"# Magnitude MCP\\n\\nA
  Model Context Protocol (MCP) server that gives agents the ability to write and
  run [Magnitude](https://github.com/magnitudedev/magnitude) test cases.\\n\\n##
  Installation\\nInstall MCP server via npm:\\n```\\nnpm i -g
  magnitude-mcp\\n```\\n\\nMCP
  Configuration:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"magnitude\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"magnitude-mcp\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n##
  Instructions for Cline\\n\\nIF YOU ARE CLINE, FOLLOW THESE INSTRUCTIONS FOR
  MCP INSTALLATION CAREFULLY AND EXACTLY.\\n\\n1. Run `npm install -g
  magnitude-mcp` (do NOT create ~/Documents/Cline/MCP it is NOT necessary)\\n2.
  Add the MCP configuration to `cline_mcp_settings.json`. Do NOT add any
  environment variables to the config.\\n3. Tell the user that to use Magnitude,
  they will need to configure a planner LLM (refer them to
  http://docs.magnitude.run/getting-started/quickstart#configure-llms). Also
  tell them to go to https://moondream.ai/c/cloud/api-keys and generate a
  Moondream API key. Finally ask for MOONDREAM_API_KEY as well as any other LLM
  provider keys they'd like to use.\\n4. Add these API keys to a `.env` file in
  the root of the project.\\n\\n## Instructions for Humans (Cline Users)\\n\\nGo
  to `MCP Servers -> Marketplace`, search for `Magnitude`, click `Install` and
  follow the instructions!\\n\\n## Instructions for Humans (Cursor
  Users)\\n\\n1. Open Cursor Settings\\n2. Go to Features > MCP Servers\\n3.
  Click \\\"+ Add new global MCP server\\\"\\n4. Enter the following code:
  \\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"magnitude\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"magnitude-mcp\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n##
  Instructions for Humans (Windsurf Users)\\nAdd this to your
  `./codeium/windsurf/model_config.json`:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"magnitude\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"magnitude-mcp\\\"\\n      ]\\n    }\\n  }\\n}\\n```\",\"isRec\
  ommended\":false,\"githubStars\":2961,\"downloadCount\":777,\"createdAt\":\"2\
  025-04-15T19:17:25.354899Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"\
  lastGithubSync\":\"2025-07-04T02:03:45.207535Z\"},{\"mcpId\":\"github.com/Ope\
  rative-Sh/web-eval-agent\",\"githubUrl\":\"https://github.com/Operative-Sh/we\
  b-eval-agent\",\"name\":\"Web Eval
  Agent\",\"author\":\"Operative-Sh\",\"description\":\"Autonomous web testing
  and debugging agent that executes and validates web applications directly in
  your code editor, with network traffic monitoring and console error
  detection.\",\"codiconIcon\":\"debug\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/web-eval-agent.png\",\"category\":\"browser-automa\
  tion\",\"tags\":[\"web-testing\",\"debugging\",\"automation\",\"browser-contr\
  ol\",\"qa-automation\"],\"requiresApiKey\":false,\"readmeContent\":\"# 
  operative.sh web-eval-agent MCP Server\\n\\n> *Let the coding agent debug
  itself, you've got better things to
  do.*\\n\\n![Demo](./demo.gif)\\n\\n\\n\\n##  Supercharge Your
  Debugging\\n\\n[operative.sh](https://www.operative.sh/mcp)'s MCP Server
  launches a browser-use powered agent to autonomously execute and debug web
  apps directly in your code editor.\\n\\n##  Features\\n\\n-  **Navigate
  your webapp** using BrowserUse (2x faster with operative backend)\\n- 
  **Capture network traffic** - requests are intelligently filtered and returned
  into the context window\\n-  **Collect console errors** - captures logs &
  errors\\n-  **Autonomous debugging** - the Cursor agent calls the web QA
  agent mcp server to test if the code it wrote works as epected
  end-to-end.\\n\\n##  MCP Tool Reference\\n\\n| Tool | Purpose
  |\\n|------|---------|\\n| `web_eval_agent` |  Automated UX evaluator that
  drives the browser, captures screenshots, console & network logs, and returns
  a rich UX report. |\\n| `setup_browser_state` |  Opens an interactive
  (non-headless) browser so you can sign in once; the saved
  cookies/local-storage are reused by subsequent `web_eval_agent` runs.
  |\\n\\n**Key arguments**\\n\\n* `web_eval_agent`\\n  * `url` **(required)** 
  address of the running app (e.g. `http://localhost:3000`)\\n  * `task`
  **(required)**  natural-language description of what to test (\\\"run through
  the signup flow and note any UX issues\\\")\\n  * `headless_browser`
  *(optional, default `false`)*  set to `true` to hide the browser
  window\\n\\n* `setup_browser_state`\\n  * `url` *(optional)*  page to open
  first (handy to land directly on a login screen)\\n\\nYou can trigger these
  tools straight from your IDE chat, for example:\\n\\n```bash\\nEvaluate my app
  at http://localhost:3000  run web_eval_agent with the task \\\"Try the full
  signup flow and report UX issues\\\".\\n```\\n\\n##  Quick Start
  (macOS/Linux)\\n\\n1. Pre-requisites (typically not needed):\\n - brew:
  `/bin/bash -c \\\"$(curl -fsSL
  https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\\"`\\n -
  npm: (`brew install npm`)\\n - jq: `brew install jq` \\n2. Run the installer
  after [getting an api key (free)](https://www.operative.sh/mcp)\\n   -
  Installs [playwright](https://github.com/microsoft/playwright) \\n   -
  [Installs uv](https://astral.sh/)\\n   - Inserts JSON into your code editor
  (Cursor/Cline/Windsurf) for you! \\n```bash\\ncurl -LSf
  https://operative.sh/install.sh -o install.sh && bash install.sh && rm
  install.sh\\n```\\n3. Visit your favorite IDE and restart to apply the
  changes\\n4. Send a prompt in chat mode to call the web eval agent tool! e.g.
  \\n```bash\\nTest my app on http://localhost:3000. Use
  web-eval-agent.\\n```\\n\\n##  Manual Installation\\n1. Get your API key at
  operative.sh/mcp\\n2. [Install
  uv](https://docs.astral.sh/uv/#highlights)\\n\\n```bash\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n```\\n\\n3. Source environment
  variables after installing UV\\n\\nMac\\n```\\nsource
  ~/.zshrc\\n```\\n\\nLinux \\n```\\nsource ~/.bashrc \\n```\\n4. Install
  playwright:\\n\\n```bash\\nnpm install -g chromium playwright && uvx --with
  playwright playwright install --with-deps\\n```\\n5. Add below JSON to your
  relevant code editor with api key \\n6. Restart your code editor\\n   \\n## 
  Updating \\n- `uv cache clean`\\n- refresh MCP server \\n\\n```json
  \\n    \\\"web-eval-agent\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"--refresh-package\\\",\\n        \\\"webEvalAgent\\\",\\n        \
  \\\"--from\\\",\\n        \\\"git+https://github.com/Operative-Sh/web-eval-ag\
  ent.git\\\",\\n        \\\"webEvalAgent\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"OPERATIVE_API_KEY\\\":
  \\\"<YOUR_KEY>\\\"\\n      }\\n    }\\n```\\n## [Operative Discord
  Server](https://discord.gg/ryjCnf9myb)\\n\\n##  Manual Installation (Mac +
  Cursor/Cline/Windsurf) \\n1. Get your API key at operative.sh/mcp\\n2.
  [Install uv](https://docs.astral.sh/uv/#highlights)\\n```bash\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh)\\n```\\n3. Install
  playwright:\\n```bash\\nnpm install -g chromium playwright && uvx --with
  playwright playwright install --with-deps\\n```\\n4. Add below JSON to your
  relevant code editor with api key \\n5. Restart your code editor\\n\\n##
  Manual Installation (Windows + Cursor/Cline/Windsurf)  \\n\\nWe're refining
  this, please open an issue if you have any issues! \\n1. Do all this in your
  code editor terminal \\n2. `curl -LSf https://operative.sh/install.sh -o
  install.sh && bash install.sh && rm install.sh`\\n3. Get your API key at
  operative.sh/mcp\\n4. Install uv `(curl -LsSf https://astral.sh/uv/install.sh
  | sh)`\\n5. `uvx --from git+https://github.com/Operative-Sh/web-eval-agent.git
  playwright install`\\n6. Restart code editor \\n\\n\\n##  Issues \\n-
  Updates aren't being received in code editors, update or reinstall for latest
  version: Run `uv cache clean` for latest \\n- Any issues feel free to open an
  Issue on this repo or in the discord!\\n- 5/5 - static apps without changes
  weren't screencasting, fixed! `uv clean` + restart to get fix\\n\\n##
  Changelog \\n- 4/29 - Agent overlay update - pause/play/stop agent run in the
  browser\\n\\n##  Example MCP Server Output Report\\n\\n```text\\n Web
  Evaluation Report for http://localhost:5173 complete!\\n Task: Test the
  API-key deletion flow by navigating to the API Keys section, deleting a key,
  and judging the UX.\\n\\n Agent Steps\\n   1. Navigate 
  http://localhost:5173\\n   2. Click     \\\"Login\\\"        (button index
  2)\\n   3. Click     \\\"API Keys\\\"     (button index 4)\\n   4.
  Click     \\\"Create Key\\\"   (button index 9)\\n   5. Type      \\\"Test
  API Key\\\" (input index 2)\\n   6. Click     \\\"Done\\\"         (button
  index 3)\\n   7. Click     \\\"Delete\\\"       (button index 10)\\n   8.
  Click     \\\"Delete\\\"       (confirm index 3)\\n Flow tested successfully
   UX felt smooth and intuitive.\\n\\n Console Logs (10)\\n  1. [debug]
  [vite] connecting\\n  2. [debug] [vite] connected.\\n  3. [info]  Download
  the React DevTools \\n     \\n\\n Network Requests (10)\\n  1. GET
  /src/pages/SleepingMasks.tsx                   304\\n  2. GET
  /src/pages/MCPRegistryRegistry.tsx             304\\n     \\n\\n
  Chronological Timeline\\n  01:16:23.293  Console [debug] [vite]
  connecting\\n  01:16:23.303  Console [debug] [vite]
  connected.\\n  01:16:23.312  GET
  /src/pages/SleepingMasks.tsx\\n  01:16:23.318  304
  /src/pages/SleepingMasks.tsx\\n     \\n  01:17:45.038   Flow finished 
  deletion verified\\n  01:17:47.038   Conclusion repeated above\\n  See
  the \\\"Operative Control Center\\\" dashboard for live logs.\\n```\\n\\n##
  Star History\\n\\n[![Star History
  Chart](https://api.star-history.com/svg?repos=Operative-Sh/web-eval-agent&typ\
  e=Date)](https://www.star-history.com/#Operative-Sh/web-eval-agent&Date)\\n\\n\
  \\n---\\n\\nBuilt with <3 @
  [operative.sh](https://www.operative.sh)\\n\",\"isRecommended\":false,\"githu\
  bStars\":1075,\"downloadCount\":2282,\"createdAt\":\"2025-04-24T06:56:24.8099\
  25Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025\
  -07-03T21:18:08.962918Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/\
  aws-documentation-mcp-server\",\"githubUrl\":\"https://github.com/awslabs/mcp\
  /tree/main/src/aws-documentation-mcp-server\",\"name\":\"AWS
  Documentation\",\"author\":\"awslabs\",\"description\":\"Access and search AWS
  documentation, fetch pages in markdown format, and get content recommendations
  for AWS documentation
  pages.\",\"codiconIcon\":\"book\",\"logoUrl\":\"https://storage.googleapis.co\
  m/cline_public_images/aws.png\",\"category\":\"knowledge-memory\",\"tags\":[\
  \"aws\",\"documentation\",\"search\",\"recommendations\",\"technical-docs\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"# AWS Documentation MCP
  Server\\n\\nModel Context Protocol (MCP) server for AWS
  Documentation\\n\\nThis MCP server provides tools to access AWS documentation,
  search for content, and get recommendations.\\n\\n## Features\\n\\n- **Read
  Documentation**: Fetch and convert AWS documentation pages to markdown
  format\\n- **Search Documentation**: Search AWS documentation using the
  official search API (global only)\\n- **Recommendations**: Get content
  recommendations for AWS documentation pages (global only)\\n- **Get Available
  Services List**: Get a list of available AWS services in China regions (China
  only)\\n\\n## Prerequisites\\n\\n### Installation Requirements\\n\\n1. Install
  `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or
  the [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python 3.10 or newer using `uv python install 3.10` (or a more recent
  version)\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.aws-documentation-mcp-server&config=eyJjb21tYW5kIj\
  oidXZ4IGF3c2xhYnMuYXdzLWRvY3VtZW50YXRpb24tbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOns\
  iRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiIsIkFXU19ET0NVTUVOVEFUSU9OX1BBUlRJVElPTiI6\
  ImF3cyJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)\\n\\nConfigure the
  MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI,
  edit `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-documentation-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.aws-documentation-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"AWS_DOCUMENTATION_PARTITION\\\":
  \\\"aws\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n>
  **Note**: Set `AWS_DOCUMENTATION_PARTITION` to `aws-cn` to query AWS China
  documentation instead of global AWS documentation.\\n\\nor docker after a
  successful `docker build -t mcp/aws-documentation
  .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-documentation-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"AWS_DOCUMENTATION_PARTITION=aws\\\",\\n        \\\
  \"mcp/aws-documentation:latest\\\"\\n      ],\\n      \\\"env\\\":
  {},\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n## Basic Usage\\n\\nExample:\\n\\n- \\\"look
  up documentation on S3 bucket naming rule. cite your sources\\\"\\n-
  \\\"recommend content for page
  https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\\\
  \"\\n\\n![AWS Documentation MCP
  Demo](https://github.com/awslabs/mcp/blob/main/src/aws-documentation-mcp-serv\
  er/basic-usage.gif?raw=true)\\n\\n## Tools\\n\\n###
  read_documentation\\n\\nFetches an AWS documentation page and converts it to
  markdown format.\\n\\n```python\\nread_documentation(url: str) ->
  str\\n```\\n\\n### search_documentation (global only)\\n\\nSearches AWS
  documentation using the official AWS Documentation Search
  API.\\n\\n```python\\nsearch_documentation(search_phrase: str, limit: int) ->
  list[dict]\\n```\\n\\n### recommend (global only)\\n\\nGets content
  recommendations for an AWS documentation page.\\n\\n```python\\nrecommend(url:
  str) -> list[dict]\\n```\\n\\n### get_available_services (China
  only)\\n\\nGets a list of available AWS services in China
  regions.\\n\\n```python\\nget_available_services() ->
  str\\n```\\n\",\"isRecommended\":false,\"githubStars\":4366,\"downloadCount\"\
  :13844,\"createdAt\":\"2025-04-04T01:26:41.014628Z\",\"updatedAt\":\"2025-07-\
  08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T05:47:32.15909Z\"},{\"m\
  cpId\":\"github.com/awslabs/mcp/tree/main/src/timestream-for-influxdb-mcp-ser\
  ver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/timestream\
  -for-influxdb-mcp-server\",\"name\":\"Timestream
  InfluxDB\",\"author\":\"awslabs\",\"description\":\"Manages AWS Timestream for
  InfluxDB resources, enabling database cluster/instance management, parameter
  configuration, and data operations using InfluxDB
  APIs.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\"aws\
  \",\"timestream\",\"influxdb\",\"time-series\",\"database-management\"],\"req\
  uiresApiKey\":false,\"readmeContent\":\"# AWS Labs Timestream for InfluxDB MCP
  Server\\n\\nAn AWS Labs Model Context Protocol (MCP) server for Timestream for
  InfluxDB. This server provides tools to interact with AWS Timestream for
  InfluxDB APIs, allowing you to create and manage database instances, clusters,
  parameter groups, and more. It also includes tools to interact with InfluxDB's
  write and query APIs.\\n\\n## Features\\n\\n- Create, update, list, describe,
  and delete Timestream for InfluxDB database instances\\n- Create, update,
  list, describe, and delete Timestream for InfluxDB database clusters\\n-
  Manage DB parameter groups\\n- Tag management for Timestream for InfluxDB
  resources\\n- Write and query data using InfluxDB's APIs\\n\\n\\n##
  Pre-requisites\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS services\\n    - You need an AWS account with appropriate
  permissions\\n    - Configure AWS credentials with `aws configure` or
  environment variables\\n    - Consider starting with Read-only permission if
  you don't want the LLM to modify any resources\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.timestream-for-influxdb-mcp-server&config=eyJjb21t\
  YW5kIjoidXZ4IGF3c2xhYnMudGltZXN0cmVhbS1mb3ItaW5mbHV4ZGItbWNwLXNlcnZlckBsYXRlc\
  3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6In\
  VzLWVhc3QtMSIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJ\
  hdXRvQXBwcm92ZSI6W119)\\n\\nYou can modify the settings of your MCP client to
  run your local server (e.g. for Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`)\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.timestream-for-influxdb-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.timestream-for-influxdb-mcp-server@latest\\\"],\\n      \\\"env\\\
  \": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n###
  Available Tools\\n\\nThe Timestream for InfluxDB MCP server provides the
  following tools:\\n\\n#### AWS Timestream for InfluxDB Management\\n\\n#####
  Database Cluster Management\\n- `CreateDbCluster`: Create a new Timestream for
  InfluxDB database cluster\\n- `GetDbCluster`: Retrieve information about a
  specific DB cluster\\n- `DeleteDbCluster`: Delete a Timestream for InfluxDB
  database cluster\\n- `ListDbClusters`: List all Timestream for InfluxDB
  database clusters\\n- `UpdateDbCluster`: Update a Timestream for InfluxDB
  database cluster\\n- `ListDbClusters`: List all Timestream for InfluxDB
  database clusters\\n- `ListDbInstancesForCluster`: List DB instances belonging
  to a specific cluster\\n- `ListClustersByStatus`: List DB clusters filtered by
  status\\n\\n##### Database Instance Management\\n- `CreateDbInstance`: Create
  a new Timestream for InfluxDB database instance\\n- `GetDbInstance`: Retrieve
  information about a specific DB instance\\n- `DeleteDbInstance`: Delete a
  Timestream for InfluxDB database instance\\n- `ListDbInstances`: List all
  Timestream for InfluxDB database instances\\n- `UpdateDbInstance`: Update a
  Timestream for InfluxDB database instance\\n- `ListDbInstancesByStatus`: List
  DB instances filtered by status\\n\\n##### Parameter Group Management\\n-
  `CreateDbParamGroup`: Create a new DB parameter group\\n-
  `GetDbParameterGroup`: Retrieve information about a specific DB parameter
  group\\n- `ListDbParamGroups`: List all DB parameter groups\\n\\n##### Tag
  Management\\n- `ListTagsForResource`: List all tags on a Timestream for
  InfluxDB resource\\n- `TagResource`: Add tags to a Timestream for InfluxDB
  resource\\n- `UntagResource`: Remove tags from a Timestream for InfluxDB
  resource\\n\\n#### InfluxDB Data Operations\\n\\n##### Write API\\n-
  `InfluxDBWritePoints`: Write data points to InfluxDB\\n- `InfluxDBWriteLP`:
  Write data in Line Protocol format to InfluxDB\\n\\n##### Query API\\n-
  `InfluxDBQuery`: Query data from InfluxDB using Flux query
  language\\n\",\"isRecommended\":false,\"githubStars\":4066,\"downloadCount\":\
  4,\"createdAt\":\"2025-06-21T01:35:44.507447Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-06-21T01:35:44.507447Z\"},{\"mcpId\
  \":\"github.com/awslabs/mcp/tree/main/src/amazon-sns-sqs-mcp-server\",\"githu\
  bUrl\":\"https://github.com/awslabs/mcp/tree/main/src/amazon-sns-sqs-mcp-serv\
  er\",\"name\":\"SNS/SQS
  Manager\",\"author\":\"awslabs\",\"description\":\"Enables secure management
  of Amazon SNS topics and SQS queues, with resource tagging, access controls,
  and messaging capabilities for AWS messaging
  services.\",\"codiconIcon\":\"bell\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"communication\",\"tags\":[\
  \"aws\",\"messaging\",\"queue-management\",\"pub-sub\",\"cloud-messaging\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"# Amazon SNS / SQS MCP
  Server\\n\\nA Model Context Protocol (MCP) server for Amazon SNS / SQS that
  enables generative AI models to manage SNS Topics and SQS Queues through MCP
  tools.\\n\\n## Features\\n\\nThis MCP server acts as a **bridge** between MCP
  clients and Amazon SNS / SQS, allowing generative AI models to create,
  configure, and manage Topics / Queues. The server provides a secure way to
  interact with Amazon SNS / SQS resources while maintaining proper access
  controls and resource tagging.\\n\\n```mermaid\\ngraph LR\\n    A[Model] <-->
  B[MCP Client]\\n    B <--> C[\\\"Amazon SNS / SQS MCP Server\\\"]\\n    C <-->
  D[Amazon SNS / SQS Service]\\n    style A
  fill:#f9f,stroke:#333,stroke-width:2px\\n    style B
  fill:#bbf,stroke:#333,stroke-width:2px\\n    style C
  fill:#bfb,stroke:#333,stroke-width:4px\\n    style D
  fill:#fbb,stroke:#333,stroke-width:2px\\n```\\n\\nFrom a **security**
  perspective, this server implements resource tagging to ensure that only
  resources created through the MCP server can be modified by it. This prevents
  unauthorized modifications to existing Amazon SNS/SQS resources that were not
  created by the MCP server.\\n\\n## Key Capabilities\\n\\nThis MCP server
  provides tools to:\\n- Create, list, and manage Amazon SNS topics\\n- Create,
  list, and manage Amazon SNS subscriptions\\n- Create, list, and manage Amazon
  SQS queues\\n- Send and receive messages using SNS and SQS\\n\\n##
  Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. AWS account with permissions to
  create and manage Amazon SNS / SQS resources\\n\\n## Setup\\n\\n### IAM
  Configuration\\n\\nThe authorization between the MCP server and your AWS
  accounts are performed with AWS profile you setup on the host. There are
  several ways to setup a AWS profile, however we recommend creating a new IAM
  role that has `AmazonSQSReadOnlyAccess` and `AmazonSNSReadOnlyAccess`
  permission following the principle of \\\"least privilege\\\". Note, if you
  want to use tools that mutate your tagged resources, you need to grant
  `AmazonSNSFullAccess` and `AmazonSQSFullAccess`. Finally, configure a AWS
  profile on the host that assumes the new role (for more information, check out
  the [AWS CLI help
  page](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-role.html)).\
  \\n\\n### Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.amazon-sns-sqs-mcp-server&config=eyJjb21tYW5kIjoid\
  XZ4IGF3c2xhYnMuYW1hem9uLXNucy1zcXMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1\
  BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIiwiQVdTX1JFR0lPTiI6InVzLWVhc3QtMSJ9fQ%3D%3\
  D)\\n\\nConfigure the MCP server in your MCP client configuration (e.g., for
  Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.amazon-sns-sqs-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.amazon-sns-sqs-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nor docker after a
  successful `docker build -t
  awslabs/amazon-sns-sqs-mcp-server.`:\\n\\n```file\\n# fictitious `.env` file
  with AWS temporary credentials\\nAWS_ACCESS_KEY_ID=<from the profile you set
  up>\\nAWS_SECRET_ACCESS_KEY=<from the profile you set
  up>\\nAWS_SESSION_TOKEN=<from the profile you set
  up>\\n```\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.sns-sqs-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file\
  /above/.env\\\",\\n          \\\"awslabs/amazon-sns-sqs-mcp-server:latest\\\"\
  \\n        ],\\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n##
  Server Configuration Options\\n\\nThe Amazon SNS / SQS MCP Server supports
  several command-line arguments that can be used to configure its
  behavior:\\n\\n### `--allow-resource-creation`\\n\\nEnables tools that create
  resources in the user's AWS account. When this flag is not enabled, the create
  new resources tools will be hidden from the MCP client, preventing the
  creation of new Amazon SNS / SQS resources. It also currently prevents
  deletion of any topics / queues. Default is False.\\n\\nThis flag is
  particularly useful for:\\n- Testing environments where resource creation
  should be restricted\\n- Limiting the scope of actions available to the AI
  model\\n\\nExample:\\n```bash\\nuv run awslabs.amazon-sns-sqs-mcp-server
  --disallow-resource-creation\\n```\\n\\n### Security Features\\n\\nThe MCP
  server implements a security mechanism that only allows modification of
  resources that were created by the MCP server itself. This is achieved
  by:\\n\\n1. Automatically tagging all created resources with a
  `mcp_server_version` tag\\n2. Validating this tag before allowing any mutative
  actions (update, delete) - this is a deterministic check that ensures only
  resources created by the MCP server can be modified\\n3. Rejecting operations
  on resources that don't have the appropriate tag\\n4.
  [Application-to-Person](https://docs.aws.amazon.com/sns/latest/dg/sns-user-no\
  tifications.html) (A2P) messaging mutative operations are not enabled by
  default for security reasons\\n\\n## Best Practices\\n\\n- Use descriptive
  topic and queue names to easily identify resources\\n- Follow the principle of
  least privilege when setting up IAM permissions\\n- Use separate AWS profiles
  for different environments (dev, test, prod)\\n- Implement proper error
  handling in your client applications\\n\\n## Security Considerations\\n\\nWhen
  using this MCP server, consider:\\n\\n- The MCP server needs permissions to
  create and manage Amazon SNS / SQS resources\\n- Only resources created by the
  MCP server can be modified by it since they are tagged\\n- Resource creation
  is disabled by default, enable it by setting the `--allow-resource-creation`
  flag on\\n\\n\\n## Troubleshooting\\n\\n- If you encounter permission errors,
  verify your IAM user has the correct policies attached\\n- For connection
  issues, check network configurations and security groups\\n- If resource
  modification fails with a tag validation error, it means the resource was not
  created by the MCP server\\n- For general Amazon SNS / SQS issues, consult the
  [Amazon SNS documentation](https://docs.aws.amazon.com/sns/) , [Amazon SQS
  documentation](https://docs.aws.amazon.com/sqs/)\\n\\n## Version\\n\\nCurrent
  MCP server version:
  1.0.0\\n\",\"isRecommended\":false,\"githubStars\":4428,\"downloadCount\":29,\
  \"createdAt\":\"2025-06-21T01:55:56.086628Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-08T01:03:23.513728Z\"},{\"mcpId\":\
  \"github.com/cloudflare/mcp-server-cloudflare\",\"githubUrl\":\"https://githu\
  b.com/cloudflare/mcp-server-cloudflare\",\"name\":\"Cloudflare\",\"author\":\
  \"cloudflare\",\"description\":\"Manages Cloudflare resources including
  Workers, KV stores, R2 storage, D1 databases, and analytics through natural
  language
  interactions.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/cloudflare.png\",\"category\":\"cloud-platforms\
  \",\"tags\":[\"cloudflare\",\"serverless\",\"edge-computing\",\"cloud-storage\
  \",\"database-management\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Cloudflare MCP Server\\n\\nModel Context Protocol (MCP) is a [new,
  standardized protocol](https://modelcontextprotocol.io/introduction) for
  managing context between large language models (LLMs) and external systems. In
  this repository, you can find several MCP servers allowing you to connect to
  Cloudflare's service from an MCP client (e.g. Cursor, Claude) and use natural
  language to accomplish tasks through your Cloudflare account.\\n\\nThese MCP
  servers allow your [MCP Client](https://modelcontextprotocol.io/clients) to
  read configurations from your account, process information, make suggestions
  based on data, and even make those suggested changes for you. All of these
  actions can happen across Cloudflare's many services including application
  development, security and performance.\\n\\nThe following servers are included
  in this repository:\\n\\n| Server
  Name                                                    |
  Description                                                                                     \
  | Server URL                                     |\\n|
  -------------------------------------------------------------- |
  -----------------------------------------------------------------------------\
  ------------------ | ---------------------------------------------- |\\n|
  [**Documentation server**](/apps/docs-vectorize)               | Get up to
  date reference information on
  Cloudflare                                              |
  `https://docs.mcp.cloudflare.com/sse`          |\\n| [**Workers Bindings
  server**](/apps/workers-bindings)          | Build Workers applications with
  storage, AI, and compute primitives                             |
  `https://bindings.mcp.cloudflare.com/sse`      |\\n| [**Workers Builds
  server**](/apps/workers-builds)              | Get insights and manage your
  Cloudflare Workers Builds                                          |
  `https://builds.mcp.cloudflare.com/sse`        |\\n| [**Observability
  server**](/apps/workers-observability)        | Debug and get insight into
  your application's logs and analytics                                |
  `https://observability.mcp.cloudflare.com/sse` |\\n| [**Radar
  server**](/apps/radar)                                | Get global Internet
  traffic insights, trends, URL scans, and other utilities                    |
  `https://radar.mcp.cloudflare.com/sse`         |\\n| [**Container
  server**](/apps/sandbox-container)                | Spin up a sandbox
  development
  environment                                                       |
  `https://containers.mcp.cloudflare.com/sse`    |\\n| [**Browser rendering
  server**](/apps/browser-rendering)        | Fetch web pages, convert them to
  markdown and take screenshots                                  |
  `https://browser.mcp.cloudflare.com/sse`       |\\n| [**Logpush
  server**](/apps/logpush)                            | Get quick summaries for
  Logpush job health                                                      |
  `https://logs.mcp.cloudflare.com/sse`          |\\n| [**AI Gateway
  server**](/apps/ai-gateway)                      | Search your logs, get
  details about the prompts and responses                                   |
  `https://ai-gateway.mcp.cloudflare.com/sse`    |\\n| [**AutoRAG
  server**](/apps/autorag)                            | List and search
  documents on your
  AutoRAGs                                                      |
  `https://autorag.mcp.cloudflare.com/sse`       |\\n| [**Audit Logs
  server**](/apps/auditlogs)                       | Query audit logs and
  generate reports for review                                                |
  `https://auditlogs.mcp.cloudflare.com/sse`     |\\n| [**DNS Analytics
  server**](/apps/dns-analytics)                | Optimize DNS performance and
  debug issues based on current set up                               |
  `https://dns-analytics.mcp.cloudflare.com/sse` |\\n| [**Digital Experience
  Monitoring server**](/apps/dex-analysis) | Get quick insight on critical
  applications for your organization                                |
  `https://dex.mcp.cloudflare.com/sse`           |\\n| [**Cloudflare One CASB
  server**](/apps/cloudflare-one-casb)    | Quickly identify any security
  misconfigurations for SaaS applications to safeguard users & data |
  `https://casb.mcp.cloudflare.com/sse`          |\\n| [**GraphQL
  server**](/apps/graphql/)                           | Get analytics data using
  Cloudflares GraphQL API                                               |
  `https://graphql.mcp.cloudflare.com/sse`       |\\n\\n## Access the remote MCP
  server from any MCP client\\n\\nIf your MCP client has first class support for
  remote MCP servers, the client will provide a way to accept the server URL
  directly within its interface (e.g. [Cloudflare AI
  Playground](https://playground.ai.cloudflare.com/))\\n\\nIf your client does
  not yet support remote MCP servers, you will need to set up its resepective
  configuration file using mcp-remote (https://www.npmjs.com/package/mcp-remote)
  to specify which servers your client can
  access.\\n\\n```json\\n{\\n\\t\\\"mcpServers\\\":
  {\\n\\t\\t\\\"cloudflare-observability\\\": {\\n\\t\\t\\t\\\"command\\\":
  \\\"npx\\\",\\n\\t\\t\\t\\\"args\\\": [\\\"mcp-remote\\\",
  \\\"https://observability.mcp.cloudflare.com/sse\\\"]\\n\\t\\t},\\n\\t\\t\\\"\
  cloudflare-bindings\\\": {\\n\\t\\t\\t\\\"command\\\":
  \\\"npx\\\",\\n\\t\\t\\t\\\"args\\\": [\\\"mcp-remote\\\",
  \\\"https://bindings.mcp.cloudflare.com/sse\\\"]\\n\\t\\t}\\n\\t}\\n}\\n```\\n\
  \\n## Using Cloudflare's MCP servers from the OpenAI Responses API\\n\\nTo use
  one of Cloudflare's MCP servers with [OpenAI's responses
  API](https://openai.com/index/new-tools-and-features-in-the-responses-api/),
  you will need to provide the Responses API with an API token that has the
  scopes (permissions) required for that particular MCP server.\\n\\nFor
  example, to use the [Browser Rendering MCP
  server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/br\
  owser-rendering) with OpenAI, create an API token in the Cloudflare dashboard
  [here](https://dash.cloudflare.com/profile/api-tokens), with the following
  permissions:\\n\\n<img width=\\\"937\\\" alt=\\\"Screenshot 2025-05-21 at 10
  38 02AM\\\"
  src=\\\"https://github.com/user-attachments/assets/872e253f-23ce-43b3-983c-45\
  f9d0f66100\\\" />\\n\\n## Need access to more Cloudflare tools?\\n\\nWe're
  continuing to add more functionality to this remote MCP server repo. If you'd
  like to leave feedback, file a bug or provide a feature request, [please open
  an
  issue](https://github.com/cloudflare/mcp-server-cloudflare/issues/new/choose)
  on this repository\\n\\n## Troubleshooting\\n\\n\\\"Claude's response was
  interrupted ... \\\"\\n\\nIf you see this message, Claude likely hit its
  context-length limit and stopped mid-reply. This happens most often on servers
  that trigger many chained tool calls such as the observability server.\\n\\nTo
  reduce the chance of running in to this issue:\\n\\n- Try to be specific, keep
  your queries concise.\\n- If a single request calls multiple tools, try to to
  break it into several smaller tool calls to keep the responses short.\\n\\n##
  Paid Features\\n\\nSome features may require a paid Cloudflare Workers plan.
  Ensure your Cloudflare account has the necessary subscription level for the
  features you intend to use.\\n\\n## Contributing\\n\\nInterested in
  contributing, and running this server locally? See
  [CONTRIBUTING.md](CONTRIBUTING.md) to get
  started.\\n\",\"isRecommended\":true,\"githubStars\":2636,\"downloadCount\":1\
  868,\"createdAt\":\"2025-02-17T22:22:47.133329Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T03:32:30.26145Z\"},{\"mcpId\
  \":\"github.com/makenotion/notion-mcp-server\",\"githubUrl\":\"https://github\
  .com/makenotion/notion-mcp-server\",\"name\":\"Notion\",\"author\":\"makenoti\
  on\",\"description\":\"Enables AI assistants to interact with Notion
  workspaces through the official API, supporting page creation, comments,
  content retrieval, and search
  functionality.\",\"codiconIcon\":\"notebook\",\"logoUrl\":\"https://storage.g\
  oogleapis.com/cline_public_images/notion.png\",\"category\":\"note-taking\",\
  \"tags\":[\"notion\",\"documentation\",\"knowledge-base\",\"collaboration\",\
  \"workspace\"],\"requiresApiKey\":false,\"readmeContent\":\"# Notion MCP
  Server\\n\\n> [!NOTE] \\n> \\n> Weve introduced **Notion MCP** (Beta), a
  remote MCP server with the following improvements:\\n> - Easy installation via
  standard OAuth. No need to fiddle with JSON or API token anymore.\\n> -
  Powerful tools tailored to AI agents. These tools are designed with optimized
  token consumption in mind.\\n> \\n> Learn more and try it out
  [here](https://notion.notion.site/Beta-Overview-Notion-MCP-206efdeead058060a5\
  9bf2c14202bd0a)\\n\\n\\n![notion-mcp-sm](https://github.com/user-attachments/\
  assets/6c07003c-8455-4636-b298-d60ffdf46cd8)\\n\\nThis project implements an
  [MCP server](https://spec.modelcontextprotocol.io/) for the [Notion
  API](https://developers.notion.com/reference/intro).
  \\n\\n![mcp-demo](https://github.com/user-attachments/assets/e3ff90a7-7801-48\
  a9-b807-f7dd47f0d3d6)\\n\\n### Installation\\n\\n#### 1. Setting up
  Integration in Notion:\\nGo to
  [https://www.notion.so/profile/integrations](https://www.notion.so/profile/in\
  tegrations) and create a new **internal** integration or select an existing
  one.\\n\\n![Creating a Notion Integration
  token](docs/images/integrations-creation.png)\\n\\nWhile we limit the scope of
  Notion API's exposed (for example, you will not be able to delete databases
  via MCP), there is a non-zero risk to workspace data by exposing it to LLMs.
  Security-conscious users may want to further configure the Integration's
  _Capabilities_. \\n\\nFor example, you can create a read-only integration
  token by giving only \\\"Read content\\\" access from the
  \\\"Configuration\\\" tab:\\n\\n![Notion Integration Token Capabilities
  showing Read content
  checked](docs/images/integrations-capabilities.png)\\n\\n#### 2. Connecting
  content to integration:\\nEnsure relevant pages and databases are connected to
  your integration.\\n\\nTo do this, visit the **Access** tab in your internal
  integration settings. Edit access and select the pages you'd like to
  use.\\n![Integration Access
  tab](docs/images/integration-access.png)\\n\\n![Edit integration
  access](docs/images/page-access-edit.png)\\n\\nAlternatively, you can grant
  page access individually. You'll need to visit the target page, and click on
  the 3 dots, and select \\\"Connect to integration\\\". \\n\\n![Adding
  Integration Token to Notion
  Connections](docs/images/connections.png)\\n\\n#### 3. Adding MCP config to
  your client:\\n\\n##### Using npm:\\nAdd the following to your
  `.cursor/mcp.json` or `claude_desktop_config.json` (MacOS:
  `~/Library/Application\\\\
  Support/Claude/claude_desktop_config.json`)\\n\\n```javascript\\n{\\n  \\\"mc\
  pServers\\\": {\\n    \\\"notionApi\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@notionhq/notion-mcp-server\\\"],\\n      \\\"env\\\":
  {\\n        \\\"OPENAPI_MCP_HEADERS\\\": \\\"{\\\\\\\"Authorization\\\\\\\":
  \\\\\\\"Bearer ntn_****\\\\\\\", \\\\\\\"Notion-Version\\\\\\\":
  \\\\\\\"2022-06-28\\\\\\\" }\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n#####
  Using Docker:\\n\\nThere are two options for running the MCP server with
  Docker:\\n\\n###### Option 1: Using the official Docker Hub image:\\n\\nAdd
  the following to your `.cursor/mcp.json` or
  `claude_desktop_config.json`:\\n\\n```javascript\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"notionApi\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"-i\\\",\\n        \
  \\\"-e\\\",
  \\\"OPENAPI_MCP_HEADERS\\\",\\n        \\\"mcp/notion\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"OPENAPI_MCP_HEADERS\\\":
  \\\"{\\\\\\\"Authorization\\\\\\\":\\\\\\\"Bearer
  ntn_****\\\\\\\",\\\\\\\"Notion-Version\\\\\\\":\\\\\\\"2022-06-28\\\\\\\"}\\\
  \"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nThis approach:\\n- Uses the official
  Docker Hub image\\n- Properly handles JSON escaping via environment
  variables\\n- Provides a more reliable configuration method\\n\\n###### Option
  2: Building the Docker image locally:\\n\\nYou can also build and run the
  Docker image locally. First, build the Docker
  image:\\n\\n```bash\\ndocker-compose build\\n```\\n\\nThen, add the following
  to your `.cursor/mcp.json` or
  `claude_desktop_config.json`:\\n\\n```javascript\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"notionApi\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"-i\\\",\\n        \
  \\\"-e\\\",\\n        \\\"OPENAPI_MCP_HEADERS={\\\\\\\"Authorization\\\\\\\":
  \\\\\\\"Bearer ntn_****\\\\\\\", \\\\\\\"Notion-Version\\\\\\\":
  \\\\\\\"2022-06-28\\\\\\\"}\\\",\\n        \\\"notion-mcp-server\\\"\\n      ]\
  \\n    }\\n  }\\n}\\n```\\n\\nDon't forget to replace `ntn_****` with your
  integration secret. Find it from your integration configuration
  tab:\\n\\n![Copying your Integration token from the Configuration tab in the
  developer
  portal](https://github.com/user-attachments/assets/67b44536-5333-49fa-809c-59\
  581bf5370a)\\n\\n\\n#### Installing via Smithery\\n\\n[![smithery
  badge](https://smithery.ai/badge/@makenotion/notion-mcp-server)](https://smit\
  hery.ai/server/@makenotion/notion-mcp-server)\\n\\nTo install Notion API
  Server for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@makenotion/notion-mcp-server):\\n\\n``\
  `bash\\nnpx -y @smithery/cli install @makenotion/notion-mcp-server --client
  claude\\n```\\n\\n### Examples\\n\\n1. Using the following
  instruction\\n```\\nComment \\\"Hello MCP\\\" on page \\\"Getting
  started\\\"\\n```\\n\\nAI will correctly plan two API calls, `v1/search` and
  `v1/comments`, to achieve the task\\n\\n2. Similarly, the following
  instruction will result in a new page named \\\"Notion MCP\\\" added to parent
  page \\\"Development\\\"\\n```\\nAdd a page titled \\\"Notion MCP\\\" to page
  \\\"Development\\\"\\n```\\n\\n3. You may also reference content ID
  directly\\n```\\nGet the content of page
  1a6b35e6e67f802fa7e1d27686f017f2\\n```\\n\\n###
  Development\\n\\nBuild\\n\\n```\\nnpm run
  build\\n```\\n\\nExecute\\n\\n```\\nnpx -y --prefix
  /path/to/local/notion-mcp-server
  @notionhq/notion-mcp-server\\n```\\n\\nPublish\\n\\n```\\nnpm publish --access
  public\\n```\\n\",\"isRecommended\":false,\"githubStars\":2413,\"downloadCount\
  \":5864,\"createdAt\":\"2025-04-10T03:19:01.544437Z\",\"updatedAt\":\"2025-07\
  -08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T08:45:21.591435Z\"},{\
  \"mcpId\":\"github.com/awslabs/mcp/tree/main/src/eks-mcp-server\",\"githubUrl\
  \":\"https://github.com/awslabs/mcp/tree/main/src/eks-mcp-server\",\"name\":\
  \"Amazon EKS Manager\",\"author\":\"awslabs\",\"description\":\"Manages Amazon
  EKS clusters and Kubernetes resources through natural language interactions,
  providing tools for cluster creation, application deployment, resource
  management, monitoring, and
  troubleshooting.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.go\
  ogleapis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\
  \"tags\":[\"kubernetes\",\"aws\",\"containerization\",\"cluster-management\",\
  \"devops\"],\"requiresApiKey\":false,\"readmeContent\":\"# Amazon EKS MCP
  Server\\n\\nThe Amazon EKS MCP server provides AI code assistants with
  resource management tools and real-time cluster state visibility. This
  provides large language models (LLMs) with essential tooling and contextual
  awareness, enabling AI code assistants to streamline application development
  through tailored guidance  from initial setup through production optimization
  and troubleshooting.\\n\\nIntegrating the EKS MCP server into AI code
  assistants enhances development workflow across all phases, from simplifying
  initial cluster setup with automated prerequisite creation and application of
  best practices. Further, it streamlines application deployment with high-level
  workflows and automated code generation. Finally, it accelerates
  troubleshooting through intelligent debugging tools and knowledge base access.
  All of this simplifies complex operations through natural language
  interactions in AI code assistants.\\n\\n## Key features\\n\\n* Enables users
  of AI code assistants to create new EKS clusters, complete with prerequisites
  such as dedicated VPCs, networking, and EKS Auto Mode node pools, by
  translating requests into the appropriate AWS CloudFormation actions.\\n*
  Provides the ability to deploy containerized applications by applying existing
  Kubernetes YAML files or by generating new deployment and service manifests
  based on user-provided parameters.\\n* Supports full lifecycle management of
  individual Kubernetes resources (such as Pods, Services, and Deployments)
  within EKS clusters, enabling create, read, update, patch, and delete
  operations.\\n* Provides the ability to list Kubernetes resources with
  filtering by namespace, labels, and fields, simplifying the process for both
  users and LLMs to gather information about the state of Kubernetes
  applications and EKS infrastructure.\\n* Facilitates operational tasks such as
  retrieving logs from specific pods and containers or fetching Kubernetes
  events related to particular resources, supporting troubleshooting and
  monitoring for both direct users and AI-driven workflows.\\n* Enables users to
  troubleshoot issues with an EKS cluster.\\n\\n## Prerequisites\\n\\n* [Install
  Python 3.10+](https://www.python.org/downloads/release/python-3100/)\\n*
  [Install the `uv` package
  manager](https://docs.astral.sh/uv/getting-started/installation/)\\n* [Install
  and configure the AWS CLI with
  credentials](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-config\
  ure.html)\\n\\n## Setup\\n\\nAdd these IAM policies to the IAM role or user
  that you use to manage your EKS cluster resources.\\n\\n### Read-Only
  Operations Policy\\n\\nFor read operations, the following permissions are
  required:\\n\\n```\\n{\\n  \\\"Version\\\":
  \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Effect\\\":
  \\\"Allow\\\",\\n      \\\"Action\\\":
  [\\n        \\\"eks:DescribeCluster\\\",\\n        \\\"cloudformation:Describ\
  eStacks\\\",\\n        \\\"cloudwatch:GetMetricData\\\",\\n        \\\"logs:S\
  tartQuery\\\",\\n        \\\"logs:GetQueryResults\\\",\\n        \\\"iam:GetR\
  ole\\\",\\n        \\\"iam:GetRolePolicy\\\",\\n        \\\"iam:ListRolePolic\
  ies\\\",\\n        \\\"iam:ListAttachedRolePolicies\\\",\\n        \\\"iam:Ge\
  tPolicy\\\",\\n        \\\"iam:GetPolicyVersion\\\",\\n        \\\"eks-mcpser\
  ver:QueryKnowledgeBase\\\"\\n      ],\\n      \\\"Resource\\\":
  \\\"*\\\"\\n    }\\n  ]\\n}\\n```\\n\\n### Write Operations Policy\\n\\nFor
  write operations, we recommend the following IAM policies to ensure successful
  deployment of EKS clusters using the CloudFormation template in
  `/awslabs/eks_mcp_server/templates/eks-templates/eks-with-vpc.yaml`:\\n\\n*
  [**IAMFullAccess**](https://docs.aws.amazon.com/aws-managed-policy/latest/ref\
  erence/IAMFullAccess.html): Enables creation and management of IAM roles and
  policies required for cluster operation\\n*
  [**AmazonVPCFullAccess**](https://docs.aws.amazon.com/aws-managed-policy/late\
  st/reference/AmazonVPCFullAccess.html): Allows creation and configuration of
  VPC resources including subnets, route tables, internet gateways, and NAT
  gateways\\n*
  [**AWSCloudFormationFullAccess**](https://docs.aws.amazon.com/aws-managed-pol\
  icy/latest/reference/AWSCloudFormationFullAccess.html): Provides permissions
  to create, update, and delete CloudFormation stacks that orchestrate the
  deployment\\n* **EKS Full Access (provided below)**: Required for creating and
  managing EKS clusters, including control plane configuration, node groups, and
  add-ons\\n   ```\\n  {\\n    \\\"Version\\\":
  \\\"2012-10-17\\\",\\n    \\\"Statement\\\":
  [\\n      {\\n        \\\"Effect\\\": \\\"Allow\\\",\\n        \\\"Action\\\":
  \\\"eks:*\\\",\\n        \\\"Resource\\\":
  \\\"*\\\"\\n      }\\n    ]\\n  }\\n   ```\\n\\n\\n**Important Security
  Note**: Users should exercise caution when `--allow-write` and
  `--allow-sensitive-data-access` modes are enabled with these broad
  permissions, as this combination grants significant privileges to the MCP
  server. Only enable these flags when necessary and in trusted environments.
  For production use, consider creating more restrictive custom
  policies.\\n\\n### Kubernetes API Access Requirements\\n\\nAll Kubernetes API
  operations will only work when one of the following conditions is met:\\n\\n1.
  The user's principal (IAM role/user) actually created the EKS cluster being
  accessed\\n2. An EKS Access Entry has been configured for the user's
  principal\\n\\nIf you encounter authorization errors when using Kubernetes API
  operations, verify that an access entry has been properly configured for your
  principal.\\n\\n## Quickstart\\n\\nThis quickstart guide walks you through the
  steps to configure the Amazon EKS MCP Server for use with both the
  [Cursor](https://www.cursor.com/en/downloads) IDE and the [Amazon Q Developer
  CLI](https://github.com/aws/amazon-q-developer-cli). By following these steps,
  you'll setup your development environment to leverage the EKS MCP Server's
  tools for managing your Amazon EKS clusters and Kubernetes
  resources.\\n\\n**Set up Cursor**\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.eks-mcp-server&config=eyJhdXRvQXBwcm92ZSI6W10sImRp\
  c2FibGVkIjpmYWxzZSwiY29tbWFuZCI6InV2eCBhd3NsYWJzLmVrcy1tY3Atc2VydmVyQGxhdGVzd\
  CAtLWFsbG93LXdyaXRlIC0tYWxsb3ctc2Vuc2l0aXZlLWRhdGEtYWNjZXNzIiwiZW52Ijp7IkZBU1\
  RNQ1BfTE9HX0xFVkVMIjoiRVJST1IifSwidHJhbnNwb3J0VHlwZSI6InN0ZGlvIn0%3D)\\n\\n**\
  Set up the Amazon Q Developer CLI**\\n\\n1. Install the [Amazon Q Developer
  CLI](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-in\
  stalling.html) .\\n2. The Q Developer CLI supports MCP servers for tools and
  prompts out-of-the-box. Edit your Q developer CLI's MCP configuration file
  named mcp.json following [these
  instructions](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/comman\
  d-line-mcp-configuration.html).\\n\\nThe example below includes both the
  `--allow-write` flag for mutating operations and the
  `--allow-sensitive-data-access` flag for accessing logs and events (see the
  Arguments section for more details):\\n\\n   **For
  Mac/Linux:**\\n\\n\\t```\\n\\t{\\n\\t  \\\"mcpServers\\\":
  {\\n\\t    \\\"awslabs.eks-mcp-server\\\": {\\n\\t      \\\"command\\\":
  \\\"uvx\\\",\\n\\t      \\\"args\\\":
  [\\n\\t        \\\"awslabs.eks-mcp-server@latest\\\",\\n\\t        \\\"--allo\
  w-write\\\",\\n\\t        \\\"--allow-sensitive-data-access\\\"\\n\\t      ],\
  \\n\\t      \\\"env\\\": {\\n\\t        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n\\t      },\\n\\t      \\\"autoApprove\\\":
  [],\\n\\t      \\\"disabled\\\":
  false\\n\\t    }\\n\\t  }\\n\\t}\\n\\t```\\n\\n   **For
  Windows:**\\n\\n\\t```\\n\\t{\\n\\t  \\\"mcpServers\\\":
  {\\n\\t    \\\"awslabs.eks-mcp-server\\\": {\\n\\t      \\\"command\\\":
  \\\"uvx\\\",\\n\\t      \\\"args\\\":
  [\\n\\t        \\\"--from\\\",\\n\\t        \\\"awslabs.eks-mcp-server@latest\
  \\\",\\n\\t        \\\"awslabs.eks-mcp-server.exe\\\",\\n\\t        \\\"--all\
  ow-write\\\",\\n\\t        \\\"--allow-sensitive-data-access\\\"\\n\\t      ],\
  \\n\\t      \\\"env\\\": {\\n\\t        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n\\t      },\\n\\t      \\\"autoApprove\\\":
  [],\\n\\t      \\\"disabled\\\":
  false\\n\\t    }\\n\\t  }\\n\\t}\\n\\t```\\n\\n3. Verify your setup by running
  the `/tools` command in the Q Developer CLI to see the available EKS MCP
  tools.\\n\\nNote that this is a basic quickstart. You can enable additional
  capabilities, such as [running MCP servers in
  containers](https://github.com/awslabs/mcp?tab=readme-ov-file#running-mcp-ser\
  vers-in-containers) or combining more MCP servers like the [AWS Documentation
  MCP
  Server](https://awslabs.github.io/mcp/servers/aws-documentation-mcp-server/)
  into a single MCP server definition. To view an example, see the [Installation
  and
  Setup](https://github.com/awslabs/mcp?tab=readme-ov-file#installation-and-set\
  up) guide in AWS MCP Servers on GitHub. To view a real-world implementation
  with application code in context with an MCP server, see the [Server
  Developer](https://modelcontextprotocol.io/quickstart/server) guide in
  Anthropic documentation.\\n\\n## Configurations\\n\\n### Arguments\\n\\nThe
  `args` field in the MCP server definition specifies the command-line arguments
  passed to the server when it starts. These arguments control how the server is
  executed and configured. For example:\\n\\n**For
  Mac/Linux:**\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.eks-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.eks-mcp-server@latest\\\",\\n        \\\"--allow-write\
  \\\",\\n        \\\"--allow-sensitive-data-access\\\"\\n      ],\\n      \\\"\
  env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n**For
  Windows:**\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.eks-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"--from\\\",\\n        \\\"awslabs.eks-mcp-server@latest\\\",\
  \\n        \\\"awslabs.eks-mcp-server.exe\\\",\\n        \\\"--allow-write\\\
  \",\\n        \\\"--allow-sensitive-data-access\\\"\\n      ],\\n      \\\"env\
  \\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n#### Command
  Format\\n\\nThe command format differs between operating systems:\\n\\n**For
  Mac/Linux:**\\n* `awslabs.eks-mcp-server@latest` - Specifies the latest
  package/version specifier for the MCP client config.\\n\\n**For Windows:**\\n*
  `--from awslabs.eks-mcp-server@latest awslabs.eks-mcp-server.exe` - Windows
  requires the `--from` flag to specify the package and the `.exe`
  extension.\\n\\nBoth formats enable MCP server startup and tool
  registration.\\n\\n#### `--allow-write` (optional)\\n\\nEnables write access
  mode, which allows mutating operations (e.g., create, update, delete
  resources) for apply_yaml, generate_app_manifest, manage_k8s_resource,
  manage_eks_stacks, add_inline_policy tool operations.\\n\\n* Default: false
  (The server runs in read-only mode by default)\\n* Example: Add
  `--allow-write` to the `args` list in your MCP server definition.\\n\\n####
  `--allow-sensitive-data-access` (optional)\\n\\nEnables access to sensitive
  data such as logs, events, and Kubernetes Secrets. This flag is required for
  tools that access potentially sensitive information, such as get_pod_logs,
  get_k8s_events, get_cloudwatch_logs, and manage_k8s_resource (when used to
  read Kubernetes secrets).\\n\\n* Default: false (Access to sensitive data is
  restricted by default)\\n* Example: Add `--allow-sensitive-data-access` to the
  `args` list in your MCP server definition.\\n\\n### Environment
  variables\\n\\nThe `env` field in the MCP server definition allows you to
  configure environment variables that control the behavior of the EKS MCP
  server.  For example:\\n\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.eks-mcp-server\\\": {\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"AWS_PROFILE\\\":
  \\\"my-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n####
  `FASTMCP_LOG_LEVEL` (optional)\\n\\nSets the logging level verbosity for the
  server.\\n\\n* Valid values: \\\"DEBUG\\\", \\\"INFO\\\", \\\"WARNING\\\",
  \\\"ERROR\\\", \\\"CRITICAL\\\"\\n* Default: \\\"WARNING\\\"\\n* Example:
  `\\\"FASTMCP_LOG_LEVEL\\\": \\\"ERROR\\\"`\\n\\n#### `AWS_PROFILE`
  (optional)\\n\\nSpecifies the AWS profile to use for authentication.\\n\\n*
  Default: None (If not set, uses default AWS credentials).\\n* Example:
  `\\\"AWS_PROFILE\\\": \\\"my-profile\\\"`\\n\\n#### `AWS_REGION`
  (optional)\\n\\nSpecifies the AWS region where EKS clusters are managed, which
  will be used for all AWS service operations.\\n\\n* Default: None (If not set,
  uses default AWS region).\\n* Example: `\\\"AWS_REGION\\\":
  \\\"us-west-2\\\"`\\n\\n## Tools\\n\\nThe following tools are provided by the
  EKS MCP server for managing Amazon EKS clusters and Kubernetes resources. Each
  tool performs a specific action that can be invoked to automate common tasks
  in your EKS clusters and Kubernetes workloads.\\n\\n### EKS Cluster
  Management\\n\\n#### `manage_eks_stacks`\\n\\nManages EKS CloudFormation
  stacks with operations for generating templates, deploying, describing, and
  deleting EKS clusters and their underlying infrastructure. **Note**: Cluster
  creation typically takes 15-20 minutes to complete.\\n\\nFeatures:\\n\\n*
  Generates CloudFormation templates for EKS clusters, embedding specified
  cluster names.\\n* Deploys EKS clusters using CloudFormation, creating or
  updating stacks with VPC, subnets, NAT gateways, IAM roles, and node
  pools.\\n* Describes existing EKS CloudFormation stacks, providing details
  like status, outputs, and creation time.\\n* Deletes EKS CloudFormation stacks
  and their associated resources, ensuring proper cleanup.\\n* Ensures safety by
  only modifying/deleting stacks that were originally created by this
  tool.\\n\\nParameters:\\n\\n* operation (generate, deploy, describe, delete),
  template_file (for generate/deploy), cluster_name\\n\\n### Kubernetes Resource
  Management\\n\\n#### `manage_k8s_resource`\\n\\nManages individual Kubernetes
  resources with various operations.\\n\\nFeatures:\\n\\n* Supports create,
  replace, patch, delete, and read Kubernetes operations.\\n* Handles both
  namespaced and non-namespaced Kubernetes resources.\\n\\nParameters:\\n\\n*
  operation (create, replace, patch, delete, read), cluster_name, kind,
  api_version, name, namespace (optional), body (for
  create/replace/patch)\\n\\n#### `apply_yaml`\\n\\nApplies Kubernetes YAML
  manifests to an EKS cluster.\\n\\nFeatures:\\n\\n* Supports multi-document
  YAML files.\\n* Applies all resources in the manifest to the specified
  namespace.\\n* Can update existing resources if force is
  true.\\n\\nParameters:\\n\\n* yaml_path, cluster_name, namespace,
  force\\n\\n#### `list_k8s_resources`\\n\\nLists Kubernetes resources of a
  specific kind in an EKS cluster.\\n\\nFeatures:\\n\\n* Returns summaries of
  EKS resources with metadata.\\n* Supports filtering by EKS cluster namespace,
  labels, and fields.\\n\\nParameters:\\n\\n* cluster_name, kind, api_version,
  namespace (optional), label_selector (optional), field_selector
  (optional)\\n\\n#### `list_api_versions`\\n\\nLists all available API versions
  in the specified Kubernetes cluster.\\n\\nFeatures:\\n\\n* Discovers all
  available API versions on the Kubernetes cluster.\\n* Helps determine the
  correct `apiVersion` to use for managing Kubernetes resources.\\n* Includes
  both core APIs (e.g., \\\"v1\\\") and API groups (e.g., \\\"apps/v1\\\",
  \\\"networking.k8s.io/v1\\\").\\n\\nParameters:\\n\\n* cluster_name\\n\\n###
  Application Support\\n\\n#### `generate_app_manifest`\\n\\nGenerates
  Kubernetes manifests for application deployment.\\n\\nFeatures:\\n\\n*
  Generates Kubernetes deployment and service YAMLs with configurable
  parameters.\\n* Supports load balancer configuration and resource
  requests.\\n* Outputs Kubernetes manifest to a specified
  directory.\\n\\nParameters:\\n\\n* app_name, image_uri, output_dir, port
  (optional), replicas (optional), cpu (optional), memory (optional), namespace
  (optional), load_balancer_scheme (optional)\\n\\n####
  `get_pod_logs`\\n\\nRetrieves logs from pods in a Kubernetes
  cluster.\\n\\nFeatures:\\n\\n* Supports filtering logs by time, line count,
  and byte size.\\n* Can retrieve logs from specific containers in a pod.\\n*
  Requires `--allow-sensitive-data-access` server flag to be
  enabled.\\n\\nParameters:\\n\\n* cluster_name, pod_name, namespace,
  container_name (optional), since_seconds (optional), tail_lines (optional),
  limit_bytes (optional)\\n\\n#### `get_k8s_events`\\n\\nRetrieves events
  related to specific Kubernetes resources.\\n\\nFeatures:\\n\\n* Returns
  Kubernetes event details including timestamps, count, message, reason,
  reporting component, and type.\\n* Supports both namespaced and non-namespaced
  Kubernetes resources.\\n* Requires `--allow-sensitive-data-access` server flag
  to be enabled.\\n\\nParameters:\\n\\n* cluster_name, kind, name, namespace
  (optional)\\n\\n### CloudWatch Integration\\n\\n####
  `get_cloudwatch_logs`\\n\\nRetrieves logs from CloudWatch for a specific
  resource within an EKS cluster.\\n\\nFeatures:\\n\\n* Fetches logs based on
  resource type (pod, node, container), resource name, and log type.\\n* Allows
  filtering by time range (minutes, start/end time), log content
  (filter_pattern), and number of entries.\\n* Supports specifying custom fields
  to be included in the query results.\\n* Requires
  `--allow-sensitive-data-access` server flag to be
  enabled.\\n\\nParameters:\\n\\n* cluster_name, log_type (application, host,
  performance, control-plane, custom), resource_type (pod, node, container,
  cluster),\\nresource_name (optional), minutes (optional), start_time
  (optional), end_time (optional), limit (optional), filter_pattern (optional),
  fields (optional)\\n\\n#### `get_cloudwatch_metrics`\\n\\nRetrieves metrics
  from CloudWatch for Kubernetes resources.\\n\\nFeatures:\\n\\n* Fetches
  metrics based on metric name and dimensions.\\n* Allows specification of
  CloudWatch namespace and time range.\\n* Configurable period, statistic
  (Average, Sum, etc.), and limit for data points.\\n* Supports providing custom
  dimensions for fine-grained metric querying.\\n\\nParameters:\\n\\n*
  cluster_name, metric_name, namespace, dimensions, minutes (optional),
  start_time (optional), end_time (optional), limit (optional), stat (optional),
  period (optional)\\n\\n#### `get_eks_metrics_guidance`\\n\\nProvides guidance
  on available CloudWatch metrics for different resource types in EKS
  clusters.\\n\\nFeatures:\\n\\n* Returns a list of available Container Insights
  metrics for the specified resource type, including metric names, dimensions,
  and descriptions.\\n* Helps determine the correct dimensions to use with the
  `get_cloudwatch_metrics` tool.\\n* Supports the following resource
  types:\\n  * `cluster`: Metrics for EKS clusters (e.g., cluster_node_count,
  cluster_failed_node_count)\\n  * `node`: Metrics for EKS nodes (e.g.,
  node_cpu_utilization, node_memory_utilization, node_network_total_bytes)\\n  *
  `pod`: Metrics for Kubernetes pods (e.g., pod_cpu_utilization,
  pod_memory_utilization, pod_network_rx_bytes)\\n  * `namespace`: Metrics for
  Kubernetes namespaces (e.g., namespace_number_of_running_pods)\\n  *
  `service`: Metrics for Kubernetes services (e.g.,
  service_number_of_running_pods)\\n\\nParameters:\\n\\n*
  resource_type\\n\\nImplementation:\\n\\nThe data in
  `/awslabs/eks_mcp_server/data/eks_cloudwatch_metrics_guidance.json` is
  generated by a Python script
  (`/awslabs/eks_mcp_server/scripts/update_eks_cloudwatch_metrics_guidance.py`)
  that scrapes the [Container Insights metrics
  table](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Contain\
  er-Insights-metrics-EKS.html) from AWS documentation. Running the script
  requires installing BeautifulSoup (used for parsing HTML content) with uv: `uv
  pip install bs4`.\\n\\n### IAM Integration\\n\\n####
  `get_policies_for_role`\\n\\nRetrieves all policies attached to a specified
  IAM role, including assume role policy, managed policies, and inline
  policies.\\n\\nFeatures:\\n\\n* Fetches the assume role policy document for
  the specified IAM role.\\n* Lists all attached managed policies and includes
  their policy documents.\\n* Lists all embedded inline policies and includes
  their policy documents.\\n\\nParameters:\\n\\n* role_name\\n\\n####
  `add_inline_policy`\\n\\nAdds a new inline policy with specified permissions
  to an IAM role; it will not modify existing policies. It will only create new
  policies; it will reject requests to modify existing
  policies.\\n\\nFeatures:\\n\\n* Creates and attaches a new inline policy to a
  specified IAM role.\\n* Rejects requests if the policy name already exists on
  the role to prevent accidental modification.\\n* Requires `--allow-write`
  server flag to be enabled.\\n* Accepts permissions as a single JSON object
  (statement) or a list of JSON objects (statements).\\n\\nParameters:\\n\\n*
  policy_name, role_name, permissions (JSON object or array of objects)\\n\\n###
  Troubleshooting\\n\\n#### `search_eks_troubleshoot_guide`\\n\\nSearches the
  EKS Troubleshoot Guide for troubleshooting information based on a
  query.\\n\\nFeatures:\\n\\n* Provides detailed troubleshooting guidance for
  Amazon EKS issues.\\n* Covers EKS Auto mode node provisioning, bootstrap
  issues, and controller failure modes.\\n* Returns symptoms, step-by-step
  short-term, and long-term fixes for identified issues.\\n\\nParameters:\\n\\n*
  query\\n\\n\\n## Security & permissions\\n\\n### Features\\n\\nThe EKS MCP
  Server implements the following security features:\\n\\n1. **AWS
  Authentication**: Uses AWS credentials from the environment for secure
  authentication.\\n2. **Kubernetes Authentication**: Generates temporary
  credentials for Kubernetes API access.\\n3. **SSL Verification**: Enforces SSL
  verification for all Kubernetes API calls.\\n4. **Resource Tagging**: Tags all
  created resources for traceability.\\n5. **Least Privilege**: Uses IAM roles
  with appropriate permissions for CloudFormation templates.\\n6. **Stack
  Protection**: Ensures CloudFormation stacks can only be modified by the tool
  that created them.\\n7. **Client Caching**: Caches Kubernetes clients with
  TTL-based expiration for security and performance.\\n\\n###
  Considerations\\n\\nWhen using the EKS MCP Server, consider the
  following:\\n\\n* **AWS Credentials**: The server needs permission to create
  and manage EKS resources.\\n* **Kubernetes Access**: The server generates
  temporary credentials for Kubernetes API access.\\n* **Network Security**:
  Configure VPC and security groups properly for EKS clusters.\\n*
  **Authentication**: Use appropriate authentication mechanisms for Kubernetes
  resources.\\n* **Authorization**: Configure RBAC properly for Kubernetes
  resources.\\n* **Data Protection**: Encrypt sensitive data in Kubernetes
  secrets.\\n* **Logging and Monitoring**: Enable logging and monitoring for EKS
  clusters.\\n\\n### Permissions\\n\\nThe EKS MCP Server can be used for
  production environments with proper security controls in place. The server
  runs in read-only mode by default, which is recommended and considered
  generally safer for production environments. Only explicitly enable write
  access when necessary. Below are the EKS MCP server tools available in
  read-only versus write-access mode:\\n\\n* **Read-only mode (default)**:
  `manage_eks_stacks` (with operation=\\\"describe\\\"), `manage_k8s_resource`
  (with operation=\\\"read\\\"), `list_k8s_resources`, `get_pod_logs`,
  `get_k8s_events`, `get_cloudwatch_logs`, `get_cloudwatch_metrics`,
  `get_policies_for_role`, `search_eks_troubleshoot_guide`,
  `list_api_versions`.\\n* **Write-access mode**: (require `--allow-write`):
  `manage_eks_stacks` (with \\\"generate\\\", \\\"deploy\\\", \\\"delete\\\"),
  `manage_k8s_resource` (with \\\"create\\\", \\\"replace\\\", \\\"patch\\\",
  \\\"delete\\\"), `apply_yaml`, `generate_app_manifest`,
  `add_inline_policy`.\\n\\n#### `autoApprove` (optional)\\n\\nAn array within
  the MCP server definition that lists tool names to be automatically approved
  by the EKS MCP Server client, bypassing user confirmation for those specific
  tools. For example:\\n\\n**For Mac/Linux:**\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.eks-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.eks-mcp-server@latest\\\"\\n      ],\\n      \\\"env\\\
  \": {\\n        \\\"AWS_PROFILE\\\":
  \\\"eks-mcp-readonly-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\"\\n      },\\n      \\\"autoApprove\\\":
  [\\n        \\\"manage_eks_stacks\\\",\\n        \\\"manage_k8s_resource\\\",\
  \\n        \\\"list_k8s_resources\\\",\\n        \\\"get_pod_logs\\\",\\n        \
  \\\"get_k8s_events\\\",\\n        \\\"get_cloudwatch_logs\\\",\\n        \\\"\
  get_cloudwatch_metrics\\\",\\n        \\\"get_policies_for_role\\\",\\n        \
  \\\"search_eks_troubleshoot_guide\\\",\\n        \\\"list_api_versions\\\"\\n      \
  ]\\n    }\\n  }\\n}\\n```\\n\\n**For
  Windows:**\\n```\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.eks-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"--from\\\",\\n        \\\"awslabs.eks-mcp-server@latest\\\",\
  \\n        \\\"awslabs.eks-mcp-server.exe\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"eks-mcp-readonly-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\"\\n      },\\n      \\\"autoApprove\\\":
  [\\n        \\\"manage_eks_stacks\\\",\\n        \\\"manage_k8s_resource\\\",\
  \\n        \\\"list_k8s_resources\\\",\\n        \\\"get_pod_logs\\\",\\n        \
  \\\"get_k8s_events\\\",\\n        \\\"get_cloudwatch_logs\\\",\\n        \\\"\
  get_cloudwatch_metrics\\\",\\n        \\\"get_policies_for_role\\\",\\n        \
  \\\"search_eks_troubleshoot_guide\\\",\\n        \\\"list_api_versions\\\"\\n      \
  ]\\n    }\\n  }\\n}\\n```\\n\\n### IAM Permissions Management\\n\\nWhen the
  `--allow-write` flag is enabled, the EKS MCP Server can create missing IAM
  permissions for EKS resources through the `add_inline_policy` tool. This tool
  enables the following:\\n\\n* Only creates new inline policies; it never
  modifies existing policies.\\n* Is useful for automatically fixing common
  permissions issues with EKS clusters.\\n* Should be used with caution and with
  properly scoped IAM roles.\\n\\n### Role Scoping Recommendations\\n\\nIn
  accordance with security best practices, we recommend the following:\\n\\n1.
  **Create dedicated IAM roles** to be used by the EKS MCP Server with the
  principle of \\\"least privilege.\\\"\\n2. **Use separate roles** for
  read-only and write operations.\\n3. **Implement resource tagging** to limit
  actions to resources created by the server.\\n4. **Enable AWS CloudTrail** to
  audit all API calls made by the server.\\n5. **Regularly review** the
  permissions granted to the server's IAM role.\\n6. **Use IAM Access Analyzer**
  to identify unused permissions that can be removed.\\n\\n### Sensitive
  Information Handling\\n\\n**IMPORTANT**: Do not pass secrets or sensitive
  information via allowed input mechanisms:\\n\\n* Do not include secrets or
  credentials in YAML files applied with `apply_yaml`.\\n* Do not pass sensitive
  information directly in the prompt to the model.\\n* Do not include secrets in
  CloudFormation templates or application manifests.\\n* Avoid using MCP tools
  for creating Kubernetes Secrets, as this would require providing the secret
  data to the model.\\n\\n**YAML Content Security**:\\n\\n* Only use YAML files
  from trustworthy sources.\\n* The server relies on Kubernetes API validation
  for YAML content and does not perform its own validation.\\n* Audit YAML files
  before applying them to your cluster.\\n\\n**Instead of passing secrets
  through MCP**:\\n\\n* Use AWS Secrets Manager or Parameter Store to store
  sensitive information.\\n* Configure proper Kubernetes RBAC for service
  accounts.\\n* Use IAM roles for service accounts (IRSA) for AWS service access
  from pods.\\n\\n## General Best Practices\\n\\n* **Resource Naming**: Use
  descriptive names for EKS clusters and Kubernetes resources.\\n* **Namespace
  Usage**: Organize resources into namespaces for better management.\\n* **Error
  Handling**: Check for errors in tool responses and handle them
  appropriately.\\n* **Resource Cleanup**: Delete unused resources to avoid
  unnecessary costs.\\n* **Monitoring**: Monitor cluster and resource status
  regularly.\\n* **Security**: Follow AWS security best practices for EKS
  clusters.\\n* **Backup**: Regularly backup important Kubernetes
  resources.\\n\\n## General Troubleshooting\\n\\n* **Permission Errors**:
  Verify that your AWS credentials have the necessary permissions.\\n*
  **CloudFormation Errors**: Check the CloudFormation console for stack creation
  errors.\\n* **Kubernetes API Errors**: Verify that the EKS cluster is running
  and accessible.\\n* **Network Issues**: Check VPC and security group
  configurations.\\n* **Client Errors**: Verify that the MCP client is
  configured correctly.\\n* **Log Level**: Increase the log level to DEBUG for
  more detailed logs.\\n\\nFor general EKS issues, consult the [Amazon EKS
  documentation](https://docs.aws.amazon.com/eks/).\\n\\n## Version\\n\\nCurrent
  MCP server version:
  0.1.0\\n\",\"isRecommended\":false,\"githubStars\":4381,\"downloadCount\":238,\
  \"createdAt\":\"2025-06-21T01:46:31.027799Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-05T07:54:26.920688Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/cost-explorer-mcp-server\",\"githubUrl\
  \":\"https://github.com/awslabs/mcp/tree/main/src/cost-explorer-mcp-server\",\
  \"name\":\"Cost Explorer\",\"author\":\"awslabs\",\"description\":\"Analyzes
  AWS costs and usage data through the Cost Explorer API, providing natural
  language querying of spending patterns, cost breakdowns, and usage trends
  across services and
  regions.\",\"codiconIcon\":\"graph\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/aws.png\",\"category\":\"monitoring\",\"tags\":[\"aws\
  \",\"cost-analysis\",\"cloud-billing\",\"expense-tracking\",\"reporting\"],\"\
  requiresApiKey\":false,\"readmeContent\":\"# Cost Explorer MCP Server\\n\\nMCP
  server for analyzing AWS costs and usage data through the AWS Cost Explorer
  API.\\n\\n## Features\\n\\n### Analyze AWS costs and usage data\\n\\n- Get
  detailed breakdown of your AWS costs by service, region, and other
  dimensions\\n- Understand how costs are distributed across various
  services\\n- Query historical cost data for specific time periods\\n- Filter
  costs by various dimensions, tags, and cost categories\\n\\n\\n### Compare
  costs between time periods\\n\\n- **NEW AWS Feature**: Leverage AWS Cost
  Explorer's new [Cost Comparison
  feature](https://docs.aws.amazon.com/cost-management/latest/userguide/ce-cost\
  -comparison.html)\\n- Compare costs between two time periods to identify
  changes and trends\\n- Analyze cost drivers to understand what caused cost
  increases or decreases\\n- Get detailed insights into the top 10 most
  significant cost change drivers automatically\\n- Identify specific usage
  types, discount changes, and infrastructure changes affecting costs\\n\\n###
  Forecast future costs\\n\\n- Generate cost forecasts based on historical usage
  patterns\\n- Get predictions with confidence intervals (80% or 95%)\\n-
  Support for daily and monthly forecast granularity\\n- Plan budgets and
  anticipate future AWS spending\\n\\n### Query cost data with natural
  language\\n\\n- Ask questions about your AWS costs in plain English\\n- Get
  instant answers about your AWS spending patterns\\n- Retrieve historical cost
  data with simple queries\\n\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS Cost Explorer\\n   - You need an AWS account with appropriate
  permissions\\n   - Configure AWS credentials with `aws configure` or
  environment variables\\n   - Ensure your IAM role/user has permissions to
  access AWS Cost Explorer API\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.cost-explorer-mcp-server&config=eyJjb21tYW5kIjoidX\
  Z4IGF3c2xhYnMuY29zdC1leHBsb3Jlci1tY3Atc2VydmVyQGxhdGVzdCIsImVudiI6eyJGQVNUTUN\
  QX0xPR19MRVZFTCI6IkVSUk9SIiwiQVdTX1BST0ZJTEUiOiJ5b3VyLWF3cy1wcm9maWxlIn0sImRp\
  c2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nHere are some ways you
  can work with MCP across AWS, and we'll be adding support to more products
  including Amazon Q Developer CLI soon: (e.g. for Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cost-explorer-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.cost-explorer-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/cost-explorer-mcp-server
  .`:\\n\\n```file\\n# fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=\\nAWS_SECRET_ACCESS_KEY=\\nAWS_SESSION_TOKEN=\
  \\n```\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cost-explorer-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env-file\\\",\\n        \\\"/full/path/to/file/above/.env\\\",\\n        \
  \\\"awslabs/cost-explorer-mcp-server:latest\\\"\\n      ],\\n      \\\"env\\\
  \": {},\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\nNOTE: Your credentials will need to be kept
  refreshed from your host\\n\\n### AWS Authentication\\n\\nThe MCP server uses
  the AWS profile specified in the `AWS_PROFILE` environment variable. If not
  provided, it defaults to the \\\"default\\\" profile in your AWS configuration
  file.\\n\\n```json\\n\\\"env\\\": {\\n  \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n}\\n```\\n\\nMake sure the AWS profile has
  permissions to access the AWS Cost Explorer API. The MCP server creates a
  boto3 session using the specified profile to authenticate with AWS services.
  Your AWS IAM credentials remain on your local machine and are strictly used
  for accessing AWS services.\\n\\n## Cost Considerations\\n\\n**Important:**
  AWS Cost Explorer API incurs charges on a per-request basis. Each API call
  made by this MCP server will result in charges to your AWS account.\\n\\n-
  **Cost Explorer API Pricing:** The AWS Cost Explorer API lets you directly
  access the interactive, ad-hoc query engine that powers AWS Cost Explorer.
  Each request will incur a cost of $0.01.\\n- Each tool invocation that queries
  Cost Explorer (get_dimension_values, get_tag_values, get_cost_and_usage) will
  generate at least one billable API request\\n- Complex queries with multiple
  filters or large date ranges may result in multiple API calls\\n\\nFor current
  pricing information, please refer to the [AWS Cost Explorer Pricing
  page](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/pricing/).\
  \\n\\n\\n## Security Considerations\\n\\n### Required IAM Permissions\\nThe
  following IAM permissions are required for this MCP server:\\n-
  ce:GetCostAndUsage\\n- ce:GetDimensionValues\\n- ce:GetTags\\n-
  ce:GetCostForecast\\n- ce:GetCostAndUsageComparisons\\n-
  ce:GetCostComparisonDrivers\\n\\n\\n\\n## Available Tools\\n\\nThe Cost
  Explorer MCP Server provides the following tools:\\n\\n1. `get_today_date` -
  Get the current date and month to determine relevent data when answering last
  month.\\n2. `get_dimension_values` - Get available values for a specific
  dimension (e.g., SERVICE, REGION)\\n3. `get_tag_values` - Get available values
  for a specific tag key\\n4. `get_cost_and_usage` - Retrieve AWS cost and usage
  data with filtering and grouping options\\n5. `get_cost_and_usage_comparisons`
  - Compare costs between two time periods to identify changes and trends\\n6.
  `get_cost_comparison_drivers` - Analyze what drove cost changes between
  periods (top 10 most significant drivers)\\n7. `get_cost_forecast` - Generate
  cost forecasts based on historical usage patterns\\n\\n## Example
  Usage\\n\\nHere are some examples of how to use the Cost Explorer MCP Server
  through natural language queries:\\n\\n### Cost Analysis
  Examples\\n\\n```\\nShow me my AWS costs for the last 3 months grouped by
  service in us-east-1 region\\nBreak down my S3 costs by storage class for Q1
  2025\\nShow me costs for production resources tagged with
  Environment=prod\\nWhat were my costs for reserved instances vs on-demand in
  May?\\nWhat was my EC2 instance usage by instance type?\\n```\\n\\n### Cost
  Comparison Examples\\n\\n```\\nCompare my AWS costs between April and May
  2025\\nHow did my EC2 costs change from last month to this month?\\nWhy did my
  AWS bill increase in June compared to May?\\nWhat caused the spike in my S3
  costs last month?\\n```\\n\\n### Forecasting Examples\\n\\n```\\nForecast my
  AWS costs for next month\\nPredict my EC2 spending for the next quarter\\nWhat
  will my total AWS bill be for the rest of 2025?\\n```\\n\\n##
  License\\n\\nThis project is licensed under the Apache License 2.0 - see the
  LICENSE file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":4378,\"downloadCount\":\
  888,\"createdAt\":\"2025-06-21T02:03:30.514734Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T03:18:48.373358Z\"},{\"mcp\
  Id\":\"github.com/modelcontextprotocol/servers/tree/main/src/puppeteer\",\"gi\
  thubUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/pup\
  peteer\",\"name\":\"Puppeteer\",\"author\":\"modelcontextprotocol\",\"descrip\
  tion\":\"Provides browser automation capabilities using Puppeteer, enabling
  web page interaction, screenshots, and JavaScript execution in a real browser
  environment.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/puppeteer.png\",\"category\":\"browser-automat\
  ion\",\"tags\":[\"web-automation\",\"screenshots\",\"browser-control\",\"java\
  script\",\"testing\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githu\
  bStars\":57003,\"downloadCount\":24227,\"createdAt\":\"2025-02-18T05:45:10.81\
  3537Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"20\
  25-07-01T10:07:59.767584Z\"},{\"mcpId\":\"github.com/executeautomation/mcp-pl\
  aywright\",\"githubUrl\":\"https://github.com/executeautomation/mcp-playwright\
  \",\"name\":\"Playwright\",\"author\":\"executeautomation\",\"description\":\
  \"Browser automation server that enables LLMs to interact with web pages, take
  screenshots, and execute JavaScript in a real browser environment using
  Playwright.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/playwright.png\",\"category\":\"browser-automat\
  ion\",\"tags\":[\"browser-automation\",\"web-testing\",\"screenshots\",\"java\
  script\",\"playwright\"],\"requiresApiKey\":false,\"readmeContent\":\"<div
  align=\\\"center\\\" markdown=\\\"1\\\">\\n  <table>\\n    <tr>\\n      <td
  align=\\\"center\\\" valign=\\\"middle\\\">\\n        <a
  href=\\\"https://mseep.ai/app/executeautomation-mcp-playwright\\\">\\n          \
  <img
  src=\\\"https://mseep.net/pr/executeautomation-mcp-playwright-badge.png\\\"
  alt=\\\"MseeP.ai Security Assessment Badge\\\"
  height=\\\"80\\\"/>\\n        </a>\\n      </td>\\n      <td
  align=\\\"center\\\" valign=\\\"middle\\\">\\n        <a
  href=\\\"https://www.warp.dev/?utm_source=github&utm_medium=referral&utm_camp\
  aign=mcp-playwright\\\">\\n          <img alt=\\\"Warp sponsorship\\\"
  width=\\\"200\\\"
  src=\\\"https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd\
  7ecac94eae\\\"/>\\n        </a>\\n      </td>\\n    </tr>\\n    <tr>\\n      \
  <td align=\\\"center\\\"><sub>MseeP.ai Security
  Assessment</sub></td>\\n      <td align=\\\"center\\\"><sub>Special thanks to
  <a
  href=\\\"https://www.warp.dev/?utm_source=github&utm_medium=referral&utm_camp\
  aign=mcp-playwright\\\">Warp, the AI terminal for
  developers</a></sub></td>\\n    </tr>\\n  </table>\\n</div>\\n<hr>\\n\\n#
  Playwright MCP Server \\n\\n[![smithery
  badge](https://smithery.ai/badge/@executeautomation/playwright-mcp-server)](h\
  ttps://smithery.ai/server/@executeautomation/playwright-mcp-server)\\n\\nA
  Model Context Protocol server that provides browser automation capabilities
  using Playwright. This server enables LLMs to interact with web pages, take
  screenshots, generate test code, web scraps the page and execute JavaScript in
  a real browser environment.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/yh4lgtwgbe\\\"><img width=\\\"380\\\"
  height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/yh4lgtwgbe/badge\\\"
  alt=\\\"mcp-playwright MCP server\\\" /></a>\\n\\n## Screenshot\\n![Playwright
  + Claude](image/playwright_claude.png)\\n\\n##
  [Documentation](https://executeautomation.github.io/mcp-playwright/) | [API
  reference](https://executeautomation.github.io/mcp-playwright/docs/playwright\
  -web/Supported-Tools)\\n\\n## Installation\\n\\nYou can install the package
  using either npm, mcp-get, or Smithery:\\n\\nUsing npm:\\n```bash\\nnpm
  install -g @executeautomation/playwright-mcp-server\\n```\\n\\nUsing
  mcp-get:\\n```bash\\nnpx @michaellatman/mcp-get@latest install
  @executeautomation/playwright-mcp-server\\n```\\nUsing Smithery\\n\\nTo
  install Playwright MCP for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@executeautomation/playwright-mcp-serve\
  r):\\n\\n```bash\\nnpx @smithery/cli install
  @executeautomation/playwright-mcp-server --client claude\\n```\\n####
  Installation in VS Code\\n\\nInstall the Playwright MCP server in VS Code
  using one of these buttons:\\n\\n<!--\\n// Generate using?:\\nconst config =
  JSON.stringify({ name: 'playwright', command: 'npx', args: [\\\"-y\\\",
  \\\"@executeautomation/playwright-mcp-server\\\"] });\\nconst urlForWebsites =
  `vscode:mcp/install?${encodeURIComponent(config)}`;\\n// Github markdown does
  not allow linking to `vscode:` directly, so you can use our redirect:\\nconst
  urlForGithub =
  `https://insiders.vscode.dev/redirect?url=${encodeURIComponent(urlForWebsites\
  )}`;\\n-->\\n\\n[<img
  src=\\\"https://img.shields.io/badge/VS_Code-VS_Code?style=flat-square&label=\
  Install%20Server&color=0098FF\\\" alt=\\\"Install in VS
  Code\\\">](https://insiders.vscode.dev/redirect?url=vscode%3Amcp%2Finstall%3F\
  %257B%2522name%2522%253A%2522playwright%2522%252C%2522command%2522%253A%2522n\
  px%2522%252C%2522args%2522%253A%255B%2522-y%2522%252C%2522%2540executeautomat\
  ion%252Fplaywright-mcp-server%2522%255D%257D) \\n[<img alt=\\\"Install in VS
  Code Insiders\\\"
  src=\\\"https://img.shields.io/badge/VS_Code_Insiders-VS_Code_Insiders?style=\
  flat-square&label=Install%20Server&color=24bfa5\\\">](https://insiders.vscode\
  .dev/redirect?url=vscode-insiders%3Amcp%2Finstall%3F%257B%2522name%2522%253A%\
  2522playwright%2522%252C%2522command%2522%253A%2522npx%2522%252C%2522args%252\
  2%253A%255B%2522-y%2522%252C%2522%2540executeautomation%252Fplaywright-mcp-se\
  rver%2522%255D%257D)\\n\\nAlternatively, you can install the Playwright MCP
  server using the VS Code CLI:\\n\\n```bash\\n# For VS Code\\ncode --add-mcp
  '{\\\"name\\\":\\\"playwright\\\",\\\"command\\\":\\\"npx\\\",\\\"args\\\":[\\\
  \"@executeautomation/playwright-mcp-server\\\"]}'\\n```\\n\\n```bash\\n# For
  VS Code Insiders\\ncode-insiders --add-mcp
  '{\\\"name\\\":\\\"playwright\\\",\\\"command\\\":\\\"npx\\\",\\\"args\\\":[\\\
  \"@executeautomation/playwright-mcp-server\\\"]}'\\n```\\n\\nAfter
  installation, the ExecuteAutomation Playwright MCP server will be available
  for use with your GitHub Copilot agent in VS Code.\\n\\n## Configuration to
  use Playwright Server\\nHere's the Claude Desktop configuration to use the
  Playwright server:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"playwright\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"@executeautomation/playwright-mcp-server\\\"]\\n    }\\n  }\\n}\\n```\\n\
  \\n## Testing\\n\\nThis project uses Jest for testing. The tests are located
  in the `src/__tests__` directory.\\n\\n### Running Tests\\n\\nYou can run the
  tests using one of the following commands:\\n\\n```bash\\n# Run tests using
  the custom script (with coverage)\\nnode run-tests.cjs\\n\\n# Run tests using
  npm scripts\\nnpm test           # Run tests without coverage\\nnpm run
  test:coverage  # Run tests with coverage\\nnpm run test:custom    # Run tests
  with custom script (same as node run-tests.cjs)\\n```\\n\\nThe test coverage
  report will be generated in the `coverage` directory.\\n\\n### Running
  evals\\n\\nThe evals package loads an mcp client that then runs the index.ts
  file, so there is no need to rebuild between tests. You can load environment
  variables by prefixing the npx command. Full documentation can be found
  [here](https://www.mcpevals.io/docs).\\n\\n```bash\\nOPENAI_API_KEY=your-key  \
  npx mcp-eval src/evals/evals.ts src/tools/codegen/index.ts\\n```\\n\\n##
  Contributing\\n\\nWhen adding new tools, please be mindful of the tool name
  length. Some clients, like Cursor, have a 60-character limit for the combined
  server and tool name (`server_name:tool_name`).\\n\\nOur server name is
  `playwright-mcp`. Please ensure your tool names are short enough to not exceed
  this limit.\\n\\n## Star History\\n\\n[![Star History
  Chart](https://api.star-history.com/svg?repos=executeautomation/mcp-playwrigh\
  t&type=Date)](https://star-history.com/#executeautomation/mcp-playwright&Date)\
  \\n\",\"isRecommended\":false,\"githubStars\":4092,\"downloadCount\":27287,\"\
  createdAt\":\"2025-02-17T22:45:31.388884Z\",\"updatedAt\":\"2025-07-08T01:10:\
  48.398933Z\",\"lastGithubSync\":\"2025-07-01T02:31:14.872859Z\"},{\"mcpId\":\
  \"github.com/stripe/agent-toolkit\",\"githubUrl\":\"https://github.com/stripe\
  /agent-toolkit\",\"name\":\"Stripe\",\"author\":\"stripe\",\"description\":\"\
  Enables AI agents to interact with Stripe APIs, supporting operations like
  customer management, payment processing, product creation, and invoice
  handling through function
  calling.\",\"codiconIcon\":\"credit-card\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/stripe.png\",\"category\":\"finance\",\"tags\"\
  :[\"payments\",\"billing\",\"invoicing\",\"stripe-api\",\"financial-services\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Stripe Agent
  Toolkit\\n\\nThe Stripe Agent Toolkit enables popular agent frameworks
  including OpenAI's Agent SDK, LangChain, CrewAI, Vercel's AI SDK, and Model
  Context Protocol (MCP) to integrate with Stripe APIs through function calling.
  The\\nlibrary is not exhaustive of the entire Stripe API. It includes support
  for both Python and TypeScript and is built directly on top of the Stripe
  [Python][python-sdk] and [Node][node-sdk] SDKs.\\n\\nIncluded below are basic
  instructions, but refer to the [Python](/python) and [TypeScript](/typescript)
  packages for more information.\\n\\n## Python\\n\\n### Installation\\n\\nYou
  don't need this source code unless you want to modify the package. If you
  just\\nwant to use the package run:\\n\\n```sh\\npip install
  stripe-agent-toolkit\\n```\\n\\n#### Requirements\\n\\n- Python 3.11+\\n\\n###
  Usage\\n\\nThe library needs to be configured with your account's secret key
  which is\\navailable in your [Stripe
  Dashboard][api-keys].\\n\\n```python\\nfrom
  stripe_agent_toolkit.openai.toolkit import
  StripeAgentToolkit\\n\\nstripe_agent_toolkit =
  StripeAgentToolkit(\\n    secret_key=\\\"sk_test_...\\\",\\n    configuration\
  ={\\n        \\\"actions\\\": {\\n            \\\"payment_links\\\":
  {\\n                \\\"create\\\":
  True,\\n            },\\n        }\\n    },\\n)\\n```\\n\\nThe toolkit works
  with OpenAI's Agent SDK, LangChain, and CrewAI and can be passed as a list of
  tools. For example:\\n\\n```python\\nfrom agents import
  Agent\\n\\nstripe_agent = Agent(\\n    name=\\\"Stripe
  Agent\\\",\\n    instructions=\\\"You are an expert at integrating with
  Stripe\\\",\\n    tools=stripe_agent_toolkit.get_tools()\\n)\\n```\\n\\nExamp\
  les for OpenAI's Agent SDK,LangChain, and CrewAI are included in
  [/examples](/python/examples).\\n\\n#### Context\\n\\nIn some cases you will
  want to provide values that serve as defaults when making requests. Currently,
  the `account` context value enables you to make API calls for your [connected
  accounts](https://docs.stripe.com/connect/authentication).\\n\\n```python\\ns\
  tripe_agent_toolkit =
  StripeAgentToolkit(\\n    secret_key=\\\"sk_test_...\\\",\\n    configuration\
  ={\\n        \\\"context\\\": {\\n            \\\"account\\\":
  \\\"acct_123\\\"\\n        }\\n    }\\n)\\n```\\n\\n## TypeScript\\n\\n###
  Installation\\n\\nYou don't need this source code unless you want to modify
  the package. If you just\\nwant to use the package run:\\n\\n```\\nnpm install
  @stripe/agent-toolkit\\n```\\n\\n#### Requirements\\n\\n- Node 18+\\n\\n###
  Usage\\n\\nThe library needs to be configured with your account's secret key
  which is available in your [Stripe Dashboard][api-keys]. Additionally,
  `configuration` enables you to specify the types of actions that can be taken
  using the toolkit.\\n\\n```typescript\\nimport { StripeAgentToolkit } from
  \\\"@stripe/agent-toolkit/langchain\\\";\\n\\nconst stripeAgentToolkit = new
  StripeAgentToolkit({\\n  secretKey:
  process.env.STRIPE_SECRET_KEY!,\\n  configuration: {\\n    actions:
  {\\n      paymentLinks: {\\n        create:
  true,\\n      },\\n    },\\n  },\\n});\\n```\\n\\n#### Tools\\n\\nThe toolkit
  works with LangChain and Vercel's AI SDK and can be passed as a list of tools.
  For example:\\n\\n```typescript\\nimport { AgentExecutor,
  createStructuredChatAgent } from \\\"langchain/agents\\\";\\n\\nconst tools =
  stripeAgentToolkit.getTools();\\n\\nconst agent = await
  createStructuredChatAgent({\\n  llm,\\n  tools,\\n  prompt,\\n});\\n\\nconst
  agentExecutor = new
  AgentExecutor({\\n  agent,\\n  tools,\\n});\\n```\\n\\n#### Context\\n\\nIn
  some cases you will want to provide values that serve as defaults when making
  requests. Currently, the `account` context value enables you to make API calls
  for your [connected
  accounts](https://docs.stripe.com/connect/authentication).\\n\\n```typescript\
  \\nconst stripeAgentToolkit = new StripeAgentToolkit({\\n  secretKey:
  process.env.STRIPE_SECRET_KEY!,\\n  configuration: {\\n    context:
  {\\n      account: \\\"acct_123\\\",\\n    },\\n  },\\n});\\n```\\n\\n####
  Metered billing\\n\\nFor Vercel's AI SDK, you can use middleware to submit
  billing events for usage. All that is required is the customer ID and the
  input/output meters to bill.\\n\\n```typescript\\nimport { StripeAgentToolkit
  } from \\\"@stripe/agent-toolkit/ai-sdk\\\";\\nimport { openai } from
  \\\"@ai-sdk/openai\\\";\\nimport
  {\\n  generateText,\\n  experimental_wrapLanguageModel as
  wrapLanguageModel,\\n} from \\\"ai\\\";\\n\\nconst stripeAgentToolkit = new
  StripeAgentToolkit({\\n  secretKey:
  process.env.STRIPE_SECRET_KEY!,\\n  configuration: {\\n    actions:
  {\\n      paymentLinks: {\\n        create:
  true,\\n      },\\n    },\\n  },\\n});\\n\\nconst model =
  wrapLanguageModel({\\n  model: openai(\\\"gpt-4o\\\"),\\n  middleware:
  stripeAgentToolkit.middleware({\\n    billing: {\\n      customer:
  \\\"cus_123\\\",\\n      meters: {\\n        input:
  \\\"input_tokens\\\",\\n        output:
  \\\"output_tokens\\\",\\n      },\\n    },\\n  }),\\n});\\n```\\n\\n## Model
  Context Protocol\\n\\nThe Stripe Agent Toolkit also supports the [Model
  Context Protocol (MCP)](https://modelcontextprotocol.com/).\\n\\nTo run the
  Stripe MCP server using npx, use the following command:\\n\\n```bash\\nnpx -y
  @stripe/mcp --tools=all --api-key=YOUR_STRIPE_SECRET_KEY\\n```\\n\\nReplace
  `YOUR_STRIPE_SECRET_KEY` with your actual Stripe secret key. Or, you could set
  the STRIPE_SECRET_KEY in your environment variables.\\n\\nAlternatively, you
  can set up your own MCP server. For example:\\n\\n```typescript\\nimport {
  StripeAgentToolkit } from
  \\\"@stripe/agent-toolkit/modelcontextprotocol\\\";\\nimport {
  StdioServerTransport } from
  \\\"@modelcontextprotocol/sdk/server/stdio.js\\\";\\n\\nconst server = new
  StripeAgentToolkit({\\n  secretKey:
  process.env.STRIPE_SECRET_KEY!,\\n  configuration: {\\n    actions:
  {\\n      paymentLinks: {\\n        create: true,\\n      },\\n      products:
  {\\n        create: true,\\n      },\\n      prices: {\\n        create:
  true,\\n      },\\n    },\\n  },\\n});\\n\\nasync function main() {\\n  const
  transport = new StdioServerTransport();\\n  await
  server.connect(transport);\\n  console.error(\\\"Stripe MCP Server running on
  stdio\\\");\\n}\\n\\nmain().catch((error) => {\\n  console.error(\\\"Fatal
  error in main():\\\", error);\\n  process.exit(1);\\n});\\n```\\n\\n##
  Supported API methods\\n\\n- [Create a
  customer](https://docs.stripe.com/api/customers/create)\\n- [List all
  customers](https://docs.stripe.com/api/customers/list)\\n- [Create a
  coupon](https://docs.stripe.com/api/coupons/create)\\n- [List all
  coupons](https://docs.stripe.com/api/coupons/list)\\n- [Create a
  product](https://docs.stripe.com/api/products/create)\\n- [List all
  products](https://docs.stripe.com/api/products/list)\\n- [Create a
  price](https://docs.stripe.com/api/prices/create)\\n- [List all
  prices](https://docs.stripe.com/api/prices/list)\\n- [Create a payment
  link](https://docs.stripe.com/api/payment-link/create)\\n- [Create an
  invoice](https://docs.stripe.com/api/invoices/create)\\n- [Create an invoice
  item](https://docs.stripe.com/api/invoiceitems/create)\\n- [Finalize an
  invoice](https://docs.stripe.com/api/invoices/finalize)\\n- [Retrieve
  balance](https://docs.stripe.com/api/balance/balance_retrieve)\\n- [List all
  subscriptions](https://docs.stripe.com/api/subscriptions/list)\\n- [Update a
  subscription](https://docs.stripe.com/api/subscriptions/update)\\n- [Cancel a
  subscription](https://docs.stripe.com/api/subscriptions/cancel)\\n- [Create a
  refund](https://docs.stripe.com/api/refunds/create)\\n- [List all
  disputes](https://docs.stripe.com/api/disputes/list)\\n- [Update a
  dispute](https://docs.stripe.com/api/disputes/update)\\n\\n[python-sdk]:
  https://github.com/stripe/stripe-python\\n[node-sdk]:
  https://github.com/stripe/stripe-node\\n[api-keys]:
  https://dashboard.stripe.com/account/apikeys\\n\",\"isRecommended\":true,\"gi\
  thubStars\":869,\"downloadCount\":1671,\"createdAt\":\"2025-02-18T06:28:40.35\
  9883Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"20\
  25-07-02T10:49:43.87814Z\"},{\"mcpId\":\"github.com/riza-io/riza-mcp\",\"gith\
  ubUrl\":\"https://github.com/riza-io/riza-mcp\",\"name\":\"Riza\",\"author\":\
  \"riza-io\",\"description\":\"Provides a secure code interpreter for executing
  LLM-generated code, with features for creating, saving, managing, and
  executing code tools in an isolated
  environment.\",\"codiconIcon\":\"terminal\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/riza.png\",\"category\":\"developer-tools\",\
  \"tags\":[\"code-execution\",\"sandbox\",\"code-interpreter\",\"tool-manageme\
  nt\",\"security\"],\"requiresApiKey\":false,\"readmeContent\":\"# Riza MCP
  Server\\n\\n[Riza](https://riza.io) offers an isolated code interpreter for
  your LLM-generated code. \\n\\nOur MCP server implementation wraps the Riza
  API and presents\\nendpoints as individual tools.\\n\\nConfigure with Claude
  Desktop as below, or adapt as necessary for your MCP client. Get a free Riza
  API key in your [Riza
  Dashboard](https://dashboard.riza.io).\\n\\n```json\\n{\\n  \\\"mcpServers\\\
  \": {\\n    \\\"riza-server\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"@riza-io/riza-mcp\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"RIZA_API_KEY\\\":
  \\\"your-api-key\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nThe Riza MCP
  server provides several tools to your LLM:\\n\\n- `create_tool`: Your LLM can
  write code and save it as a tool using the Riza [Tools
  API](https://docs.riza.io/api-reference/tool/create-tool). It can then execute
  these tools securely on Riza using `execute_tool`.\\n- `fetch_tool`: Your LLM
  can fetch saved Riza tools, including source code, which can be useful for
  editing tools.\\n- `execute_tool`: Executes a saved tool securely on Riza's
  code interpreter API.\\n- `edit_tool`: Edits an existing saved tool.\\n-
  `list_tools`: Lists available saved tools.\\n- `execute_code`: Executes
  arbitrary code safely on Riza's code interpreter API, without saving it as a
  tool.\\n\",\"isRecommended\":true,\"githubStars\":11,\"downloadCount\":157,\"\
  createdAt\":\"2025-02-18T06:28:33.910457Z\",\"updatedAt\":\"2025-07-08T01:10:\
  48.398933Z\",\"lastGithubSync\":\"2025-07-07T21:17:03.995844Z\"},{\"mcpId\":\
  \"github.com/qdrant/mcp-server-qdrant\",\"githubUrl\":\"https://github.com/qd\
  rant/mcp-server-qdrant\",\"name\":\"Qdrant\",\"author\":\"qdrant\",\"descript\
  ion\":\"A semantic memory layer enabling storage and retrieval of vector-based
  memories using the Qdrant vector search engine, with support for both cloud
  and local
  deployments.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/qdrant.png\",\"category\":\"knowledge-memory\
  \",\"tags\":[\"vector-search\",\"semantic-memory\",\"embeddings\",\"storage\",\
  \"retrieval\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  mcp-server-qdrant: A Qdrant MCP server\\n\\n[![smithery
  badge](https://smithery.ai/badge/mcp-server-qdrant)](https://smithery.ai/prot\
  ocol/mcp-server-qdrant)\\n\\n> The [Model Context Protocol
  (MCP)](https://modelcontextprotocol.io/introduction) is an open protocol that
  enables\\n> seamless integration between LLM applications and external data
  sources and tools. Whether you're building an\\n> AI-powered IDE, enhancing a
  chat interface, or creating custom AI workflows, MCP provides a standardized
  way to\\n> connect LLMs with the context they need.\\n\\nThis repository is an
  example of how to create a MCP server for [Qdrant](https://qdrant.tech/), a
  vector search engine.\\n\\n## Overview\\n\\nAn official Model Context Protocol
  server for keeping and retrieving memories in the Qdrant vector search
  engine.\\nIt acts as a semantic memory layer on top of the Qdrant
  database.\\n\\n## Components\\n\\n### Tools\\n\\n1. `qdrant-store`\\n   -
  Store some information in the Qdrant database\\n   - Input:\\n     -
  `information` (string): Information to store\\n     - `metadata` (JSON):
  Optional metadata to store\\n     - `collection_name` (string): Name of the
  collection to store the information in. This field is required if there are no
  default collection name.\\n                                   If there is a
  default collection name, this field is not enabled.\\n   - Returns:
  Confirmation message\\n2. `qdrant-find`\\n   - Retrieve relevant information
  from the Qdrant database\\n   - Input:\\n     - `query` (string): Query to use
  for searching\\n     - `collection_name` (string): Name of the collection to
  store the information in. This field is required if there are no default
  collection name.\\n                                   If there is a default
  collection name, this field is not enabled.\\n   - Returns: Information stored
  in the Qdrant database as separate messages\\n\\n## Environment
  Variables\\n\\nThe configuration of the server is done using environment
  variables:\\n\\n| Name                     |
  Description                                                         | Default
  Value                                                     |\\n|--------------\
  ------------|----------------------------------------------------------------\
  -----|-------------------------------------------------------------------|\\n|
  `QDRANT_URL`             | URL of the Qdrant
  server                                            |
  None                                                              |\\n|
  `QDRANT_API_KEY`         | API key for the Qdrant
  server                                       |
  None                                                              |\\n|
  `COLLECTION_NAME`        | Name of the default collection to
  use.                              |
  None                                                              |\\n|
  `QDRANT_LOCAL_PATH`      | Path to the local Qdrant database (alternative to
  `QDRANT_URL`)     |
  None                                                              |\\n|
  `EMBEDDING_PROVIDER`     | Embedding provider to use (currently only
  \\\"fastembed\\\" is supported) |
  `fastembed`                                                       |\\n|
  `EMBEDDING_MODEL`        | Name of the embedding model to
  use                                  |
  `sentence-transformers/all-MiniLM-L6-v2`                          |\\n|
  `TOOL_STORE_DESCRIPTION` | Custom description for the store
  tool                               | See default in
  [`settings.py`](src/mcp_server_qdrant/settings.py) |\\n|
  `TOOL_FIND_DESCRIPTION`  | Custom description for the find
  tool                                | See default in
  [`settings.py`](src/mcp_server_qdrant/settings.py) |\\n\\nNote: You cannot
  provide both `QDRANT_URL` and `QDRANT_LOCAL_PATH` at the same time.\\n\\n>
  [!IMPORTANT]\\n> Command-line arguments are not supported anymore! Please use
  environment variables for all configuration.\\n\\n### FastMCP Environment
  Variables\\n\\nSince `mcp-server-qdrant` is based on FastMCP, it also supports
  all the FastMCP environment variables. The most\\nimportant ones are listed
  below:\\n\\n| Environment Variable                  |
  Description                                               | Default Value
  |\\n|---------------------------------------|--------------------------------\
  ---------------------------|---------------|\\n|
  `FASTMCP_DEBUG`                       | Enable debug
  mode                                         | `false`       |\\n|
  `FASTMCP_LOG_LEVEL`                   | Set logging level (DEBUG, INFO,
  WARNING, ERROR, CRITICAL) | `INFO`        |\\n|
  `FASTMCP_HOST`                        | Host address to bind the server
  to                        | `127.0.0.1`   |\\n|
  `FASTMCP_PORT`                        | Port to run the server
  on                                 | `8000`        |\\n|
  `FASTMCP_WARN_ON_DUPLICATE_RESOURCES` | Show warnings for duplicate
  resources                     | `true`        |\\n|
  `FASTMCP_WARN_ON_DUPLICATE_TOOLS`     | Show warnings for duplicate
  tools                         | `true`        |\\n|
  `FASTMCP_WARN_ON_DUPLICATE_PROMPTS`   | Show warnings for duplicate
  prompts                       | `true`        |\\n|
  `FASTMCP_DEPENDENCIES`                | List of dependencies to install in the
  server environment | `[]`          |\\n\\n## Installation\\n\\n### Using
  uvx\\n\\nWhen using
  [`uvx`](https://docs.astral.sh/uv/guides/tools/#running-tools) no specific
  installation is needed to directly run
  *mcp-server-qdrant*.\\n\\n```shell\\nQDRANT_URL=\\\"http://localhost:6333\\\"
  \\\\\\nCOLLECTION_NAME=\\\"my-collection\\\"
  \\\\\\nEMBEDDING_MODEL=\\\"sentence-transformers/all-MiniLM-L6-v2\\\"
  \\\\\\nuvx mcp-server-qdrant\\n```\\n\\n#### Transport Protocols\\n\\nThe
  server supports different transport protocols that can be specified using the
  `--transport` flag:\\n\\n```shell\\nQDRANT_URL=\\\"http://localhost:6333\\\"
  \\\\\\nCOLLECTION_NAME=\\\"my-collection\\\" \\\\\\nuvx mcp-server-qdrant
  --transport sse\\n```\\n\\nSupported transport protocols:\\n\\n- `stdio`
  (default): Standard input/output transport, might only be used by local MCP
  clients\\n- `sse`: Server-Sent Events transport, perfect for remote
  clients\\n- `streamable-http`: Streamable HTTP transport, perfect for remote
  clients, more recent than SSE\\n\\nThe default transport is `stdio` if not
  specified.\\n\\nWhen SSE transport is used, the server will listen on the
  specified port and wait for incoming connections. The default\\nport is 8000,
  however it can be changed using the `FASTMCP_PORT` environment
  variable.\\n\\n```shell\\nQDRANT_URL=\\\"http://localhost:6333\\\"
  \\\\\\nCOLLECTION_NAME=\\\"my-collection\\\" \\\\\\nFASTMCP_PORT=1234
  \\\\\\nuvx mcp-server-qdrant --transport sse\\n```\\n\\n### Using
  Docker\\n\\nA Dockerfile is available for building and running the MCP
  server:\\n\\n```bash\\n# Build the container\\ndocker build -t
  mcp-server-qdrant .\\n\\n# Run the container\\ndocker run -p 8000:8000
  \\\\\\n  -e FASTMCP_HOST=\\\"0.0.0.0\\\" \\\\\\n  -e
  QDRANT_URL=\\\"http://your-qdrant-server:6333\\\" \\\\\\n  -e
  QDRANT_API_KEY=\\\"your-api-key\\\" \\\\\\n  -e
  COLLECTION_NAME=\\\"your-collection\\\"
  \\\\\\n  mcp-server-qdrant\\n```\\n\\n> [!TIP]\\n> Please note that we set
  `FASTMCP_HOST=\\\"0.0.0.0\\\"` to make the server listen on all network
  interfaces. This is\\n> necessary when running the server in a Docker
  container.\\n\\n### Installing via Smithery\\n\\nTo install Qdrant MCP Server
  for Claude Desktop automatically via
  [Smithery](https://smithery.ai/protocol/mcp-server-qdrant):\\n\\n```bash\\nnpx
  @smithery/cli install mcp-server-qdrant --client claude\\n```\\n\\n### Manual
  configuration of Claude Desktop\\n\\nTo use this server with the Claude
  Desktop app, add the following configuration to the \\\"mcpServers\\\" section
  of your\\n`claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"qdrant\\\":
  {\\n    \\\"command\\\": \\\"uvx\\\",\\n    \\\"args\\\":
  [\\\"mcp-server-qdrant\\\"],\\n    \\\"env\\\": {\\n      \\\"QDRANT_URL\\\":
  \\\"https://xyz-example.eu-central.aws.cloud.qdrant.io:6333\\\",\\n      \\\"\
  QDRANT_API_KEY\\\": \\\"your_api_key\\\",\\n      \\\"COLLECTION_NAME\\\":
  \\\"your-collection-name\\\",\\n      \\\"EMBEDDING_MODEL\\\":
  \\\"sentence-transformers/all-MiniLM-L6-v2\\\"\\n    }\\n  }\\n}\\n```\\n\\nF\
  or local Qdrant mode:\\n\\n```json\\n{\\n  \\\"qdrant\\\":
  {\\n    \\\"command\\\": \\\"uvx\\\",\\n    \\\"args\\\":
  [\\\"mcp-server-qdrant\\\"],\\n    \\\"env\\\":
  {\\n      \\\"QDRANT_LOCAL_PATH\\\":
  \\\"/path/to/qdrant/database\\\",\\n      \\\"COLLECTION_NAME\\\":
  \\\"your-collection-name\\\",\\n      \\\"EMBEDDING_MODEL\\\":
  \\\"sentence-transformers/all-MiniLM-L6-v2\\\"\\n    }\\n  }\\n}\\n```\\n\\nT\
  his MCP server will automatically create a collection with the specified name
  if it doesn't exist.\\n\\nBy default, the server will use the
  `sentence-transformers/all-MiniLM-L6-v2` embedding model to encode
  memories.\\nFor the time being, only
  [FastEmbed](https://qdrant.github.io/fastembed/) models are supported.\\n\\n##
  Support for other tools\\n\\nThis MCP server can be used with any
  MCP-compatible client. For example, you can use it
  with\\n[Cursor](https://docs.cursor.com/context/model-context-protocol) and
  [VS Code](https://code.visualstudio.com/docs), which provide built-in support
  for the Model Context\\nProtocol.\\n\\n### Using with Cursor/Windsurf\\n\\nYou
  can configure this MCP server to work as a code search tool for Cursor or
  Windsurf by customizing the
  tool\\ndescriptions:\\n\\n```bash\\nQDRANT_URL=\\\"http://localhost:6333\\\"
  \\\\\\nCOLLECTION_NAME=\\\"code-snippets\\\"
  \\\\\\nTOOL_STORE_DESCRIPTION=\\\"Store reusable code snippets for later
  retrieval. \\\\\\nThe 'information' parameter should contain a natural
  language description of what the code does, \\\\\\nwhile the actual code
  should be included in the 'metadata' parameter as a 'code' property.
  \\\\\\nThe value of 'metadata' is a Python dictionary with strings as keys.
  \\\\\\nUse this whenever you generate some code snippet.\\\"
  \\\\\\nTOOL_FIND_DESCRIPTION=\\\"Search for relevant code snippets based on
  natural language descriptions. \\\\\\nThe 'query' parameter should describe
  what you're looking for, \\\\\\nand the tool will return the most relevant
  code snippets. \\\\\\nUse this when you need to find existing code snippets
  for reuse or reference.\\\" \\\\\\nuvx mcp-server-qdrant --transport sse #
  Enable SSE transport\\n```\\n\\nIn Cursor/Windsurf, you can then configure the
  MCP server in your settings by pointing to this running server using\\nSSE
  transport protocol. The description on how to add an MCP server to Cursor can
  be found in the
  [Cursor\\ndocumentation](https://docs.cursor.com/context/model-context-protoc\
  ol#adding-an-mcp-server-to-cursor). If you are\\nrunning Cursor/Windsurf
  locally, you can use the following
  URL:\\n\\n```\\nhttp://localhost:8000/sse\\n```\\n\\n> [!TIP]\\n> We suggest
  SSE transport as a preferred way to connect Cursor/Windsurf to the MCP server,
  as it can support remote\\n> connections. That makes it easy to share the
  server with your team or use it in a cloud environment.\\n\\nThis
  configuration transforms the Qdrant MCP server into a specialized code search
  tool that can:\\n\\n1. Store code snippets, documentation, and implementation
  details\\n2. Retrieve relevant code examples based on semantic search\\n3.
  Help developers find specific implementations or usage patterns\\n\\nYou can
  populate the database by storing natural language descriptions of code
  snippets (in the `information` parameter)\\nalong with the actual code (in the
  `metadata.code` property), and then search for them using natural language
  queries\\nthat describe what you're looking for.\\n\\n> [!NOTE]\\n> The tool
  descriptions provided above are examples and may need to be customized for
  your specific use case. Consider\\n> adjusting the descriptions to better
  match your team's workflow and the specific types of code snippets you want
  to\\n> store and retrieve.\\n\\n**If you have successfully installed the
  `mcp-server-qdrant`, but still can't get it to work with Cursor,
  please\\nconsider creating the [Cursor
  rules](https://docs.cursor.com/context/rules-for-ai) so the MCP tools are
  always used when\\nthe agent produces a new code snippet.** You can restrict
  the rules to only work for certain file types, to avoid using\\nthe MCP server
  for the documentation or other types of content.\\n\\n### Using with Claude
  Code\\n\\nYou can enhance Claude Code's capabilities by connecting it to this
  MCP server, enabling semantic search over your\\nexisting codebase.\\n\\n####
  Setting up mcp-server-qdrant\\n\\n1. Add the MCP server to Claude
  Code:\\n\\n    ```shell\\n    # Add mcp-server-qdrant configured for code
  search\\n    claude mcp add code-search \\\\\\n    -e
  QDRANT_URL=\\\"http://localhost:6333\\\" \\\\\\n    -e
  COLLECTION_NAME=\\\"code-repository\\\" \\\\\\n    -e
  EMBEDDING_MODEL=\\\"sentence-transformers/all-MiniLM-L6-v2\\\" \\\\\\n    -e
  TOOL_STORE_DESCRIPTION=\\\"Store code snippets with descriptions. The
  'information' parameter should contain a natural language description of what
  the code does, while the actual code should be included in the 'metadata'
  parameter as a 'code' property.\\\" \\\\\\n    -e
  TOOL_FIND_DESCRIPTION=\\\"Search for relevant code snippets using natural
  language. The 'query' parameter should describe the functionality you're
  looking for.\\\" \\\\\\n    -- uvx mcp-server-qdrant\\n    ```\\n\\n2. Verify
  the server was added:\\n\\n    ```shell\\n    claude mcp
  list\\n    ```\\n\\n#### Using Semantic Code Search in Claude Code\\n\\nTool
  descriptions, specified in `TOOL_STORE_DESCRIPTION` and
  `TOOL_FIND_DESCRIPTION`, guide Claude Code on how to use\\nthe MCP server. The
  ones provided above are examples and may need to be customized for your
  specific use case. However,\\nClaude Code should be already able to:\\n\\n1.
  Use the `qdrant-store` tool to store code snippets with descriptions.\\n2. Use
  the `qdrant-find` tool to search for relevant code snippets using natural
  language.\\n\\n### Run MCP server in Development Mode\\n\\nThe MCP server can
  be run in development mode using the `mcp dev` command. This will start the
  server and open the MCP\\ninspector in your
  browser.\\n\\n```shell\\nCOLLECTION_NAME=mcp-dev fastmcp dev
  src/mcp_server_qdrant/server.py\\n```\\n\\n### Using with VS Code\\n\\nFor
  one-click installation, click one of the install buttons
  below:\\n\\n[![Install with UVX in VS
  Code](https://img.shields.io/badge/VS_Code-UVX-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=qdrant&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22m\
  cp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%24%7Binput%3Aq\
  drantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantApiKey%7D%22%2\
  C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7D%7D&inputs=%\
  5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%22%2C%22descri\
  ption%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%2\
  2%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%22%2C%22passwo\
  rd%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22collecti\
  onName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D) [![Install with
  UVX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-UVX-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22uvx%22%2C%22args\
  %22%3A%5B%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A%22%2\
  4%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3AqdrantA\
  piKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D%22%7\
  D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrantUrl%2\
  2%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptString\
  %22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+Key%2\
  2%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22id%22%\
  3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D&qual\
  ity=insiders)\\n\\n[![Install with Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=qdrant&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%\
  5B%22run%22%2C%22-p%22%2C%228000%3A8000%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22\
  %2C%22QDRANT_URL%22%2C%22-e%22%2C%22QDRANT_API_KEY%22%2C%22-e%22%2C%22COLLECT\
  ION_NAME%22%2C%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDRANT_URL%22%3A\
  %22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24%7Binput%3Aqd\
  rantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3AcollectionName%7D\
  %22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22qdrant\
  Url%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22%3A%22promptS\
  tring%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%22Qdrant+API+\
  Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptString%22%2C%22i\
  d%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+Name%22%7D%5D)
  [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=qdrant&config=%7B%22command%22%3A%22docker%22%2C%\
  22args%22%3A%5B%22run%22%2C%22-p%22%2C%228000%3A8000%22%2C%22-i%22%2C%22--rm%\
  22%2C%22-e%22%2C%22QDRANT_URL%22%2C%22-e%22%2C%22QDRANT_API_KEY%22%2C%22-e%22\
  %2C%22COLLECTION_NAME%22%2C%22mcp-server-qdrant%22%5D%2C%22env%22%3A%7B%22QDR\
  ANT_URL%22%3A%22%24%7Binput%3AqdrantUrl%7D%22%2C%22QDRANT_API_KEY%22%3A%22%24\
  %7Binput%3AqdrantApiKey%7D%22%2C%22COLLECTION_NAME%22%3A%22%24%7Binput%3Acoll\
  ectionName%7D%22%7D%7D&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%2\
  2%3A%22qdrantUrl%22%2C%22description%22%3A%22Qdrant+URL%22%7D%2C%7B%22type%22\
  %3A%22promptString%22%2C%22id%22%3A%22qdrantApiKey%22%2C%22description%22%3A%\
  22Qdrant+API+Key%22%2C%22password%22%3Atrue%7D%2C%7B%22type%22%3A%22promptStr\
  ing%22%2C%22id%22%3A%22collectionName%22%2C%22description%22%3A%22Collection+\
  Name%22%7D%5D&quality=insiders)\\n\\n#### Manual Installation\\n\\nAdd the
  following JSON block to your User Settings (JSON) file in VS Code. You can do
  this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User
  Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"qdrantUrl\\\",\\n        \\\"description\\\": \\\"Qdrant
  URL\\\"\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"qdrantApiKey\\\",\\n        \\\"description\\\": \\\"Qdrant API
  Key\\\",\\n        \\\"password\\\":
  true\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"collectionName\\\",\\n        \\\"description\\\": \\\"Collection
  Name\\\"\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"qdrant\\\":
  {\\n        \\\"command\\\": \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"mcp-server-qdrant\\\"],\\n        \\\"env\\\":
  {\\n          \\\"QDRANT_URL\\\":
  \\\"${input:qdrantUrl}\\\",\\n          \\\"QDRANT_API_KEY\\\":
  \\\"${input:qdrantApiKey}\\\",\\n          \\\"COLLECTION_NAME\\\":
  \\\"${input:collectionName}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nOr if you prefer using Docker, add this configuration
  instead:\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\":
  [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"qdrantUrl\\\",\\n        \\\"description\\\": \\\"Qdrant
  URL\\\"\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"qdrantApiKey\\\",\\n        \\\"description\\\": \\\"Qdrant API
  Key\\\",\\n        \\\"password\\\":
  true\\n      },\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"collectionName\\\",\\n        \\\"description\\\": \\\"Collection
  Name\\\"\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"qdrant\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"-p\\\",
  \\\"8000:8000\\\",\\n          \\\"-i\\\",\\n          \\\"--rm\\\",\\n          \
  \\\"-e\\\", \\\"QDRANT_URL\\\",\\n          \\\"-e\\\",
  \\\"QDRANT_API_KEY\\\",\\n          \\\"-e\\\",
  \\\"COLLECTION_NAME\\\",\\n          \\\"mcp-server-qdrant\\\"\\n        ],\\\
  n        \\\"env\\\": {\\n          \\\"QDRANT_URL\\\":
  \\\"${input:qdrantUrl}\\\",\\n          \\\"QDRANT_API_KEY\\\":
  \\\"${input:qdrantApiKey}\\\",\\n          \\\"COLLECTION_NAME\\\":
  \\\"${input:collectionName}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\
  \\n\\nAlternatively, you can create a `.vscode/mcp.json` file in your
  workspace with the following content:\\n\\n```json\\n{\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"qdrantUrl\\\",\\n      \\\"description\\\": \\\"Qdrant
  URL\\\"\\n    },\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"qdrantApiKey\\\",\\n      \\\"description\\\": \\\"Qdrant API
  Key\\\",\\n      \\\"password\\\": true\\n    },\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"collectionName\\\",\\n      \\\"description\\\": \\\"Collection
  Name\\\"\\n    }\\n  ],\\n  \\\"servers\\\": {\\n    \\\"qdrant\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-qdrant\\\"],\\n      \\\"env\\\":
  {\\n        \\\"QDRANT_URL\\\":
  \\\"${input:qdrantUrl}\\\",\\n        \\\"QDRANT_API_KEY\\\":
  \\\"${input:qdrantApiKey}\\\",\\n        \\\"COLLECTION_NAME\\\":
  \\\"${input:collectionName}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor
  workspace configuration with Docker, use this in
  `.vscode/mcp.json`:\\n\\n```json\\n{\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"qdrantUrl\\\",\\n      \\\"description\\\": \\\"Qdrant
  URL\\\"\\n    },\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"qdrantApiKey\\\",\\n      \\\"description\\\": \\\"Qdrant API
  Key\\\",\\n      \\\"password\\\": true\\n    },\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"collectionName\\\",\\n      \\\"description\\\": \\\"Collection
  Name\\\"\\n    }\\n  ],\\n  \\\"servers\\\": {\\n    \\\"qdrant\\\":
  {\\n      \\\"command\\\": \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-p\\\",
  \\\"8000:8000\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \\\
  \"-e\\\", \\\"QDRANT_URL\\\",\\n        \\\"-e\\\",
  \\\"QDRANT_API_KEY\\\",\\n        \\\"-e\\\",
  \\\"COLLECTION_NAME\\\",\\n        \\\"mcp-server-qdrant\\\"\\n      ],\\n      \
  \\\"env\\\": {\\n        \\\"QDRANT_URL\\\":
  \\\"${input:qdrantUrl}\\\",\\n        \\\"QDRANT_API_KEY\\\":
  \\\"${input:qdrantApiKey}\\\",\\n        \\\"COLLECTION_NAME\\\":
  \\\"${input:collectionName}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n##
  Contributing\\n\\nIf you have suggestions for how mcp-server-qdrant could be
  improved, or want to report a bug, open an issue!\\nWe'd love all and any
  contributions.\\n\\n### Testing `mcp-server-qdrant` locally\\n\\nThe [MCP
  inspector](https://github.com/modelcontextprotocol/inspector) is a developer
  tool for testing and debugging MCP\\nservers. It runs both a client UI
  (default port 5173) and an MCP proxy server (default port 3000). Open the
  client UI in\\nyour browser to use the
  inspector.\\n\\n```shell\\nQDRANT_URL=\\\":memory:\\\"
  COLLECTION_NAME=\\\"test\\\" \\\\\\nfastmcp dev
  src/mcp_server_qdrant/server.py\\n```\\n\\nOnce started, open your browser to
  http://localhost:5173 to access the inspector interface.\\n\\n##
  License\\n\\nThis MCP server is licensed under the Apache License 2.0. This
  means you are free to use, modify, and distribute the\\nsoftware, subject to
  the terms and conditions of the Apache License 2.0. For more details, please
  see the LICENSE file\\nin the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":743,\"downloadCount\"\
  :1302,\"createdAt\":\"2025-02-18T05:47:07.82849Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T06:55:12.23877Z\"},{\"mcp\
  Id\":\"github.com/nickbaumann98/everart-forge-mcp\",\"githubUrl\":\"https://g\
  ithub.com/nickbaumann98/everart-forge-mcp\",\"name\":\"EverArt
  Forge\",\"author\":\"nickbaumann98\",\"description\":\"Advanced image
  generation server integrating EverArt's AI models for creating vector and
  raster images, supporting multiple formats and styles with flexible storage
  options.\",\"codiconIcon\":\"image\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/everart.png\",\"category\":\"image-video-processing\
  \",\"tags\":[\"image-generation\",\"vector-graphics\",\"ai-models\",\"file-co\
  nversion\",\"content-creation\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"# EverArt Forge MCP for Cline\\n\\n![EverArt Forge MCP](icon.svg)\\n\\nAn
  advanced Model Context Protocol (MCP) server for
  [Cline](https://github.com/cline/cline) that integrates with EverArt's AI
  models to generate both vector and raster images. This server provides
  powerful image generation capabilities with flexible storage options and
  format conversion.\\n\\n## Features\\n\\n- **Vector Graphics
  Generation**\\n  - Create SVG vector graphics using Recraft-Vector model\\n  -
  Automatic SVG optimization\\n  - Perfect for logos, icons, and scalable
  graphics\\n\\n- **Raster Image Generation**\\n  - Support for PNG, JPEG, and
  WebP formats\\n  - Multiple AI models for different styles\\n  - High-quality
  image processing\\n\\n- **Flexible Storage**\\n  - Custom output paths and
  filenames\\n  - Automatic directory creation\\n  - Format validation and
  extension handling\\n  - Web project integration\\n\\n## Available
  Models\\n\\n- **5000:FLUX1.1**: Standard quality, general-purpose image
  generation\\n- **9000:FLUX1.1-ultra**: Ultra high quality for detailed
  images\\n- **6000:SD3.5**: Stable Diffusion 3.5 for diverse styles\\n-
  **7000:Recraft-Real**: Photorealistic style\\n- **8000:Recraft-Vector**:
  Vector art style (SVG output)\\n\\n## Installation\\n\\n1. Clone the
  repository:\\n   ```bash\\n   git clone
  https://github.com/nickbaumann98/everart-forge-mcp.git\\n   cd
  everart-forge-mcp\\n   ```\\n\\n2. Install dependencies:\\n   ```bash\\n   npm
  install\\n   ```\\n\\n3. Build the project:\\n   ```bash\\n   npm run
  build\\n   ```\\n\\n4. Get your EverArt API key:\\n   - Sign up at
  [EverArt](https://everart.ai/) \\n   - Navigate to your account
  settings\\n   - Create or copy your API key\\n\\n5. Add the server to your
  Cline MCP settings file:\\n\\n   **For VS Code Extension**:  \\n   Edit
  `~/Library/Application
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json`:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"everart-forge\\\": {\\n         \\\"command\\\":
  \\\"node\\\",\\n         \\\"args\\\":
  [\\\"/absolute/path/to/everart-forge-mcp/build/index.js\\\"],\\n         \\\"\
  env\\\": {\\n           \\\"EVERART_API_KEY\\\":
  \\\"your_api_key_here\\\"\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n   **For Claude Desktop
  App**:  \\n   Edit `~/Library/Application
  Support/Claude/claude_desktop_config.json` (macOS) or appropriate location for
  your OS\\n\\n6. Restart Cline to load the new MCP server\\n\\n## Usage
  Examples\\n\\nOnce configured, you can use Cline to generate images with
  prompts like:\\n\\n- \\\"Generate a minimalist tech logo in SVG format using
  the Recraft-Vector model\\\"\\n- \\\"Create a photorealistic landscape image
  with the FLUX1.1-ultra model\\\"\\n- \\\"Make me a vector icon for my project
  that represents artificial intelligence\\\"\\n- \\\"Generate a professional
  company logo as an SVG file and save it to my desktop\\\"\\n\\n### Tool
  Capabilities\\n\\nThe server provides these tools:\\n\\n####
  generate_image\\n\\nGenerate images with extensive customization
  options:\\n\\n```\\nParameters:\\n- prompt (required): Text description of
  desired image\\n- model: Model ID (5000:FLUX1.1, 9000:FLUX1.1-ultra,
  6000:SD3.5, 7000:Recraft-Real, 8000:Recraft-Vector)\\n- format: Output format
  (svg, png, jpg, webp)\\n- output_path: Custom output path for the image\\n-
  web_project_path: Path to web project root for proper asset organization\\n-
  project_type: Web project type (react, vue, html, next, etc.)\\n- asset_path:
  Subdirectory within the web project assets\\n- image_count: Number of images
  to generate (1-10)\\n```\\n\\nNotes:\\n- SVG format is only available with
  Recraft-Vector (8000) model\\n- Default format is \\\"svg\\\" for model 8000,
  \\\"png\\\" for others\\n- You can specify combined model IDs (e.g.,
  \\\"8000:Recraft-Vector\\\")\\n\\n#### list_images\\n\\nList all previously
  generated images stored by the server.\\n\\n#### view_image\\n\\nOpen a
  specific image in the default image viewer:\\n\\n```\\nParameters:\\n-
  filename: Name of the image file to view\\n```\\n\\n## Troubleshooting\\n\\n-
  **Error: Invalid model ID**: Make sure you're using one of the supported model
  IDs (5000, 6000, 7000, 8000, 9000)\\n- **Format not compatible with model**:
  SVG format is only available with Recraft-Vector (8000) model\\n- **Image not
  found**: Use the list_images tool to see available images\\n- **API
  authentication failed**: Check your EverArt API key\\n- **Images not
  appearing**: Check file permissions and paths\\n\\n## License\\n\\nMIT License
  - see LICENSE file for details.\\n\",\"llmsInstallationContent\":\"# EverArt
  Forge MCP - LLM Installation Guide\\n\\nThis guide is specifically designed to
  help LLM agents like Cline install and configure the EverArt Forge MCP
  server.\\n\\n## Prerequisites\\n\\n- Node.js v14+ installed\\n- Access to an
  EverArt API key\\n- Permission to edit MCP configuration files\\n\\n##
  Step-by-Step Installation\\n\\n1. **Clone the
  repository**:\\n   ```bash\\n   git clone
  https://github.com/nickbaumann98/everart-forge-mcp.git\\n   cd
  everart-forge-mcp\\n   ```\\n\\n2. **Install
  dependencies**:\\n   ```bash\\n   npm install\\n   ```\\n\\n3. **Build the
  project**:\\n   ```bash\\n   npm run build\\n   ```\\n\\n4. **Configure the
  MCP server**:\\n\\n   You'll need to add the server to the appropriate MCP
  configuration file based on the client:\\n\\n   **For Cline VS Code
  Extension**:\\n   Edit the file at `~/Library/Application
  Support/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_set\
  tings.json` on macOS, or the equivalent path on Windows/Linux.\\n\\n   **For
  Claude Desktop**:\\n   Edit the file at `~/Library/Application
  Support/Claude/claude_desktop_config.json` on macOS, or the equivalent path on
  Windows/Linux.\\n\\n   Add this configuration (update the paths and API
  key):\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"everart-forge\\\": {\\n         \\\"command\\\":
  \\\"node\\\",\\n         \\\"args\\\":
  [\\\"/absolute/path/to/everart-forge-mcp/build/index.js\\\"],\\n         \\\"\
  env\\\": {\\n           \\\"EVERART_API_KEY\\\":
  \\\"your_everart_api_key_here\\\"\\n         },\\n         \\\"disabled\\\":
  false,\\n         \\\"autoApprove\\\":
  []\\n       }\\n     }\\n   }\\n   ```\\n\\n5. **Getting an EverArt API
  key**:\\n   - Sign up at [EverArt](https://everart.ai/)\\n   - Navigate to
  account settings\\n   - Create or copy your API key\\n\\n6.
  **Verification**:\\n   After adding the configuration, restart Cline and
  verify the server is connected by checking the MCP servers section. You can
  then test the server by asking Cline to generate an image.\\n\\n##
  Troubleshooting\\n\\n- If the server doesn't appear in the MCP list, check if
  the path to the index.js file is correct and absolute\\n- If the server
  appears but shows errors, verify your API key is correct\\n- If you see
  \\\"Error: Invalid model ID\\\", ensure you're using a supported model ID
  (5000, 6000, 7000, 8000, 9000)\\n- SVG format is only available with the
  Recraft-Vector (8000) model\\n\\n## Configuration Options\\n\\nAll server
  configuration is done through environment variables in the MCP settings
  file:\\n\\n| Variable | Description | Required
  |\\n|----------|-------------|----------|\\n| EVERART_API_KEY | Your EverArt
  API key | Yes |\\n\\n## Usage Examples\\n\\nOnce configured, the LLM can
  generate images with:\\n\\n```\\nI'll help you generate an image using EverArt
  Forge
  MCP.\\n\\n<use_mcp_tool>\\n<server_name>github.com/nickbaumann98/everart-forg\
  e-mcp</server_name>\\n<tool_name>generate_image</tool_name>\\n<arguments>\\n{\
  \\n  \\\"prompt\\\": \\\"A minimalist tech logo with clean
  lines\\\",\\n  \\\"model\\\": \\\"8000:Recraft-Vector\\\",\\n  \\\"format\\\":
  \\\"svg\\\"\\n}\\n</arguments>\\n</use_mcp_tool>\\n```\\n\\nFor listing
  existing
  images:\\n\\n```\\n<use_mcp_tool>\\n<server_name>github.com/nickbaumann98/eve\
  rart-forge-mcp</server_name>\\n<tool_name>list_images</tool_name>\\n<argument\
  s>\\n{}\\n</arguments>\\n</use_mcp_tool>\\n\",\"isRecommended\":false,\"githu\
  bStars\":9,\"downloadCount\":341,\"createdAt\":\"2025-02-18T23:04:08.935882Z\
  \",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07\
  -03T06:55:51.945408Z\"},{\"mcpId\":\"github.com/alexander-zuev/supabase-mcp-s\
  erver\",\"githubUrl\":\"https://github.com/alexander-zuev/supabase-mcp-server\
  \",\"name\":\"Supabase\",\"author\":\"alexander-zuev\",\"description\":\"Enab\
  les direct interaction with Supabase PostgreSQL databases, providing database
  management tools including schema exploration, SQL query validation, and
  secure read-only
  access.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/supabase.png\",\"category\":\"databases\",\"tags\"\
  :[\"postgresql\",\"supabase\",\"database-management\",\"sql\",\"schema-explor\
  ation\"],\"requiresApiKey\":false,\"readmeContent\":\"# Query | MCP server for
  Supabase\\n\\n>  More than 17k installs via pypi and close to 30k downloads
  on Smithery.ai  in short, this was fun! \\n> Thanks to everyone who has
  been using this server for the past few months, and I hope it was useful for
  you.\\n> Since Supabase has released their own [official MCP
  server](https://github.com/supabase-community/supabase-mcp),\\n> I've decided
  to no longer actively maintain this one. The official MCP server is as
  feature-rich, and many more\\n> features will be added in the future. Check it
  out!\\n\\n\\n<p class=\\\"center-text\\\">\\n  <strong>Query MCP is an
  open-source MCP server that lets your IDE safely run SQL, manage schema
  changes, call the Supabase Management API, and use Auth Admin SDK  all with
  built-in safety controls.</strong>\\n</p>\\n\\n\\n<p
  class=\\\"center-text\\\">\\n  <a
  href=\\\"https://pypi.org/project/supabase-mcp-server/\\\"><img
  src=\\\"https://img.shields.io/pypi/v/supabase-mcp-server.svg\\\" alt=\\\"PyPI
  version\\\" /></a>\\n  <a
  href=\\\"https://github.com/alexander-zuev/supabase-mcp-server/actions\\\"><i\
  mg
  src=\\\"https://github.com/alexander-zuev/supabase-mcp-server/workflows/CI/ba\
  dge.svg\\\" alt=\\\"CI Status\\\" /></a>\\n  <a
  href=\\\"https://codecov.io/gh/alexander-zuev/supabase-mcp-server\\\"><img
  src=\\\"https://codecov.io/gh/alexander-zuev/supabase-mcp-server/branch/main/\
  graph/badge.svg\\\" alt=\\\"Code Coverage\\\" /></a>\\n  <a
  href=\\\"https://www.python.org/downloads/\\\"><img
  src=\\\"https://img.shields.io/badge/python-3.12%2B-blue.svg\\\"
  alt=\\\"Python 3.12+\\\" /></a>\\n  <a
  href=\\\"https://github.com/astral-sh/uv\\\"><img
  src=\\\"https://img.shields.io/badge/uv-package%20manager-blueviolet\\\"
  alt=\\\"uv package manager\\\" /></a>\\n  <a
  href=\\\"https://pepy.tech/project/supabase-mcp-server\\\"><img
  src=\\\"https://static.pepy.tech/badge/supabase-mcp-server\\\" alt=\\\"PyPI
  Downloads\\\" /></a>\\n  <a
  href=\\\"https://smithery.ai/server/@alexander-zuev/supabase-mcp-server\\\"><\
  img src=\\\"https://smithery.ai/badge/@alexander-zuev/supabase-mcp-server\\\"
  alt=\\\"Smithery.ai Downloads\\\" /></a>\\n  <a
  href=\\\"https://modelcontextprotocol.io/introduction\\\"><img
  src=\\\"https://img.shields.io/badge/MCP-Server-orange\\\" alt=\\\"MCP
  Server\\\" /></a>\\n  <a href=\\\"LICENSE\\\"><img
  src=\\\"https://img.shields.io/badge/license-Apache%202.0-blue.svg\\\"
  alt=\\\"License\\\" /></a>\\n</p>    \\n\\n## Table of contents\\n\\n<p
  class=\\\"center-text\\\">\\n  <a href=\\\"#getting-started\\\">Getting
  started</a> \\n  <a href=\\\"#feature-overview\\\">Feature overview</a>
  \\n  <a href=\\\"#troubleshooting\\\">Troubleshooting</a> \\n  <a
  href=\\\"#changelog\\\">Changelog</a>\\n</p>\\n\\n##  Key features\\n- 
  Compatible with Cursor, Windsurf, Cline and other MCP clients supporting
  `stdio` protocol\\n-  Control read-only and read-write modes of SQL query
  execution\\n-  Runtime SQL query validation with risk level assessment\\n-
   Three-tier safety system for SQL operations: safe, write, and
  destructive\\n-  Robust transaction handling for both direct and pooled
  database connections\\n-  Automatic versioning of database schema
  changes\\n-  Manage your Supabase projects with Supabase Management API\\n-
   Manage users with Supabase Auth Admin methods via Python SDK\\n- 
  Pre-built tools to help Cursor & Windsurf work with MCP more effectively\\n-
   Dead-simple install & setup via package manager (uv, pipx, etc.)\\n\\n\\n##
  Getting Started\\n\\n### Prerequisites\\nInstalling the server requires the
  following on your system:\\n- Python 3.12+\\n\\nIf you plan to install via
  `uv`, ensure it's
  [installed](https://docs.astral.sh/uv/getting-started/installation/#__tabbed_\
  1_1).\\n\\n### PostgreSQL Installation\\nPostgreSQL installation is no longer
  required for the MCP server itself, as it now uses asyncpg which doesn't
  depend on PostgreSQL development libraries.\\n\\nHowever, you'll still need
  PostgreSQL if you're running a local Supabase
  instance:\\n\\n**MacOS**\\n```bash\\nbrew install
  postgresql@16\\n```\\n\\n**Windows**\\n  - Download and install PostgreSQL 16+
  from https://www.postgresql.org/download/windows/\\n  - Ensure \\\"PostgreSQL
  Server\\\" and \\\"Command Line Tools\\\" are selected during
  installation\\n\\n### Step 1. Installation\\n\\nSince v0.2.0 I introduced
  support for package installation. You can use your favorite Python package
  manager to install the server via:\\n\\n```bash\\n# if pipx is installed
  (recommended)\\npipx install supabase-mcp-server\\n\\n# if uv is
  installed\\nuv pip install supabase-mcp-server\\n```\\n\\n`pipx` is
  recommended because it creates isolated environments for each
  package.\\n\\nYou can also install the server manually by cloning the
  repository and running `pipx install -e .` from the root directory.\\n\\n####
  Installing from source\\nIf you would like to install from source, for example
  for local development:\\n```bash\\nuv venv\\n# On Mac\\nsource
  .venv/bin/activate\\n# On Windows\\n.venv\\\\Scripts\\\\activate\\n# Install
  package in editable mode\\nuv pip install -e .\\n```\\n\\n#### Installing via
  Smithery.ai\\n\\nYou can find the full instructions on how to use Smithery.ai
  to connect to this MCP server
  [here](https://smithery.ai/server/@alexander-zuev/supabase-mcp-server).\\n\\n\
  \\n### Step 2. Configuration\\n\\nThe Supabase MCP server requires
  configuration to connect to your Supabase database, access the Management API,
  and use the Auth Admin SDK. This section explains all available configuration
  options and how to set them up.\\n\\n>  **Important**: Since v0.4 MCP server
  requires an API key which you can get for free at
  [thequery.dev](https://thequery.dev) to use this MCP server.\\n\\n####
  Environment Variables\\n\\nThe server uses the following environment
  variables:\\n\\n| Variable | Required | Default | Description
  |\\n|----------|----------|---------|-------------|\\n| `SUPABASE_PROJECT_REF`
  | Yes | `127.0.0.1:54322` | Your Supabase project reference ID (or local
  host:port) |\\n| `SUPABASE_DB_PASSWORD` | Yes | `postgres` | Your database
  password |\\n| `SUPABASE_REGION` | Yes* | `us-east-1` | AWS region where your
  Supabase project is hosted |\\n| `SUPABASE_ACCESS_TOKEN` | No | None |
  Personal access token for Supabase Management API |\\n|
  `SUPABASE_SERVICE_ROLE_KEY` | No | None | Service role key for Auth Admin SDK
  |\\n| `QUERY_API_KEY` | Yes | None | API key from thequery.dev (required for
  all operations) |\\n\\n> **Note**: The default values are configured for local
  Supabase development. For remote Supabase projects, you must provide your own
  values for `SUPABASE_PROJECT_REF` and `SUPABASE_DB_PASSWORD`.\\n\\n> 
  **CRITICAL CONFIGURATION NOTE**: For remote Supabase projects, you MUST
  specify the correct region where your project is hosted using
  `SUPABASE_REGION`. If you encounter a \\\"Tenant or user not found\\\" error,
  this is almost certainly because your region setting doesn't match your
  project's actual region. You can find your project's region in the Supabase
  dashboard under Project Settings.\\n\\n#### Connection Types\\n\\n#####
  Database Connection\\n- The server connects to your Supabase PostgreSQL
  database using the transaction pooler endpoint\\n- Local development uses a
  direct connection to `127.0.0.1:54322`\\n- Remote projects use the format:
  `postgresql://postgres.[project_ref]:[password]@aws-0-[region].pooler.supabas\
  e.com:6543/postgres`\\n\\n>  **Important**: Session pooling connections are
  not supported. The server exclusively uses transaction pooling for better
  compatibility with the MCP server architecture.\\n\\n##### Management API
  Connection\\n- Requires `SUPABASE_ACCESS_TOKEN` to be set\\n- Connects to the
  Supabase Management API at `https://api.supabase.com`\\n- Only works with
  remote Supabase projects (not local development)\\n\\n##### Auth Admin SDK
  Connection\\n- Requires `SUPABASE_SERVICE_ROLE_KEY` to be set\\n- For local
  development, connects to `http://127.0.0.1:54321`\\n- For remote projects,
  connects to `https://[project_ref].supabase.co`\\n\\n#### Configuration
  Methods\\n\\nThe server looks for configuration in this order (highest to
  lowest priority):\\n\\n1. **Environment Variables**: Values set directly in
  your environment\\n2. **Local `.env` File**: A `.env` file in your current
  working directory (only works when running from source)\\n3. **Global Config
  File**:\\n   - Windows: `%APPDATA%\\\\supabase-mcp\\\\.env`\\n   -
  macOS/Linux: `~/.config/supabase-mcp/.env`\\n4. **Default Settings**: Local
  development defaults (if no other config is found)\\n\\n>  **Important**:
  When using the package installed via pipx or uv, local `.env` files in your
  project directory are **not** detected. You must use either environment
  variables or the global config file.\\n\\n#### Setting Up
  Configuration\\n\\n##### Option 1: Client-Specific Configuration
  (Recommended)\\n\\nSet environment variables directly in your MCP client
  configuration (see client-specific setup instructions in Step 3). Most MCP
  clients support this approach, which keeps your configuration with your client
  settings.\\n\\n##### Option 2: Global Configuration\\n\\nCreate a global
  `.env` configuration file that will be used for all MCP server
  instances:\\n\\n```bash\\n# Create config directory\\n# On macOS/Linux\\nmkdir
  -p ~/.config/supabase-mcp\\n# On Windows (PowerShell)\\nmkdir -Force
  \\\"$env:APPDATA\\\\supabase-mcp\\\"\\n\\n# Create and edit .env file\\n# On
  macOS/Linux\\nnano ~/.config/supabase-mcp/.env\\n# On Windows
  (PowerShell)\\nnotepad
  \\\"$env:APPDATA\\\\supabase-mcp\\\\.env\\\"\\n```\\n\\nAdd your configuration
  values to the
  file:\\n\\n```\\nQUERY_API_KEY=your-api-key\\nSUPABASE_PROJECT_REF=your-proje\
  ct-ref\\nSUPABASE_DB_PASSWORD=your-db-password\\nSUPABASE_REGION=us-east-1\\n\
  SUPABASE_ACCESS_TOKEN=your-access-token\\nSUPABASE_SERVICE_ROLE_KEY=your-serv\
  ice-role-key\\n```\\n\\n##### Option 3: Project-Specific Configuration (Source
  Installation Only)\\n\\nIf you're running the server from source (not via
  package), you can create a `.env` file in your project directory with the same
  format as above.\\n\\n#### Finding Your Supabase Project Information\\n\\n-
  **Project Reference**: Found in your Supabase project URL:
  `https://supabase.com/dashboard/project/<project-ref>`\\n- **Database
  Password**: Set during project creation or found in Project Settings 
  Database\\n- **Access Token**: Generate at
  https://supabase.com/dashboard/account/tokens\\n- **Service Role Key**: Found
  in Project Settings  API  Project API keys\\n\\n#### Supported
  Regions\\n\\nThe server supports all Supabase regions:\\n\\n- `us-west-1` -
  West US (North California)\\n- `us-east-1` - East US (North Virginia) -
  default\\n- `us-east-2` - East US (Ohio)\\n- `ca-central-1` - Canada
  (Central)\\n- `eu-west-1` - West EU (Ireland)\\n- `eu-west-2` - West Europe
  (London)\\n- `eu-west-3` - West EU (Paris)\\n- `eu-central-1` - Central EU
  (Frankfurt)\\n- `eu-central-2` - Central Europe (Zurich)\\n- `eu-north-1` -
  North EU (Stockholm)\\n- `ap-south-1` - South Asia (Mumbai)\\n-
  `ap-southeast-1` - Southeast Asia (Singapore)\\n- `ap-northeast-1` - Northeast
  Asia (Tokyo)\\n- `ap-northeast-2` - Northeast Asia (Seoul)\\n-
  `ap-southeast-2` - Oceania (Sydney)\\n- `sa-east-1` - South America (So
  Paulo)\\n\\n#### Limitations\\n\\n- **No Self-Hosted Support**: The server
  only supports official Supabase.com hosted projects and local development\\n-
  **No Connection String Support**: Custom connection strings are not
  supported\\n- **No Session Pooling**: Only transaction pooling is supported
  for database connections\\n- **API and SDK Features**: Management API and Auth
  Admin SDK features only work with remote Supabase projects, not local
  development\\n\\n### Step 3. Usage\\n\\nIn general, any MCP client that
  supports `stdio` protocol should work with this MCP server. This server was
  explicitly tested to work with:\\n- Cursor\\n- Windsurf\\n- Cline\\n- Claude
  Desktop\\n\\nAdditionally, you can also use smithery.ai to install this server
  a number of clients, including the ones above.\\n\\nFollow the guides below to
  install this MCP server in your client.\\n\\n#### Cursor\\nGo to Settings ->
  Features -> MCP Servers and add a new server with this
  configuration:\\n```bash\\n# can be set to any name\\nname: supabase\\ntype:
  command\\n# if you installed with pipx\\ncommand: supabase-mcp-server\\n# if
  you installed with uv\\ncommand: uv run supabase-mcp-server\\n# if the above
  doesn't work, use the full path (recommended)\\ncommand:
  /full/path/to/supabase-mcp-server  # Find with 'which supabase-mcp-server'
  (macOS/Linux) or 'where supabase-mcp-server' (Windows)\\n```\\n\\nIf
  configuration is correct, you should see a green dot indicator and the number
  of tools exposed by the server.\\n![How successful Cursor config looks
  like](https://github.com/user-attachments/assets/45df080a-8199-4aca-b59c-a84d\
  c7fe2c09)\\n\\n#### Windsurf\\nGo to Cascade -> Click on the hammer icon ->
  Configure -> Fill in the
  configuration:\\n```json\\n{\\n    \\\"mcpServers\\\":
  {\\n      \\\"supabase\\\": {\\n        \\\"command\\\":
  \\\"/Users/username/.local/bin/supabase-mcp-server\\\",  // update
  path\\n        \\\"env\\\": {\\n          \\\"QUERY_API_KEY\\\":
  \\\"your-api-key\\\",  // Required - get your API key at
  thequery.dev\\n          \\\"SUPABASE_PROJECT_REF\\\":
  \\\"your-project-ref\\\",\\n          \\\"SUPABASE_DB_PASSWORD\\\":
  \\\"your-db-password\\\",\\n          \\\"SUPABASE_REGION\\\":
  \\\"us-east-1\\\",  // optional, defaults to
  us-east-1\\n          \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"your-access-token\\\",  // optional, for management
  API\\n          \\\"SUPABASE_SERVICE_ROLE_KEY\\\":
  \\\"your-service-role-key\\\"  // optional, for Auth Admin
  SDK\\n        }\\n      }\\n    }\\n}\\n```\\nIf configuration is correct, you
  should see green dot indicator and clickable supabase server in the list of
  available servers.\\n\\n![How successful Windsurf config looks
  like](https://github.com/user-attachments/assets/322b7423-8c71-410b-bcab-aff1\
  b143faa4)\\n\\n#### Claude Desktop\\nClaude Desktop also supports MCP servers
  through a JSON configuration. Follow these steps to set up the Supabase MCP
  server:\\n\\n1. **Find the full path to the executable** (this step is
  critical):\\n   ```bash\\n   # On macOS/Linux\\n   which
  supabase-mcp-server\\n\\n   # On Windows\\n   where
  supabase-mcp-server\\n   ```\\n   Copy the full path that is returned (e.g.,
  `/Users/username/.local/bin/supabase-mcp-server`).\\n\\n2. **Configure the MCP
  server** in Claude Desktop:\\n   - Open Claude Desktop\\n   - Go to Settings 
  Developer -> Edit Config MCP Servers\\n   - Add a new configuration with the
  following JSON:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"supabase\\\": {\\n         \\\"command\\\":
  \\\"/full/path/to/supabase-mcp-server\\\",  // Replace with the actual path
  from step 1\\n         \\\"env\\\": {\\n           \\\"QUERY_API_KEY\\\":
  \\\"your-api-key\\\",  // Required - get your API key at
  thequery.dev\\n           \\\"SUPABASE_PROJECT_REF\\\":
  \\\"your-project-ref\\\",\\n           \\\"SUPABASE_DB_PASSWORD\\\":
  \\\"your-db-password\\\",\\n           \\\"SUPABASE_REGION\\\":
  \\\"us-east-1\\\",  // optional, defaults to
  us-east-1\\n           \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"your-access-token\\\",  // optional, for management
  API\\n           \\\"SUPABASE_SERVICE_ROLE_KEY\\\":
  \\\"your-service-role-key\\\"  // optional, for Auth Admin
  SDK\\n         }\\n       }\\n     }\\n   }\\n   ```\\n\\n>  **Important**:
  Unlike Windsurf and Cursor, Claude Desktop requires the **full absolute path**
  to the executable. Using just the command name (`supabase-mcp-server`) will
  result in a \\\"spawn ENOENT\\\" error.\\n\\nIf configuration is correct, you
  should see the Supabase MCP server listed as available in Claude
  Desktop.\\n\\n![How successful Windsurf config looks
  like](https://github.com/user-attachments/assets/500bcd40-6245-40a7-b23b-1898\
  27ed2923)\\n\\n#### Cline\\nCline also supports MCP servers through a similar
  JSON configuration. Follow these steps to set up the Supabase MCP
  server:\\n\\n1. **Find the full path to the executable** (this step is
  critical):\\n   ```bash\\n   # On macOS/Linux\\n   which
  supabase-mcp-server\\n\\n   # On Windows\\n   where
  supabase-mcp-server\\n   ```\\n   Copy the full path that is returned (e.g.,
  `/Users/username/.local/bin/supabase-mcp-server`).\\n\\n2. **Configure the MCP
  server** in Cline:\\n   - Open Cline in VS Code\\n   - Click on the \\\"MCP
  Servers\\\" tab in the Cline sidebar\\n   - Click \\\"Configure MCP
  Servers\\\"\\n   - This will open the `cline_mcp_settings.json` file\\n   -
  Add the following
  configuration:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"supabase\\\": {\\n         \\\"command\\\":
  \\\"/full/path/to/supabase-mcp-server\\\",  // Replace with the actual path
  from step 1\\n         \\\"env\\\": {\\n           \\\"QUERY_API_KEY\\\":
  \\\"your-api-key\\\",  // Required - get your API key at
  thequery.dev\\n           \\\"SUPABASE_PROJECT_REF\\\":
  \\\"your-project-ref\\\",\\n           \\\"SUPABASE_DB_PASSWORD\\\":
  \\\"your-db-password\\\",\\n           \\\"SUPABASE_REGION\\\":
  \\\"us-east-1\\\",  // optional, defaults to
  us-east-1\\n           \\\"SUPABASE_ACCESS_TOKEN\\\":
  \\\"your-access-token\\\",  // optional, for management
  API\\n           \\\"SUPABASE_SERVICE_ROLE_KEY\\\":
  \\\"your-service-role-key\\\"  // optional, for Auth Admin
  SDK\\n         }\\n       }\\n     }\\n   }\\n   ```\\n\\nIf configuration is
  correct, you should see a green indicator next to the Supabase MCP server in
  the Cline MCP Servers list, and a message confirming \\\"supabase MCP server
  connected\\\" at the bottom of the panel.\\n\\n![How successful configuration
  in Cline looks
  like](https://github.com/user-attachments/assets/6c4446ad-7a58-44c6-bf12-6c82\
  222bbe59)\\n\\n### Troubleshooting\\n\\nHere are some tips & tricks that might
  help you:\\n- **Debug installation** - run `supabase-mcp-server` directly from
  the terminal to see if it works. If it doesn't, there might be an issue with
  the installation.\\n- **MCP Server configuration** - if the above step works,
  it means the server is installed and configured correctly. As long as you
  provided the right command, IDE should be able to connect. Make sure to
  provide the right path to the server executable.\\n- **\\\"No tools found\\\"
  error** - If you see \\\"Client closed - no tools available\\\" in Cursor
  despite the package being installed:\\n  - Find the full path to the
  executable by running `which supabase-mcp-server` (macOS/Linux) or `where
  supabase-mcp-server` (Windows)\\n  - Use the full path in your MCP server
  configuration instead of just `supabase-mcp-server`\\n  - For example:
  `/Users/username/.local/bin/supabase-mcp-server` or
  `C:\\\\Users\\\\username\\\\.local\\\\bin\\\\supabase-mcp-server.exe`\\n-
  **Environment variables** - to connect to the right database, make sure you
  either set env variables in `mcp_config.json` or in `.env` file placed in a
  global config directory (`~/.config/supabase-mcp/.env` on macOS/Linux or
  `%APPDATA%\\\\supabase-mcp\\\\.env` on Windows).\\n- **Accessing logs** - The
  MCP server writes detailed logs to a file:\\n  - Log file location:\\n    -
  macOS/Linux: `~/.local/share/supabase-mcp/mcp_server.log`\\n    - Windows:
  `%USERPROFILE%\\\\.local\\\\share\\\\supabase-mcp\\\\mcp_server.log`\\n  -
  Logs include connection status, configuration details, and operation
  results\\n  - View logs using any text editor or terminal
  commands:\\n    ```bash\\n    # On macOS/Linux\\n    cat
  ~/.local/share/supabase-mcp/mcp_server.log\\n\\n    # On Windows
  (PowerShell)\\n    Get-Content
  \\\"$env:USERPROFILE\\\\.local\\\\share\\\\supabase-mcp\\\\mcp_server.log\\\"\
  \\n    ```\\n\\nIf you are stuck or any of the instructions above are
  incorrect, please raise an issue.\\n\\n### MCP Inspector\\nA super useful tool
  to help debug MCP server issues is MCP Inspector. If you installed from
  source, you can run `supabase-mcp-inspector` from the project repo and it will
  run the inspector instance. Coupled with logs this will give you complete
  overview over what's happening in the server.\\n>  Running
  `supabase-mcp-inspector`, if installed from package, doesn't work properly - I
  will validate and fix in the coming release.\\n\\n## Feature Overview\\n\\n###
  Database query tools\\n\\nSince v0.3+ server provides comprehensive database
  management capabilities with built-in safety controls:\\n\\n- **SQL Query
  Execution**: Execute PostgreSQL queries with risk assessment\\n  -
  **Three-tier safety system**:\\n    - `safe`: Read-only operations (SELECT) -
  always allowed\\n    - `write`: Data modifications (INSERT, UPDATE, DELETE) -
  require unsafe mode\\n    - `destructive`: Schema changes (DROP, CREATE) -
  require unsafe mode + confirmation\\n\\n- **SQL Parsing and
  Validation**:\\n  - Uses PostgreSQL's parser (pglast) for accurate analysis
  and provides clear feedback on safety requirements\\n\\n- **Automatic
  Migration Versioning**:\\n  - Database-altering operations operations are
  automatically versioned\\n  - Generates descriptive names based on operation
  type and target\\n\\n\\n- **Safety Controls**:\\n  - Default SAFE mode allows
  only read-only operations\\n  - All statements run in transaction mode via
  `asyncpg`\\n  - 2-step confirmation for high-risk operations\\n\\n-
  **Available Tools**:\\n  - `get_schemas`: Lists schemas with sizes and table
  counts\\n  - `get_tables`: Lists tables, foreign tables, and views with
  metadata\\n  - `get_table_schema`: Gets detailed table structure (columns,
  keys, relationships)\\n  - `execute_postgresql`: Executes SQL statements
  against your database\\n  - `confirm_destructive_operation`: Executes
  high-risk operations after confirmation\\n  - `retrieve_migrations`: Gets
  migrations with filtering and pagination options\\n  - `live_dangerously`:
  Toggles between safe and unsafe modes\\n\\n### Management API tools\\n\\nSince
  v0.3.0 server provides secure access to the Supabase Management API with
  built-in safety controls:\\n\\n- **Available Tools**:\\n  -
  `send_management_api_request`: Sends arbitrary requests to Supabase Management
  API with auto-injection of project ref\\n  - `get_management_api_spec`: Gets
  the enriched API specification with safety information\\n    - Supports
  multiple query modes: by domain, by specific path/method, or all paths\\n    -
  Includes risk assessment information for each endpoint\\n    - Provides
  detailed parameter requirements and response formats\\n    - Helps LLMs
  understand the full capabilities of the Supabase Management API\\n  -
  `get_management_api_safety_rules`: Gets all safety rules with human-readable
  explanations\\n  - `live_dangerously`: Toggles between safe and unsafe
  operation modes\\n\\n- **Safety Controls**:\\n  - Uses the same safety manager
  as database operations for consistent risk management\\n  - Operations
  categorized by risk level:\\n    - `safe`: Read-only operations (GET) - always
  allowed\\n    - `unsafe`: State-changing operations (POST, PUT, PATCH, DELETE)
  - require unsafe mode\\n    - `blocked`: Destructive operations (delete
  project, etc.) - never allowed\\n  - Default safe mode prevents accidental
  state changes\\n  - Path-based pattern matching for precise safety
  rules\\n\\n**Note**: Management API tools only work with remote Supabase
  instances and are not compatible with local Supabase development
  setups.\\n\\n### Auth Admin tools\\n\\nI was planning to add support for
  Python SDK methods to the MCP server. Upon consideration I decided to only add
  support for Auth admin methods as I often found myself manually creating test
  users which was prone to errors and time consuming. Now I can just ask Cursor
  to create a test user and it will be done seamlessly. Check out the full Auth
  Admin SDK method docs to know what it can do.\\n\\nSince v0.3.6 server
  supports direct access to Supabase Auth Admin methods via Python SDK:\\n  -
  Includes the following tools:\\n    - `get_auth_admin_methods_spec` to
  retrieve documentation for all available Auth Admin methods\\n    -
  `call_auth_admin_method` to directly invoke Auth Admin methods with proper
  parameter handling\\n  - Supported methods:\\n    - `get_user_by_id`: Retrieve
  a user by their ID\\n    - `list_users`: List all users with
  pagination\\n    - `create_user`: Create a new user\\n    - `delete_user`:
  Delete a user by their ID\\n    - `invite_user_by_email`: Send an invite link
  to a user's email\\n    - `generate_link`: Generate an email link for various
  authentication purposes\\n    - `update_user_by_id`: Update user attributes by
  ID\\n    - `delete_factor`: Delete a factor on a user (currently not
  implemented in SDK)\\n\\n#### Why use Auth Admin SDK instead of raw SQL
  queries?\\n\\nThe Auth Admin SDK provides several key advantages over direct
  SQL manipulation:\\n- **Functionality**: Enables operations not possible with
  SQL alone (invites, magic links, MFA)\\n- **Accuracy**: More reliable then
  creating and executing raw SQL queries on auth schemas\\n- **Simplicity**:
  Offers clear methods with proper validation and error handling\\n\\n  -
  Response format:\\n    - All methods return structured Python objects instead
  of raw dictionaries\\n    - Object attributes can be accessed using dot
  notation (e.g., `user.id` instead of `user[\\\"id\\\"]`)\\n  - Edge cases and
  limitations:\\n    - UUID validation: Many methods require valid UUID format
  for user IDs and will return specific validation errors\\n    - Email
  configuration: Methods like `invite_user_by_email` and `generate_link` require
  email sending to be configured in your Supabase project\\n    - Link types:
  When generating links, different link types have different
  requirements:\\n      - `signup` links don't require the user to
  exist\\n      - `magiclink` and `recovery` links require the user to already
  exist in the system\\n    - Error handling: The server provides detailed error
  messages from the Supabase API, which may differ from the dashboard
  interface\\n    - Method availability: Some methods like `delete_factor` are
  exposed in the API but not fully implemented in the SDK\\n\\n### Logs &
  Analytics\\n\\nThe server provides access to Supabase logs and analytics data,
  making it easier to monitor and troubleshoot your applications:\\n\\n-
  **Available Tool**: `retrieve_logs` - Access logs from any Supabase
  service\\n\\n- **Log Collections**:\\n  - `postgres`: Database server
  logs\\n  - `api_gateway`: API gateway requests\\n  - `auth`: Authentication
  events\\n  - `postgrest`: RESTful API service logs\\n  - `pooler`: Connection
  pooling logs\\n  - `storage`: Object storage operations\\n  - `realtime`:
  WebSocket subscription logs\\n  - `edge_functions`: Serverless function
  executions\\n  - `cron`: Scheduled job logs\\n  - `pgbouncer`: Connection
  pooler logs\\n\\n- **Features**: Filter by time, search text, apply field
  filters, or use custom SQL queries\\n\\nSimplifies debugging across your
  Supabase stack without switching between interfaces or writing complex
  queries.\\n\\n### Automatic Versioning of Database Changes\\n\\n\\\"With great
  power comes great responsibility.\\\" While `execute_postgresql` tool coupled
  with aptly named `live_dangerously` tool provide a powerful and simple way to
  manage your Supabase database, it also means that dropping a table or
  modifying one is one chat message away. In order to reduce the risk of
  irreversible changes, since v0.3.8 the server supports:\\n- automatic creation
  of migration scripts for all write & destructive sql operations executed on
  the database\\n- improved safety mode of query execution, in which all queries
  are categorized in:\\n  - `safe` type: always allowed. Includes all read-only
  ops.\\n  - `write`type: requires `write` mode to be enabled by the user.\\n  -
  `destructive` type: requires `write` mode to be enabled by the user AND a
  2-step confirmation of query execution for clients that do not execute tools
  automatically.\\n\\n### Universal Safety Mode\\nSince v0.3.8 Safety Mode has
  been standardized across all services (database, API, SDK) using a universal
  safety manager. This provides consistent risk management and a unified
  interface for controlling safety settings across the entire MCP
  server.\\n\\nAll operations (SQL queries, API requests, SDK methods) are
  categorized into risk levels:\\n- `Low` risk: Read-only operations that don't
  modify data or structure (SELECT queries, GET API requests)\\n- `Medium` risk:
  Write operations that modify data but not structure (INSERT/UPDATE/DELETE,
  most POST/PUT API requests)\\n- `High` risk: Destructive operations that
  modify database structure or could cause data loss (DROP/TRUNCATE, DELETE API
  endpoints)\\n- `Extreme` risk: Operations with severe consequences that are
  blocked entirely (deleting projects)\\n\\nSafety controls are applied based on
  risk level:\\n- Low risk operations are always allowed\\n- Medium risk
  operations require unsafe mode to be enabled\\n- High risk operations require
  unsafe mode AND explicit confirmation\\n- Extreme risk operations are never
  allowed\\n\\n#### How confirmation flow works\\n\\nAny high-risk operations
  (be it a postgresql or api request) will be blocked even in `unsafe`
  mode.\\n![Every high-risk operation is
  blocked](https://github.com/user-attachments/assets/c0df79c2-a879-4b1f-a39d-2\
  50f9965c36a)\\nYou will have to confirm and approve every high-risk operation
  explicitly in order for it to be executed.\\n![Explicit approval is always
  required](https://github.com/user-attachments/assets/5cd7a308-ec2a-414e-abe2-\
  ff2f3836dd8b)\\n\\n\\n## Changelog\\n\\n-  Simplified installation via
  package manager -  (v0.2.0)\\n-  Support for different Supabase regions - 
  (v0.2.2)\\n-  Programmatic access to Supabase management API with safety
  controls -  (v0.3.0)\\n-  Read and read-write database SQL queries with
  safety controls -  (v0.3.0)\\n-  Robust transaction handling for both
  direct and pooled connections -  (v0.3.2)\\n-  Support methods and objects
  available in native Python SDK -  (v0.3.6)\\n-  Stronger SQL query
  validation  (v0.3.8)\\n-  Automatic versioning of database changes 
  (v0.3.8)\\n-  Radically improved knowledge and tools of api spec 
  (v0.3.8)\\n-  Improved consistency of migration-related tools for a more
  organized database vcs  (v0.3.10)\\n-  Query MCP is released
  (v0.4.0)\\n\\n\\nFor a more detailed roadmap, please see this
  [discussion](https://github.com/alexander-zuev/supabase-mcp-server/discussion\
  s/46) on GitHub.\\n\\n\\n## Star History\\n\\n[![Star History
  Chart](https://api.star-history.com/svg?repos=alexander-zuev/supabase-mcp-ser\
  ver&type=Date)](https://star-history.com/#alexander-zuev/supabase-mcp-server&\
  Date)\\n\\n---\\n\\nEnjoy!
  \\n\",\"isRecommended\":false,\"githubStars\":746,\"downloadCount\":11252,\
  \"createdAt\":\"2025-02-19T00:44:50.26296Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-07-02T08:45:04.36132Z\"},{\"mcpId\":\
  \"github.com/metoro-io/metoro-mcp-server\",\"githubUrl\":\"https://github.com\
  /metoro-io/metoro-mcp-server\",\"name\":\"Kubernetes
  Observer\",\"author\":\"metoro-io\",\"description\":\"Enables interaction with
  Kubernetes clusters through Metoro's observability platform, providing
  eBPF-based telemetry and monitoring capabilities via natural language
  queries.\",\"codiconIcon\":\"server-environment\",\"logoUrl\":\"https://stora\
  ge.googleapis.com/cline_public_images/metoro.png\",\"category\":\"monitoring\
  \",\"tags\":[\"kubernetes\",\"observability\",\"ebpf\",\"telemetry\",\"micros\
  ervices\"],\"requiresApiKey\":false,\"readmeContent\":\"<div
  align=\\\"center\\\">\\n<img src=\\\"./images/Metoro_square.svg\\\"
  height=\\\"300\\\" alt=\\\"Metoro MCP Logo\\\">\\n</div>\\n<br/>\\n<div
  align=\\\"center\\\">\\n\\n![GitHub
  stars](https://img.shields.io/github/stars/metoro-io/metoro-mcp-server?style=\
  social)\\n![GitHub
  forks](https://img.shields.io/github/forks/metoro-io/metoro-mcp-server?style=\
  social)\\n![GitHub
  issues](https://img.shields.io/github/issues/metoro-io/metoro-mcp-server)\\n!\
  [GitHub pull
  requests](https://img.shields.io/github/issues-pr/metoro-io/metoro-mcp-server)\
  \\n![GitHub
  license](https://img.shields.io/github/license/metoro-io/metoro-mcp-server)\\\
  n![GitHub
  contributors](https://img.shields.io/github/contributors/metoro-io/metoro-mcp\
  -server)\\n![GitHub last
  commit](https://img.shields.io/github/last-commit/metoro-io/metoro-mcp-server)\
  \\n[![GoDoc](https://pkg.go.dev/badge/github.com/metoro-io/metoro-mcp-server.\
  svg)](https://pkg.go.dev/github.com/metoro-io/metoro-mcp-server)\\n[![Go
  Report
  Card](https://goreportcard.com/badge/github.com/metoro-io/metoro-mcp-server)]\
  (https://goreportcard.com/report/github.com/metoro-io/metoro-mcp-server)\\n![\
  Tests](https://github.com/metoro-io/metoro-mcp-server/actions/workflows/go-te\
  st.yml/badge.svg)\\n\\n</div>\\n\\n# metoro-mcp-server\\nThis repository
  contains th Metoro MCP (Model Context Protocol) Server. This MCP Server allows
  you to interact with your Kubernetes cluster via the Claude Desktop
  App!\\n\\n## What is MCP (Model Context Protocol)? \\nYou can read more about
  the Model Context Protocol here: https://modelcontextprotocol.io\\n\\nBut in a
  nutshell\\n> The Model Context Protocol (MCP) is an open protocol that enables
  seamless integration between LLM applications and external data sources and
  tools. Whether youre building an AI-powered IDE, enhancing a chat interface,
  or creating custom AI workflows, MCP provides a standardized way to connect
  LLMs with the context they need.\\n\\n## What is
  Metoro?\\n[Metoro](https://metoro.io/) is an observability platform designed
  for microservices running in Kubernetes and uses eBPF based instrumentation to
  generate deep telemetry without code changes.\\nThe data that is generated by
  the eBPF agents is sent to Metoro's backend to be stored and in the Metoro
  frontend using our apis.\\n\\nThis MCP server exposes those APIs to an LLM so
  you can ask your AI questions about your Kubernetes cluster.\\n\\n##
  Demo\\n\\nhttps://github.com/user-attachments/assets/b3f21e9a-45b8-4c17-8d8c-\
  cff560d8694f\\n\\n## How can I use Metoro MCP Server? \\n1. Install the
  [Claude Desktop App](https://claude.ai/download).\\n2. Make sure you have
  [Golang](https://golang.org/dl/) installed. `brew install go` for mac or `sudo
  apt-get install golang` for ubuntu.\\n3. Clone the repository: `git clone
  https://github.com/metoro-io/metoro-mcp-server.git`\\n4. Navigate to the
  repository directory: `cd metoro-mcp-server`\\n5. Build the server executable:
  `go build -o metoro-mcp-server`\\n\\n### If you already have a Metoro
  Account:\\nCopy your auth token from your Metoro account in
  [Settings](https://us-east.metoro.io/settings) -> Users Settings. \\nCreate a
  file in `~/Library/Application Support/Claude/claude_desktop_config.json` with
  the following contents:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"metoro-mcp-server\\\": {\\n      \\\"command\\\": \\\"<your path
  to Metoro MCP server go
  executable>/metoro-mcp-server\\\",\\n      \\\"args\\\":
  [],\\n      \\\"env\\\": {\\n          \\\"METORO_AUTH_TOKEN\\\" : \\\"<your
  auth token>\\\",\\n          \\\"METORO_API_URL\\\":
  \\\"https://us-east.metoro.io\\\"\\n       }\\n    }\\n  }\\n}\\n```\\n\\n###
  If you don't have a Metoro Account:\\nNo worries, you can still play around
  using the [Live Demo Cluster](https://demo.us-east.metoro.io/).\\nThe included
  token is a demo token, publicly available for anyone to use.\\n   Create a
  file in `~/Library/Application Support/Claude/claude_desktop_config.json` with
  the following contents:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"metoro-mcp-server\\\": {\\n      \\\"command\\\": \\\"<your path
  to Metoro MCP server go
  executable>/metoro-mcp-server\\\",\\n      \\\"args\\\":
  [],\\n      \\\"env\\\": {\\n          \\\"METORO_AUTH_TOKEN\\\" :
  \\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJjdXN0b21lcklkIjoiOThlZDU1M2QtYzY4\
  ZC00MDRhLWFhZjItNDM2ODllNWJiMGUzIiwiZW1haWwiOiJ0ZXN0QGNocmlzYmF0dGFyYmVlLmNvb\
  SIsImV4cCI6MTgyMTI0NzIzN30.7G6alDpcZh_OThYj293Jce5rjeOBqAhOlANR_Fl5auw\\\",\\\
  n          \\\"METORO_API_URL\\\":
  \\\"https://demo.us-east.metoro.io\\\"\\n       }\\n    }\\n  }\\n}\\n```\\n\
  \\n4. Once you are done editing `claude_desktop_config.json` save the file and
  restart Claude Desktop app.\\n5. You should now see the Metoro MCP Server in
  the dropdown list of MCP Servers in the Claude Desktop App. You are ready to
  start using Metoro MCP Server with Claude Desktop App!\\n\\n## Built
  with\\n\\nThis server is built on top of our [Golang MCP
  SDK](https://github.com/metoro-io/mcp-golang).\\n\",\"isRecommended\":true,\"\
  githubStars\":41,\"downloadCount\":105,\"createdAt\":\"2025-02-18T06:07:51.69\
  3578Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"20\
  25-06-26T22:25:30.354789Z\"},{\"mcpId\":\"github.com/pashpashpash/mcp-spotify\
  \",\"githubUrl\":\"https://github.com/pashpashpash/mcp-spotify\",\"name\":\"S\
  potify\",\"author\":\"pashpashpash\",\"description\":\"Enables interaction
  with Spotify's music catalog, including search, artist information, playlist
  management, and audiobook access through the Spotify Web
  API.\",\"codiconIcon\":\"music\",\"logoUrl\":\"https://storage.googleapis.com\
  /cline_public_images/spotify.png\",\"category\":\"entertainment-media\",\"tags\
  \":[\"music\",\"spotify-api\",\"playlist-management\",\"audiobooks\",\"stream\
  ing\"],\"requiresApiKey\":false,\"readmeContent\":\"# MCP Spotify
  Server\\n\\nA Model Context Protocol (MCP) server that provides access to the
  Spotify Web API. This server enables interaction with Spotify's music catalog,
  including searching for tracks, albums, and artists, as well as accessing
  artist-specific information like top tracks and related artists.\\n\\n##
  Prerequisites\\n\\n1. Node.js (version 16 or higher)\\n2. Spotify API
  Credentials:\\n   - Go to [Spotify Developer
  Dashboard](https://developer.spotify.com/dashboard)\\n   - Create a new
  application\\n   - Get your Client ID and Client Secret\\n\\n##
  Installation\\n\\n1. **Clone the Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/mcp-spotify.git\\n   cd
  mcp-spotify\\n   ```\\n\\n2. **Install Dependencies**:\\n   ```bash\\n   npm
  install\\n   ```\\n\\n3. **Build the Project**:\\n   ```bash\\n   npm run
  build\\n   ```\\n\\n## Configuration\\n\\nAdd to your Claude Desktop
  configuration file:\\n- macOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"spotify\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/mcp-spotify/dist/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"SPOTIFY_CLIENT_ID\\\":
  \\\"your_client_id\\\",\\n        \\\"SPOTIFY_CLIENT_SECRET\\\":
  \\\"your_client_secret\\\"\\n      }\\n    }\\n  }\\n}\\n```\\nNote: Replace
  \\\"path/to/mcp-spotify\\\" with the actual path to your cloned
  repository.\\n\\n## Features\\n\\n### Music Search and Discovery\\n- Search
  for tracks, albums, artists, and playlists\\n- Get artist information
  including top tracks and related artists\\n- Get album information and
  tracks\\n- Access new releases and recommendations\\n\\n### Audiobooks\\n- Get
  audiobook information with market-specific content and chapters\\n- Note:
  Audiobook endpoints may require additional authentication or market-specific
  access\\n\\n### Playlist Management\\n- Get and modify playlist information
  (name, description, public/private status)\\n- Access playlist tracks and
  items with pagination support\\n- Add and remove tracks from
  playlists\\n\\n### Additional Features\\n- Support for both Spotify IDs and
  URIs\\n- Automatic token management with client credentials flow\\n\\n##
  Available Tools\\n\\n### Authentication\\n- `get_access_token`: Get a valid
  Spotify access token\\n\\n### Search and Discovery\\n- `search`: Search for
  tracks, albums, artists, or playlists\\n- `get_new_releases`: Get new album
  releases\\n- `get_recommendations`: Get track recommendations\\n\\n### Artist
  Information\\n- `get_artist`: Get artist information\\n-
  `get_artist_top_tracks`: Get an artist's top tracks\\n-
  `get_artist_related_artists`: Get artists similar to a given artist\\n-
  `get_artist_albums`: Get an artist's albums\\n\\n### Album and Track
  Information\\n- `get_album`: Get album information\\n- `get_album_tracks`: Get
  an album's tracks\\n- `get_track`: Get track information\\n\\n### Audiobook
  Access\\n- `get_audiobook`: Get audiobook information with optional market
  parameter\\n- `get_multiple_audiobooks`: Get information for multiple
  audiobooks (max 50)\\n- `get_audiobook_chapters`: Get chapters of an audiobook
  with pagination support (1-50 chapters per request)\\n\\n### Playlist
  Management\\n- `get_playlist`: Get a playlist owned by a Spotify user\\n-
  `get_playlist_tracks`: Get full details of the tracks of a playlist (1-100
  tracks per request)\\n- `get_playlist_items`: Get full details of the items of
  a playlist (1-100 items per request)\\n- `modify_playlist`: Change playlist
  details (name, description, public/private state, collaborative status)\\n-
  `add_tracks_to_playlist`: Add one or more tracks to a playlist with optional
  position\\n- `remove_tracks_from_playlist`: Remove one or more tracks from a
  playlist with optional positions and snapshot ID\\n-
  `get_current_user_playlists`: Get a list of the playlists owned or followed by
  the current Spotify user (1-50 playlists per request)\\n\\n##
  Debugging\\n\\nIf you run into issues, check Claude Desktop's MCP
  logs:\\n```bash\\ntail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n```\\n\\nCommon issues:\\n1. **Authentication
  Errors**:\\n   - Verify your Spotify Client ID and Secret are correct\\n   -
  Check that your application is properly registered in the Spotify Developer
  Dashboard\\n\\n2. **Rate Limiting**:\\n   - The server includes automatic
  token management\\n   - Be aware of Spotify API rate limits for different
  endpoints\\n\\n## Development\\n\\n```bash\\n# Install dependencies\\nnpm
  install\\n\\n# Build the project\\nnpm run build\\n\\n# Development with
  auto-rebuild\\nnpm run watch\\n```\\n\\n## License\\n\\nMIT
  License\\n\\n---\\nNote: This is a fork of the [original mcp-spotify
  repository](https://github.com/superseoworld/mcp-spotify)\\n\",\"isRecommended\
  \":false,\"githubStars\":4,\"downloadCount\":1248,\"createdAt\":\"2025-02-19T\
  01:25:58.60191Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubS\
  ync\":\"2025-07-06T09:29:19.32543Z\"},{\"mcpId\":\"github.com/fireproof-stora\
  ge/mcp-database-server\",\"githubUrl\":\"https://github.com/fireproof-storage\
  /mcp-database-server\",\"name\":\"Fireproof\",\"author\":\"fireproof-storage\
  \",\"description\":\"A JSON document store server providing CRUD operations
  and field-based sorting queries, powered by Fireproof database for seamless
  integration with AI
  systems.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/fireproof.png\",\"category\":\"databases\",\"tags\
  \":[\"document-store\",\"json\",\"crud\",\"database\",\"storage\"],\"requires\
  ApiKey\":false,\"readmeContent\":\"# Model Context Protocol and Fireproof
  Demo: JSON Document Server\\n\\nThis is a simple example of how to use a
  [Fireproof](https://fireproof.storage/) database in a [Model Context
  Protocol](https://github.com/modelcontextprotocol) server (used for plugging
  code and data into A.I. systems such as [Claude
  Desktop](https://claude.ai/download)).\\n\\nThis demo server implements a
  basic JSON document store with CRUD operations (Create, Read, Update, Delete)
  and the ability to query documents sorted by any field.\\n\\n#
  Installation\\n\\nInstall dependencies:\\n\\n```bash\\nnpm install\\nnpm
  build\\n```\\n\\n## Running the Server\\n\\nTo use with Claude Desktop, add
  the server config:\\n\\nOn MacOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\nOn Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"fireproof\\\": {\\n      \\\"command\\\":
  \\\"/path/to/fireproof-mcp/build/index.js\\\"\\n    }\\n  }\\n}\\n```\\n\\n###
  Debugging\\n\\nSince MCP servers communicate over stdio, debugging can be
  challenging. We recommend using the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector), which is
  available as a package script:\\n\\n```bash\\nnpm run inspector\\n```\\n\\nThe
  Inspector will provide a URL to access debugging tools in your
  browser.\\n\\n\",\"isRecommended\":true,\"githubStars\":20,\"downloadCount\":\
  113,\"createdAt\":\"2025-02-18T06:27:56.840721Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T22:14:43.387209Z\"},{\"mcp\
  Id\":\"github.com/awslabs/mcp/tree/main/src/cfn-mcp-server\",\"githubUrl\":\"\
  https://github.com/awslabs/mcp/tree/main/src/cfn-mcp-server\",\"name\":\"Clou\
  dFormation\",\"author\":\"awslabs\",\"description\":\"Enables natural language
  management of AWS resources through Cloud Control API and IaC Generator,
  supporting creation, modification, and templating of over 1,100 AWS
  services.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\"\
  :[\"aws\",\"infrastructure-as-code\",\"cloud-control\",\"resource-management\
  \",\"cloudformation\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  CloudFormation MCP Server\\n\\nModel Context Protocol (MCP) server that
  enables LLMs to directly create and manage over 1,100 AWS resources through
  natural language using AWS Cloud Control API and Iac Generator with
  Infrastructure as Code best practices.\\n\\n## Features\\n\\n- **Resource
  Creation**: Uses a declarative approach to create any of 1,100+ AWS resources
  through Cloud Control API\\n- **Resource Reading**: Reads all properties and
  attributes of specific AWS resources\\n- **Resource Updates**: Uses a
  declarative approach to apply changes to existing AWS resources\\n- **Resource
  Deletion**: Safely removes AWS resources with proper validation\\n- **Resource
  Listing**: Enumerates all resources of a specified type across your AWS
  environment\\n- **Schema Information**: Returns detailed CloudFormation schema
  for any resource to enable more effective operations\\n- **Natural Language
  Interface**: Transform infrastructure-as-code from static authoring to dynamic
  conversations\\n- **Partner Resource Support**: Works with both AWS-native and
  partner-defined resources\\n- **Template Generation**: Generates a template on
  created/existing resources for a [subset of resource
  types](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resourc\
  e-import-supported-resources.html)\\n\\n## Prerequisites\\n\\n1. Configure AWS
  credentials:\\n   - Via AWS CLI: `aws configure`\\n   - Or set environment
  variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION)\\n2.
  Ensure your IAM role or user has the necessary permissions (see [Security
  Considerations](#security-considerations))\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.cfn-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2xh\
  YnMuY2ZuLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci1uYW1lZ\
  C1wcm9maWxlIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\nCon\
  figure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cfn-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.cfn-mcp-server@latest\\\"\\n      ],\\n      \\\"env\\\
  \": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-named-profile\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nIf you
  would like to prevent the MCP from taking any mutating actions (i.e.
  Create/Update/Delete Resource), you can specify the readonly flag as
  demonstrated below:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.cfn-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.cfn-mcp-server@latest\\\",\\n        \\\"--readonly\\\
  \"\\n      ],\\n      \\\"env\\\": {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-named-profile\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/cfn-mcp-server
  .`:\\n\\n```file\\n# fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\": {\\n      \\\"awslabs.cfn-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file\
  /above/.env\\\",\\n          \\\"awslabs/cfn-mcp-server:latest\\\",\\n          \
  \\\"--readonly\\\" // Optional paramter if you would like to restrict the MCP
  to only read actions\\n        ],\\n        \\\"env\\\":
  {},\\n        \\\"disabled\\\": false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\n## Tools\\n\\n###
  create_resource\\n\\nCreates an AWS resource using the AWS Cloud Control API
  with a declarative approach.\\n**Example**: Create an S3 bucket with
  versioning and encryption enabled.\\n\\n### get_resource\\n\\nGets details of
  a specific AWS resource using the AWS Cloud Control API.\\n**Example**: Get
  the configuration of an EC2 instance.\\n\\n### update_resource\\n\\nUpdates an
  AWS resource using the AWS Cloud Control API with a declarative
  approach.\\n**Example**: Update an RDS instance's storage capacity.\\n\\n###
  delete_resource\\n\\nDeletes an AWS resource using the AWS Cloud Control
  API.\\n**Example**: Remove an unused NAT gateway.\\n\\n###
  list_resources\\n\\nLists AWS resources of a specified type using AWS Cloud
  Control API.\\n**Example**: List all EC2 instances in a region.\\n\\n###
  get_resource_schema_information\\n\\nGet schema information for an AWS
  CloudFormation resource.\\n**Example**: Get the schema for AWS::S3::Bucket to
  understand all available properties.\\n\\n### get_request_status\\n\\nGet the
  status of a mutation that was initiated by create/update/delete
  resource.\\n**Example**: Give me the status of the last request I
  made.\\n\\n### create_template\\n\\nCreate a Cloudformation template from
  created or listed resources.\\n**Example**: Create a YAML template for those
  resources.\\n\\n## Basic Usage\\n\\nExamples of how to use the AWS
  Infrastructure as Code MCP Server:\\n\\n- \\\"Create a new S3 bucket with
  versioning and encryption enabled\\\"\\n- \\\"List all EC2 instances in the
  production environment\\\"\\n- \\\"Update the RDS instance to increase storage
  to 500GB\\\"\\n- \\\"Delete unused NAT gateways in VPC-123\\\"\\n- \\\"Set up
  a three-tier architecture with web, app, and database layers\\\"\\n-
  \\\"Create a disaster recovery environment in us-east-1\\\"\\n- \\\"Configure
  CloudWatch alarms for all production resources\\\"\\n- \\\"Implement
  cross-region replication for critical S3 buckets\\\"\\n- \\\"Show me the
  schema for AWS::Lambda::Function\\\"\\n- \\\"Create a template for all the
  resources we created and modified\\\"\\n\\n## Resource Type
  support\\n\\nResources which are supported by this MCP and the supported
  operations can be found here:
  <https://docs.aws.amazon.com/cloudcontrolapi/latest/userguide/supported-resou\
  rces.html>\\n\\n## Security Considerations\\n\\nWhen using this MCP server,
  you should consider:\\n\\n- Ensuring proper IAM permissions are configured
  before use\\n- Use AWS CloudTrail for additional security monitoring\\n-
  Configure resource-specific permissions when possible instead of wildcard
  permissions\\n- Consider using resource tagging for better governance and cost
  management\\n- Review all changes made by the MCP server as part of your
  regular security reviews\\n- If you would like to restrict the MCP to readonly
  operations, specify --readonly True in the startup arguments for the
  MCP\\n\\n### Required IAM Permissions\\n\\nEnsure your AWS credentials have
  the following minimum permissions:\\n\\n```json\\n{\\n    \\\"Version\\\":
  \\\"2012-10-17\\\",\\n    \\\"Statement\\\":
  [\\n        {\\n            \\\"Effect\\\":
  \\\"Allow\\\",\\n            \\\"Action\\\":
  [\\n                \\\"cloudcontrol:ListResources\\\",\\n                \\\
  \"cloudcontrol:GetResource\\\",\\n                \\\"cloudcontrol:CreateReso\
  urce\\\",\\n                \\\"cloudcontrol:DeleteResource\\\",\\n                \
  \\\"cloudcontrol:UpdateResource\\\",\\n                \\\"cloudformation:Cre\
  ateGeneratedTemplate\\\",\\n                \\\"cloudformation:DescribeGenera\
  tedTemplate\\\",\\n                \\\"cloudformation:GetGeneratedTemplate\\\"\
  \\n            ],\\n            \\\"Resource\\\":
  \\\"*\\\"\\n        }\\n    ]\\n}\\n```\\n\\n## Limitations\\n\\n- Operations
  are limited to resources supported by AWS Cloud Control API and Iac
  Generator\\n- Performance depends on the underlying AWS services' response
  times\\n- Some complex resource relationships may require multiple
  operations\\n- This MCP server can only manage resources in the AWS regions
  where Cloud Control API and/or Iac Generator is available\\n- Resource
  modification operations may be limited by service-specific constraints\\n-
  Rate limiting may affect operations when managing many resources
  simultaneously\\n- Some resource types might not support all operations
  (create, read, update, delete)\\n- Generated templates are primarily intended
  for importing existing resources into a CloudFormation stack and may not
  always work for creating new resources (in another account or
  region)\\n\",\"isRecommended\":false,\"githubStars\":4416,\"downloadCount\":1\
  73,\"createdAt\":\"2025-06-21T01:50:50.868656Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-07T13:17:40.050161Z\"},{\"mcpId\
  \":\"github.com/oxylabs/oxylabs-mcp\",\"githubUrl\":\"https://github.com/oxyl\
  abs/oxylabs-mcp\",\"name\":\"Oxylabs
  Scraper\",\"author\":\"oxylabs\",\"description\":\"Advanced web scraping tool
  using Oxylabs Web Scraper API, supporting JavaScript rendering, HTML parsing,
  and content transformation with flexible parsing
  options.\",\"codiconIcon\":\"globe\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/oxylabs-scraper.png\",\"category\":\"search\",\"tags\
  \":[\"web-scraping\",\"content-extraction\",\"javascript-rendering\",\"html-p\
  arsing\",\"data-collection\"],\"requiresApiKey\":false,\"readmeContent\":\"<p
  align=\\\"center\\\">\\n  <img
  src=\\\"https://storage.googleapis.com/oxylabs-public-assets/oxylabs_mcp.svg\\\
  \" alt=\\\"Oxylabs + MCP\\\">\\n</p>\\n<h1 align=\\\"center\\\"
  style=\\\"border-bottom: none;\\\">\\n  Oxylabs MCP Server\\n</h1>\\n\\n<p
  align=\\\"center\\\">\\n  <em>The missing link between AI models and the
  realworld web: one API that delivers clean, structured data from any
  site.</em>\\n</p>\\n\\n<div align=\\\"center\\\">\\n\\n[![smithery
  badge](https://smithery.ai/badge/@oxylabs/oxylabs-mcp)](https://smithery.ai/s\
  erver/@oxylabs/oxylabs-mcp)\\n[![pypi
  package](https://img.shields.io/pypi/v/oxylabs-mcp?color=%2334D058&label=pypi\
  %20package)](https://pypi.org/project/oxylabs-mcp/)\\n[![](https://dcbadge.ve\
  rcel.app/api/server/eWsVUJrnG5?style=flat)](https://discord.gg/Pds3gBmKMH)\\n\
  [![Licence](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\\n[!\
  [Verified on
  MseeP](https://mseep.ai/badge.svg)](https://mseep.ai/app/f6a9c0bc-83a6-4f78-8\
  9d9-f2cec4ece98d)\\n![Coverage
  badge](https://raw.githubusercontent.com/oxylabs/oxylabs-mcp/coverage/coverag\
  e-badge.svg)\\n\\n<br/>\\n<a
  href=\\\"https://glama.ai/mcp/servers/@oxylabs/oxylabs-mcp\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/@oxylabs/oxylabs-mcp/badge\\\"
  alt=\\\"Oxylabs Server MCP server\\\" />\\n</a>\\n\\n</div>\\n\\n---\\n\\n##
   Overview\\n\\nThe Oxylabs MCP server provides a bridge between AI models
  and the web. It enables them to scrape any URL, render JavaScript-heavy pages,
  extract and format content for AI use, bypass anti-scraping measures, and
  access geo-restricted web data from 195+ countries.\\n\\nThis implementation
  leverages the Model Context Protocol (MCP) to create a secure, standardized
  way for AI assistants to interact with web content.\\n\\n---\\n\\n## Why
  Oxylabs MCP? &nbsp;    \\n\\nImagine telling your LLM *\\\"Summarise
  the latest Hacker News discussion about GPT7\\\"*  and it simply
  answers.  \\nMCP (MultiClient Proxy) makes that happen by doing the boring
  parts for you:\\n\\n| What Oxylabs MCP
  does                                             | Why it matters to
  you                    |\\n|-------------------------------------------------\
  ------------------|------------------------------------------|\\n| **Bypasses
  antibot walls** with the Oxylabs global proxy network | Keeps you unblocked
  and anonymous        |\\n| **Renders JavaScript** in headless
  Chrome                         | Singlepage apps,
  sorted                 |\\n| **Cleans HTML 
  JSON**                                            | Drop straight into vector
  DBs or prompts |\\n| **Optional structured parsers** (Google, Amazon,
  etc.)            | Oneline access to popular targets       |\\n\\n##  Key
  Features\\n\\n<details>\\n<summary><strong> Scrape content from any
  site</strong></summary>\\n<br>\\n\\n- Extract data from any URL, including
  complex single-page applications\\n- Fully render dynamic websites using
  headless browser support\\n- Choose full JavaScript rendering, HTML-only, or
  none\\n- Emulate Mobile and Desktop viewports for realistic
  rendering\\n\\n</details>\\n\\n<details>\\n<summary><strong> Automatically get
  AI-ready data</strong></summary>\\n<br>\\n\\n- Automatically clean and convert
  HTML to Markdown for improved readability\\n- Use automated parsers for
  popular targets like Google, Amazon, and
  etc.\\n\\n</details>\\n\\n<details>\\n<summary><strong> Bypass blocks &
  geo-restrictions</strong></summary>\\n<br>\\n\\n- Bypass sophisticated bot
  protection systems with high success rate\\n- Reliably scrape even the most
  complex websites\\n- Get automatically rotating IPs from a proxy pool covering
  195+ countries\\n\\n</details>\\n\\n<details>\\n<summary><strong> Flexible
  setup & cross-platform support</strong></summary>\\n<br>\\n\\n- Set rendering
  and parsing options if needed\\n- Feed data directly into AI models or
  analytics tools\\n- Works on macOS, Windows, and
  Linux\\n\\n</details>\\n\\n<details>\\n<summary><strong> Built-in error
  handling and request management</strong></summary>\\n<br>\\n\\n- Comprehensive
  error handling and reporting\\n- Smart rate limiting and request
  management\\n\\n</details>\\n\\n---\\n\\n##  MCP Tools\\n\\nOxylabs MCP
  provides the following tools:\\n\\n1. **universal_scraper**: Uses Oxylabs Web
  Scraper API for general website scraping.\\n2. **google_search_scraper**: Uses
  Oxylabs Web Scraper API to extract results from Google Search.\\n3.
  **amazon_search_scraper**: Uses Oxylabs Web Scraper API to scrape Amazon
  search result pages.\\n4. **amazon_product_scraper**: Uses Oxylabs Web Scraper
  API to extract data from individual Amazon product pages.\\n\\n\\n## 
  Example Queries\\nWhen you've set up the MCP server with **Claude**, you can
  make requests like:\\n\\n- Could you scrape
  `https://www.google.com/search?q=ai` page?\\n- Scrape
  `https://www.amazon.de/-/en/Smartphone-Contract-Function-Manufacturer-Exclusi\
  ve/dp/B0CNKD651V` with **parse** enabled\\n- Scrape
  `https://www.amazon.de/-/en/gp/bestsellers/beauty/ref=zg_bs_nav_beauty_0` with
  **parse** and **render** enabled\\n- Use web unblocker with **render** to
  scrape
  `https://www.bestbuy.com/site/top-deals/all-electronics-on-sale/pcmcat1674241\
  939957.c`\\n\\n---\\n\\n##  Prerequisites\\n\\nBefore you begin, make sure
  you have:\\n\\n- **Oxylabs Account**: Obtain your username and password from
  [Oxylabs](https://dashboard.oxylabs.io/) (1-week free trial
  available)\\n\\n### Basic Usage\\nVia Smithery CLI:\\n- **Node.js** (v16+)\\n-
  `npx` command-line tool\\n\\nVia uv:\\n- `uv` package manager  install it
  using [this
  guide](https://docs.astral.sh/uv/getting-started/installation/)\\n\\n###
  Local/Dev Setup\\n- **Python 3.12+**\\n- `uv` package manager  install it
  using [this
  guide](https://docs.astral.sh/uv/getting-started/installation/)\\n\\n---\\n\\\
  n##  API Parameters\\n\\nThe Oxylabs MCP Universal Scraper accepts these
  parameters:\\n\\n| Parameter         |
  Description                                     |
  Values                    |\\n|-------------------|--------------------------\
  -----------------------|---------------------------|\\n| `url`             |
  The URL to scrape                               | Any valid
  URL             |\\n| `render`          | Use headless browser
  rendering                  | `html` or `None`          |\\n|
  `geo_location`    | Sets the proxy's geo location to retrieve data. |
  `Brasil`, `Canada`, etc.  |\\n| `user_agent_type` | Device type and
  browser                         | `desktop`, `tablet`, etc. |\\n|
  `output_format`   | The format of the output                        | `links`,
  `md`, `html`     |\\n\\n---\\n\\n##  Configuration\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=oxylabs&config=eyJjb21tYW5kIjoidXZ4IG94eWxhYnMtbWNwIiwiZW52\
  Ijp7Ik9YWUxBQlNfVVNFUk5BTUUiOiJPWFlMQUJTX1VTRVJOQU1FIiwiT1hZTEFCU19QQVNTV09SR\
  CI6Ik9YWUxBQlNfUEFTU1dPUkQifX0%3D)\\n\\n<details>\\n<summary><strong><code>sm\
  ithery</code></strong></summary>\\n\\n1. Go to
  https://smithery.ai/server/@oxylabs/oxylabs-mcp\\n2. Login with GitHub\\n3.
  Find the _Install_ section\\n4. Follow the instructions to generate the
  config\\n\\nAuto install with Smithery CLI\\n```bash\\n# example for Claude
  Desktop\\nnpx -y @smithery/cli@latest install @upstash/context7-mcp --client
  claude --key
  <smithery_key>\\n```\\n</details>\\n\\n<details>\\n<summary><strong><code>uvx\
  </code></strong></summary>\\n\\n1. Install the uv\\n```bash\\n# macOS and
  Linux\\ncurl -LsSf https://astral.sh/uv/install.sh | sh\\n\\n#
  Windows\\npowershell -ExecutionPolicy ByPass -c \\\"irm
  https://astral.sh/uv/install.ps1 | iex\\\"\\n```\\n\\n2. Use the following
  config\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"oxylabs\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"oxylabs-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"OXYLABS_USERNAME\\\":
  \\\"OXYLABS_USERNAME\\\",\\n        \\\"OXYLABS_PASSWORD\\\":
  \\\"OXYLABS_PASSWORD\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n\
  <details>\\n<summary><strong><code>uv</code></strong></summary>\\n\\n1.
  Install the uvx \\n```bash\\n# macOS and Linux\\ncurl -LsSf
  https://astral.sh/uv/install.sh | sh\\n\\n# Windows\\npowershell
  -ExecutionPolicy ByPass -c \\\"irm https://astral.sh/uv/install.ps1 |
  iex\\\"\\n```\\n\\n2. Use the following
  config\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"oxylabs\\\":
  {\\n      \\\"command\\\": \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/<Absolute-path-to-folder>/oxy\
  labs-mcp\\\",\\n        \\\"run\\\",\\n        \\\"oxylabs-mcp\\\"\\n      ],\
  \\n      \\\"env\\\": {\\n        \\\"OXYLABS_USERNAME\\\":
  \\\"OXYLABS_USERNAME\\\",\\n        \\\"OXYLABS_PASSWORD\\\":
  \\\"OXYLABS_PASSWORD\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n\
  ### Manual Setup with Claude Desktop\\n\\nNavigate to **Claude  Settings 
  Developer  Edit Config** and add one of the configurations above to the
  `claude_desktop_config.json` file.\\n\\n### Manual Setup with Cursor
  AI\\n\\nNavigate to **Cursor  Settings  Cursor Settings  MCP**. Click **Add
  new global MCP server** and add one of the configurations
  above.\\n\\n---\\n\\n##  Environment variables\\n\\nOxylabs MCP server
  supports the following environment variables\\n\\n| Name               |
  Description                                   | Mandatory           | Default
  |\\n|--------------------|-----------------------------------------------|---\
  ------------------|---------|\\n| `OXYLABS_USERNAME` | Your Oxylabs
  username                         | true                |         |\\n|
  `OXYLABS_PASSWORD` | Your Oxylabs password                         |
  true                |         |\\n| `LOG_LEVEL`        | Log level for the
  logs returned to the client | false               | `INFO`  |\\n\\n---\\n\\n##
   Logging\\n\\nServer provides additional information about the tool calls in
  `notification/message` events\\n\\n```json\\n{\\n  \\\"method\\\":
  \\\"notifications/message\\\",\\n  \\\"params\\\": {\\n    \\\"level\\\":
  \\\"info\\\",\\n    \\\"data\\\": \\\"Create job with params:
  {\\\\\\\"url\\\\\\\":
  \\\\\\\"https://ip.oxylabs.io\\\\\\\"}\\\"\\n  }\\n}\\n```\\n\\n```json\\n{\\\
  n  \\\"method\\\": \\\"notifications/message\\\",\\n  \\\"params\\\":
  {\\n    \\\"level\\\": \\\"info\\\",\\n    \\\"data\\\": \\\"Job info:
  job_id=7333113830223918081
  job_status=done\\\"\\n  }\\n}\\n```\\n\\n```json\\n{\\n  \\\"method\\\":
  \\\"notifications/message\\\",\\n  \\\"params\\\": {\\n    \\\"level\\\":
  \\\"error\\\",\\n    \\\"data\\\": \\\"Error: request to Oxylabs API
  failed\\\"\\n  }\\n}\\n```\\n\\n---\\n\\n##  License\\n\\nDistributed under
  the MIT License  see [LICENSE](LICENSE) for details.\\n\\n---\\n\\n## About
  Oxylabs\\n\\nEstablished in 2015, Oxylabs is a market-leading web intelligence
  collection\\nplatform, driven by the highest business, ethics, and compliance
  standards,\\nenabling companies worldwide to unlock data-driven
  insights.\\n\\n[![image](https://oxylabs.io/images/og-image.png)](https://oxy\
  labs.io/)\\n\\n<div align=\\\"center\\\">\\n<sub>\\n  Made with  by <a
  href=\\\"https://oxylabs.io\\\">Oxylabs</a>.  Feel free to give us a  if MCP
  saved you a
  weekend.\\n</sub>\\n</div>\\n\",\"isRecommended\":true,\"githubStars\":40,\"d\
  ownloadCount\":258,\"createdAt\":\"2025-02-18T06:08:21.891007Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06-30T00:27:15.9\
  01453Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/terraform-mcp-ser\
  ver\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/terraform-\
  mcp-server\",\"name\":\"AWS
  Terraform\",\"author\":\"awslabs\",\"description\":\"Provides Terraform best
  practices, security compliance scanning with Checkov, and AWS infrastructure
  management tools with focus on security and AWS Well-Architected
  guidance.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"tags\"\
  :[\"terraform\",\"aws\",\"infrastructure-as-code\",\"security-compliance\",\"\
  checkov\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Terraform MCP
  Server\\n\\nMCP server for Terraform on AWS best practices, infrastructure as
  code patterns, and security compliance with Checkov.\\n\\n## Features\\n\\n-
  **Terraform Best Practices** - Get prescriptive Terraform advice for building
  applications on AWS\\n  - AWS Well-Architected guidance for Terraform
  configurations\\n  - Security and compliance recommendations\\n  - AWSCC
  provider prioritization for consistent API behavior\\n\\n- **Security-First
  Development Workflow** - Follow a structured process for creating secure
  code\\n  - Step-by-step guidance for validation and security scanning\\n  -
  Integration of Checkov at the right stages of development\\n  - Clear handoff
  points between AI assistance and developer deployment\\n\\n- **Checkov
  Integration** - Work with Checkov for security and compliance scanning\\n  -
  Run security scans on Terraform code to identify vulnerabilities\\n  -
  Automatically fix identified security issues when possible\\n  - Get detailed
  remediation guidance for compliance issues\\n\\n- **AWS Provider
  Documentation** - Search for AWS and AWSCC provider resources\\n  - Find
  documentation for specific resources and attributes\\n  - Get example snippets
  and implementation guidance\\n  - Compare AWS and AWSCC provider
  capabilities\\n\\n- **AWS-IA GenAI Modules** - Access specialized modules for
  AI/ML workloads\\n  - Amazon Bedrock module for generative AI
  applications\\n  - OpenSearch Serverless for vector search capabilities\\n  -
  SageMaker endpoint deployment for ML model hosting\\n  - Serverless Streamlit
  application deployment for AI interfaces\\n\\n- **Terraform Registry Module
  Analysis** - Analyze Terraform Registry modules\\n  - Search for modules by
  URL or identifier\\n  - Extract input variables, output variables, and README
  content\\n  - Understand module usage and configuration options\\n  - Analyze
  module structure and dependencies\\n\\n- **Terraform Workflow Execution** -
  Run Terraform commands directly\\n  - Initialize, plan, validate, apply, and
  destroy operations\\n  - Pass variables and specify AWS regions\\n  - Get
  formatted command output for analysis\\n\\n- **Terragrunt Workflow Execution**
  - Run Terragrunt commands directly\\n  - Initialize, plan, validate, apply,
  run-all and destroy operations\\n  - Pass variables and specify AWS
  regions\\n  - Configure terragrunt-config and and include/exclude paths
  flags\\n  - Get formatted command output for analysis\\n\\n## Tools and
  Resources\\n\\n- **Terraform Development Workflow**: Follow security-focused
  development process via `terraform://workflow_guide`\\n- **AWS Best
  Practices**: Access AWS-specific guidance via
  `terraform://aws_best_practices`\\n- **AWS Provider Resources**: Access
  resource listings via `terraform://aws_provider_resources_listing`\\n- **AWSCC
  Provider Resources**: Access resource listings via
  `terraform://awscc_provider_resources_listing`\\n\\n## Prerequisites\\n\\n1.
  Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Install Terraform CLI for workflow
  execution\\n4. Install Checkov for security scanning\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.terraform-mcp-server&config=eyJjb21tYW5kIjoidXZ4IG\
  F3c2xhYnMudGVycmFmb3JtLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0x\
  FVkVMIjoiRVJST1IifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nConfi\
  gure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.terraform-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.terraform-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/terraform-mcp-server
  .`:\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.terraform-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"awslabs/terraform-mcp-server:latest\\\"\\n        ],\\n        \
  \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n\\n##
  Security Considerations\\n\\nWhen using this MCP server, you should
  consider:\\n- **Following the structured development workflow** that
  integrates validation and security scanning\\n- Reviewing all Checkov warnings
  and errors manually\\n- Fixing security issues rather than ignoring them
  whenever possible\\n- Documenting clear justifications for any necessary
  exceptions\\n- Using the RunCheckovScan tool regularly to verify security
  compliance\\n- Preferring the AWSCC provider for its consistent API behavior
  and better security defaults\\n\\nBefore applying Terraform changes to
  production environments, you should conduct your own independent assessment to
  ensure that your infrastructure would comply with your own specific security
  and quality control practices and standards, as well as the local laws, rules,
  and regulations that govern you and your
  content.\\n\",\"isRecommended\":false,\"githubStars\":4370,\"downloadCount\":\
  1158,\"createdAt\":\"2025-04-24T06:32:09.176617Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T16:53:04.273888Z\"},{\"mc\
  pId\":\"github.com/mendableai/firecrawl-mcp-server\",\"githubUrl\":\"https://\
  github.com/mendableai/firecrawl-mcp-server\",\"name\":\"FireCrawl\",\"author\
  \":\"mendableai\",\"description\":\"Advanced web scraping and crawling server
  with JavaScript rendering, batch processing, smart content filtering, and
  structured data extraction
  capabilities.\",\"codiconIcon\":\"globe\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/firecrawl.jpg\",\"category\":\"search\",\"tags\
  \":[\"web-scraping\",\"crawling\",\"data-extraction\",\"batch-processing\",\"\
  content-filtering\"],\"requiresApiKey\":false,\"readmeContent\":\"# Firecrawl
  MCP Server\\n\\nA Model Context Protocol (MCP) server implementation that
  integrates with [Firecrawl](https://github.com/mendableai/firecrawl) for web
  scraping capabilities.\\n\\n> Big thanks to
  [@vrknetha](https://github.com/vrknetha),
  [@knacklabs](https://www.knacklabs.ai) for the initial
  implementation!\\n\\n\\n## Features\\n\\n- Web scraping, crawling, and
  discovery\\n- Search and content extraction\\n- Deep research and batch
  scraping\\n- Automatic retries and rate limiting\\n- Cloud and self-hosted
  support\\n- SSE support\\n\\n> Play around with [our MCP Server on MCP.so's
  playground](https://mcp.so/playground?server=firecrawl-mcp-server) or on
  [Klavis AI](https://www.klavis.ai/mcp-servers).\\n\\n## Installation\\n\\n###
  Running with npx\\n\\n```bash\\nenv FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y
  firecrawl-mcp\\n```\\n\\n### Manual Installation\\n\\n```bash\\nnpm install -g
  firecrawl-mcp\\n```\\n\\n### Running on Cursor\\n\\nConfiguring Cursor
  \\nNote: Requires Cursor version 0.45.6+\\nFor the most up-to-date
  configuration instructions, please refer to the official Cursor documentation
  on configuring MCP servers:\\n[Cursor MCP Server Configuration
  Guide](https://docs.cursor.com/context/model-context-protocol#configuring-mcp\
  -servers)\\n\\nTo configure Firecrawl MCP in Cursor **v0.48.6**\\n\\n1. Open
  Cursor Settings\\n2. Go to Features > MCP Servers\\n3. Click \\\"+ Add new
  global MCP server\\\"\\n4. Enter the following
  code:\\n   ```json\\n   {\\n     \\\"mcpServers\\\":
  {\\n       \\\"firecrawl-mcp\\\": {\\n         \\\"command\\\":
  \\\"npx\\\",\\n         \\\"args\\\": [\\\"-y\\\",
  \\\"firecrawl-mcp\\\"],\\n         \\\"env\\\":
  {\\n           \\\"FIRECRAWL_API_KEY\\\":
  \\\"YOUR-API-KEY\\\"\\n         }\\n       }\\n     }\\n   }\\n   ```\\n   \\\
  nTo configure Firecrawl MCP in Cursor **v0.45.6**\\n\\n1. Open Cursor
  Settings\\n2. Go to Features > MCP Servers\\n3. Click \\\"+ Add New MCP
  Server\\\"\\n4. Enter the following:\\n   - Name: \\\"firecrawl-mcp\\\" (or
  your preferred name)\\n   - Type: \\\"command\\\"\\n   - Command: `env
  FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp`\\n\\n\\n\\n> If you are
  using Windows and are running into issues, try `cmd /c \\\"set
  FIRECRAWL_API_KEY=your-api-key && npx -y firecrawl-mcp\\\"`\\n\\nReplace
  `your-api-key` with your Firecrawl API key. If you don't have one yet, you can
  create an account and get it from
  https://www.firecrawl.dev/app/api-keys\\n\\nAfter adding, refresh the MCP
  server list to see the new tools. The Composer Agent will automatically use
  Firecrawl MCP when appropriate, but you can explicitly request it by
  describing your web scraping needs. Access the Composer via Command+L (Mac),
  select \\\"Agent\\\" next to the submit button, and enter your query.\\n\\n###
  Running on Windsurf\\n\\nAdd this to your
  `./codeium/windsurf/model_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\
  \": {\\n    \\\"mcp-server-firecrawl\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FIRECRAWL_API_KEY\\\":
  \\\"YOUR_API_KEY\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Running with
  SSE Local Mode\\n\\nTo run the server using Server-Sent Events (SSE) locally
  instead of the default stdio transport:\\n\\n```bash\\nenv SSE_LOCAL=true
  FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp\\n```\\n\\nUse the url:
  http://localhost:3000/sse\\n\\n### Installing via Smithery (Legacy)\\n\\nTo
  install Firecrawl for Claude Desktop automatically via
  [Smithery](https://smithery.ai/server/@mendableai/mcp-server-firecrawl):\\n\\\
  n```bash\\nnpx -y @smithery/cli install @mendableai/mcp-server-firecrawl
  --client claude\\n```\\n\\n### Running on VS Code\\n\\nFor one-click
  installation, click one of the install buttons below...\\n\\n[![Install with
  NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=firecrawl&inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22\
  %3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22passwo\
  rd%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-\
  y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%\
  24%7Binput%3AapiKey%7D%22%7D%7D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=firecrawl&inputs=%5B%7B%22type%22%3A%22promptString%\
  22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%2\
  2%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22npx%22%2C%22args\
  %22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_\
  KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D&quality=insiders)\\n\\nFor manual
  installation, add the following JSON block to your User Settings (JSON) file
  in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing
  `Preferences: Open User Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"inputs\\\": [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"apiKey\\\",\\n        \\\"description\\\": \\\"Firecrawl API
  Key\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"firecrawl\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\",
  \\\"firecrawl-mcp\\\"],\\n        \\\"env\\\":
  {\\n          \\\"FIRECRAWL_API_KEY\\\":
  \\\"${input:apiKey}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nOp\
  tionally, you can add it to a file called `.vscode/mcp.json` in your
  workspace. This will allow you to share the configuration with
  others:\\n\\n```json\\n{\\n  \\\"inputs\\\": [\\n    {\\n      \\\"type\\\":
  \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"apiKey\\\",\\n      \\\"description\\\": \\\"Firecrawl API
  Key\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\":
  {\\n    \\\"firecrawl\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FIRECRAWL_API_KEY\\\":
  \\\"${input:apiKey}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n##
  Configuration\\n\\n### Environment Variables\\n\\n#### Required for Cloud
  API\\n\\n- `FIRECRAWL_API_KEY`: Your Firecrawl API key\\n  - Required when
  using cloud API (default)\\n  - Optional when using self-hosted instance with
  `FIRECRAWL_API_URL`\\n- `FIRECRAWL_API_URL` (Optional): Custom API endpoint
  for self-hosted instances\\n  - Example:
  `https://firecrawl.your-domain.com`\\n  - If not provided, the cloud API will
  be used (requires API key)\\n\\n#### Optional Configuration\\n\\n##### Retry
  Configuration\\n\\n- `FIRECRAWL_RETRY_MAX_ATTEMPTS`: Maximum number of retry
  attempts (default: 3)\\n- `FIRECRAWL_RETRY_INITIAL_DELAY`: Initial delay in
  milliseconds before first retry (default: 1000)\\n-
  `FIRECRAWL_RETRY_MAX_DELAY`: Maximum delay in milliseconds between retries
  (default: 10000)\\n- `FIRECRAWL_RETRY_BACKOFF_FACTOR`: Exponential backoff
  multiplier (default: 2)\\n\\n##### Credit Usage Monitoring\\n\\n-
  `FIRECRAWL_CREDIT_WARNING_THRESHOLD`: Credit usage warning threshold (default:
  1000)\\n- `FIRECRAWL_CREDIT_CRITICAL_THRESHOLD`: Credit usage critical
  threshold (default: 100)\\n\\n### Configuration Examples\\n\\nFor cloud API
  usage with custom retry and credit monitoring:\\n\\n```bash\\n# Required for
  cloud API\\nexport FIRECRAWL_API_KEY=your-api-key\\n\\n# Optional retry
  configuration\\nexport FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Increase max
  retry attempts\\nexport FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Start with 2s
  delay\\nexport FIRECRAWL_RETRY_MAX_DELAY=30000       # Maximum 30s
  delay\\nexport FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # More aggressive
  backoff\\n\\n# Optional credit monitoring\\nexport
  FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Warning at 2000 credits\\nexport
  FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Critical at 500
  credits\\n```\\n\\nFor self-hosted instance:\\n\\n```bash\\n# Required for
  self-hosted\\nexport
  FIRECRAWL_API_URL=https://firecrawl.your-domain.com\\n\\n# Optional
  authentication for self-hosted\\nexport FIRECRAWL_API_KEY=your-api-key  # If
  your instance requires auth\\n\\n# Custom retry configuration\\nexport
  FIRECRAWL_RETRY_MAX_ATTEMPTS=10\\nexport
  FIRECRAWL_RETRY_INITIAL_DELAY=500     # Start with faster
  retries\\n```\\n\\n### Usage with Claude Desktop\\n\\nAdd this to your
  `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-firecrawl\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FIRECRAWL_API_KEY\\\":
  \\\"YOUR_API_KEY_HERE\\\",\\n\\n        \\\"FIRECRAWL_RETRY_MAX_ATTEMPTS\\\":
  \\\"5\\\",\\n        \\\"FIRECRAWL_RETRY_INITIAL_DELAY\\\":
  \\\"2000\\\",\\n        \\\"FIRECRAWL_RETRY_MAX_DELAY\\\":
  \\\"30000\\\",\\n        \\\"FIRECRAWL_RETRY_BACKOFF_FACTOR\\\":
  \\\"3\\\",\\n\\n        \\\"FIRECRAWL_CREDIT_WARNING_THRESHOLD\\\":
  \\\"2000\\\",\\n        \\\"FIRECRAWL_CREDIT_CRITICAL_THRESHOLD\\\":
  \\\"500\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### System
  Configuration\\n\\nThe server includes several configurable parameters that
  can be set via environment variables. Here are the default values if not
  configured:\\n\\n```typescript\\nconst CONFIG = {\\n  retry:
  {\\n    maxAttempts: 3, // Number of retry attempts for rate-limited
  requests\\n    initialDelay: 1000, // Initial delay before first retry (in
  milliseconds)\\n    maxDelay: 10000, // Maximum delay between retries (in
  milliseconds)\\n    backoffFactor: 2, // Multiplier for exponential
  backoff\\n  },\\n  credit: {\\n    warningThreshold: 1000, // Warn when credit
  usage reaches this level\\n    criticalThreshold: 100, // Critical alert when
  credit usage reaches this level\\n  },\\n};\\n```\\n\\nThese configurations
  control:\\n\\n1. **Retry Behavior**\\n\\n   - Automatically retries failed
  requests due to rate limits\\n   - Uses exponential backoff to avoid
  overwhelming the API\\n   - Example: With default settings, retries will be
  attempted at:\\n     - 1st retry: 1 second delay\\n     - 2nd retry: 2 seconds
  delay\\n     - 3rd retry: 4 seconds delay (capped at maxDelay)\\n\\n2.
  **Credit Usage Monitoring**\\n   - Tracks API credit consumption for cloud API
  usage\\n   - Provides warnings at specified thresholds\\n   - Helps prevent
  unexpected service interruption\\n   - Example: With default
  settings:\\n     - Warning at 1000 credits remaining\\n     - Critical alert
  at 100 credits remaining\\n\\n### Rate Limiting and Batch Processing\\n\\nThe
  server utilizes Firecrawl's built-in rate limiting and batch processing
  capabilities:\\n\\n- Automatic rate limit handling with exponential
  backoff\\n- Efficient parallel processing for batch operations\\n- Smart
  request queuing and throttling\\n- Automatic retries for transient
  errors\\n\\n## How to Choose a Tool\\n\\nUse this guide to select the right
  tool for your task:\\n\\n- **If you know the exact URL(s) you want:**\\n  -
  For one: use **scrape**\\n  - For many: use **batch_scrape**\\n- **If you need
  to discover URLs on a site:** use **map**\\n- **If you want to search the web
  for info:** use **search**\\n- **If you want to extract structured data:** use
  **extract**\\n- **If you want to analyze a whole site or section:** use
  **crawl** (with limits!)\\n- **If you want to do in-depth research:** use
  **deep_research**\\n- **If you want to generate LLMs.txt:** use
  **generate_llmstxt**\\n\\n### Quick Reference Table\\n\\n|
  Tool                | Best for                                 |
  Returns         |\\n|---------------------|----------------------------------\
  --------|-----------------|\\n| scrape              | Single page
  content                      | markdown/html   |\\n| batch_scrape        |
  Multiple known URLs                      | markdown/html[] |\\n|
  map                 | Discovering URLs on a site               |
  URL[]           |\\n| crawl               | Multi-page extraction (with
  limits)      | markdown/html[] |\\n| search              | Web search for
  info                      | results[]       |\\n| extract             |
  Structured data from pages               | JSON            |\\n|
  deep_research       | In-depth, multi-source research          | summary,
  sources|\\n| generate_llmstxt    | LLMs.txt for a domain                    |
  text            |\\n\\n## Available Tools\\n\\n### 1. Scrape Tool
  (`firecrawl_scrape`)\\n\\nScrape content from a single URL with advanced
  options.\\n\\n**Best for:**\\n- Single page content extraction, when you know
  exactly which page contains the information.\\n\\n**Not recommended for:**\\n-
  Extracting content from multiple pages (use batch_scrape for known URLs, or
  map + batch_scrape to discover URLs first, or crawl for full page content)\\n-
  When you're unsure which page contains the information (use search)\\n- When
  you need structured data (use extract)\\n\\n**Common mistakes:**\\n- Using
  scrape for a list of URLs (use batch_scrape instead).\\n\\n**Prompt
  Example:**\\n> \\\"Get the content of the page at
  https://example.com.\\\"\\n\\n**Usage
  Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_scrape\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\":
  \\\"https://example.com\\\",\\n    \\\"formats\\\":
  [\\\"markdown\\\"],\\n    \\\"onlyMainContent\\\":
  true,\\n    \\\"waitFor\\\": 1000,\\n    \\\"timeout\\\":
  30000,\\n    \\\"mobile\\\": false,\\n    \\\"includeTags\\\":
  [\\\"article\\\", \\\"main\\\"],\\n    \\\"excludeTags\\\": [\\\"nav\\\",
  \\\"footer\\\"],\\n    \\\"skipTlsVerification\\\":
  false\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Markdown, HTML, or other formats
  as specified.\\n\\n### 2. Batch Scrape Tool
  (`firecrawl_batch_scrape`)\\n\\nScrape multiple URLs efficiently with built-in
  rate limiting and parallel processing.\\n\\n**Best for:**\\n- Retrieving
  content from multiple pages, when you know exactly which pages to
  scrape.\\n\\n**Not recommended for:**\\n- Discovering URLs (use map first if
  you don't know the URLs)\\n- Scraping a single page (use scrape)\\n\\n**Common
  mistakes:**\\n- Using batch_scrape with too many URLs at once (may hit rate
  limits or token overflow)\\n\\n**Prompt Example:**\\n> \\\"Get the content of
  these three blog posts: [url1, url2, url3].\\\"\\n\\n**Usage
  Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_batch_scrape\\\",\\n  \\\"arguments\\\": {\\n    \\\"urls\\\":
  [\\\"https://example1.com\\\",
  \\\"https://example2.com\\\"],\\n    \\\"options\\\":
  {\\n      \\\"formats\\\":
  [\\\"markdown\\\"],\\n      \\\"onlyMainContent\\\":
  true\\n    }\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Response includes operation
  ID for status checking:\\n\\n```json\\n{\\n  \\\"content\\\":
  [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": \\\"Batch
  operation queued with ID: batch_1. Use firecrawl_check_batch_status to check
  progress.\\\"\\n    }\\n  ],\\n  \\\"isError\\\": false\\n}\\n```\\n\\n### 3.
  Check Batch Status (`firecrawl_check_batch_status`)\\n\\nCheck the status of a
  batch operation.\\n\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_check_batch_status\\\",\\n  \\\"arguments\\\":
  {\\n    \\\"id\\\": \\\"batch_1\\\"\\n  }\\n}\\n```\\n\\n### 4. Map Tool
  (`firecrawl_map`)\\n\\nMap a website to discover all indexed URLs on the
  site.\\n\\n**Best for:**\\n- Discovering URLs on a website before deciding
  what to scrape\\n- Finding specific sections of a website\\n\\n**Not
  recommended for:**\\n- When you already know which specific URL you need (use
  scrape or batch_scrape)\\n- When you need the content of the pages (use scrape
  after mapping)\\n\\n**Common mistakes:**\\n- Using crawl to discover URLs
  instead of map\\n\\n**Prompt Example:**\\n> \\\"List all URLs on
  example.com.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_map\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\":
  \\\"https://example.com\\\"\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Array of
  URLs found on the site\\n\\n### 5. Search Tool
  (`firecrawl_search`)\\n\\nSearch the web and optionally extract content from
  search results.\\n\\n**Best for:**\\n- Finding specific information across
  multiple websites, when you don't know which website has the information.\\n-
  When you need the most relevant content for a query\\n\\n**Not recommended
  for:**\\n- When you already know which website to scrape (use scrape)\\n- When
  you need comprehensive coverage of a single website (use map or
  crawl)\\n\\n**Common mistakes:**\\n- Using crawl or map for open-ended
  questions (use search instead)\\n\\n**Usage
  Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_search\\\",\\n  \\\"arguments\\\": {\\n    \\\"query\\\":
  \\\"latest AI research papers 2023\\\",\\n    \\\"limit\\\":
  5,\\n    \\\"lang\\\": \\\"en\\\",\\n    \\\"country\\\":
  \\\"us\\\",\\n    \\\"scrapeOptions\\\": {\\n      \\\"formats\\\":
  [\\\"markdown\\\"],\\n      \\\"onlyMainContent\\\":
  true\\n    }\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Array of search results
  (with optional scraped content)\\n\\n**Prompt Example:**\\n> \\\"Find the
  latest research papers on AI published in 2023.\\\"\\n\\n### 6. Crawl Tool
  (`firecrawl_crawl`)\\n\\nStarts an asynchronous crawl job on a website and
  extract content from all pages.\\n\\n**Best for:**\\n- Extracting content from
  multiple related pages, when you need comprehensive coverage.\\n\\n**Not
  recommended for:**\\n- Extracting content from a single page (use scrape)\\n-
  When token limits are a concern (use map + batch_scrape)\\n- When you need
  fast results (crawling can be slow)\\n\\n**Warning:** Crawl responses can be
  very large and may exceed token limits. Limit the crawl depth and number of
  pages, or use map + batch_scrape for better control.\\n\\n**Common
  mistakes:**\\n- Setting limit or maxDepth too high (causes token overflow)\\n-
  Using crawl for a single page (use scrape instead)\\n\\n**Prompt
  Example:**\\n> \\\"Get all blog posts from the first two levels of
  example.com/blog.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_crawl\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\":
  \\\"https://example.com/blog/*\\\",\\n    \\\"maxDepth\\\":
  2,\\n    \\\"limit\\\": 100,\\n    \\\"allowExternalLinks\\\":
  false,\\n    \\\"deduplicateSimilarURLs\\\":
  true\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Response includes operation ID for
  status checking:\\n\\n```json\\n{\\n  \\\"content\\\":
  [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\":
  \\\"Started crawl for: https://example.com/* with job ID:
  550e8400-e29b-41d4-a716-446655440000. Use firecrawl_check_crawl_status to
  check progress.\\\"\\n    }\\n  ],\\n  \\\"isError\\\":
  false\\n}\\n```\\n\\n### 7. Check Crawl Status
  (`firecrawl_check_crawl_status`)\\n\\nCheck the status of a crawl
  job.\\n\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_check_crawl_status\\\",\\n  \\\"arguments\\\":
  {\\n    \\\"id\\\":
  \\\"550e8400-e29b-41d4-a716-446655440000\\\"\\n  }\\n}\\n```\\n\\n**Returns:**\
  \\n- Response includes the status of the crawl job:\\n  \\n### 8. Extract Tool
  (`firecrawl_extract`)\\n\\nExtract structured information from web pages using
  LLM capabilities. Supports both cloud AI and self-hosted LLM
  extraction.\\n\\n**Best for:**\\n- Extracting specific structured data like
  prices, names, details.\\n\\n**Not recommended for:**\\n- When you need the
  full content of a page (use scrape)\\n- When you're not looking for specific
  structured data\\n\\n**Arguments:**\\n- `urls`: Array of URLs to extract
  information from\\n- `prompt`: Custom prompt for the LLM extraction\\n-
  `systemPrompt`: System prompt to guide the LLM\\n- `schema`: JSON schema for
  structured data extraction\\n- `allowExternalLinks`: Allow extraction from
  external links\\n- `enableWebSearch`: Enable web search for additional
  context\\n- `includeSubdomains`: Include subdomains in extraction\\n\\nWhen
  using a self-hosted instance, the extraction will use your configured LLM. For
  cloud API, it uses Firecrawl's managed LLM service.\\n**Prompt Example:**\\n>
  \\\"Extract the product name, price, and description from these product
  pages.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_extract\\\",\\n  \\\"arguments\\\": {\\n    \\\"urls\\\":
  [\\\"https://example.com/page1\\\",
  \\\"https://example.com/page2\\\"],\\n    \\\"prompt\\\": \\\"Extract product
  information including name, price, and
  description\\\",\\n    \\\"systemPrompt\\\": \\\"You are a helpful assistant
  that extracts product information\\\",\\n    \\\"schema\\\":
  {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\":
  {\\n        \\\"name\\\": { \\\"type\\\": \\\"string\\\"
  },\\n        \\\"price\\\": { \\\"type\\\": \\\"number\\\"
  },\\n        \\\"description\\\": { \\\"type\\\": \\\"string\\\"
  }\\n      },\\n      \\\"required\\\": [\\\"name\\\",
  \\\"price\\\"]\\n    },\\n    \\\"allowExternalLinks\\\":
  false,\\n    \\\"enableWebSearch\\\": false,\\n    \\\"includeSubdomains\\\":
  false\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Extracted structured data as
  defined by your schema\\n\\n```json\\n{\\n  \\\"content\\\":
  [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\":
  {\\n        \\\"name\\\": \\\"Example Product\\\",\\n        \\\"price\\\":
  99.99,\\n        \\\"description\\\": \\\"This is an example product
  description\\\"\\n      }\\n    }\\n  ],\\n  \\\"isError\\\":
  false\\n}\\n```\\n\\n### 9. Deep Research Tool
  (`firecrawl_deep_research`)\\n\\nConduct deep web research on a query using
  intelligent crawling, search, and LLM analysis.\\n\\n**Best for:**\\n- Complex
  research questions requiring multiple sources, in-depth analysis.\\n\\n**Not
  recommended for:**\\n- Simple questions that can be answered with a single
  search\\n- When you need very specific information from a known page (use
  scrape)\\n- When you need results quickly (deep research can take
  time)\\n\\n**Arguments:**\\n- query (string, required): The research question
  or topic to explore.\\n- maxDepth (number, optional): Maximum recursive depth
  for crawling/search (default: 3).\\n- timeLimit (number, optional): Time limit
  in seconds for the research session (default: 120).\\n- maxUrls (number,
  optional): Maximum number of URLs to analyze (default: 50).\\n\\n**Prompt
  Example:**\\n> \\\"Research the environmental impact of electric vehicles
  versus gasoline vehicles.\\\"\\n\\n**Usage
  Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_deep_research\\\",\\n  \\\"arguments\\\": {\\n    \\\"query\\\":
  \\\"What are the environmental impacts of electric vehicles compared to
  gasoline vehicles?\\\",\\n    \\\"maxDepth\\\": 3,\\n    \\\"timeLimit\\\":
  120,\\n    \\\"maxUrls\\\": 50\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Final
  analysis generated by an LLM based on research. (data.finalAnalysis)\\n- May
  also include structured activities and sources used in the research
  process.\\n\\n### 10. Generate LLMs.txt Tool
  (`firecrawl_generate_llmstxt`)\\n\\nGenerate a standardized llms.txt (and
  optionally llms-full.txt) file for a given domain. This file defines how large
  language models should interact \\nwith the site.\\n\\n**Best for:**\\n-
  Creating machine-readable permission guidelines for AI models.\\n\\n**Not
  recommended for:**\\n- General content extraction or
  research\\n\\n**Arguments:**\\n- url (string, required): The base URL of the
  website to analyze.\\n- maxUrls (number, optional): Max number of URLs to
  include (default: 10).\\n- showFullText (boolean, optional): Whether to
  include llms-full.txt contents in the response.\\n\\n**Prompt Example:**\\n>
  \\\"Generate an LLMs.txt file for example.com.\\\"\\n\\n**Usage
  Example:**\\n```json\\n{\\n  \\\"name\\\":
  \\\"firecrawl_generate_llmstxt\\\",\\n  \\\"arguments\\\":
  {\\n    \\\"url\\\": \\\"https://example.com\\\",\\n    \\\"maxUrls\\\":
  20,\\n    \\\"showFullText\\\": true\\n  }\\n}\\n```\\n\\n**Returns:**\\n-
  LLMs.txt file contents (and optionally llms-full.txt)\\n\\n## Logging
  System\\n\\nThe server includes comprehensive logging:\\n\\n- Operation status
  and progress\\n- Performance metrics\\n- Credit usage monitoring\\n- Rate
  limit tracking\\n- Error conditions\\n\\nExample log
  messages:\\n\\n```\\n[INFO] Firecrawl MCP Server initialized
  successfully\\n[INFO] Starting scrape for URL: https://example.com\\n[INFO]
  Batch operation queued with ID: batch_1\\n[WARNING] Credit usage has reached
  warning threshold\\n[ERROR] Rate limit exceeded, retrying in
  2s...\\n```\\n\\n## Error Handling\\n\\nThe server provides robust error
  handling:\\n\\n- Automatic retries for transient errors\\n- Rate limit
  handling with backoff\\n- Detailed error messages\\n- Credit usage
  warnings\\n- Network resilience\\n\\nExample error
  response:\\n\\n```json\\n{\\n  \\\"content\\\":
  [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": \\\"Error:
  Rate limit exceeded. Retrying in 2
  seconds...\\\"\\n    }\\n  ],\\n  \\\"isError\\\": true\\n}\\n```\\n\\n##
  Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n#
  Build\\nnpm run build\\n\\n# Run tests\\nnpm test\\n```\\n\\n###
  Contributing\\n\\n1. Fork the repository\\n2. Create your feature branch\\n3.
  Run tests: `npm test`\\n4. Submit a pull request\\n\\n### Thanks to
  contributors\\n\\nThanks to [@vrknetha](https://github.com/vrknetha),
  [@cawstudios](https://caw.tech) for the initial implementation!\\n\\nThanks to
  MCP.so and Klavis AI for hosting and [@gstarwd](https://github.com/gstarwd),
  [@xiangkaiz](https://github.com/xiangkaiz) and
  [@zihaolin96](https://github.com/zihaolin96) for integrating our
  server.\\n\\n## License\\n\\nMIT License - see LICENSE file for
  details\\n\",\"isRecommended\":false,\"githubStars\":3684,\"downloadCount\":2\
  3627,\"createdAt\":\"2025-02-21T18:35:28.390028Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T02:10:34.090841Z\"},{\"mc\
  pId\":\"github.com/modelcontextprotocol/servers/tree/main/src/slack\",\"githu\
  bUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/slack\
  \",\"name\":\"Slack\",\"author\":\"modelcontextprotocol\",\"description\":\"E\
  nables AI assistants to interact with Slack workspaces, providing tools for
  messaging, channel management, reactions, user profiles, and thread
  management.\",\"codiconIcon\":\"comment-discussion\",\"logoUrl\":\"https://st\
  orage.googleapis.com/cline_public_images/slack.png\",\"category\":\"communica\
  tion\",\"tags\":[\"slack\",\"messaging\",\"team-collaboration\",\"chat\",\"wo\
  rkspace-management\"],\"requiresApiKey\":false,\"isRecommended\":true,\"githu\
  bStars\":57063,\"downloadCount\":2830,\"createdAt\":\"2025-02-17T22:23:00.036\
  614Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"202\
  5-07-01T17:25:00.219453Z\"},{\"mcpId\":\"github.com/AgentDeskAI/browser-tools\
  -mcp\",\"githubUrl\":\"https://github.com/AgentDeskAI/browser-tools-mcp\",\"n\
  ame\":\"Browser Tools\",\"author\":\"AgentDeskAI\",\"description\":\"A browser
  monitoring and interaction toolkit that enables AI tools to capture
  screenshots, analyze console logs, track network activity, perform audits, and
  interact with DOM elements via Chrome
  extension.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/browser-tools.png\",\"category\":\"browser-autom\
  ation\",\"tags\":[\"chrome-extension\",\"debugging\",\"web-auditing\",\"monit\
  oring\",\"automation\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  BrowserTools MCP\\n\\n> Make your AI tools 10x more aware and capable of
  interacting with your browser\\n\\nThis application is a powerful browser
  monitoring and interaction tool that enables AI-powered applications via
  Anthropic's Model Context Protocol (MCP) to capture and analyze browser data
  through a Chrome extension.\\n\\nRead our
  [docs](https://browsertools.agentdesk.ai/) for the full installation,
  quickstart and contribution guides.\\n\\n## Roadmap\\n\\nCheck out our project
  roadmap here: [Github Roadmap / Project
  Board](https://github.com/orgs/AgentDeskAI/projects/1/views/1)\\n\\n##
  Updates\\n\\nv1.2.0 is out! Here's a quick breakdown of the update:\\n- You
  can now enable \\\"Allow Auto-Paste into Cursor\\\" within the DevTools panel.
  Screenshots will be automatically pasted into Cursor (just make sure to
  focus/click into the Agent input field in Cursor, otherwise it won't
  work!)\\n- Integrated a suite of SEO, performance, accessibility, and best
  practice analysis tools via Lighthouse\\n- Implemented a NextJS specific
  prompt used to improve SEO for a NextJS application\\n- Added Debugger Mode as
  a tool which executes all debugging tools in a particular sequence, along with
  a prompt to improve reasoning\\n- Added Audit Mode as a tool to execute all
  auditing tools in a particular sequence\\n- Resolved Windows connectivity
  issues\\n- Improved networking between BrowserTools server, extension and MCP
  server with host/port auto-discovery, auto-reconnect, and graceful shutdown
  mechanisms\\n- Added ability to more easily exit out of the Browser Tools
  server with Ctrl+C\\n\\n## Quickstart Guide\\n\\nThere are three components to
  run this MCP tool:\\n\\n1. Install our chrome extension from here: [v1.2.0
  BrowserToolsMCP Chrome
  Extension](https://github.com/AgentDeskAI/browser-tools-mcp/releases/download\
  /v1.2.0/BrowserTools-1.2.0-extension.zip)\\n2. Install the MCP server from
  this command within your IDE: `npx @agentdeskai/browser-tools-mcp@latest`\\n3.
  Open a new terminal and run this command: `npx
  @agentdeskai/browser-tools-server@latest`\\n\\n* Different IDEs have different
  configs but this command is generally a good starting point; please reference
  your IDEs docs for the proper config setup\\n\\nIMPORTANT TIP - there are two
  servers you need to install. There's...\\n- browser-tools-server (local nodejs
  server that's a middleware for gathering logs)\\nand\\n- browser-tools-mcp
  (MCP server that you install into your IDE that communicates w/ the extension
  + browser-tools-server)\\n\\n`npx @agentdeskai/browser-tools-mcp@latest` is
  what you put into your IDE\\n`npx @agentdeskai/browser-tools-server@latest` is
  what you run in a new terminal window\\n\\nAfter those three steps, open up
  your chrome dev tools and then the BrowserToolsMCP panel.\\n\\nIf you're still
  having issues try these steps:\\n- Quit / close down your browser. Not just
  the window but all of Chrome itself. \\n- Restart the local node server
  (browser-tools-server)\\n- Make sure you only have ONE instance of chrome dev
  tools panel open\\n\\nAfter that, it should work but if it doesn't let me know
  and I can share some more steps to gather logs/info about the issue!\\n\\nIf
  you have any questions or issues, feel free to open an issue ticket! And if
  you have any ideas to make this better, feel free to reach out or open an
  issue ticket with an enhancement tag or reach out to me at [@tedx_ai on
  x](https://x.com/tedx_ai)\\n\\n## Full Update Notes:\\n\\nCoding agents like
  Cursor can run these audits against the current page seamlessly. By leveraging
  Puppeteer and the Lighthouse npm library, BrowserTools MCP can now:\\n\\n-
  Evaluate pages for WCAG compliance\\n- Identify performance bottlenecks\\n-
  Flag on-page SEO issues\\n- Check adherence to web development best
  practices\\n- Review NextJS specific issues with SEO\\n\\n...all without
  leaving your IDE \\n\\n---\\n\\n##  Key Additions\\n\\n| Audit
  Type         |
  Description                                                                                                                              \
  |\\n| ------------------ |
  -----------------------------------------------------------------------------\
  ----------------------------------------------------------- |\\n|
  **Accessibility**  | WCAG-compliant checks for color contrast, missing alt
  text, keyboard navigation traps, ARIA attributes, and
  more.                        |\\n| **Performance**    | Lighthouse-driven
  analysis of render-blocking resources, excessive DOM size, unoptimized images,
  and other factors affecting page speed. |\\n| **SEO**            | Evaluates
  on-page SEO factors (like metadata, headings, and link structure) and suggests
  improvements for better search visibility.      |\\n| **Best Practices** |
  Checks for general best practices in web
  development.                                                                                    \
  |\\n| **NextJS Audit**   | Injects a prompt used to perform a NextJS
  audit.                                                                                         \
  |\\n| **Audit Mode**     | Runs all auditing tools in a
  sequence.                                                                                                   \
  |\\n| **Debugger Mode**  | Runs all debugging tools in a
  sequence.                                                                                                  \
  |\\n\\n---\\n\\n##  Using Audit Tools\\n\\n###  **Before You
  Start**\\n\\nEnsure you have:\\n\\n- An **active tab** in your browser\\n- The
  **BrowserTools extension enabled**\\n\\n###  **Running
  Audits**\\n\\n**Headless Browser Automation**:  \\n Puppeteer automates a
  headless Chrome instance to load the page and collect audit data, ensuring
  accurate results even for SPAs or content loaded via JavaScript.\\n\\nThe
  headless browser instance remains active for **60 seconds** after the last
  audit call to efficiently handle consecutive audit requests.\\n\\n**Structured
  Results**:  \\n Each audit returns results in a structured JSON format,
  including overall scores and detailed issue lists. This makes it easy for
  MCP-compatible clients to interpret the findings and present actionable
  insights.\\n\\nThe MCP server provides tools to run audits on the current
  page. Here are example queries you can use to trigger them:\\n\\n####
  Accessibility Audit (`runAccessibilityAudit`)\\n\\nEnsures the page meets
  accessibility standards like WCAG.\\n\\n> **Example Queries:**\\n>\\n> -
  \\\"Are there any accessibility issues on this page?\\\"\\n> - \\\"Run an
  accessibility audit.\\\"\\n> - \\\"Check if this page meets WCAG
  standards.\\\"\\n\\n#### Performance Audit
  (`runPerformanceAudit`)\\n\\nIdentifies performance bottlenecks and loading
  issues.\\n\\n> **Example Queries:**\\n>\\n> - \\\"Why is this page loading so
  slowly?\\\"\\n> - \\\"Check the performance of this page.\\\"\\n> - \\\"Run a
  performance audit.\\\"\\n\\n#### SEO Audit (`runSEOAudit`)\\n\\nEvaluates how
  well the page is optimized for search engines.\\n\\n> **Example
  Queries:**\\n>\\n> - \\\"How can I improve SEO for this page?\\\"\\n> -
  \\\"Run an SEO audit.\\\"\\n> - \\\"Check SEO on this page.\\\"\\n\\n#### Best
  Practices Audit (`runBestPracticesAudit`)\\n\\nChecks for general best
  practices in web development.\\n\\n> **Example Queries:**\\n>\\n> - \\\"Run a
  best practices audit.\\\"\\n> - \\\"Check best practices on this page.\\\"\\n>
  - \\\"Are there any best practices issues on this page?\\\"\\n\\n#### Audit
  Mode (`runAuditMode`)\\n\\nRuns all audits in a particular sequence. Will run
  a NextJS audit if the framework is detected.\\n\\n> **Example
  Queries:**\\n>\\n> - \\\"Run audit mode.\\\"\\n> - \\\"Enter audit
  mode.\\\"\\n\\n#### NextJS Audits (`runNextJSAudit`)\\n\\nChecks for best
  practices and SEO improvements for NextJS applications\\n\\n> **Example
  Queries:**\\n>\\n> - \\\"Run a NextJS audit.\\\"\\n> - \\\"Run a NextJS audit,
  I'm using app router.\\\"\\n> - \\\"Run a NextJS audit, I'm using page
  router.\\\"\\n\\n#### Debugger Mode (`runDebuggerMode`)\\n\\nRuns all
  debugging tools in a particular sequence\\n\\n> **Example Queries:**\\n>\\n> -
  \\\"Enter debugger mode.\\\"\\n\\n## Architecture\\n\\nThere are three core
  components all used to capture and analyze browser data:\\n\\n1. **Chrome
  Extension**: A browser extension that captures screenshots, console logs,
  network activity and DOM elements.\\n2. **Node Server**: An intermediary
  server that facilitates communication between the Chrome extension and any
  instance of an MCP server.\\n3. **MCP Server**: A Model Context Protocol
  server that provides standardized tools for AI clients to interact with the
  browser.\\n\\n```\\n          \
       \\n  MCP Client     MCP Server      Node
  Server       Chrome    \\n  (e.g.          (Protocol     
  (Middleware)   
    Extension  \\n   Cursor)           Handler)                            \
               \\n               \
  \\n```\\n\\nModel Context Protocol (MCP) is a capability
  supported by Anthropic AI models that\\nallow you to create custom tools for
  any compatible client. MCP clients like Claude\\nDesktop, Cursor, Cline or Zed
  can run an MCP server which \\\"teaches\\\" these clients\\nabout a new tool
  that they can use.\\n\\nThese tools can call out to external APIs but in our
  case, **all logs are stored locally** on your machine and NEVER sent out to
  any third-party service or API. BrowserTools MCP runs a local instance of a
  NodeJS API server which communicates with the BrowserTools Chrome
  Extension.\\n\\nAll consumers of the BrowserTools MCP Server interface with
  the same NodeJS API and Chrome extension.\\n\\n#### Chrome Extension\\n\\n-
  Monitors XHR requests/responses and console logs\\n- Tracks selected DOM
  elements\\n- Sends all logs and current element to the BrowserTools
  Connector\\n- Connects to Websocket server to capture/send screenshots\\n-
  Allows user to configure token/truncation limits + screenshot folder
  path\\n\\n#### Node Server\\n\\n- Acts as middleware between the Chrome
  extension and MCP server\\n- Receives logs and currently selected element from
  Chrome extension\\n- Processes requests from MCP server to capture logs,
  screenshot or current element\\n- Sends Websocket command to the Chrome
  extension for capturing a screenshot\\n- Intelligently truncates strings and #
  of duplicate objects in logs to avoid token limits\\n- Removes cookies and
  sensitive headers to avoid sending to LLMs in MCP clients\\n\\n#### MCP
  Server\\n\\n- Implements the Model Context Protocol\\n- Provides standardized
  tools for AI clients\\n- Compatible with various MCP clients (Cursor, Cline,
  Zed, Claude Desktop, etc.)\\n\\n## Installation\\n\\nInstallation steps can be
  found in our documentation:\\n\\n- [BrowserTools MCP
  Docs](https://browsertools.agentdesk.ai/)\\n\\n## Usage\\n\\nOnce installed
  and configured, the system allows any compatible MCP client to:\\n\\n- Monitor
  browser console output\\n- Capture network traffic\\n- Take screenshots\\n-
  Analyze selected elements\\n- Wipe logs stored in our MCP server\\n- Run
  accessibility, performance, SEO, and best practices audits\\n\\n##
  Compatibility\\n\\n- Works with any MCP-compatible client\\n- Primarily
  designed for Cursor IDE integration\\n- Supports other AI editors and MCP
  clients\\n\",\"isRecommended\":false,\"githubStars\":5485,\"downloadCount\":6\
  4067,\"createdAt\":\"2025-03-11T02:29:39.738183Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T03:10:21.286688Z\"},{\"mc\
  pId\":\"github.com/awslabs/mcp/tree/main/src/bedrock-kb-retrieval-mcp-server\
  \",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/bedrock-kb-re\
  trieval-mcp-server\",\"name\":\"Bedrock Knowledge
  Base\",\"author\":\"awslabs\",\"description\":\"Enables natural language
  querying of Amazon Bedrock Knowledge Bases with features for discovery,
  filtering, and result
  reranking.\",\"codiconIcon\":\"library\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"knowledge-memory\",\"ta\
  gs\":[\"aws-bedrock\",\"knowledge-base\",\"search\",\"retrieval\",\"document-\
  management\"],\"requiresApiKey\":false,\"readmeContent\":\"# Amazon Bedrock
  Knowledge Base Retrieval MCP Server\\n\\nMCP server for accessing Amazon
  Bedrock Knowledge Bases\\n\\n## Features\\n\\n### Discover knowledge bases and
  their data sources\\n\\n- Find and explore all available knowledge bases\\n-
  Search for knowledge bases by name or tag\\n- List data sources associated
  with each knowledge base\\n\\n### Query knowledge bases with natural
  language\\n\\n- Retrieve information using conversational queries\\n- Get
  relevant passages from your knowledge bases\\n- Access citation information
  for all results\\n\\n### Filter results by data source\\n\\n- Focus your
  queries on specific data sources\\n- Include or exclude specific data
  sources\\n- Prioritize results from specific data sources\\n\\n### Rerank
  results\\n\\n- Improve relevance of retrieval results\\n- Use Amazon Bedrock
  reranking capabilities\\n- Sort results by relevance to your query\\n\\n##
  Prerequisites\\n\\n### Installation Requirements\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n### AWS Requirements\\n\\n1. **AWS
  CLI Configuration**: You must have the AWS CLI configured with credentials and
  an AWS_PROFILE that has access to Amazon Bedrock and Knowledge Bases\\n2.
  **Amazon Bedrock Knowledge Base**: You must have at least one Amazon Bedrock
  Knowledge Base with the tag key `mcp-multirag-kb` with a value of `true`\\n3.
  **IAM Permissions**: Your IAM role/user must have appropriate permissions
  to:\\n   - List and describe knowledge bases\\n   - Access data sources\\n   -
  Query knowledge bases\\n\\n### Reranking Requirements\\n\\nIf you intend to
  use reranking functionality, your Bedrock Knowledge Base needs additional
  permissions:\\n\\n1. Your IAM role must have permissions for both
  `bedrock:Rerank` and `bedrock:InvokeModel` actions\\n2. The Amazon Bedrock
  Knowledge Bases service role must also have these permissions\\n3. Reranking
  is only available in specific regions. Please refer to the official
  [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/rerank-s\
  upported.html) for an up to date list of supported regions.\\n4. Enable model
  access for the available reranking models in the specified region.\\n\\n###
  Controlling Reranking\\n\\nReranking can be globally enabled or disabled using
  the `BEDROCK_KB_RERANKING_ENABLED` environment variable:\\n\\n- Set to `false`
  (default): Disables reranking for all queries unless explicitly enabled\\n-
  Set to `true`: Enables reranking for all queries unless explicitly
  disabled\\n\\nThe environment variable accepts various formats:\\n\\n- For
  enabling: 'true', '1', 'yes', or 'on' (case-insensitive)\\n- For disabling:
  any other value or not set (default behavior)\\n\\nThis setting provides a
  global default, while individual API calls can still override it by explicitly
  setting the `reranking` parameter.\\n\\nFor detailed instructions on setting
  up knowledge bases, see:\\n\\n- [Create a knowledge
  base](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-cre\
  ate.html)\\n- [Managing permissions for Amazon Bedrock knowledge
  bases](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-pr\
  ereq-permissions-general.html)\\n- [Permissions for reranking in Amazon
  Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/rerank-prereq.h\
  tml)\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.bedrock-kb-retrieval-mcp-server&config=eyJjb21tYW5\
  kIjoidXZ4IGF3c2xhYnMuYmVkcm9jay1rYi1yZXRyaWV2YWwtbWNwLXNlcnZlckBsYXRlc3QiLCJl\
  bnYiOnsiQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy1lY\
  XN0LTEiLCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiS0JfSU5DTFVTSU9OX1RBR19LRVkiOi\
  JvcHRpb25hbC10YWcta2V5LXRvLWZpbHRlci1rYnMiLCJCRURST0NLX0tCX1JFUkFOS0lOR19FTkF\
  CTEVEIjoiZmFsc2UifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nConfi\
  gure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.bedrock-kb-retrieval-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.bedrock-kb-retrieval-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-profile-name\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"KB_INCLUSION_TAG_KEY\\\":
  \\\"optional-tag-key-to-filter-kbs\\\",\\n        \\\"BEDROCK_KB_RERANKING_EN\
  ABLED\\\": \\\"false\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/bedrock-kb-retrieval-mcp-server
  .`:\\n\\n```file\\n# fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\\nAWS_SECRET_ACCESS_KEY=\
  wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH\
  0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\\n```\\n\\n```json\\n  {\
  \\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.bedrock-kb-retrieval-mcp-server\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"--env\\\",\\n          \\\"KB_INCLUSION_TAG_KEY=optiona\
  l-tag-key-to-filter-kbs\\\",\\n          \\\"--env\\\",\\n          \\\"BEDRO\
  CK_KB_RERANKING_ENABLED=false\\\",\\n          \\\"--env\\\",\\n          \\\
  \"AWS_REGION=us-east-1\\\",\\n          \\\"--env-file\\\",\\n          \\\"/\
  full/path/to/file/above/.env\\\",\\n          \\\"awslabs/bedrock-kb-retrieva\
  l-mcp-server:latest\\\"\\n        ],\\n        \\\"env\\\":
  {},\\n        \\\"disabled\\\": false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\\nNOTE: Your credentials will need to be
  kept refreshed from your host\\n\\n## Limitations\\n\\n- Results with `IMAGE`
  content type are not included in the KB query response.\\n- The `reranking`
  parameter requires additional permissions, Amazon Bedrock model access, and is
  only available in specific
  regions.\\n\",\"isRecommended\":false,\"githubStars\":4391,\"downloadCount\":\
  1900,\"createdAt\":\"2025-04-04T01:25:39.965466Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-06T00:41:28.013941Z\"},{\"mc\
  pId\":\"github.com/needle-ai/needle-mcp\",\"githubUrl\":\"https://github.com/\
  needle-ai/needle-mcp\",\"name\":\"Needle
  Search\",\"author\":\"needle-ai\",\"description\":\"Enables document
  management and natural language search capabilities through the Needle
  platform, allowing users to organize, store, and retrieve documents using
  Claude's language
  model.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/needle-search.png\",\"category\":\"knowledge-memory\",\
  \"tags\":[\"document-management\",\"search\",\"knowledge-base\",\"needle-api\
  \",\"content-organization\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Build Agents with Needle MCP Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/needle-mcp)](https://smithery.ai/server/need\
  le-mcp)\\n\\n![Screenshot of Feature -
  Claude](https://github.com/user-attachments/assets/a7286901-e7be-4efe-afd9-72\
  021dce03d4)\\n\\nMCP (Model Context Protocol) server to manage documents and
  perform searches using [Needle](https://needle-ai.com) through Claudes
  Desktop Application.\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/5jw1t7hur2\\\">\\n  <img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/5jw1t7hur2/badge\\\" alt=\\\"Needle
  Server MCP server\\\" />\\n</a>\\n\\n## Table of Contents\\n\\n-
  [Overview](#overview)\\n- [Features](#features)\\n- [Usage](#usage)\\n  -
  [Commands in Claude Desktop](#commands-in-claude-desktop)\\n  - [Result in
  Needle](#result-in-needle)\\n- [Installation](#installation)\\n- [Video
  Explanation](#youtube-video-explanation)\\n\\n---\\n\\n## Overview\\n\\nNeedle
  MCP Server allows you to:\\n\\n- Organize and store documents for quick
  retrieval.\\n- Perform powerful searches via Claudes large language
  model.\\n- Integrate seamlessly with the Needle ecosystem for advanced
  document management.\\n\\n---\\n\\n## Features\\n\\n- **Document Management:**
  Easily add and organize documents on the server.\\n- **Search & Retrieval:**
  Claude-based natural language search for quick answers.\\n- **Easy
  Integration:** Works with [Claude Desktop](#commands-in-claude-desktop) and
  Needle collections.\\n\\n---\\n\\n## Usage\\n\\n### Commands in Claude
  Desktop\\n\\nBelow is an example of how the commands can be used in Claude
  Desktop to interact with the server:\\n\\n![Using commands in Claude
  Desktop](https://github.com/user-attachments/assets/9e0ce522-6675-46d9-9bfb-3\
  162d214625b)\\n\\n1. **Open Claude Desktop** and connect to the Needle MCP
  Server.  \\n2. **Use simple text commands** to search, retrieve, or modify
  documents.  \\n3. **Review search results** returned by Claude in a
  user-friendly interface.\\n\\n### Result in
  Needle\\n\\nhttps://github.com/user-attachments/assets/0235e893-af96-4920-836\
  4-1e86f73b3e6c\\n\\n---\\n\\n## Youtube Video Explanation\\n\\nFor a full
  walkthrough on using the Needle MCP Server with Claude and Claude Desktop,
  watch this [YouTube explanation
  video](https://youtu.be/nVrRYp9NZYg).\\n\\n---\\n\\n## Installation\\n\\n###
  Installing via Smithery\\n\\nTo install Needle MCP for Claude Desktop
  automatically via
  [Smithery](https://smithery.ai/server/needle-mcp):\\n\\n```bash\\nnpx -y
  @smithery/cli install needle-mcp --client claude\\n```\\n\\n### Manual
  Installation\\n1. Clone the repository:\\n```bash\\ngit clone
  https://github.com/yourusername/needle-mcp.git\\n```\\n\\n2. Install UV
  globally using Homebrew in Terminal:\\n```bash\\nbrew install uv\\n```\\n\\n3.
  Create claude_desktop_config.json:\\n   - For MacOS: Open directory
  `~/Library/Application Support/Claude/` and create the file inside it\\n   -
  For Windows: Open directory `%APPDATA%/Claude/` and create the file inside
  it\\n\\n4. Add this configuration to
  claude_desktop_config.json:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"needle_mcp\\\": {\\n      \\\"command\\\":
  \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/path/to/needle-mcp\\\",\\n        \
  \\\"run\\\",\\n        \\\"needle-mcp\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"NEEDLE_API_KEY\\\":
  \\\"your_needle_api_key\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n5. Get your
  Needle API key from needle.xyz\\n\\n6. Update the config file:\\n   - Replace
  `/path/to/needle-mcp` with your actual repository path\\n   - Add your Needle
  API key\\n\\n7. Quit Claude completely and reopen it\\n\\n## Usage
  Examples\\n\\n* \\\"Create a new collection called 'Technical Docs'\\\"\\n*
  \\\"Add this document to the collection, which is
  https://needle-ai.com\\\"\\n* \\\"Search the collection for information about
  AI\\\"\\n* \\\"List all my collections\\\"\\n\\n## Troubleshooting\\n\\nIf not
  working:\\n- Make sure UV is installed globally (if not, uninstall with `pip
  uninstall uv` and reinstall with `brew install uv`)\\n- Or find UV path with
  `which uv` and replace `\\\"command\\\": \\\"uv\\\"` with the full path\\n-
  Verify your Needle API key is correct\\n- Check if the needle-mcp path in
  config matches your actual repository location\\n\\n### Reset Claude Desktop
  Configuration\\n\\nIf you're seeing old configurations or the integration
  isn't working:\\n\\n1. Find all Claude Desktop config files:\\n```bash\\nfind
  / -name \\\"claude_desktop_config.json\\\" 2>/dev/null\\n```\\n\\n2. Remove
  all Claude Desktop data:\\n- On MacOS: `rm -rf ~/Library/Application\\\\
  Support/Claude/*`\\n- On Windows: Delete contents of
  `%APPDATA%/Claude/`\\n\\n3. Create a fresh config with only
  Needle:\\n```\\nmkdir -p ~/Library/Application\\\\ Support/Claude\\ncat >
  ~/Library/Application\\\\ Support/Claude/claude_desktop_config.json\\n<<
  'EOL'\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"needle_mcp\\\":
  {\\n      \\\"command\\\": \\\"uv\\\",\\n      \\\"args\\\":
  [\\n        \\\"--directory\\\",\\n        \\\"/path/to/needle-mcp\\\",\\n        \
  \\\"run\\\",\\n        \\\"needle-mcp\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"NEEDLE_API_KEY\\\":
  \\\"your_needle_api_key\\\"\\n      }\\n    }\\n  }\\n}\\nEOL\\n```\\n\\n4.
  Completely quit Claude Desktop (Command+Q on Mac) and relaunch it\\n\\n5. If
  you still see old configurations:\\n- Check for additional config files in
  other locations\\n- Try clearing browser cache if using web version\\n- Verify
  the config file is being read from the correct
  location\",\"isRecommended\":true,\"githubStars\":56,\"downloadCount\":109,\"\
  createdAt\":\"2025-02-18T06:08:09.63413Z\",\"updatedAt\":\"2025-07-08T01:10:4\
  8.398933Z\",\"lastGithubSync\":\"2025-06-30T17:27:28.67645Z\"},{\"mcpId\":\"g\
  ithub.com/IBM/wxflows/tree/main/examples/mcp/javascript\",\"githubUrl\":\"htt\
  ps://github.com/IBM/wxflows/tree/main/examples/mcp/javascript\",\"name\":\"Wa\
  tsonX Flows\",\"author\":\"IBM\",\"description\":\"Enables integration with
  watsonx.ai Flows Engine, providing tools for Google Books and Wikipedia
  searches through a TypeScript-based MCP server
  implementation.\",\"codiconIcon\":\"flow\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/watsonx-flows.png\",\"category\":\"cloud-platf\
  orms\",\"tags\":[\"watsonx\",\"flows-engine\",\"tool-integration\",\"search-t\
  ools\",\"ibm-cloud\"],\"requiresApiKey\":false,\"readmeContent\":\"# Using
  watsonx.ai Flows Engine with Model Context Protocol (MCP)\\n\\nHere's a
  step-by-step tutorial for setting up and deploying a project with `wxflows`,
  including installing necessary tools, deploying the app, and running it
  locally.\\n\\nThis example consists of the following pieces:\\n\\n- MCP
  TypeScript SDK (mcp server)\\n- wxflows SDK (tools)\\n\\n> You can use any of
  the [supported MCP
  clients](https://modelcontextprotocol.io/clients).\\n\\nThis guide will walk
  you through installing the `wxflows` CLI, initializing and deploying a
  project, and running the application locally. Well use `google_books` and
  `wikipedia` tools as examples for tool calling with `wxflows`.\\n\\n## Before
  you start\\n\\nClone this repository and open the right
  directory:\\n\\n```bash\\ngit clone https://github.com/IBM/wxflows.git\\ncd
  examples/mcp/javascript\\n```\\n\\n## Step 1: Set up wxflows\\n\\nBefore you
  can start building AI applications using watsonx.ai Flows Engine:\\n\\n1.
  [Sign up](https://ibm.biz/wxflows) for a free account\\n2. [Download &
  install](https://wxflows.ibm.stepzen.com/docs/installation) the Node.js
  CLI\\n3. [Authenticate](https://wxflows.ibm.stepzen.com/docs/authentication)
  your account\\n\\n## Step 2: Deploy a Flows Engine project\\n\\nMove into the
  `wxflows` directory:\\n\\n```bash\\ncd wxflows\\n```\\n\\nThere's already a
  wxflows project for you set up this repository with the following
  values:\\n\\n- **Defines an endpoint** `api/mcp-example` for the project.\\n-
  **Imports `google_books` tool** with a description for searching books and
  specifying fields `books|book`.\\n- **Imports `wikipedia` tool** with a
  description for Wikipedia searches and specifying fields
  `search|page`.\\n\\nYou can deploy this tool configuration to a Flows Engine
  endpoint by running:\\n\\n```bash\\nwxflows deploy\\n```\\n\\nThis command
  deploys the endpoint and tools defined, these will be used by the `wxflows`
  SDK in your application.\\n\\n## Step 3: Set Up Environment
  Variables\\n\\nFrom the projects root directory copy the sample environment
  file to create your `.env` file:\\n\\n```bash\\ncp .env.sample
  .env\\n```\\n\\nEdit the `.env` file and add your credentials, such as API
  keys and other required environment variables. Ensure the credentials are
  correct to allow the tools to authenticate and interact with external
  services.\\n\\n## Step 4: Install Dependencies in the Application\\n\\nTo run
  the application you need to install the necessary
  dependencies:\\n\\n```bash\\nnpm i\\n```\\n\\nThis command installs all
  required packages, including the `@wxflows/sdk` package and any dependencies
  specified in the project.\\n\\n## Step 5: Build the MCP server\\n\\nBuild the
  server by running:\\n\\n```bash\\nnpm run build\\n```\\n\\n## Step 6: Use in a
  MCP client\\n\\nFinally, you can use the MCP server in a client. To use with
  Claude Desktop, add the server config:\\n\\nOn MacOS: `~/Library/Application
  Support/Claude/claude_desktop_config.json`\\nOn Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"wxflows-server\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/wxflows-server/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"WXFLOWS_APIKEY\\\":
  \\\"YOUR_WXFLOWS_APIKEY\\\",\\n        \\\"WXFLOWS_ENDPOINT\\\":
  \\\"YOUR_WXFLOWS_ENDPOINT\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nYou can
  now open Claude Desktop and should be seeing the tools from the
  `wxflows-server` listed. You can now test the `google_books` and `wikipedia`
  tools through Claude Desktop.\\n\\n## Summary\\n\\nYouve now successfully set
  up, deployed, and run a `wxflows` project with `google_books` and `wikipedia`
  tools. This setup provides a flexible environment to leverage external tools
  for data retrieval, allowing you to further build and expand your app with
  `wxflows`. See the instructions in [tools](../../../../tools/README.md) to add
  more tools or create your own tools from Databases, NoSQL, REST or GraphQL
  APIs.\\n\\n## Support\\n\\nPlease [reach out to us on
  Discord](https://ibm.biz/wxflows-discord) if you have any questions or want to
  share feedback. We'd love to hear from you!\\n\\n## Installation\\n\\nTo use
  with Claude Desktop, add the server config:\\n\\nOn MacOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\nOn
  Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"weather-server\\\": {\\n      \\\"command\\\":
  \\\"/path/to/weather-server/build/index.js\\\"\\n    }\\n  }\\n}\\n```\\n\\n#\
  ## Debugging\\n\\nSince MCP servers communicate over stdio, debugging can be
  challenging. We recommend using the [MCP
  Inspector](https://github.com/modelcontextprotocol/inspector), which is
  available as a package script:\\n\\n```bash\\nnpm run inspector\\n```\\n\\nThe
  Inspector will provide a URL to access debugging tools in your
  browser.\\n\",\"isRecommended\":true,\"githubStars\":92,\"downloadCount\":70,\
  \"createdAt\":\"2025-02-18T05:46:21.470556Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-04T17:20:13.300852Z\"},{\"mcpId\":\
  \"github.com/firebase/genkit/tree/HEAD/js/plugins/mcp\",\"githubUrl\":\"https\
  ://github.com/firebase/genkit/tree/HEAD/js/plugins/mcp\",\"name\":\"Genkit
  Integration\",\"author\":\"firebase\",\"description\":\"Enables bi-directional
  integration with Model Context Protocol, allowing applications to both consume
  MCP tools/prompts as a client and expose Genkit tools/prompts as an MCP
  server.\",\"codiconIcon\":\"extensions\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/genkit-integration.png\",\"category\":\"develope\
  r-tools\",\"tags\":[\"mcp-integration\",\"client-server\",\"tools-prompts\",\
  \"plugin\",\"genkit\"],\"requiresApiKey\":false,\"readmeContent\":\"# Genkit
  MCP\\n\\n> [!WARNING]  \\n> This plugin is experimental, meaning it may not be
  supported long-term and APIs are subject to more often breaking
  changes.\\n\\nThis plugin provides integration between Genkit and the [Model
  Context Protocol](https://modelcontextprotocol.io) (MCP). MCP is an open
  standard allowing developers to build \\\"servers\\\" which provide tools,
  resources, and prompts to clients. Genkit MCP allows Genkit developers to both
  consume MCP tools, prompts, and resources as a client and provide tools and
  prompts as a server.\\n\\n## Installation\\n\\nTo get started, you'll need
  Genkit and the MCP plugin:\\n\\n```bash\\nnpm i genkit
  genkitx-mcp\\n```\\n\\n## MCP Client\\n\\nTo create an MCP client, you call
  the `mcpClient` function to generate a Genkit plugin for an MCP server. For
  example, to use MCP's example [filesystem
  server](https://github.com/modelcontextprotocol/servers/tree/main/src/filesys\
  tem):\\n\\n```ts\\nimport { genkit } from 'genkit';\\nimport { mcpClient }
  from 'genkitx-mcp';\\n\\n// the filesystem server requires one or more allowed
  directories\\nconst ALLOWED_DIRS = ['/Users/yourusername/Desktop'];\\n\\nconst
  filesystemClient = mcpClient({\\n  name: 'filesystem',\\n  serverProcess:
  {\\n    command: 'npx',\\n    args: ['-y',
  '@modelcontextprotocol/server-everything',
  ...ALLOWED_DIRS],\\n  },\\n});\\n\\nconst ai = genkit({\\n  plugins:
  [\\n    filesystemClient /* ... other plugins such as model providers
  ...*/,\\n  ],\\n});\\n```\\n\\nMost MCP servers are built to run as spawned
  processes on the same machine using the `stdio` transport. When you supply the
  `serverProcess` option, you are specifying the command, arguments, and
  environment variables for spawning the server as a subprocess.\\n\\n###
  mcpClient() Options\\n\\n- **`name`**: (required) The name for this client,
  which namespaces its tools and prompts.\\n- **`version`**: (optional) The
  client's version number. Defaults to \\\"1.0.0\\\".\\n- You must supply one
  of:\\n  - **`serverProcess`**: Parameters for launching a local server process
  using the stdio MCP transport.\\n    - **`command`**: Shell command path for
  launching the MCP server. Can be e.g. `npx` or `uvx` to download and run the
  server from a package manager.\\n    - **`args`**: (optional) Array of string
  arguments to pass to the command.\\n    - **`env`**: (optional) Key value
  object of environment variables to pass to the command.\\n  - **`serverUrl`**:
  The URL of a remote server to connect to using the SSE MCP transport.\\n  -
  **`serverWebsocketUrl`: The URL of a remote server to connect to using the
  WebSocket MCP transport.\\n  - **`transport`**: An existing MCP transport
  object for connecting to the server.\\n- **`rawToolResponses`**: (optional) A
  boolean flag. If `true`, tool responses are returned in their raw MCP format;
  otherwise, they are processed for Genkit compatibility.\\n\\n### Using MCP
  Actions\\n\\nThe Genkit MCP client automatically discovers available tools and
  prompts and registers them with Genkit making them available anywhere other
  tools and prompts can be used. To access resources, special `list_resources`
  and `read_resource` tools are registered that will access resources for the
  server.\\n\\nAll MCP actions are namespaced under the name you supply, so a
  client called `filesystem` will register tools such as
  `filesystem/read_file`.\\n\\n### Tool Responses\\n\\nMCP tools return a
  `content` array as opposed to a structured response like most Genkit tools.
  The Genkit MCP plugin attempts to parse and coerce returned content:\\n\\n1.
  If content is text and valid JSON, the JSON is parsed and returned.\\n2. If
  content is text and not valid JSON, the text is returned.\\n3. If content has
  a single non-text part, it is returned.\\n4. If content has multiple/mixed
  parts, the full content response is returned.\\n\\n## MCP Server\\n\\nYou can
  also expose all of the tools and prompts from a Genkit instance as an MCP
  server:\\n\\n```ts\\nimport { genkit, z } from 'genkit';\\nimport { mcpServer
  } from 'genkitx-mcp';\\n\\nconst ai =
  genkit({});\\n\\nai.defineTool(\\n  {\\n    name: 'add',\\n    description:
  'add two numbers together',\\n    inputSchema: z.object({ a: z.number(), b:
  z.number() }),\\n    outputSchema: z.number(),\\n  },\\n  async ({ a, b }) =>
  {\\n    return a + b;\\n  }\\n);\\n\\nai.definePrompt(\\n  {\\n    name:
  \\\"happy\\\",\\n    description: \\\"everybody together now\\\",\\n    input:
  {\\n      schema: z.object({\\n        action: z.string().default(\\\"clap
  your hands\\\").optional(),\\n      }),\\n    },\\n  },\\n  `If you're happy
  and you know it, {{action}}.`\\n);\\n\\nmcpServer(ai, { name:
  'example_server', version: '0.0.1' }).start();\\n```\\n\\nThe above will start
  up an MCP server with the stdio transport that exposes a tool called `add` and
  a prompt called `happy`. To start the server with a different transport, use
  `mcpServer(...).start(otherTransport)`.\\n\\n### Known Limitations\\n\\n- MCP
  prompts are only able to take string parameters, so inputs to schemas must be
  objects with only string property values.\\n- MCP prompts only support `user`
  and `model` messages. `system` messages are not supported.\\n- MCP prompts
  only support a single \\\"type\\\" within a message so you can't mix media and
  text in the same message.\\n\\n### Testing your MCP server\\n\\nYou can test
  your MCP server using the official inspector. For example, if your server code
  compiled into `dist/index.js`, you could run:\\n\\n    npx
  @modelcontextprotocol/inspector dist/index.js\\n\\nOnce you start the
  inspector, you can list prompts and actions and test them out
  manually.\\n\",\"isRecommended\":true,\"githubStars\":2504,\"downloadCount\":\
  458,\"createdAt\":\"2025-02-17T22:27:07.661085Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T01:22:28.729123Z\"},{\"mcp\
  Id\":\"github.com/awslabs/mcp/tree/main/src/finch-mcp-server\",\"githubUrl\":\
  \"https://github.com/awslabs/mcp/tree/main/src/finch-mcp-server\",\"name\":\"\
  Finch Container Tools\",\"author\":\"awslabs\",\"description\":\"Build and
  push container images through Finch CLI, with support for ECR repositories and
  automated VM management for macOS and
  Windows.\",\"codiconIcon\":\"package\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/aws.png\",\"category\":\"virtualization\",\"tags\"\
  :[\"containers\",\"docker\",\"ecr\",\"image-building\",\"devops\"],\"requires\
  ApiKey\":false,\"readmeContent\":\"# Finch MCP Server\\n\\nA Model Context
  Protocol (MCP) server for Finch that enables generative AI models to build and
  push container images through finch cli leveraged MCP tools.\\n\\n##
  Features\\n\\nThis MCP server acts as a bridge between MCP clients and Finch,
  allowing generative AI models to build and push container images to
  repositories, and create ECR repositories as needed. The server provides a
  secure way to interact with Finch, ensuring that the Finch VM is properly
  initialized and running before performing operations.\\n\\n## Key
  Capabilities\\n\\n- Build container images using Finch\\n- Push container
  images to repositories, including Amazon ECR\\n- Check if ECR repositories
  exist and create them if needed\\n- Automatic management of the Finch VM on
  macos and windows (initialization, starting, etc.)\\n- Automatic configuration
  of ECR credential helpers when needed (only modifies finch.yaml as config.json
  is automatically handled)\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Install
  [Finch](https://github.com/runfinch/finch) on your system\\n4. For ECR
  operations, AWS credentials with permissions to push to ECR repositories and
  create/describe ECR repositories\\n\\n## Setup\\n\\n###
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.finch-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c2\
  xhYnMuZmluY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiQVdTX1BST0ZJTEUiOiJkZWZhdWx\
  0IiwiQVdTX1JFR0lPTiI6InVzLXdlc3QtMiIsIkZBU1RNQ1BfTE9HX0xFVkVMIjoiSU5GTyJ9LCJ0\
  cmFuc3BvcnRUeXBlIjoic3RkaW8iLCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3\
  D)\\n\\nConfigure the MCP server in your MCP client configuration:\\n\\n####
  Default Mode (Read-only AWS Resources)\\n\\nBy default, the server runs in a
  mode that prevents the creation of new AWS resources. This is useful for
  environments where you want to limit resource creation or for users who should
  only be able to build and push to existing
  repositories.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.finch-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.finch-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"default\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\"\\n      },\\n      \\\"transportType\\\":
  \\\"stdio\\\",\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\nIn this default mode:\\n- The
  `finch_build_container_image` tools will work normally\\n- The
  `finch_create_ecr_repo` and `finch_push_image` tool will return an error and
  will not create or modify AWS resources.\\n\\n#### AWS Resource Write
  Mode\\n\\nThe server can also be set to enable AWS resource creation and
  modification by using the `--enable-aws-resource-write`
  flag.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.finch-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.finch-mcp-server@latest\\\",\\n        \\\"--enable-a\
  ws-resource-write\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"default\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"INFO\\\"\\n      },\\n      \\\"transportType\\\":
  \\\"stdio\\\",\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n## Available Tools\\n\\n###
  `finch_build_container_image`\\n\\nBuild a container image using
  Finch.\\n\\nThe tool builds a Docker image using the specified Dockerfile and
  context directory. It supports a range of build options including tags,
  platforms, and more.\\n\\nArguments:\\n- `dockerfile_path` (str): Absolute
  path to the Dockerfile\\n- `context_path` (str): Absolute path to the build
  context directory\\n- `tags` (List[str], optional): List of tags to apply to
  the image (e.g., [\\\"myimage:latest\\\", \\\"myimage:v1\\\"])\\n- `platforms`
  (List[str], optional): List of target platforms (e.g., [\\\"linux/amd64\\\",
  \\\"linux/arm64\\\"])\\n- `target` (str, optional): Target build stage to
  build\\n- `no_cache` (bool, optional): Whether to disable cache. Defaults to
  False.\\n- `pull` (bool, optional): Whether to always pull base images.
  Defaults to False.\\n- `build_contexts` (List[str], optional): List of
  additional build contexts\\n- `outputs` (str, optional): Output
  destination\\n- `cache_from` (List[str], optional): List of external cache
  sources\\n- `quiet` (bool, optional): Whether to suppress build output.
  Defaults to False.\\n- `progress` (str, optional): Type of progress output.
  Defaults to \\\"auto\\\".\\n\\n### `finch_push_image`\\n\\nPush a container
  image to a repository using Finch, replacing the tag with the image
  hash.\\n\\nIf the image URL is an ECR repository, it verifies that ECR login
  credential helper is configured. This tool gets the image hash, creates a new
  tag using the hash, and pushes the image with the hash tag to the
  repository.\\n\\nThe workflow is:\\n1. Get the image hash using `finch image
  inspect`\\n2. Create a new tag for the image using the short form of the hash
  (first 12 characters)\\n3. Push the hash-tagged image to the
  repository\\n\\nArguments:\\n- `image` (str): The full image name to push,
  including the repository URL and tag. For ECR repositories, it must follow the
  format:
  `<aws_account_id>.dkr.ecr.<region>.amazonaws.com/<repository_name>:<tag>`\\n\
  \\nExample:\\n```\\n# Original image: myrepo/myimage:latest\\n# After
  processing: myrepo/myimage:1a2b3c4d5e6f (where 1a2b3c4d5e6f is the short
  hash)\\n```\\n\\n### `finch_create_ecr_repo`\\n\\nCheck if an ECR repository
  exists and create it if it doesn't.\\n\\nThis tool checks if the specified ECR
  repository exists using boto3. If the repository doesn't exist, it creates a
  new one with the given name with scan on push enabled and immutable tags for
  enhanced security. The tool requires appropriate AWS credentials
  configured.\\n\\n**Note:** When the server is running in readonly mode, this
  tool will return an error and will not create any AWS
  resources.\\n\\nArguments:\\n- `app_name` (str): The name of the
  application/repository to check or create in ECR\\n- `region` (str, optional):
  AWS region for the ECR repository. If not provided, uses the default region
  from AWS configuration\\n\\nExample:\\n```\\n# Check if 'my-app' repository
  exists in us-west-2 region, create it if it doesn't\\n{\\n  \\\"app_name\\\":
  \\\"my-app\\\",\\n  \\\"region\\\": \\\"us-west-2\\\"\\n}\\n\\n# Response if
  repository already exists:\\n{\\n  \\\"status\\\":
  \\\"success\\\",\\n  \\\"message\\\": \\\"ECR repository 'my-app' already
  exists.\\\",\\n}\\n\\n# Response if repository was
  created:\\n{\\n  \\\"status\\\": \\\"success\\\",\\n  \\\"message\\\":
  \\\"Successfully created ECR repository 'my-app'.\\\",\\n}\\n\\n# Response if
  server is in readonly mode:\\n{\\n  \\\"status\\\":
  \\\"error\\\",\\n  \\\"message\\\": \\\"Server running in read-only mode,
  unable to perform the action\\\"\\n}\\n```\\n\\n## Best Practices\\n\\n-
  **Development and Prototyping Only**: The tools provided by this MCP server
  are intended for development and prototyping purposes only. They are not meant
  for production use cases.\\n- **Security Considerations**: Always review the
  Dockerfiles and container configurations before building and pushing
  images.\\n- **Resource Management**: Regularly clean up unused images and
  containers to free up disk space.\\n- **Version Control**: Keep track of image
  versions and tags to ensure reproducibility.\\n- **Error Handling**: Implement
  proper error handling in your applications when using these tools.\\n\\n\\n##
  Troubleshooting\\n\\n- If you encounter permission errors with ECR, verify
  your AWS credentials and boto3 configuration are properly set up\\n- For Finch
  VM issues, try running `finch vm stop` and then `finch vm start` manually\\n-
  If the build fails with errors about missing files, check that your context
  path is correct\\n- For general Finch issues, consult the [Finch
  documentation](https://github.com/runfinch/finch)\\n\\n## Version\\n\\nCurrent
  MCP server version:
  0.1.0\\n\",\"isRecommended\":false,\"githubStars\":4361,\"downloadCount\":22,\
  \"createdAt\":\"2025-06-21T01:45:37.779967Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-03T21:53:42.164056Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/amazon-mq-mcp-server\",\"githubUrl\":\
  \"https://github.com/awslabs/mcp/tree/main/src/amazon-mq-mcp-server\",\"name\
  \":\"Amazon MQ\",\"author\":\"awslabs\",\"description\":\"Enables management
  of RabbitMQ and ActiveMQ message brokers through Amazon MQ, providing secure
  broker creation, configuration, and administration
  capabilities.\",\"codiconIcon\":\"server\",\"logoUrl\":\"https://storage.goog\
  leapis.com/cline_public_images/aws.png\",\"category\":\"cloud-platforms\",\"t\
  ags\":[\"message-brokers\",\"aws\",\"rabbitmq\",\"activemq\",\"cloud-messaging\
  \"],\"requiresApiKey\":false,\"readmeContent\":\"# Amazon MQ MCP Server\\n\\nA
  Model Context Protocol (MCP) server for Amazon MQ that enables generative AI
  models to manage RabbitMQ and ActiveMQ message brokers through MCP
  tools.\\n\\n## Features\\n\\nThis MCP server acts as a **bridge** between MCP
  clients and Amazon MQ, allowing generative AI models to create, configure, and
  manage message brokers. The server provides a secure way to interact with
  Amazon MQ resources while maintaining proper access controls and resource
  tagging.\\n\\n```mermaid\\ngraph LR\\n    A[Model] <--> B[MCP Client]\\n    B
  <--> C[\\\"Amazon MQ MCP Server\\\"]\\n    C <--> D[Amazon MQ Service]\\n    D
  --> E[RabbitMQ Brokers]\\n    D --> F[ActiveMQ Brokers]\\n\\n    style A
  fill:#f9f,stroke:#333,stroke-width:2px\\n    style B
  fill:#bbf,stroke:#333,stroke-width:2px\\n    style C
  fill:#bfb,stroke:#333,stroke-width:4px\\n    style D
  fill:#fbb,stroke:#333,stroke-width:2px\\n    style E
  fill:#fbf,stroke:#333,stroke-width:2px\\n    style F
  fill:#dff,stroke:#333,stroke-width:2px\\n```\\n\\nFrom a **security**
  perspective, this server implements resource tagging to ensure that only
  resources created through the MCP server can be modified by it. This prevents
  unauthorized modifications to existing Amazon MQ resources that were not
  created by the MCP server.\\n\\n## Key Capabilities\\n\\n- Create and manage
  Amazon MQ brokers (RabbitMQ and ActiveMQ)\\n- Configure broker settings and
  parameters\\n- List and describe existing brokers\\n- Reboot and update
  brokers\\n- Create and manage broker configurations\\n- Automatic resource
  tagging for security\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. AWS account with permissions to
  create and manage Amazon MQ resources\\n\\n## Setup\\n\\n### IAM
  Configuration\\n\\nThe authorization between AmazonMQ MCP server and your AWS
  accounts are performed with AWS profile you setup on the host. There are
  several ways to setup a AWS profile, however we recommend creating a new IAM
  role that has `AmazonMQReadOnlyAccess` permission following the principle of
  \\\"least privilege\\\". Note, if you want to use tools that mutate your
  tagged resources, you need to grant `AmazonMQFullAccess`. Finally, configure a
  AWS profile on the host that assumes the new role (for more information, check
  out the [AWS CLI help
  page](https://docs.aws.amazon.com/cli/v1/userguide/cli-configure-role.html)).\
  \\n\\n### Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.amazon-mq-mcp-server&config=eyJjb21tYW5kIjoidXZ4IG\
  F3c2xhYnMuYW1hem9uLW1xLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9GSUxFIjo\
  ieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEifX0%3D)\\n\\nConfigu\
  re the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.amazon-mq-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.amazon-mq-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nIf you would like to
  specify a flag (for example, to allow creation of resources), you can pass it
  to the args\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.amazon-mq-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.amazon-mq-mcp-server@latest\\\",
  \\\"--allow-resource-creation\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n\\nor docker after a
  successful `docker build -t awslabs/amazon-mq-mcp-server .`:\\n\\n```file\\n#
  fictitious `.env` file with AWS temporary
  credentials\\nAWS_ACCESS_KEY_ID=<from the profile you set
  up>\\nAWS_SECRET_ACCESS_KEY=<from the profile you set
  up>\\nAWS_SESSION_TOKEN=<from the profile you set
  up>\\n```\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.amazon-mq-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env-file\\\",\\n          \\\"/full/path/to/file\
  /above/.env\\\",\\n          \\\"awslabs/amazon-mq-mcp-server:latest\\\"\\n        \
  ],\\n        \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n      }\\n    }\\n  }\\n```\\n##
  Server Configuration Options\\n\\nThe Amazon MQ MCP Server supports several
  command-line arguments that can be used to configure its behavior:\\n\\n###
  `--allow-resource-creation`\\n\\nAllow tools that create resources in the
  user's AWS account. When this flag is enabled, the `create_broker` and
  `create_configuration` tools will be created for the MCP client, preventing
  the creation of new Amazon MQ resources. Default is False.\\n\\nThis flag is
  particularly useful for:\\n- Testing environments where resource creation
  should be restricted\\n- Limiting the scope of actions available to the AI
  model\\n\\nExample:\\n```bash\\nuv run awslabs.amazon-mq-mcp-server
  --allow-resource-creation\\n```\\n\\n### Security Features\\n\\nThe MCP server
  implements a security mechanism that only allows modification of resources
  that were created by the MCP server itself. This is achieved by:\\n\\n1.
  Automatically tagging all created resources with a `mcp_server_version`
  tag\\n2. Validating this tag before allowing any mutative actions (update,
  delete, reboot)\\n3. Rejecting operations on resources that don't have the
  appropriate tag\\n\\n## Best Practices\\n\\n- Use descriptive broker names to
  easily identify resources\\n- Follow the principle of least privilege when
  setting up IAM permissions\\n- Use separate AWS profiles for different
  environments (dev, test, prod)\\n- Monitor broker metrics and logs for
  performance and issues\\n- Implement proper error handling in your client
  applications\\n\\n## Security Considerations\\n\\nWhen using this MCP server,
  consider:\\n\\n- The MCP server needs permissions to create and manage Amazon
  MQ resources\\n- Only resources created by the MCP server can be modified by
  it\\n- Ensure proper network security for your brokers (use
  `publicly_accessible: false` when possible)\\n- Implement strong
  authentication for broker users\\n- Review and rotate credentials
  regularly\\n\\n## Troubleshooting\\n\\n- If you encounter permission errors,
  verify your IAM user has the correct policies attached\\n- For connection
  issues, check network configurations and security groups\\n- If resource
  modification fails with a tag validation error, it means the resource was not
  created by the MCP server\\n- For general Amazon MQ issues, consult the
  [Amazon MQ documentation](https://docs.aws.amazon.com/amazon-mq/)\\n\\n##
  Version\\n\\nCurrent MCP server version:
  1.0.0\\n\",\"isRecommended\":false,\"githubStars\":4397,\"downloadCount\":12,\
  \"createdAt\":\"2025-06-21T01:57:44.25607Z\",\"updatedAt\":\"2025-07-08T01:10\
  :48.398933Z\",\"lastGithubSync\":\"2025-07-06T10:53:36.412372Z\"},{\"mcpId\":\
  \"github.com/hyperbrowserai/mcp\",\"githubUrl\":\"https://github.com/hyperbro\
  wserai/mcp\",\"name\":\"Hyperbrowser\",\"author\":\"hyperbrowserai\",\"descri\
  ption\":\"Advanced web automation server providing tools for web scraping,
  structured data extraction, and browser automation with support for multiple
  AI agents including OpenAI's CUA and Claude's Computer
  Use.\",\"codiconIcon\":\"browser\",\"logoUrl\":\"https://storage.googleapis.c\
  om/cline_public_images/hyperbrowser.png\",\"category\":\"browser-automation\",\
  \"tags\":[\"web-scraping\",\"browser-automation\",\"data-extraction\",\"web-c\
  rawling\",\"search\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Hyperbrowser MCP Server\\n[![smithery
  badge](https://smithery.ai/badge/@hyperbrowserai/mcp)](https://smithery.ai/se\
  rver/@hyperbrowserai/mcp)\\n\\n![Frame
  5](https://github.com/user-attachments/assets/3309a367-e94b-418a-a047-1bf1ad5\
  49c0a)\\n\\nThis is Hyperbrowser's Model Context Protocol (MCP) Server. It
  provides various tools to scrape, extract structured data, and crawl webpages.
  It also provides easy access to general purpose browser agents like OpenAI's
  CUA, Anthropic's Claude Computer Use, and Browser Use.\\n\\nMore information
  about the Hyperbrowser can be found [here](https://docs.hyperbrowser.ai/). The
  hyperbrowser API supports a superset of features present in the mcp
  server.\\n\\nMore information about the Model Context Protocol can be found
  [here](https://modelcontextprotocol.io/introduction).\\n\\n## Table of
  Contents\\n\\n- [Installation](#installation)\\n- [Usage](#usage)\\n-
  [Tools](#tools)\\n- [Configuration](#configuration)\\n-
  [License](#license)\\n\\n## Installation\\n\\n### Manual Installation\\nTo
  install the server, run:\\n\\n```bash\\nnpx hyperbrowser-mcp
  <YOUR-HYPERBROWSER-API-KEY>\\n```\\n\\n## Running on Cursor\\nAdd to
  `~/.cursor/mcp.json` like this:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"hyperbrowser\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"hyperbrowser-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"HYPERBROWSER_API_KEY\\\":
  \\\"YOUR-API-KEY\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Running on
  Windsurf\\nAdd to your `./codeium/windsurf/model_config.json` like
  this:\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"hyperbrowser\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\",
  \\\"hyperbrowser-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"HYPERBROWSER_API_KEY\\\":
  \\\"YOUR-API-KEY\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n###
  Development\\n\\nFor development purposes, you can run the server directly
  from the source code.\\n\\n1. Clone the repository:\\n\\n   ```sh\\n   git
  clone git@github.com:hyperbrowserai/mcp.git hyperbrowser-mcp\\n   cd
  hyperbrowser-mcp\\n   ```\\n\\n2. Install dependencies:\\n\\n   ```sh\\n   npm
  install # or yarn install\\n   npm run build\\n   ```\\n\\n3. Run the
  server:\\n\\n   ```sh\\n   node dist/server.js\\n   ```\\n\\n## Claude Desktop
  app\\nThis is an example config for the Hyperbrowser MCP server for the Claude
  Desktop client.\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"hyperbrowser\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\": [\\\"--yes\\\",
  \\\"hyperbrowser-mcp\\\"],\\n      \\\"env\\\":
  {\\n        \\\"HYPERBROWSER_API_KEY\\\":
  \\\"your-api-key\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n\\n## Tools\\n*
  `scrape_webpage` - Extract formatted (markdown, screenshot etc) content from
  any webpage \\n* `crawl_webpages` - Navigate through multiple linked pages and
  extract LLM-friendly formatted content\\n* `extract_structured_data` - Convert
  messy HTML into structured JSON\\n* `search_with_bing` - Query the web and get
  results with Bing search\\n* `browser_use_agent` - Fast, lightweight browser
  automation with the Browser Use agent\\n* `openai_computer_use_agent` -
  General-purpose automation using OpenAIs CUA model\\n*
  `claude_computer_use_agent` - Complex browser tasks using Claude computer
  use\\n* `create_profile` - Creates a new persistent Hyperbrowser profile.\\n*
  `delete_profile` - Deletes an existing persistent Hyperbrowser profile.\\n*
  `list_profiles` - Lists existing persistent Hyperbrowser profiles.\\n\\n###
  Installing via Smithery\\n\\nTo install Hyperbrowser MCP Server for Claude
  Desktop automatically via
  [Smithery](https://smithery.ai/server/@hyperbrowserai/mcp):\\n\\n```bash\\nnpx
  -y @smithery/cli install @hyperbrowserai/mcp --client claude\\n```\\n\\n##
  Resources\\n\\nThe server provides the documentation about hyperbrowser
  through the `resources` methods. Any client which can do discovery over
  resources has access to it.\\n\\n## License\\n\\nThis project is licensed
  under the MIT
  License.\\n\",\"isRecommended\":false,\"githubStars\":375,\"downloadCount\":3\
  219,\"createdAt\":\"2025-04-02T02:03:55.398324Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T22:10:57.563395Z\"},{\"mcp\
  Id\":\"github.com/Flux159/mcp-server-kubernetes\",\"githubUrl\":\"https://git\
  hub.com/Flux159/mcp-server-kubernetes\",\"name\":\"Kubernetes\",\"author\":\"\
  Flux159\",\"description\":\"Connects to and manages Kubernetes clusters,
  enabling pod, service, and deployment operations through kubectl
  integration.\",\"codiconIcon\":\"server-environment\",\"logoUrl\":\"https://s\
  torage.googleapis.com/cline_public_images/kubernetes.png\",\"category\":\"vir\
  tualization\",\"tags\":[\"kubernetes\",\"containers\",\"cluster-management\",\
  \"kubectl\",\"deployments\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  MCP Server
  Kubernetes\\n\\n[![CI](https://github.com/Flux159/mcp-server-kubernetes/actio\
  ns/workflows/ci.yml/badge.svg)](https://github.com/yourusername/mcp-server-ku\
  bernetes/actions/workflows/ci.yml)\\n[![Language](https://img.shields.io/gith\
  ub/languages/top/Flux159/mcp-server-kubernetes)](https://github.com/yourusern\
  ame/mcp-server-kubernetes)\\n[![Bun](https://img.shields.io/badge/runtime-bun\
  -orange)](https://bun.sh)\\n[![Kubernetes](https://img.shields.io/badge/kuber\
  netes-%23326ce5.svg?style=flat&logo=kubernetes&logoColor=white)](https://kube\
  rnetes.io/)\\n[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?st\
  yle=flat&logo=docker&logoColor=white)](https://www.docker.com/)\\n[![Stars](h\
  ttps://img.shields.io/github/stars/Flux159/mcp-server-kubernetes)](https://gi\
  thub.com/Flux159/mcp-server-kubernetes/stargazers)\\n[![Issues](https://img.s\
  hields.io/github/issues/Flux159/mcp-server-kubernetes)](https://github.com/Fl\
  ux159/mcp-server-kubernetes/issues)\\n[![PRs
  Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://g\
  ithub.com/Flux159/mcp-server-kubernetes/pulls)\\n[![Last
  Commit](https://img.shields.io/github/last-commit/Flux159/mcp-server-kubernet\
  es)](https://github.com/Flux159/mcp-server-kubernetes/commits/main)\\n[![smit\
  hery
  badge](https://smithery.ai/badge/mcp-server-kubernetes)](https://smithery.ai/\
  protocol/mcp-server-kubernetes)\\n\\nMCP Server that can connect to a
  Kubernetes cluster and manage it. Supports loading kubeconfig from multiple
  sources in priority
  order.\\n\\nhttps://github.com/user-attachments/assets/f25f8f4e-4d04-479b-9ae\
  0-5dac452dd2ed\\n\\n<a
  href=\\\"https://glama.ai/mcp/servers/w71ieamqrt\\\"><img width=\\\"380\\\"
  height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/w71ieamqrt/badge\\\"
  /></a>\\n\\n## Usage with Claude
  Desktop\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"kubernetes\\\":
  {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-kubernetes\\\"]\\n    }\\n  }\\n}\\n```\\n\\nBy default, the
  server loads kubeconfig from `~/.kube/config`. For additional authentication
  options (environment variables, custom paths, etc.), see
  [ADVANCED_README.md](ADVANCED_README.md).\\n\\nThe server will automatically
  connect to your current kubectl context. Make sure you have:\\n\\n1. kubectl
  installed and in your PATH\\n2. A valid kubeconfig file with contexts
  configured\\n3. Access to a Kubernetes cluster configured for kubectl (e.g.
  minikube, Rancher Desktop, GKE, etc.)\\n4. Helm v3 installed and in your PATH
  (no Tiller required). Optional if you don't plan to use Helm.\\n\\nYou can
  verify your connection by asking Claude to list your pods or create a test
  deployment.\\n\\nIf you have errors open up a standard terminal and run
  `kubectl get pods` to see if you can connect to your cluster without
  credentials issues.\\n\\n## Usage with
  mcp-chat\\n\\n[mcp-chat](https://github.com/Flux159/mcp-chat) is a CLI chat
  client for MCP servers. You can use it to interact with the Kubernetes
  server.\\n\\n```shell\\nnpx mcp-chat --server \\\"npx
  mcp-server-kubernetes\\\"\\n```\\n\\nAlternatively, pass it your existing
  Claude Desktop configuration file from above (Linux should pass the correct
  path to config):\\n\\nMac:\\n\\n```shell\\nnpx mcp-chat --config
  \\\"~/Library/Application
  Support/Claude/claude_desktop_config.json\\\"\\n```\\n\\nWindows:\\n\\n```she\
  ll\\nnpx mcp-chat --config
  \\\"%APPDATA%\\\\Claude\\\\claude_desktop_config.json\\\"\\n```\\n\\n##
  Features\\n\\n- [x] Connect to a Kubernetes cluster\\n- [x] Unified kubectl
  API for managing resources\\n  - Get or list resources with
  `kubectl_get`\\n  - Describe resources with `kubectl_describe`\\n  - List
  resources with `kubectl_get`\\n  - Create resources with
  `kubectl_create`\\n  - Apply YAML manifests with `kubectl_apply`\\n  - Delete
  resources with `kubectl_delete`\\n  - Get logs with `kubectl_logs`\\n  -
  Manage kubectl contexts with `kubectl_context`\\n  - Explain Kubernetes
  resources with `explain_resource`\\n  - List API resources with
  `list_api_resources`\\n  - Scale resources with `kubectl_scale`\\n  - Update
  field(s) of a resource with `kubectl_patch`\\n  - Manage deployment rollouts
  with `kubectl_rollout`\\n  - Execute any kubectl command with
  `kubectl_generic`\\n  - Verify connection with `ping`\\n- [x] Advanced
  operations\\n  - Scale deployments with `kubectl_scale` (replaces legacy
  `scale_deployment`)\\n  - Port forward to pods and services with
  `port_forward`\\n  - Run Helm operations\\n    - Install, upgrade, and
  uninstall charts\\n    - Support for custom values, repositories, and
  versions\\n- [x] Troubleshooting Prompt (`k8s-diagnose`)\\n  - Guides through
  a systematic Kubernetes troubleshooting flow for pods based on a keyword and
  optional namespace.\\n- [x] Non-destructive mode for read and
  create/update-only access to clusters\\n\\n## Prompts\\n\\nThe MCP Kubernetes
  server includes specialized prompts to assist with common diagnostic
  operations.\\n\\n### k8s-diagnose Prompt\\n\\nThis prompt provides a
  systematic troubleshooting flow for Kubernetes pods. It accepts a `keyword` to
  identify relevant pods and an optional `namespace` to narrow the search.\\nThe
  prompt's output will guide you through an autonomous troubleshooting flow,
  providing instructions for identifying issues, collecting evidence, and
  suggesting remediation steps.\\n\\n## Local Development\\n\\nMake sure that
  you have [bun installed](https://bun.sh/docs/installation). Clone the repo &
  install dependencies:\\n\\n```bash\\ngit clone
  https://github.com/Flux159/mcp-server-kubernetes.git\\ncd
  mcp-server-kubernetes\\nbun install\\n```\\n\\n### Development
  Workflow\\n\\n1. Start the server in development mode (watches for file
  changes):\\n\\n```bash\\nbun run dev\\n```\\n\\n2. Run unit
  tests:\\n\\n```bash\\nbun run test\\n```\\n\\n3. Build the
  project:\\n\\n```bash\\nbun run build\\n```\\n\\n4. Local Testing with
  [Inspector](https://github.com/modelcontextprotocol/inspector)\\n\\n```bash\\\
  nnpx @modelcontextprotocol/inspector node dist/index.js\\n# Follow further
  instructions on terminal for Inspector link\\n```\\n\\n5. Local testing with
  Claude Desktop\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"mcp-server-kubernetes\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/your/mcp-server-kubernetes/dist/index.js\\\"]\\n    }\\n  }\\n}\
  \\n```\\n\\n6. Local testing with
  [mcp-chat](https://github.com/Flux159/mcp-chat)\\n\\n```bash\\nbun run
  chat\\n```\\n\\n## Contributing\\n\\nSee the
  [CONTRIBUTING.md](CONTRIBUTING.md) file for details.\\n\\n## Advanced\\n\\n###
  Non-Destructive Mode\\n\\nYou can run the server in a non-destructive mode
  that disables all destructive operations (delete pods, delete deployments,
  delete namespaces,
  etc.):\\n\\n```shell\\nALLOW_ONLY_NON_DESTRUCTIVE_TOOLS=true npx
  mcp-server-kubernetes\\n```\\n\\nFor Claude Desktop configuration with
  non-destructive mode:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"kubernetes-readonly\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-kubernetes\\\"],\\n      \\\"env\\\":
  {\\n        \\\"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\\\":
  \\\"true\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Commands Available in
  Non-Destructive Mode\\n\\nAll read-only and resource creation/update
  operations remain available:\\n\\n- Resource Information: `kubectl_get`,
  `kubectl_describe`, `kubectl_logs`, `explain_resource`,
  `list_api_resources`\\n- Resource Creation/Modification: `kubectl_apply`,
  `kubectl_create`, `kubectl_scale`, `kubectl_patch`, `kubectl_rollout`\\n- Helm
  Operations: `install_helm_chart`, `upgrade_helm_chart`\\n- Connectivity:
  `port_forward`, `stop_port_forward`\\n- Context Management:
  `kubectl_context`\\n\\n### Commands Disabled in Non-Destructive Mode\\n\\nThe
  following destructive operations are disabled:\\n\\n- `kubectl_delete`:
  Deleting any Kubernetes resources\\n- `uninstall_helm_chart`: Uninstalling
  Helm charts\\n- `cleanup`: Cleanup of managed resources\\n- `kubectl_generic`:
  General kubectl command access (may include destructive operations)\\n\\nFor
  additional advanced features, see the
  [ADVANCED_README.md](ADVANCED_README.md).\\n\\n## Architecture\\n\\nSee this
  [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more
  indepth architecture overview created by Devin.\\n\\nThis section describes
  the high-level architecture of the MCP Kubernetes server.\\n\\n### Request
  Flow\\n\\nThe sequence diagram below illustrates how requests flow through the
  system:\\n\\n```mermaid\\nsequenceDiagram\\n    participant
  Client\\n    participant Transport as Transport Layer\\n    participant Server
  as MCP Server\\n    participant Filter as Tool Filter\\n    participant
  Handler as Request Handler\\n    participant K8sManager as
  KubernetesManager\\n    participant K8s as Kubernetes API\\n\\n    Note over
  Transport: StdioTransport or<br>SSE Transport\\n\\n    Client->>Transport:
  Send Request\\n    Transport->>Server: Forward Request\\n\\n    alt Tools
  Request\\n        Server->>Filter: Filter available tools\\n        Note over
  Filter: Remove destructive tools<br>if in non-destructive
  mode\\n        Filter->>Handler: Route to tools handler\\n\\n        alt
  kubectl operations\\n            Handler->>K8sManager: Execute kubectl
  operation\\n            K8sManager->>K8s: Make API call\\n        else Helm
  operations\\n            Handler->>K8sManager: Execute Helm
  operation\\n            K8sManager->>K8s: Make API call\\n        else Port
  Forward operations\\n            Handler->>K8sManager: Set up port
  forwarding\\n            K8sManager->>K8s: Make API
  call\\n        end\\n\\n        K8s-->>K8sManager: Return
  result\\n        K8sManager-->>Handler: Process
  response\\n        Handler-->>Server: Return tool result\\n    else Resource
  Request\\n        Server->>Handler: Route to resource
  handler\\n        Handler->>K8sManager: Get resource
  data\\n        K8sManager->>K8s: Query API\\n        K8s-->>K8sManager: Return
  data\\n        K8sManager-->>Handler: Format
  response\\n        Handler-->>Server: Return resource
  data\\n    end\\n\\n    Server-->>Transport: Send
  Response\\n    Transport-->>Client: Return Final Response\\n```\\n\\nSee this
  [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more
  indepth architecture overview created by Devin.\\n\\n## Publishing new
  release\\n\\nGo to the [releases
  page](https://github.com/Flux159/mcp-server-kubernetes/releases), click on
  \\\"Draft New Release\\\", click \\\"Choose a tag\\\" and create a new tag by
  typing out a new version number using \\\"v{major}.{minor}.{patch}\\\" semver
  format. Then, write a release title \\\"Release v{major}.{minor}.{patch}\\\"
  and description / changelog if necessary and click \\\"Publish
  Release\\\".\\n\\nThis will create a new tag which will trigger a new release
  build via the cd.yml workflow. Once successful, the new release will be
  published to [npm](https://www.npmjs.com/package/mcp-server-kubernetes). Note
  that there is no need to update the package.json version manually, as the
  workflow will automatically update the version number in the package.json file
  & push a commit to main.\\n\\n## Not planned\\n\\nAdding clusters to
  kubectx.\\n\",\"isRecommended\":false,\"githubStars\":814,\"downloadCount\":1\
  741,\"createdAt\":\"2025-02-17T22:30:26.383193Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T02:35:41.608954Z\"},{\"mcp\
  Id\":\"github.com/Garoth/sleep-mcp\",\"githubUrl\":\"https://github.com/Garot\
  h/sleep-mcp\",\"name\":\"Sleep\",\"author\":\"Garoth\",\"description\":\"Prov\
  ides timing control with configurable delays between operations, useful for
  rate limiting, API call spacing, and testing eventually consistent
  systems.\",\"codiconIcon\":\"clock\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/sleep.png\",\"category\":\"developer-tools\",\"tags\
  \":[\"timing\",\"rate-limiting\",\"delays\",\"testing\",\"automation\"],\"req\
  uiresApiKey\":false,\"readmeContent\":\"# Sleep MCP Server\\n\\n<img
  src=\\\"assets/sleep-server.png\\\" width=\\\"256\\\" alt=\\\"Sleep MCP
  Logo\\\" />\\n\\nA Model Context Protocol (MCP) server that provides a simple
  sleep/wait tool. Useful for adding delays between operations, such as waiting
  between API calls or testing eventually consistent systems.\\n\\n## Available
  Tools\\n\\n- `sleep`: Wait for a specified duration in milliseconds\\n\\n##
  Installation\\n\\n```bash\\ngit clone
  https://github.com/Garoth/sleep-mcp.git\\nnpm install\\n```\\n\\n##
  Configuration\\n\\nAdd to your Cline MCP settings file (ex.
  ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_s\
  ettings.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"sleep\\\":
  {\\n      \\\"command\\\": \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/sleep-server/build/index.js\\\"],\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": [],\\n      \\\"timeout\\\":
  300\\n    }\\n  }\\n}\\n```\\n\\n> **Note:** The `timeout` parameter specifies
  the maximum time (in milliseconds) that the MCP server will wait for a
  response before timing out. This is particularly important for the sleep tool,
  as setting a timeout that's shorter than your sleep duration will cause the
  operation to fail. Make sure your timeout value is always greater than the
  maximum sleep duration you plan to use.\\n\\n## Development\\n\\n### Setting
  Up Tests\\n\\nThe tests verify the sleep functionality with various
  durations:\\n\\n```bash\\nnpm test\\n```\\n\\n### Building\\n\\n```bash\\nnpm
  run build\\n```\\n\\n##
  License\\n\\nMIT\\n\",\"isRecommended\":false,\"githubStars\":12,\"downloadCo\
  unt\":3228,\"createdAt\":\"2025-02-23T01:49:49.815207Z\",\"updatedAt\":\"2025\
  -07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-04T10:35:40.959401Z\"}\
  ,{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/valkey-mcp-server\",\"gith\
  ubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/valkey-mcp-server\",\"\
  name\":\"Valkey\",\"author\":\"awslabs\",\"description\":\"Interact with
  Amazon ElastiCache and MemoryDB Valkey datastores, supporting multiple data
  types like strings, lists, sets, hashes, streams, and JSON documents with
  advanced features like clustering and SSL/TLS
  security.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\
  \"cache\",\"redis\",\"aws\",\"datastore\",\"key-value\"],\"requiresApiKey\":f\
  alse,\"readmeContent\":\"# Amazon ElastiCache/MemoryDB Valkey MCP
  Server\\n\\nAn AWS Labs Model Context Protocol (MCP) server for Amazon
  ElastiCache [Valkey](https://valkey.io/) datastores.\\n\\n## Features\\nThis
  MCP server provides tools to operate on Valkey data types. For example, it
  allows an agent to operate with Valkey Strings using commands such as SET,
  SETRANGE, GET, GETRANGE, APPEND, INCREMENT and more.\\n\\n### Supported Data
  Types\\n- `Strings`- Store, retrieve, append, increment, decrement, length and
  more.\\n- `Lists`- Manage List collections with push/pop operations.\\n- `Sets
  and Sorted Sets`- Store and retrieve items from Sets.\\n- `Hashes`- Store and
  retrieve items in Hashes. Check for existence of items in a hash, increment
  item values in a Hash, and more.\\n- `Streams`- Store, retrieve, trim items in
  Streams.\\n- `Bitmaps`- Bitmaps let you perform bitwise operations on
  strings.\\n- `JSONs`- Store and retrieve JSON documents with path-based
  access.\\n- `HyperLogLog`- Store and count items in HyperLogs.\\n\\n###
  Advanced Features\\n- **Cluster Support**: Support for standalone and
  clustered Valkey deployments.\\n- **SSL/TLS Security**: Configure secure
  connections using SSL/TLS.\\n- **Connection Pooling**: Pools connections by
  default to enable efficient connection management.\\n- **Readonly Mode**:
  Prevent write operations to ensure data safety.\\n\\n## Prerequisites\\n\\n1.
  Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Access to a Valkey datastore.\\n4.
  For instructions to connect to an Amazon ElastiCache/MemoryDB Valkey datastore
  [click
  here](https://github.com/awslabs/mcp/blob/main/src/valkey-mcp-server/ELASTICA\
  CHECONNECT.md).\\n\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.valkey-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF3c\
  2xhYnMudmFsa2V5LW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IlZBTEtFWV9IT1NUIjoiMTI3Lj\
  AuMC4xIiwiVkFMS0VZX1BPUlQiOiI2Mzc5IiwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJ\
  hdXRvQXBwcm92ZSI6W10sImRpc2FibGVkIjpmYWxzZX0%3D)\\n\\nHere are some ways you
  can work with MCP across AWS tools (e.g., for Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.valkey-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.valkey-mcp-server@latest\\\"\\n      ],\\n      \\\"e\
  nv\\\": {\\n        \\\"VALKEY_HOST\\\":
  \\\"127.0.0.1\\\",\\n        \\\"VALKEY_PORT\\\":
  \\\"6379\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"autoApprove\\\":
  [],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\nTo run in
  readonly mode:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.valkey-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.valkey-mcp-server@latest\\\",\\n        \\\"--readonly\
  \\\"\\n      ],\\n      \\\"env\\\": {\\n        \\\"VALKEY_HOST\\\":
  \\\"127.0.0.1\\\",\\n        \\\"VALKEY_PORT\\\":
  \\\"6379\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"autoApprove\\\":
  [],\\n      \\\"disabled\\\": false\\n    }\\n  }\\n}\\n```\\n\\nOr using
  Docker after a successful `docker build -t awslabs/valkey-mcp-server
  .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.valkey-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"VALKEY_HOST=127.0.0.1\\\",\\n        \\\"--env\\\
  \",\\n        \\\"VALKEY_PORT=6379\\\",\\n        \\\"awslabs/valkey-mcp-serv\
  er:latest\\\"\\n      ],\\n      \\\"env\\\": {},\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nTo run in
  readonly mode with Docker:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.valkey-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"--interactive\\\
  \",\\n        \\\"--env\\\",\\n        \\\"FASTMCP_LOG_LEVEL=ERROR\\\",\\n        \
  \\\"--env\\\",\\n        \\\"VALKEY_HOST=127.0.0.1\\\",\\n        \\\"--env\\\
  \",\\n        \\\"VALKEY_PORT=6379\\\",\\n        \\\"awslabs/valkey-mcp-serv\
  er:latest\\\",\\n        \\\"--readonly\\\"\\n      ],\\n      \\\"env\\\":
  {},\\n      \\\"disabled\\\": false,\\n      \\\"autoApprove\\\":
  []\\n    }\\n  }\\n}\\n```\\n\\n## Configuration\\n\\nThe server can be
  configured using the following environment variables:\\n\\n| Name |
  Description | Default Value |\\n|------|-------------|---------------|\\n|
  `VALKEY_HOST` | ElastiCache Primary Endpoint or MemoryDB Cluster Endpoint or
  Valkey IP or hostname | `\\\"127.0.0.1\\\"` |\\n| `VALKEY_PORT` | Valkey port
  | `6379` |\\n| `VALKEY_USERNAME` | Default database username | `None` |\\n|
  `VALKEY_PWD` | Default database password | `\\\"\\\"` |\\n| `VALKEY_USE_SSL` |
  Enables or disables SSL/TLS | `False` |\\n| `VALKEY_CA_PATH` | CA certificate
  for verifying server | `None` |\\n| `VALKEY_SSL_KEYFILE` | Client's private
  key file | `None` |\\n| `VALKEY_SSL_CERTFILE` | Client's certificate file |
  `None` |\\n| `VALKEY_CERT_REQS` | Server certificate verification |
  `\\\"required\\\"` |\\n| `VALKEY_CA_CERTS` | Path to trusted CA certificates |
  `None` |\\n| `VALKEY_CLUSTER_MODE` | Enable Valkey Cluster mode | `False`
  |\\n\\n## Example Usage\\n\\nHere are some example natural language queries
  that the server can handle:\\n\\n```\\n\\\"Store user profile data in a
  hash\\\"\\n\\\"Add this event to the activity stream\\\"\\n\\\"Cache API
  response for 5 minutes\\\"\\n\\\"Store JSON document with nested
  fields\\\"\\n\\\"Add score 100 to user123 in leaderboard\\\"\\n\\\"Get all
  members of the admins set\\\"\\n```\\n\\n## Development\\n\\n### Running
  Tests\\n```bash\\nuv venv\\nsource .venv/bin/activate\\nuv sync\\nuv run
  --frozen pytest\\n```\\n\\n### Building Docker Image\\n```bash\\ndocker build
  -t awslabs/valkey-mcp-server .\\n```\\n\\n### Running Docker
  Container\\n```bash\\ndocker run -p 8080:8080 \\\\\\n  -e
  VALKEY_HOST=host.docker.internal \\\\\\n  -e VALKEY_PORT=6379
  \\\\\\n  awslabs/valkey-mcp-server\\n```\\n\\nTo run in readonly
  mode:\\n```bash\\ndocker run -p 8080:8080 \\\\\\n  -e
  VALKEY_HOST=host.docker.internal \\\\\\n  -e VALKEY_PORT=6379
  \\\\\\n  awslabs/valkey-mcp-server
  --readonly\\n```\\n\",\"isRecommended\":false,\"githubStars\":4307,\"download\
  Count\":8,\"createdAt\":\"2025-06-21T01:34:59.520214Z\",\"updatedAt\":\"2025-\
  07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T19:24:48.020814Z\"},{\
  \"mcpId\":\"github.com/modelcontextprotocol/servers/tree/main/src/sequentialt\
  hinking\",\"githubUrl\":\"https://github.com/modelcontextprotocol/servers/tre\
  e/main/src/sequentialthinking\",\"name\":\"Sequential
  Thinking\",\"author\":\"modelcontextprotocol\",\"description\":\"A structured
  problem-solving tool that enables step-by-step analysis, thought revision, and
  branching logic for complex reasoning
  tasks.\",\"codiconIcon\":\"brain\",\"logoUrl\":\"https://storage.googleapis.c\
  om/cline_public_images/sequential-thinking.png\",\"category\":\"knowledge-mem\
  ory\",\"tags\":[\"problem-solving\",\"reasoning\",\"analysis\",\"structured-t\
  hinking\",\"decision-making\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  Sequential Thinking MCP Server\\n\\nAn MCP server implementation that provides
  a tool for dynamic and reflective problem-solving through a structured
  thinking process.\\n\\n## Features\\n\\n- Break down complex problems into
  manageable steps\\n- Revise and refine thoughts as understanding deepens\\n-
  Branch into alternative paths of reasoning\\n- Adjust the total number of
  thoughts dynamically\\n- Generate and verify solution hypotheses\\n\\n##
  Tool\\n\\n### sequential_thinking\\n\\nFacilitates a detailed, step-by-step
  thinking process for problem-solving and analysis.\\n\\n**Inputs:**\\n-
  `thought` (string): The current thinking step\\n- `nextThoughtNeeded`
  (boolean): Whether another thought step is needed\\n- `thoughtNumber`
  (integer): Current thought number\\n- `totalThoughts` (integer): Estimated
  total thoughts needed\\n- `isRevision` (boolean, optional): Whether this
  revises previous thinking\\n- `revisesThought` (integer, optional): Which
  thought is being reconsidered\\n- `branchFromThought` (integer, optional):
  Branching point thought number\\n- `branchId` (string, optional): Branch
  identifier\\n- `needsMoreThoughts` (boolean, optional): If more thoughts are
  needed\\n\\n## Usage\\n\\nThe Sequential Thinking tool is designed for:\\n-
  Breaking down complex problems into steps\\n- Planning and design with room
  for revision\\n- Analysis that might need course correction\\n- Problems where
  the full scope might not be clear initially\\n- Tasks that need to maintain
  context over multiple steps\\n- Situations where irrelevant information needs
  to be filtered out\\n\\n## Configuration\\n\\n### Usage with Claude
  Desktop\\n\\nAdd this to your `claude_desktop_config.json`:\\n\\n####
  npx\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"sequential-thinking\\\": {\\n      \\\"command\\\":
  \\\"npx\\\",\\n      \\\"args\\\":
  [\\n        \\\"-y\\\",\\n        \\\"@modelcontextprotocol/server-sequential\
  -thinking\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n####
  docker\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"sequentialthinking\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"--rm\\\",\\n        \\\"-i\\\",\\n        \
  \\\"mcp/sequentialthinking\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nTo
  disable logging of thought information set env var: `DISABLE_THOUGHT_LOGGING`
  to `true`.\\nComment\\n\\n### Usage with VS Code\\n\\nFor quick installation,
  click one of the installation buttons below...\\n\\n[![Install with NPX in VS
  Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square&logo=\
  visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/i\
  nstall?name=sequentialthinking&config=%7B%22command%22%3A%22npx%22%2C%22args%\
  22%3A%5B%22-y%22%2C%22%40modelcontextprotocol%2Fserver-sequential-thinking%22\
  %5D%7D) [![Install with NPX in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat\
  -square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/r\
  edirect/mcp/install?name=sequentialthinking&config=%7B%22command%22%3A%22npx%\
  22%2C%22args%22%3A%5B%22-y%22%2C%22%40modelcontextprotocol%2Fserver-sequentia\
  l-thinking%22%5D%7D&quality=insiders)\\n\\n[![Install with Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=sequentialthinking&config=%7B%22command%22%3A%22docker%22%2C%2\
  2args%22%3A%5B%22run%22%2C%22--rm%22%2C%22-i%22%2C%22mcp%2Fsequentialthinking\
  %22%5D%7D) [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=sequentialthinking&config=%7B%22command%22%3A%22d\
  ocker%22%2C%22args%22%3A%5B%22run%22%2C%22--rm%22%2C%22-i%22%2C%22mcp%2Fseque\
  ntialthinking%22%5D%7D&quality=insiders)\\n\\nFor manual installation, add the
  following JSON block to your User Settings (JSON) file in VS Code. You can do
  this by pressing `Ctrl + Shift + P` and typing `Preferences: Open Settings
  (JSON)`.\\n\\nOptionally, you can add it to a file called `.vscode/mcp.json`
  in your workspace. This will allow you to share the configuration with
  others.\\n\\n> Note that the `mcp` key is not needed in the `.vscode/mcp.json`
  file.\\n\\nFor NPX installation:\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"sequential-thinking\\\":
  {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\":
  [\\n          \\\"-y\\\",\\n          \\\"@modelcontextprotocol/server-sequen\
  tial-thinking\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFor
  Docker installation:\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"sequential-thinking\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"-i\\\",\
  \\n          \\\"mcp/sequentialthinking\\\"\\n        ]\\n      }\\n    }\\n  \
  }\\n}\\n```\\n\\n## Building\\n\\nDocker:\\n\\n```bash\\ndocker build -t
  mcp/sequentialthinking -f src/sequentialthinking/Dockerfile .\\n```\\n\\n##
  License\\n\\nThis MCP server is licensed under the MIT License. This means you
  are free to use, modify, and distribute the software, subject to the terms and
  conditions of the MIT License. For more details, please see the LICENSE file
  in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":56967,\"downloadCount\
  \":50000,\"createdAt\":\"2025-02-18T05:45:21.365219Z\",\"updatedAt\":\"2025-0\
  7-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T06:42:55.601412Z\"},{\
  \"mcpId\":\"github.com/awslabs/mcp/tree/main/src/frontend-mcp-server\",\"gith\
  ubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/frontend-mcp-server\",\
  \"name\":\"React Development
  Guide\",\"author\":\"awslabs\",\"description\":\"Provides comprehensive
  documentation and tools for modern React application development with AWS
  integrations, including setup guides, authentication, routing, and
  troubleshooting.\",\"codiconIcon\":\"book\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/aws.png\",\"category\":\"developer-tools\",\"\
  tags\":[\"react\",\"aws-integration\",\"web-development\",\"documentation\",\
  \"frontend\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Labs Frontend
  MCP Server\\n\\n[![smithery
  badge](https://smithery.ai/badge/@awslabs/frontend-mcp-server)](https://smith\
  ery.ai/server/@awslabs/frontend-mcp-server)\\n\\nA Model Context Protocol
  (MCP) server that provides specialized tools for modern web application
  development.\\n\\n## Features\\n\\n### Modern React Application
  Documentation\\n\\nThis MCP Server provides comprehensive documentation on
  modern React application development through its `GetReactDocsByTopic` tool,
  which offers guidance on:\\n\\n- **Essential Knowledge**: Fundamental concepts
  for building React applications\\n- **Basic UI Setup**: Setting up a React
  project with Tailwind CSS and shadcn/ui\\n- **Authentication**: AWS Amplify
  authentication integration\\n- **Routing**: Implementing routing with React
  Router\\n- **Customizing**: Theming with AWS Amplify components\\n- **Creating
  Components**: Building React components with AWS integrations\\n-
  **Troubleshooting**: Common issues and solutions for React development\\n\\n##
  Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.frontend-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF\
  3c2xhYnMuZnJvbnRlbmQtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRkFTVE1DUF9MT0dfTEVW\
  RUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3ZlIjpbXX0%3D)\\n\\nConf\
  igure the MCP server in your MCP client configuration (e.g., for Amazon Q
  Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.frontend-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.frontend-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Usage\\n\\nThe Frontend MCP Server provides the `GetReactDocsByTopic` tool for
  accessing specialized documentation on modern web application development with
  AWS technologies. This server will instruct the caller to clone a base web
  application repo and use that as the starting point for
  customization.\\n\\n### GetReactDocsByTopic\\n\\nThis tool retrieves
  comprehensive documentation on specific React and AWS integration topics. To
  use it, specify which topic you need information on:\\n\\n```python\\nresult =
  await get_react_docs_by_topic('essential-knowledge')\\n```\\n\\nAvailable
  topics:\\n\\n1. **essential-knowledge**: Foundational concepts for building
  React applications with AWS services\\n2. **troubleshooting**: Common issues
  and solutions for React development with AWS integrations\\n\\nEach topic
  returns comprehensive markdown documentation with explanations, code examples,
  and implementation
  guidance.\\n\",\"isRecommended\":false,\"githubStars\":4378,\"downloadCount\"\
  :352,\"createdAt\":\"2025-06-21T01:44:45.19624Z\",\"updatedAt\":\"2025-07-08T\
  01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T04:24:13.287572Z\"},{\"mcp\
  Id\":\"github.com/awslabs/mcp/tree/main/src/dynamodb-mcp-server\",\"githubUrl\
  \":\"https://github.com/awslabs/mcp/tree/main/src/dynamodb-mcp-server\",\"name\
  \":\"DynamoDB\",\"author\":\"awslabs\",\"description\":\"Comprehensive suite
  of tools for managing AWS DynamoDB resources, including table operations, item
  management, querying, backups, TTL settings, and resource
  policies.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\
  \"aws\",\"dynamodb\",\"nosql\",\"database-management\",\"cloud-database\"],\"\
  requiresApiKey\":false,\"readmeContent\":\"# AWS DynamoDB MCP Server\\n\\nThe
  official MCP Server for interacting with AWS DynamoDB\\n\\n## Available MCP
  Tools\\n\\n### Table Operations\\n- `create_table` - Creates a new DynamoDB
  table with optional secondary indexes\\n- `delete_table` - Deletes a table and
  all of its items\\n- `describe_table` - Returns table information including
  status, creation time, key schema and indexes\\n- `list_tables` - Returns a
  paginated list of table names in your account\\n- `update_table` - Modifies
  table settings including provisioned throughput, global secondary indexes, and
  DynamoDB Streams configuration\\n\\n### Item Operations\\n- `get_item` -
  Returns attributes for an item with the given primary key\\n- `put_item` -
  Creates a new item or replaces an existing item in a table\\n- `update_item` -
  Edits an existing item's attributes, or adds a new item if it does not already
  exist\\n- `delete_item` - Deletes a single item in a table by primary
  key\\n\\n### Query and Scan Operations\\n- `query` - Returns items from a
  table or index matching a partition key value, with optional sort key
  filtering\\n- `scan` - Returns items and attributes by scanning a table or
  secondary index\\n\\n### Backup and Recovery\\n- `create_backup` - Creates a
  backup of a DynamoDB table\\n- `describe_backup` - Describes an existing
  backup of a table\\n- `list_backups` - Returns a list of table backups\\n-
  `restore_table_from_backup` - Creates a new table from a backup\\n-
  `describe_continuous_backups` - Returns continuous backup and point in time
  recovery status\\n- `update_continuous_backups` - Enables or disables point in
  time recovery\\n\\n### Time to Live (TTL)\\n- `update_time_to_live` - Enables
  or disables Time to Live (TTL) for the specified table\\n-
  `describe_time_to_live` - Returns the Time to Live (TTL) settings for a
  table\\n\\n### Export Operations\\n- `describe_export` - Returns information
  about a table export\\n- `list_exports` - Returns a list of table
  exports\\n\\n### Tags and Resource Policies\\n- `put_resource_policy` -
  Attaches a resource-based policy document to a table or stream\\n-
  `get_resource_policy` - Returns the resource-based policy document attached to
  a table or stream\\n- `tag_resource` - Adds tags to a DynamoDB resource\\n-
  `untag_resource` - Removes tags from a DynamoDB resource\\n-
  `list_tags_of_resource` - Returns tags for a DynamoDB resource\\n\\n###
  Misc\\n- `describe_limits` - Returns the current provisioned-capacity quotas
  for your AWS account\\n- `describe_endpoints` - Returns DynamoDB endpoints for
  the current region\\n\\n## Instructions\\n\\nThe official MCP Server for
  interacting with AWS DynamoDB provides a comprehensive set of tools for
  managing DynamoDB resources. Each tool maps directly to DynamoDB API
  operations and supports all relevant parameters.\\n\\nTo use these tools,
  ensure you have proper AWS credentials configured with appropriate permissions
  for DynamoDB operations. The server will automatically use credentials from
  environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY,
  AWS_SESSION_TOKEN) or other standard AWS credential sources.\\n\\nAll tools
  support an optional `region_name` parameter to specify which AWS region to
  operate in. If not provided, it will use the AWS_REGION environment variable
  or default to 'us-west-2'.\\n\\n## Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n3. Set up AWS credentials with access
  to AWS services\\n   - Consider setting up Read-only permission if you don't
  want the LLM to modify any resources\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.dynamodb-mcp-server&config=eyJjb21tYW5kIjoidXZ4IGF\
  3c2xhYnMuZHluYW1vZGItbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsiRERCLU1DUC1SRUFET05M\
  WSI6InRydWUiLCJBV1NfUFJPRklMRSI6ImRlZmF1bHQiLCJBV1NfUkVHSU9OIjoidXMtd2VzdC0yI\
  iwiRkFTVE1DUF9MT0dfTEVWRUwiOiJFUlJPUiJ9LCJkaXNhYmxlZCI6ZmFsc2UsImF1dG9BcHByb3\
  ZlIjpbXX0%3D)\\n\\nAdd the MCP to your favorite agentic tools. (e.g. for
  Amazon Q Developer CLI MCP,
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.dynamodb-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.dynamodb-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"DDB-MCP-READONLY\\\":
  \\\"true\\\",\\n        \\\"AWS_PROFILE\\\":
  \\\"default\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\nor docker
  after a successful `docker build -t awslabs/dynamodb-mcp-server
  .`:\\n\\n```json\\n  {\\n    \\\"mcpServers\\\":
  {\\n      \\\"awslabs.dynamodb-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"--intera\
  ctive\\\",\\n          \\\"--env\\\",\\n          \\\"FASTMCP_LOG_LEVEL=ERROR\
  \\\",\\n          \\\"awslabs/dynamodb-mcp-server:latest\\\"\\n        ],\\n        \
  \\\"env\\\": {},\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\":
  []\\n      }\\n    }\\n  }\\n```\\n\",\"isRecommended\":false,\"githubStars\"\
  :4378,\"downloadCount\":146,\"createdAt\":\"2025-06-21T01:47:24.354814Z\",\"u\
  pdatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T03\
  :20:46.401333Z\"},{\"mcpId\":\"github.com/anaisbetts/mcp-youtube\",\"githubUrl\
  \":\"https://github.com/anaisbetts/mcp-youtube\",\"name\":\"YouTube
  Subtitles\",\"author\":\"anaisbetts\",\"description\":\"Downloads and extracts
  YouTube video subtitles using yt-dlp, enabling AI assistants to analyze and
  summarize video content through subtitle
  text.\",\"codiconIcon\":\"play-circle\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/youtube-subtitles.png\",\"category\":\"entertainm\
  ent-media\",\"tags\":[\"youtube\",\"subtitles\",\"video-analysis\",\"content-\
  summarization\",\"yt-dlp\"],\"requiresApiKey\":false,\"readmeContent\":\"#
  YouTube MCP Server\\n\\nUses `yt-dlp` to download subtitles from YouTube and
  connects it to claude.ai via [Model Context
  Protocol](https://modelcontextprotocol.io/introduction). Try it by asking
  Claude, \\\"Summarize the YouTube video <<URL>>\\\". Requires `yt-dlp` to be
  installed locally e.g. via Homebrew.\\n\\n### How do I get this
  working?\\n\\n1. Install `yt-dlp` (Homebrew and WinGet both work great
  here)\\n1. Now, install this via
  [mcp-installer](https://github.com/anaisbetts/mcp-installer), use the name
  `@anaisbetts/mcp-youtube`\",\"isRecommended\":true,\"githubStars\":386,\"down\
  loadCount\":2231,\"createdAt\":\"2025-02-17T22:27:37.384353Z\",\"updatedAt\":\
  \"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T02:51:53.0264\
  32Z\"},{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/aurora-dsql-mcp-serv\
  er\",\"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/aurora-dsql\
  -mcp-server\",\"name\":\"Aurora
  DSQL\",\"author\":\"awslabs\",\"description\":\"Enables natural language to
  SQL query conversion and execution against Aurora DSQL databases, with
  configurable read/write access and connection
  pooling.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/aws.png\",\"category\":\"databases\",\"tags\":[\"\
  aurora\",\"postgresql\",\"sql\",\"aws\",\"database-queries\"],\"requiresApiKey\
  \":false,\"readmeContent\":\"# AWS Labs Aurora DSQL MCP Server\\n\\nAn AWS
  Labs Model Context Protocol (MCP) server for Aurora DSQL\\n\\n##
  Features\\n\\n- Converting human-readable questions and commands into
  structured Postgres-compatible SQL queries and executing them against the
  configured Aurora DSQL database.\\n- Read-only by default, transactions
  enabled with `--allow-writes`\\n- Connection reuse between requests for
  improved performance\\n\\n## Prerequisites\\n\\n1. An AWS account with an
  [Aurora DSQL
  Cluster](https://docs.aws.amazon.com/aurora-dsql/latest/userguide/getting-sta\
  rted.html)\\n1. This MCP server can only be run locally on the same host as
  your LLM client.\\n1. Set up AWS credentials with access to AWS
  services\\n   - You need an AWS account with appropriate permissions\\n   -
  Configure AWS credentials with `aws configure` or environment
  variables\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.aurora-dsql-mcp-server&config=eyJjb21tYW5kIjoidXZ4\
  IGF3c2xhYnMuYXVyb3JhLWRzcWwtbWNwLXNlcnZlckBsYXRlc3QgLS1jbHVzdGVyX2VuZHBvaW50I\
  Ft5b3VyIGRzcWwgY2x1c3RlciBlbmRwb2ludF0gLS1yZWdpb24gW3lvdXIgZHNxbCBjbHVzdGVyIH\
  JlZ2lvbiwgZS5nLiB1cy1lYXN0LTFdIC0tZGF0YWJhc2VfdXNlciBbeW91ciBkc3FsIHVzZXJuYW1\
  lXSAtLXByb2ZpbGUgZGVmYXVsdCIsImVudiI6eyJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIn0s\
  ImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%3D)\\n\\n### Using
  `uv`\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\nConfigure the MCP server in your
  MCP client configuration (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aurora-dsql-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.aurora-dsql-mcp-server@latest\\\",\\n        \\\"--cl\
  uster_endpoint\\\",\\n        \\\"[your dsql cluster
  endpoint]\\\",\\n        \\\"--region\\\",\\n        \\\"[your dsql cluster
  region, e.g.
  us-east-1]\\\",\\n        \\\"--database_user\\\",\\n        \\\"[your dsql
  username]\\\",\\n        \\\"--profile\\\",
  \\\"default\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n### Using
  Docker\\n\\n1. 'git clone https://github.com/awslabs/mcp.git'\\n2. Go to
  sub-directory 'src/aurora-dsql-mcp-server/'\\n3. Run 'docker build -t
  awslabs/aurora-dsql-mcp-server:latest .'\\n4. Create a env file with temporary
  credentials:\\n\\nEither manually:\\n```file\\n# fictitious `.env` file with
  AWS temporary credentials\\nAWS_ACCESS_KEY_ID=<from the profile you set
  up>\\nAWS_SECRET_ACCESS_KEY=<from the profile you set
  up>\\nAWS_SESSION_TOKEN=<from the profile you set up>\\n```\\n\\nOr using `aws
  configure`:\\n\\n```bash\\naws configure export-credentials --profile
  your-profile-name --format env > temp_aws_credentials.env | sed 's/^export //'
  > temp_aws_credentials.env\\n```\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aurora-dsql-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"--env-file\\\",\\n        \\\"/full/path/to/file/above/.env\\\",\\n        \
  \\\"awslabs/aurora-dsql-mcp-server:latest\\\",\\n        \\\"--cluster_endpoi\
  nt\\\", \\\"[your data]\\\",\\n        \\\"--database_user\\\", \\\"[your
  data]\\\",\\n        \\\"--region\\\", \\\"[your
  data]\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n## Server Configuration
  options\\n\\n### `--allow-writes`\\n\\nBy default, the dsql mcp server does
  not allow write operations (\\\"read-only mode\\\"). Any invocations of
  transact tool will fail in this mode. To use transact tool, allow writes by
  passing `--allow-writes` parameter.\\n\\nWe recommend using least-privilege
  access when connecting to DSQL. For example, users should use a role that is
  read-only when possible. The read-only mode has a best-effort client-side
  enforcement to reject mutations.\\n\\n### `--cluster_endpoint`\\n\\nThis is
  mandatory parameter to specify the cluster to connect to. This should be the
  full endpoint of your cluster, e.g.,
  `01abc2ldefg3hijklmnopqurstu.dsql.us-east-1.on.aws`\\n\\n###
  `--database_user`\\n\\nThis is a mandatory parameter to specify the user to
  connect as. For example\\n`admin`, or `my_user`. Note that the AWS credentials
  you are using must have\\npermission to login as that user. For more
  information on setting up and using\\ndatabase roles in DSQL, see [Using
  database roles with IAM
  roles](https://docs.aws.amazon.com/aurora-dsql/latest/userguide/using-databas\
  e-and-iam-roles.html).\\n\\n### `--profile`\\n\\nYou can specify the aws
  profile to use for your credentials. Note that this is\\nnot supported for
  docker installation.\\n\\nUsing the `AWS_PROFILE` environment variable in your
  MCP configuration is also\\nsupported:\\n\\n```json\\n\\\"env\\\":
  {\\n  \\\"AWS_PROFILE\\\": \\\"your-aws-profile\\\"\\n}\\n```\\n\\nIf neither
  is provided, the MCP server defaults to using the \\\"default\\\" profile in
  your AWS configuration file.\\n\\n### `--region`\\n\\nThis is a mandatory
  parameter to specify the region of your DSQL database.\\n\\n## Development and
  Testing\\n\\n### Running Tests\\n\\nThis project includes comprehensive tests
  to validate the readonly enforcement mechanisms. To run the
  tests:\\n\\n```bash\\n# Install dependencies and run tests\\nuv run pytest
  tests/test_readonly_enforcement.py -v\\n\\n# Run all tests\\nuv run pytest
  -v\\n\\n# Run tests with coverage\\nuv run pytest
  --cov=awslabs.aurora_dsql_mcp_server tests/ -v\\n```\\n\\n### Local Docker
  Testing\\n\\nTo test the MCP server locally using Docker:\\n\\n1. **Build the
  Docker image:**\\n   ```bash\\n   cd src/aurora-dsql-mcp-server\\n   docker
  build -t awslabs/aurora-dsql-mcp-server:latest .\\n   ```\\n\\n2. **Create AWS
  credentials file:**\\n\\n   Option A - Manual creation:\\n   ```bash\\n   #
  Create .env file with your AWS credentials\\n   cat > .env <<
  EOF\\n   AWS_ACCESS_KEY_ID=your_access_key_here\\n   AWS_SECRET_ACCESS_KEY=yo\
  ur_secret_key_here\\n   AWS_SESSION_TOKEN=your_session_token_here\\n   EOF\\n   \
  ```\\n\\n   Option B - Export from AWS CLI:\\n   ```bash\\n   aws configure
  export-credentials --profile your-profile-name --format env >
  temp_aws_credentials.env\\n   sed 's/^export //' temp_aws_credentials.env >
  .env\\n   rm temp_aws_credentials.env\\n   ```\\n\\n3. **Test the container
  directly:**\\n   ```bash\\n   docker run -i --rm \\\\\\n     --env-file .env
  \\\\\\n     awslabs/aurora-dsql-mcp-server:latest
  \\\\\\n     --cluster_endpoint \\\"your-dsql-cluster-endpoint\\\"
  \\\\\\n     --database_user \\\"your-username\\\" \\\\\\n     --region
  \\\"us-east-1\\\"\\n   ```\\n\\n4. **Test with write operations
  enabled:**\\n   ```bash\\n   docker run -i --rm \\\\\\n     --env-file .env
  \\\\\\n     awslabs/aurora-dsql-mcp-server:latest
  \\\\\\n     --cluster_endpoint \\\"your-dsql-cluster-endpoint\\\"
  \\\\\\n     --database_user \\\"your-username\\\" \\\\\\n     --region
  \\\"us-east-1\\\" \\\\\\n     --allow-writes\\n   ```\\n\\n**Note:** Replace
  the placeholder values with your actual DSQL cluster endpoint, username, and
  region.\\n\",\"isRecommended\":false,\"githubStars\":4282,\"downloadCount\":2\
  1,\"createdAt\":\"2025-06-21T01:54:58.119053Z\",\"updatedAt\":\"2025-07-08T01\
  :10:48.398933Z\",\"lastGithubSync\":\"2025-06-30T17:26:18.45981Z\"},{\"mcpId\
  \":\"github.com/modelcontextprotocol/servers/tree/main/src/gdrive\",\"githubU\
  rl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/gdrive\",\
  \"name\":\"Google
  Drive\",\"author\":\"modelcontextprotocol\",\"description\":\"Enables
  searching, listing, and reading files from Google Drive, with automatic export
  of Google Workspace files to common formats like Markdown, CSV, and
  PNG.\",\"codiconIcon\":\"file-directory\",\"logoUrl\":\"https://storage.googl\
  eapis.com/cline_public_images/google-drive.png\",\"category\":\"cloud-storage\
  \",\"tags\":[\"google-drive\",\"file-management\",\"document-storage\",\"work\
  space\",\"file-search\"],\"requiresApiKey\":false,\"isRecommended\":true,\"gi\
  thubStars\":57074,\"downloadCount\":6193,\"createdAt\":\"2025-02-18T05:45:06.\
  878261Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"\
  2025-07-01T19:23:55.075354Z\"},{\"mcpId\":\"github.com/pashpashpash/shopify-m\
  cp-server\",\"githubUrl\":\"https://github.com/pashpashpash/shopify-mcp-server\
  \",\"name\":\"Shopify\",\"author\":\"pashpashpash\",\"description\":\"Integra\
  tes with Shopify's GraphQL Admin API to manage store data, including products,
  customers, orders, collections, discounts, and
  webhooks.\",\"codiconIcon\":\"cart\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/shopify.png\",\"category\":\"ecommerce-retail\",\"ta\
  gs\":[\"shopify\",\"ecommerce\",\"store-management\",\"graphql\",\"retail\"],\
  \"requiresApiKey\":false,\"readmeContent\":\"# Shopify MCP Server\\n\\nMCP
  Server for Shopify API, enabling interaction with store data through GraphQL
  API. This server provides tools for managing products, customers, orders, and
  more.\\n\\n<a href=\\\"https://glama.ai/mcp/servers/bemvhpy885\\\"><img
  width=\\\"380\\\" height=\\\"200\\\"
  src=\\\"https://glama.ai/mcp/servers/bemvhpy885/badge\\\" alt=\\\"Shopify
  Server MCP server\\\" /></a>\\n\\n## Features\\n\\n* **Product Management**:
  Search and retrieve product information\\n* **Customer Management**: Load
  customer data and manage customer tags\\n* **Order Management**: Advanced
  order querying and filtering\\n* **GraphQL Integration**: Direct integration
  with Shopify's GraphQL Admin API\\n* **Comprehensive Error Handling**: Clear
  error messages for API and authentication issues\\n\\n## Prerequisites\\n\\n1.
  Node.js (version 16 or higher)\\n2. Shopify Custom App Access Token (see setup
  instructions below)\\n\\n## Installation\\n\\n1. **Clone the
  Repository**:\\n   ```bash\\n   git clone
  https://github.com/pashpashpash/shopify-mcp-server.git\\n   cd
  shopify-mcp-server\\n   ```\\n\\n2. **Install
  Dependencies**:\\n   ```bash\\n   npm install\\n   ```\\n\\n3. **Build the
  Project**:\\n   ```bash\\n   npm run build\\n   ```\\n\\n## Shopify
  Setup\\n\\n### Creating a Custom App\\n\\n1. From your Shopify admin, go to
  **Settings** > **Apps and sales channels**\\n2. Click **Develop apps** (you
  may need to enable developer preview first)\\n3. Click **Create an app**\\n4.
  Set a name for your app (e.g., \\\"Shopify MCP Server\\\")\\n5. Click
  **Configure Admin API scopes**\\n6. Select the following scopes:\\n   *
  `read_products`, `write_products`\\n   * `read_customers`,
  `write_customers`\\n   * `read_orders`, `write_orders`\\n7. Click
  **Save**\\n8. Click **Install app**\\n9. Click **Install** to give the app
  access to your store data\\n10. After installation, you'll see your **Admin
  API access token**\\n11. Copy this token - you'll need it for
  configuration\\n\\nNote: Store your access token securely. It provides access
  to your store data and should never be shared or committed to version
  control.\\n\\n## Configuration\\n\\n1. **Create Environment
  File**:\\n   Create a `.env` file in the project
  root:\\n   ```\\n   SHOPIFY_ACCESS_TOKEN=your_access_token\\n   MYSHOPIFY_DOM\
  AIN=your-store.myshopify.com\\n   ```\\n\\n2. **Configure Claude
  Desktop**:\\n\\nAdd this to your claude_desktop_config.json:\\n- macOS:
  `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- Windows:
  `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpSer\
  vers\\\": {\\n    \\\"shopify\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"path/to/shopify-mcp-server/dist/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"SHOPIFY_ACCESS_TOKEN\\\":
  \\\"your_access_token\\\",\\n        \\\"MYSHOPIFY_DOMAIN\\\":
  \\\"your-store.myshopify.com\\\"\\n      }\\n    }\\n  }\\n}\\n```\\nNote:
  Replace \\\"path/to/shopify-mcp-server\\\" with the actual path to your cloned
  repository.\\n\\n## Available Tools\\n\\n### Product Management\\n\\n1.
  `get-products`\\n   * Get all products or search by title\\n   *
  Inputs:\\n     * `searchTitle` (optional string): Filter products by
  title\\n     * `limit` (number): Maximum number of products to return\\n\\n2.
  `get-products-by-collection`\\n   * Get products from a specific
  collection\\n   * Inputs:\\n     * `collectionId` (string): ID of the
  collection\\n     * `limit` (optional number, default: 10): Maximum products
  to return\\n\\n3. `get-products-by-ids`\\n   * Get products by their
  IDs\\n   * Inputs:\\n     * `productIds` (array of strings): Array of product
  IDs to retrieve\\n\\n4. `get-variants-by-ids`\\n   * Get product variants by
  their IDs\\n   * Inputs:\\n     * `variantIds` (array of strings): Array of
  variant IDs to retrieve\\n\\n### Customer Management\\n\\n5.
  `get-customers`\\n   * Get shopify customers with pagination\\n   *
  Inputs:\\n     * `limit` (optional number): Maximum customers to
  return\\n     * `next` (optional string): Next page cursor\\n\\n6.
  `tag-customer`\\n   * Add tags to a customer\\n   * Inputs:\\n     *
  `customerId` (string): Customer ID to tag\\n     * `tags` (array of strings):
  Tags to add\\n\\n### Order Management\\n\\n7. `get-orders`\\n   * Get orders
  with advanced filtering\\n   * Inputs:\\n     * `first` (optional number):
  Limit of orders to return\\n     * `after` (optional string): Next page
  cursor\\n     * `query` (optional string): Filter query\\n     * `sortKey`
  (optional enum): Sort field\\n     * `reverse` (optional boolean): Reverse
  sort\\n\\n8. `get-order`\\n   * Get a single order by ID\\n   *
  Inputs:\\n     * `orderId` (string): ID of the order\\n\\n9.
  `create-draft-order`\\n    * Create a draft order\\n    * Inputs:\\n      *
  `lineItems` (array): Items with variantId and quantity\\n      * `email`
  (string): Customer email\\n      * `shippingAddress` (object): Shipping
  details\\n      * `note` (optional string): Optional note\\n\\n10.
  `complete-draft-order`\\n    * Complete a draft order\\n    *
  Inputs:\\n      * `draftOrderId` (string): ID of draft order\\n      *
  `variantId` (string): ID of variant\\n\\n### Discount Management\\n\\n11.
  `create-discount`\\n    * Create a basic discount code\\n    *
  Inputs:\\n      * `title` (string): Discount title\\n      * `code` (string):
  Discount code\\n      * `valueType` (enum): 'percentage' or
  'fixed_amount'\\n      * `value` (number): Discount value\\n      * `startsAt`
  (string): Start date\\n      * `endsAt` (optional string): End date\\n      *
  `appliesOncePerCustomer` (boolean): Once per customer flag\\n\\n### Collection
  Management\\n\\n12. `get-collections`\\n    * Get all collections\\n    *
  Inputs:\\n      * `limit` (optional number, default: 10)\\n      * `name`
  (optional string): Filter by name\\n\\n### Shop Information\\n\\n13.
  `get-shop`\\n    * Get basic shop details\\n    * No inputs required\\n\\n14.
  `get-shop-details`\\n    * Get extended shop details\\n    * No inputs
  required\\n\\n### Webhook Management\\n\\n15. `manage-webhook`\\n    * Manage
  webhooks\\n    * Inputs:\\n      * `action` (enum): 'subscribe', 'find',
  'unsubscribe'\\n      * `callbackUrl` (string): Webhook URL\\n      * `topic`
  (enum): Webhook topic\\n      * `webhookId` (optional string): Required for
  unsubscribe\\n\\n## Debugging\\n\\nIf you run into issues, check Claude
  Desktop's MCP logs:\\n```bash\\ntail -n 20 -f
  ~/Library/Logs/Claude/mcp*.log\\n```\\n\\nCommon issues:\\n1. **Authentication
  Errors**:\\n   - Verify your Shopify access token\\n   - Check your shop
  domain format\\n   - Ensure all required API scopes are enabled\\n\\n2. **API
  Errors**:\\n   - Check rate limits\\n   - Verify input formats\\n   - Ensure
  required fields are provided\\n\\n## Development\\n\\n```bash\\n# Install
  dependencies\\nnpm install\\n\\n# Build the project\\nnpm run build\\n\\n# Run
  tests\\nnpm test\\n```\\n\\n## Dependencies\\n\\n- @modelcontextprotocol/sdk -
  MCP protocol implementation\\n- graphql-request - GraphQL client for Shopify
  API\\n- zod - Runtime type validation\\n\\n##
  License\\n\\nMIT\\n\\n---\\nNote: This is a fork of the [original
  shopify-mcp-server
  repository](https://github.com/rezapex/shopify-mcp-server-main\\n\",\"isRecom\
  mended\":false,\"githubStars\":29,\"downloadCount\":1085,\"createdAt\":\"2025\
  -02-19T01:26:05.505451Z\",\"updatedAt\":\"2025-07-08T01:10:48.398933Z\",\"las\
  tGithubSync\":\"2025-07-01T03:05:25.155468Z\"},{\"mcpId\":\"github.com/aliyun\
  /alibaba-cloud-ops-mcp-server\",\"githubUrl\":\"https://github.com/aliyun/ali\
  baba-cloud-ops-mcp-server\",\"name\":\"Alibaba Cloud
  Ops\",\"author\":\"aliyun\",\"description\":\"Manages Alibaba Cloud resources
  including ECS, VPC, RDS, OSS and CloudMonitor, providing comprehensive cloud
  infrastructure management through API and OOS
  automation.\",\"codiconIcon\":\"cloud\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/alibaba-cloud-ops.png\",\"category\":\"cloud-plat\
  forms\",\"tags\":[\"alibaba-cloud\",\"infrastructure-management\",\"cloud-aut\
  omation\",\"monitoring\",\"resource-management\"],\"requiresApiKey\":false,\"\
  readmeContent\":\"# Alibaba Cloud Ops MCP Server\\n\\n[![GitHub
  stars](https://img.shields.io/github/stars/aliyun/alibaba-cloud-ops-mcp-serve\
  r?style=social)](https://github.com/aliyun/alibaba-cloud-ops-mcp-server)\\n\\\
  n[](./README_zh.md)\\n\\nAlibaba Cloud Ops MCP Server is a [Model Context
  Protocol (MCP)](https://modelcontextprotocol.io/introduction) server that
  provides seamless integration with Alibaba Cloud APIs, enabling AI assistants
  to operation resources on Alibaba Cloud, supporting ECS, Cloud Monitor, OOS
  andother widely used cloud products.\\n\\n## Prepare\\n\\nInstall
  [uv](https://github.com/astral-sh/uv)\\n\\n```bash\\n# On macOS and
  Linux.\\ncurl -LsSf https://astral.sh/uv/install.sh | sh\\n```\\n\\n##
  Configuration\\n\\nUse [VS Code](https://code.visualstudio.com/) +
  [Cline](https://cline.bot/) to config MCP Server.\\n\\nTo use
  `alibaba-cloud-ops-mcp-server` MCP Server with any other MCP Client, you can
  manually add this configuration and restart for changes to take
  effect:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"alibaba-cloud-ops-mcp-server\\\": {\\n      \\\"timeout\\\":
  600,\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"alibaba-cloud-ops-mcp-server@latest\\\"\\n      ],\\n      \\\
  \"env\\\": {\\n        \\\"ALIBABA_CLOUD_ACCESS_KEY_ID\\\": \\\"Your Access
  Key ID\\\",\\n        \\\"ALIBABA_CLOUD_ACCESS_KEY_SECRET\\\": \\\"Your Access
  Key SECRET\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n[For detailed parameter
  description, see MCP startup parameter document](./README_mcp_args.md)\\n\\n##
  MCP Maketplace Integration\\n\\n*
  [Cline](https://cline.bot/mcp-marketplace)\\n*
  [Cursor](https://docs.cursor.com/tools) [![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com\
  /install-mcp?name=alibaba-cloud-ops-mcp-server&config=eyJ0aW1lb3V0Ijo2MDAsImN\
  vbW1hbmQiOiJ1dnggYWxpYmFiYS1jbG91ZC1vcHMtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOnsi\
  QUxJQkFCQV9DTE9VRF9BQ0NFU1NfS0VZX0lEIjoiWW91ciBBY2Nlc3MgS2V5IElEIiwiQUxJQkFCQ\
  V9DTE9VRF9BQ0NFU1NfS0VZX1NFQ1JFVCI6IllvdXIgQWNjZXNzIEtleSBTRUNSRVQifX0%3D)\\n*
  [ModelScope](https://www.modelscope.cn/mcp/servers/@aliyun/alibaba-cloud-ops-\
  mcp-server?lang=en_US)\\n* [Lingma](https://lingma.aliyun.com/)\\n* [Smithery
  AI](https://smithery.ai/server/@aliyun/alibaba-cloud-ops-mcp-server)\\n*
  [FC-Function
  AI](https://cap.console.aliyun.com/template-detail?template=237)\\n* [Alibaba
  Cloud Model
  Studio](https://bailian.console.aliyun.com/?tab=mcp#/mcp-market/detail/alibab\
  a-cloud-ops)\\n\\n## Know More\\n\\n* [Alibaba Cloud Ops MCP Server is ready
  to use out of the box!](https://developer.aliyun.com/article/1661348)\\n*
  [Setup Alibaba Cloud Ops MCP Server on
  Bailian](https://developer.aliyun.com/article/1662120)\\n* [Build your own
  Alibaba Cloud OpenAPI MCP Server with 10 lines of
  code](https://developer.aliyun.com/article/1662202)\\n* [Alibaba Cloud Ops MCP
  Server is officially available on the Alibaba Cloud Model Studio Platform MCP
  Marketplace](https://developer.aliyun.com/article/1665019)\\n\\n##
  Tools\\n\\n| **Product** | **Tool** | **Function** | **Implematation** |
  **Status** |\\n| --- | --- | --- | --- | --- |\\n| ECS | RunCommand | Run
  Command | OOS | Done |\\n| | StartInstances | Start Instances | OOS | Done
  |\\n| | StopInstances | Stop Instances | OOS | Done |\\n| | RebootInstances |
  Reboot Instances | OOS | Done |\\n| | DescribeInstances | View Instances | API
  | Done |\\n| | DescribeRegions | View Regions | API | Done |\\n| |
  DescribeZones | View Zones | API | Done |\\n| | DescribeAvailableResource |
  View Resource Inventory | API | Done |\\n| | DescribeImages | View Images |
  API | Done |\\n| | DescribeSecurityGroups | View Security Groups | API | Done
  |\\n| | RunInstances | Create Instances | OOS | Done |\\n| | DeleteInstances |
  Delete Instances | API | Done |\\n| | ResetPassword | Modify Password | OOS |
  Done |\\n| | ReplaceSystemDisk | Replace Operating System | OOS | Done |\\n|
  VPC | DescribeVpcs | View VPCs | API | Done |\\n| | DescribeVSwitches | View
  VSwitches | API | Done |\\n| RDS | DescribeDBInstances | List RDS Instances |
  API | Done |\\n|  | StartDBInstances | Start the RDS instance | OOS | Done
  |\\n|  | StopDBInstances | Stop the RDS instance | OOS | Done |\\n|  |
  RestartDBInstances | Restart the RDS instance | OOS | Done |\\n| OSS |
  ListBuckets | List Bucket | API | Done |\\n|  | PutBucket | Create Bucket |
  API | Done |\\n|  | DeleteBucket | Delete Bucket | API | Done |\\n|  |
  ListObjects | View object information in the bucket | API | Done |\\n|
  CloudMonitor | GetCpuUsageData | Get CPU Usage Data for ECS Instances | API |
  Done |\\n| | GetCpuLoadavgData | Get CPU One-Minute Average Load Metric Data |
  API | Done |\\n| | GetCpuloadavg5mData | Get CPU Five-Minute Average Load
  Metric Data | API | Done |\\n| | GetCpuloadavg15mData | Get CPU Fifteen-Minute
  Average Load Metric Data | API | Done |\\n| | GetMemUsedData | Get Memory
  Usage Metric Data | API | Done |\\n| | GetMemUsageData | Get Memory
  Utilization Metric Data | API | Done |\\n| | GetDiskUsageData | Get Disk
  Utilization Metric Data | API | Done |\\n| | GetDiskTotalData | Get Total Disk
  Partition Capacity Metric Data | API | Done |\\n| | GetDiskUsedData | Get Disk
  Partition Usage Metric Data | API | Done |\\n\\n## Contact us\\n\\nIf you have
  any questions, please join the [Alibaba Cloud Ops MCP discussion
  group](https://qr.dingtalk.com/action/joingroup?code=v1,k1,iFxYG4jjLVh1jfmNAk\
  kclji7CN5DSIdT+jvFsLyI60I=&_dt_no_comment=1&origin=11) (DingTalk group:
  113455011677) for discussion.\\n\\n<img
  src=\\\"https://oos-public-cn-hangzhou.oss-cn-hangzhou.aliyuncs.com/alibaba-c\
  loud-ops-mcp-server/Alibaba-Cloud-Ops-MCP-User-Group-en.png\\\"
  width=\\\"500\\\">\\n\",\"isRecommended\":false,\"githubStars\":55,\"download\
  Count\":256,\"createdAt\":\"2025-04-24T06:27:33.110757Z\",\"updatedAt\":\"202\
  5-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-02T00:48:24.806249Z\"\
  },{\"mcpId\":\"github.com/awslabs/mcp/tree/main/src/aws-location-mcp-server\",\
  \"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/aws-location-mcp\
  -server\",\"name\":\"Amazon
  Location\",\"author\":\"awslabs\",\"description\":\"Provides location-based
  services including place search, geocoding, route calculation, and nearby
  points of interest using Amazon Location
  Service.\",\"codiconIcon\":\"location\",\"logoUrl\":\"https://storage.googlea\
  pis.com/cline_public_images/aws.png\",\"category\":\"location-services\",\"ta\
  gs\":[\"geocoding\",\"route-planning\",\"places-search\",\"aws\",\"location-s\
  ervices\"],\"requiresApiKey\":false,\"readmeContent\":\"# Amazon Location
  Service MCP Server\\n\\nModel Context Protocol (MCP) server for Amazon
  Location Service\\n\\nThis MCP server provides tools to access Amazon Location
  Service capabilities, focusing on place search and geographical
  coordinates.\\n\\n## Features\\n\\n- **Search for Places**: Search for places
  using geocoding\\n- **Get Place Details**: Get details for specific places by
  PlaceId\\n- **Reverse Geocode**: Convert coordinates to addresses\\n- **Search
  Nearby**: Search for places near a specified location\\n- **Open Now Search**:
  Search for places that are currently open\\n- **Route Calculation**: Calculate
  routes between locations using Amazon Location Service\\n- **Optimize
  Waypoints**: Optimize the order of waypoints for a route using Amazon Location
  Service\\n\\n## Prerequisites\\n\\n### Requirements\\n\\n1. Have an AWS
  account with Amazon Location Service enabled\\n2. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n3. Install
  Python 3.10 or newer using `uv python install 3.10` (or a more recent
  version)\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.aws-location-mcp-server&config=eyJjb21tYW5kIjoidXZ\
  4IGF3c2xhYnMuYXdzLWxvY2F0aW9uLW1jcC1zZXJ2ZXJAbGF0ZXN0IiwiZW52Ijp7IkFXU19QUk9G\
  SUxFIjoieW91ci1hd3MtcHJvZmlsZSIsIkFXU19SRUdJT04iOiJ1cy1lYXN0LTEiLCJGQVNUTUNQX\
  0xPR19MRVZFTCI6IkVSUk9SIn0sImRpc2FibGVkIjpmYWxzZSwiYXV0b0FwcHJvdmUiOltdfQ%3D%\
  3D)\\n\\nHere are the ways you can work with the Amazon Location MCP
  server:\\n\\n## Configuration\\n\\nConfigure the server in your MCP
  configuration file. Here are some ways you can work with MCP across AWS, and
  we'll be adding support to more products soon: (e.g. for Amazon Q Developer
  CLI MCP, `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-location-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"awslabs.aws-location-mcp-server@latest\\\"],\\n        \\\"env\\\":
  {\\n          \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n          \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n###
  Using Temporary Credentials\\n\\nFor temporary credentials (such as those from
  AWS STS, IAM roles, or
  federation):\\n\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-location-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"awslabs.aws-location-mcp-server@latest\\\"],\\n        \\\"env\\\":
  {\\n          \\\"AWS_ACCESS_KEY_ID\\\":
  \\\"your-temporary-access-key\\\",\\n          \\\"AWS_SECRET_ACCESS_KEY\\\":
  \\\"your-temporary-secret-key\\\",\\n          \\\"AWS_SESSION_TOKEN\\\":
  \\\"your-session-token\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\",\\n          \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n###
  Docker Configuration\\n\\nAfter building with `docker build -t
  awslabs/aws-location-mcp-server .`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-location-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"-i\\\",\
  \\n          \\\"awslabs/aws-location-mcp-server\\\"\\n        ],\\n        \\\
  \"env\\\": {\\n          \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n###
  Docker with Temporary Credentials\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.aws-location-mcp-server\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"--rm\\\",\\n          \\\"-i\\\",\
  \\n          \\\"awslabs/aws-location-mcp-server\\\"\\n        ],\\n        \\\
  \"env\\\": {\\n          \\\"AWS_ACCESS_KEY_ID\\\":
  \\\"your-temporary-access-key\\\",\\n          \\\"AWS_SECRET_ACCESS_KEY\\\":
  \\\"your-temporary-secret-key\\\",\\n          \\\"AWS_SESSION_TOKEN\\\":
  \\\"your-session-token\\\",\\n          \\\"AWS_REGION\\\":
  \\\"us-east-1\\\"\\n        },\\n        \\\"disabled\\\":
  false,\\n        \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n###
  Environment Variables\\n\\n- `AWS_PROFILE`: AWS CLI profile to use for
  credentials\\n- `AWS_REGION`: AWS region to use (default: us-east-1)\\n-
  `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`: Explicit AWS credentials
  (alternative to AWS_PROFILE)\\n- `AWS_SESSION_TOKEN`: Session token for
  temporary credentials (used with AWS_ACCESS_KEY_ID and
  AWS_SECRET_ACCESS_KEY)\\n- `FASTMCP_LOG_LEVEL`: Logging level (ERROR, WARNING,
  INFO, DEBUG)\\n\\n## Tools\\n\\nThe server exposes the following tools through
  the MCP interface:\\n\\n### search_places\\n\\nSearch for places using Amazon
  Location Service geocoding capabilities.\\n\\n```python\\nsearch_places(query:
  str, max_results: int = 5, mode: str = 'summary') -> dict\\n```\\n\\n###
  get_place\\n\\nGet details for a specific place using its unique place
  ID.\\n\\n```python\\nget_place(place_id: str, mode: str = 'summary') ->
  dict\\n```\\n\\n### reverse_geocode\\n\\nConvert coordinates to an address
  using reverse geocoding.\\n\\n```python\\nreverse_geocode(longitude: float,
  latitude: float) -> dict\\n```\\n\\n### search_nearby\\n\\nSearch for places
  near a specific location with optional radius
  expansion.\\n\\n```python\\nsearch_nearby(longitude: float, latitude: float,
  radius: int = 500, max_results: int = 5,\\n              query: str = None,
  max_radius: int = 10000, expansion_factor: float = 2.0,\\n              mode:
  str = 'summary') -> dict\\n```\\n\\n### search_places_open_now\\n\\nSearch for
  places that are currently open, with radius expansion if
  needed.\\n\\n```python\\nsearch_places_open_now(query: str, max_results: int =
  5, initial_radius: int = 500,\\n                       max_radius: int =
  50000, expansion_factor: float = 2.0) -> dict\\n```\\n\\n###
  calculate_route\\n\\nCalculate a route between two locations using Amazon
  Location Service.\\n\\n```python\\ncalculate_route(\\n    departure_position:
  list,  # [longitude, latitude]\\n    destination_position: list,  #
  [longitude, latitude]\\n    travel_mode: str = 'Car',  # 'Car', 'Truck',
  'Walking', or 'Bicycle'\\n    optimize_for: str = 'FastestRoute'  #
  'FastestRoute' or 'ShortestRoute'\\n) -> dict\\n```\\nReturns route geometry,
  distance, duration, and turn-by-turn directions.\\n\\n- `departure_position`:
  List of [longitude, latitude] for the starting point.\\n-
  `destination_position`: List of [longitude, latitude] for the destination.\\n-
  `travel_mode`: Travel mode, one of `'Car'`, `'Truck'`, `'Walking'`, or
  `'Bicycle'`.\\n- `optimize_for`: Route optimization, either `'FastestRoute'`
  or `'ShortestRoute'`.\\n\\nSee [AWS
  documentation](https://docs.aws.amazon.com/location/latest/developerguide/cal\
  culate-routes-custom-avoidance-shortest.html) for more details.\\n\\n###
  get_coordinates\\n\\nGet coordinates for a location name or
  address.\\n\\n```python\\nget_coordinates(location: str) ->
  dict\\n```\\n\\n### optimize_waypoints\\n\\nOptimize the order of waypoints
  using Amazon Location Service geo-routes
  API.\\n\\n```python\\noptimize_waypoints(\\n    origin_position: list,  #
  [longitude, latitude]\\n    destination_position: list,  # [longitude,
  latitude]\\n    waypoints: list,  # List of waypoints, each as a dict with at
  least Position [longitude, latitude]\\n    travel_mode: str =
  'Car',\\n    mode: str = 'summary'\\n) -> dict\\n```\\nReturns the optimized
  order of waypoints, total distance, and duration.\\n\\n## Amazon Location
  Service Resources\\n\\nThis server uses the Amazon Location Service geo-places
  and route calculation APIs for:\\n- Geocoding (converting addresses to
  coordinates)\\n- Reverse geocoding (converting coordinates to addresses)\\n-
  Place search (finding places by name, category, etc.)\\n- Place details
  (getting information about specific places)\\n- **Route calculation (finding
  routes between locations)**\\n\\n## Security Considerations\\n\\n- Use AWS
  profiles for credential management\\n- Use IAM policies to restrict access to
  only the required Amazon Location Service resources\\n- Use temporary
  credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN)
  from AWS STS for enhanced security\\n- Implement AWS IAM roles with temporary
  credentials for applications and services\\n- Regularly rotate credentials and
  use the shortest practical expiration time for temporary
  credentials\\n\",\"isRecommended\":false,\"githubStars\":4265,\"downloadCount\
  \":24,\"createdAt\":\"2025-06-21T01:53:18.183079Z\",\"updatedAt\":\"2025-07-0\
  8T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06-29T20:02:21.845862Z\"},{\"m\
  cpId\":\"github.com/awslabs/mcp/tree/main/src/git-repo-research-mcp-server\",\
  \"githubUrl\":\"https://github.com/awslabs/mcp/tree/main/src/git-repo-researc\
  h-mcp-server\",\"name\":\"Git Repo
  Research\",\"author\":\"awslabs\",\"description\":\"Enables semantic search
  and exploration of Git repositories using FAISS and Amazon Bedrock, allowing
  natural language querying of code without local
  cloning.\",\"codiconIcon\":\"search\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/aws.png\",\"category\":\"version-control\",\"tags\"\
  :[\"semantic-search\",\"git\",\"repository-analysis\",\"code-research\",\"bed\
  rock\"],\"requiresApiKey\":false,\"readmeContent\":\"# Git Repo Research MCP
  Server\\n\\nModel Context Protocol (MCP) server for researching Git
  repositories using semantic search\\n\\nThis MCP server enables developers to
  research external Git repositories and influence their code generation without
  having to clone repositories to local projects. It provides tools to index,
  search, and explore Git repositories using semantic search powered by Amazon
  Bedrock and FAISS.\\n\\n## Features\\n\\n- **Repository Indexing**: Create
  searchable FAISS indexes from local or remote Git repositories\\n- **Semantic
  Search**: Query repository content using natural language and retrieve
  relevant code snippets\\n- **Repository Summary**: Get directory structures
  and identify key files like READMEs\\n- **GitHub Repository Search**: Find
  repositories in AWS-related organizations filtered by licenses and
  keywords\\n- **File Access**: Access repository files and directories with
  support for both text and binary content\\n\\n## Prerequisites\\n\\n###
  Installation Requirements\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python 3.12 or newer using `uv python install 3.12`\\n3. -
  [uv](https://github.com/astral-sh/uv) - Fast Python package installer and
  resolver\\n4. AWS credentials configured with Bedrock access\\n5. Node.js (for
  UVX installation support)\\n\\n\\n### AWS Requirements\\n\\n1. **AWS CLI
  Configuration**: You must have the AWS CLI configured with credentials that
  have access to Amazon Bedrock\\n2. **Amazon Bedrock Access**: Ensure your AWS
  account has access to embedding models like Titan Embeddings\\n3.
  **Environment Variables**: The server uses `AWS_REGION` and `AWS_PROFILE`
  environment variables\\n\\n### Optional Requirements\\n\\n1. **GitHub Token**:
  Set `GITHUB_TOKEN` environment variable for higher rate limits when searching
  GitHub repositories\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.git-repo-research-mcp-server&config=eyJjb21tYW5kIj\
  oidXZ4IGF3c2xhYnMuZ2l0LXJlcG8tcmVzZWFyY2gtbWNwLXNlcnZlckBsYXRlc3QiLCJlbnYiOns\
  iQVdTX1BST0ZJTEUiOiJ5b3VyLXByb2ZpbGUtbmFtZSIsIkFXU19SRUdJT04iOiJ1cy13ZXN0LTIi\
  LCJGQVNUTUNQX0xPR19MRVZFTCI6IkVSUk9SIiwiR0lUSFVCX1RPS0VOIjoieW91ci1naXRodWItd\
  G9rZW4ifSwiZGlzYWJsZWQiOmZhbHNlLCJhdXRvQXBwcm92ZSI6W119)\\n\\nTo add this MCP
  server to your Amazon Q or Claude, add the following to your MCP config
  file:\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.git-repo-research-mcp-server\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"awslabs.git-repo-research-mcp-server@latest\\\"],\\n      \\\"env\\\":
  {\\n        \\\"AWS_PROFILE\\\":
  \\\"your-profile-name\\\",\\n        \\\"AWS_REGION\\\":
  \\\"us-west-2\\\",\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"ERROR\\\",\\n        \\\"GITHUB_TOKEN\\\":
  \\\"your-github-token\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\": []\\n    }\\n  }\\n}\\n```\\n\\n##
  Tools\\n\\n### create_research_repository\\n\\nIndexes a Git repository (local
  or remote) using FAISS and Amazon Bedrock
  embeddings.\\n\\n```python\\ncreate_research_repository(\\n    repository_pat\
  h: str,\\n    output_path: Optional[str] = None,\\n    embedding_model: str =
  \\\"amazon.titan-embed-text-v2:0\\\",\\n    include_patterns:
  Optional[List[str]] = None,\\n    exclude_patterns: Optional[List[str]] =
  None,\\n    chunk_size: int = 1000,\\n    chunk_overlap: int = 200\\n) ->
  Dict\\n```\\n\\n### search_research_repository\\n\\nPerforms semantic search
  within an indexed
  repository.\\n\\n```python\\nsearch_research_repository(\\n    index_path:
  str,\\n    query: str,\\n    limit: int = 10,\\n    threshold: float = 0.0\\n)
  -> Dict\\n```\\n\\n### search_repos_on_github\\n\\nSearches for GitHub
  repositories based on keywords, scoped to AWS
  organizations.\\n\\n```python\\nsearch_repos_on_github(\\n    keywords:
  List[str],\\n    num_results: int = 5\\n) -> Dict\\n```\\n\\n###
  access_file\\n\\nAccesses file or directory contents within repositories or on
  the filesystem.\\n\\n```python\\naccess_file(\\n    filepath: str\\n) -> Dict
  | ImageContent\\n```\\n\\n### delete_research_repository\\n\\nDeletes an
  indexed
  repository.\\n\\n```python\\ndelete_research_repository(\\n    repository_nam\
  e_or_path: str,\\n    index_directory: Optional[str] = None\\n) ->
  Dict\\n```\\n\\n## Resources\\n\\n###
  repositories://{repository_name}/summary\\n\\nGet a summary of an indexed
  repository including structure and helpful
  files.\\n\\n```\\nrepositories://awslabs_mcp/summary\\n```\\n\\n###
  repositories://\\n\\nList all indexed repositories with detailed
  information.\\n\\n```\\nrepositories://\\n```\\n\\n###
  repositories://{index_directory}\\n\\nList all indexed repositories from a
  specific index
  directory.\\n\\n```\\nrepositories:///path/to/custom/index/directory\\n```\\n\
  \\n## Considerations\\n\\n- Repository indexing requires Amazon Bedrock access
  and sufficient permissions\\n- Large repositories may take significant time to
  index\\n- Binary files (except images) are not supported for content
  viewing\\n- GitHub repository search is by default limited to AWS
  organizations: aws-samples, aws-solutions-library-samples, and awslabs (but
  can be configured to include other
  organizations)\\n\",\"isRecommended\":false,\"githubStars\":4383,\"downloadCo\
  unt\":235,\"createdAt\":\"2025-06-21T01:43:53.537904Z\",\"updatedAt\":\"2025-\
  07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T11:23:35.569325Z\"},{\
  \"mcpId\":\"github.com/modelcontextprotocol/servers/tree/main/src/time\",\"gi\
  thubUrl\":\"https://github.com/modelcontextprotocol/servers/tree/main/src/time\
  \",\"name\":\"Time\",\"author\":\"modelcontextprotocol\",\"description\":\"Pr\
  ovides time and timezone conversion capabilities using IANA timezone names,
  with automatic system timezone detection and support for current time
  queries.\",\"codiconIcon\":\"clock\",\"logoUrl\":\"https://storage.googleapis\
  .com/cline_public_images/time.png\",\"category\":\"developer-tools\",\"tags\"\
  :[\"timezone\",\"time-conversion\",\"datetime\",\"scheduling\",\"automation\"\
  ],\"requiresApiKey\":false,\"readmeContent\":\"# Time MCP Server\\n\\nA Model
  Context Protocol server that provides time and timezone conversion
  capabilities. This server enables LLMs to get current time information and
  perform timezone conversions using IANA timezone names, with automatic system
  timezone detection.\\n\\n### Available Tools\\n\\n- `get_current_time` - Get
  current time in a specific timezone or system timezone.\\n  - Required
  arguments:\\n    - `timezone` (string): IANA timezone name (e.g.,
  'America/New_York', 'Europe/London')\\n\\n- `convert_time` - Convert time
  between timezones.\\n  - Required arguments:\\n    - `source_timezone`
  (string): Source IANA timezone name\\n    - `time` (string): Time in 24-hour
  format (HH:MM)\\n    - `target_timezone` (string): Target IANA timezone
  name\\n\\n## Installation\\n\\n### Using uv (recommended)\\n\\nWhen using
  [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We
  will\\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run
  *mcp-server-time*.\\n\\n### Using PIP\\n\\nAlternatively you can install
  `mcp-server-time` via pip:\\n\\n```bash\\npip install
  mcp-server-time\\n```\\n\\nAfter installation, you can run it as a script
  using:\\n\\n```bash\\npython -m mcp_server_time\\n```\\n\\n##
  Configuration\\n\\n### Configure for Claude.app\\n\\nAdd to your Claude
  settings:\\n\\n<details>\\n<summary>Using
  uvx</summary>\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"time\\\":
  {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\":
  [\\\"mcp-server-time\\\"]\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n<details>\
  \\n<summary>Using docker</summary>\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"time\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\",
  \\\"mcp/time\\\"]\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n<details>\\n<summ\
  ary>Using pip installation</summary>\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"time\\\": {\\n      \\\"command\\\":
  \\\"python\\\",\\n      \\\"args\\\": [\\\"-m\\\",
  \\\"mcp_server_time\\\"]\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n###
  Configure for Zed\\n\\nAdd to your Zed
  settings.json:\\n\\n<details>\\n<summary>Using
  uvx</summary>\\n\\n```json\\n\\\"context_servers\\\":
  [\\n  \\\"mcp-server-time\\\": {\\n    \\\"command\\\":
  \\\"uvx\\\",\\n    \\\"args\\\":
  [\\\"mcp-server-time\\\"]\\n  }\\n],\\n```\\n</details>\\n\\n<details>\\n<sum\
  mary>Using pip installation</summary>\\n\\n```json\\n\\\"context_servers\\\":
  {\\n  \\\"mcp-server-time\\\": {\\n    \\\"command\\\":
  \\\"python\\\",\\n    \\\"args\\\": [\\\"-m\\\",
  \\\"mcp_server_time\\\"]\\n  }\\n},\\n```\\n</details>\\n\\n### Configure for
  VS Code\\n\\nFor quick installation, use one of the one-click install buttons
  below...\\n\\n[![Install with UV in VS
  Code](https://img.shields.io/badge/VS_Code-UV-0098FF?style=flat-square&logo=v\
  isualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mcp/in\
  stall?name=time&config=%7B%22command%22%3A%22uvx%22%2C%22args%22%3A%5B%22mcp-\
  server-time%22%5D%7D) [![Install with UV in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-UV-24bfa5?style=flat-\
  square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/re\
  direct/mcp/install?name=time&config=%7B%22command%22%3A%22uvx%22%2C%22args%22\
  %3A%5B%22mcp-server-time%22%5D%7D&quality=insiders)\\n\\n[![Install with
  Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Docker-0098FF?style=flat-square&lo\
  go=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/redirect/mc\
  p/install?name=time&config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B\
  %22run%22%2C%22-i%22%2C%22--rm%22%2C%22mcp%2Ftime%22%5D%7D) [![Install with
  Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Docker-24bfa5?style=f\
  lat-square&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.de\
  v/redirect/mcp/install?name=time&config=%7B%22command%22%3A%22docker%22%2C%22\
  args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22mcp%2Ftime%22%5D%7D&quali\
  ty=insiders)\\n\\nFor manual installation, add the following JSON block to
  your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl +
  Shift + P` and typing `Preferences: Open User Settings
  (JSON)`.\\n\\nOptionally, you can add it to a file called `.vscode/mcp.json`
  in your workspace. This will allow you to share the configuration with
  others.\\n\\n> Note that the `mcp` key is needed when using the `mcp.json`
  file.\\n\\n<details>\\n<summary>Using
  uvx</summary>\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"servers\\\":
  {\\n      \\\"time\\\": {\\n        \\\"command\\\":
  \\\"uvx\\\",\\n        \\\"args\\\":
  [\\\"mcp-server-time\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n</details>\\n\\\
  n<details>\\n<summary>Using Docker</summary>\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"time\\\": {\\n        \\\"command\\\":
  \\\"docker\\\",\\n        \\\"args\\\": [\\\"run\\\", \\\"-i\\\",
  \\\"--rm\\\",
  \\\"mcp/time\\\"]\\n      }\\n    }\\n  }\\n}\\n```\\n</details>\\n\\n###
  Customization - System Timezone\\n\\nBy default, the server automatically
  detects your system's timezone. You can override this by adding the argument
  `--local-timezone` to the `args` list in the
  configuration.\\n\\nExample:\\n```json\\n{\\n  \\\"command\\\":
  \\\"python\\\",\\n  \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\",
  \\\"--local-timezone=America/New_York\\\"]\\n}\\n```\\n\\n## Example
  Interactions\\n\\n1. Get current time:\\n```json\\n{\\n  \\\"name\\\":
  \\\"get_current_time\\\",\\n  \\\"arguments\\\": {\\n    \\\"timezone\\\":
  \\\"Europe/Warsaw\\\"\\n  }\\n}\\n```\\nResponse:\\n```json\\n{\\n  \\\"timez\
  one\\\": \\\"Europe/Warsaw\\\",\\n  \\\"datetime\\\":
  \\\"2024-01-01T13:00:00+01:00\\\",\\n  \\\"is_dst\\\": false\\n}\\n```\\n\\n2.
  Convert time between timezones:\\n```json\\n{\\n  \\\"name\\\":
  \\\"convert_time\\\",\\n  \\\"arguments\\\": {\\n    \\\"source_timezone\\\":
  \\\"America/New_York\\\",\\n    \\\"time\\\":
  \\\"16:30\\\",\\n    \\\"target_timezone\\\":
  \\\"Asia/Tokyo\\\"\\n  }\\n}\\n```\\nResponse:\\n```json\\n{\\n  \\\"source\\\
  \": {\\n    \\\"timezone\\\":
  \\\"America/New_York\\\",\\n    \\\"datetime\\\":
  \\\"2024-01-01T12:30:00-05:00\\\",\\n    \\\"is_dst\\\":
  false\\n  },\\n  \\\"target\\\": {\\n    \\\"timezone\\\":
  \\\"Asia/Tokyo\\\",\\n    \\\"datetime\\\":
  \\\"2024-01-01T12:30:00+09:00\\\",\\n    \\\"is_dst\\\":
  false\\n  },\\n  \\\"time_difference\\\": \\\"+13.0h\\\",\\n}\\n```\\n\\n##
  Debugging\\n\\nYou can use the MCP inspector to debug the server. For uvx
  installations:\\n\\n```bash\\nnpx @modelcontextprotocol/inspector uvx
  mcp-server-time\\n```\\n\\nOr if you've installed the package in a specific
  directory or are developing on it:\\n\\n```bash\\ncd
  path/to/servers/src/time\\nnpx @modelcontextprotocol/inspector uv run
  mcp-server-time\\n```\\n\\n## Examples of Questions for Claude\\n\\n1.
  \\\"What time is it now?\\\" (will use system timezone)\\n2. \\\"What time is
  it in Tokyo?\\\"\\n3. \\\"When it's 4 PM in New York, what time is it in
  London?\\\"\\n4. \\\"Convert 9:30 AM Tokyo time to New York time\\\"\\n\\n##
  Build\\n\\nDocker build:\\n\\n```bash\\ncd src/time\\ndocker build -t mcp/time
  .\\n```\\n\\n## Contributing\\n\\nWe encourage contributions to help expand
  and improve mcp-server-time. Whether you want to add new time-related tools,
  enhance existing functionality, or improve documentation, your input is
  valuable.\\n\\nFor examples of other MCP servers and implementation patterns,
  see:\\nhttps://github.com/modelcontextprotocol/servers\\n\\nPull requests are
  welcome! Feel free to contribute new ideas, bug fixes, or enhancements to make
  mcp-server-time even more powerful and useful.\\n\\n##
  License\\n\\nmcp-server-time is licensed under the MIT License. This means you
  are free to use, modify, and distribute the software, subject to the terms and
  conditions of the MIT License. For more details, please see the LICENSE file
  in the project
  repository.\\n\",\"isRecommended\":true,\"githubStars\":57005,\"downloadCount\
  \":18489,\"createdAt\":\"2025-02-18T05:45:35.164727Z\",\"updatedAt\":\"2025-0\
  7-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T10:26:36.406145Z\"},{\
  \"mcpId\":\"github.com/github/github-mcp-server\",\"githubUrl\":\"https://git\
  hub.com/github/github-mcp-server\",\"name\":\"GitHub\",\"author\":\"github\",\
  \"description\":\"Provides comprehensive GitHub API integration for repository
  management, issues, pull requests, and code operations with authentication and
  enterprise
  support.\",\"codiconIcon\":\"github\",\"logoUrl\":\"https://storage.googleapi\
  s.com/cline_public_images/github.png\",\"category\":\"version-control\",\"tags\
  \":[\"github\",\"repository-management\",\"code-collaboration\",\"git\",\"sou\
  rce-control\"],\"requiresApiKey\":false,\"readmeContent\":\"# GitHub MCP
  Server\\n\\nThe GitHub MCP Server is a [Model Context Protocol
  (MCP)](https://modelcontextprotocol.io/introduction)\\nserver that provides
  seamless integration with GitHub APIs, enabling advanced\\nautomation and
  interaction capabilities for developers and tools.\\n\\n### Use Cases\\n\\n-
  Automating GitHub workflows and processes.\\n- Extracting and analyzing data
  from GitHub repositories.\\n- Building AI powered tools and applications that
  interact with GitHub's ecosystem.\\n\\n---\\n\\n## Remote GitHub MCP
  Server\\n\\n[![Install in VS
  Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-s\
  quare&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/red\
  irect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%22%2C%22url%2\
  2%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS
  Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5\
  ?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.v\
  scode.dev/redirect/mcp/install?name=github&config=%7B%22type%22%3A%20%22http%\
  22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&qua\
  lity=insiders)\\n\\nThe remote GitHub MCP Server is hosted by GitHub and
  provides the easiest method for getting up and running. If your MCP host does
  not support remote MCP servers, don't worry! You can use the [local version of
  the GitHub MCP
  Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-\
  github-mcp-server) instead.\\n\\n## Prerequisites\\n\\n1. An MCP host that
  supports the latest MCP specification and remote servers, such as [VS
  Code](https://code.visualstudio.com/).\\n\\n## Installation\\n\\n### Usage
  with VS Code\\n\\nFor quick installation, use one of the one-click install
  buttons above. Once you complete that flow, toggle Agent mode (located by the
  Copilot Chat text input) and the server will start. Make sure you're using [VS
  Code 1.101](https://code.visualstudio.com/updates/v1_101) or
  [later](https://code.visualstudio.com/updates) for remote MCP and OAuth
  support.\\n\\n\\nAlternatively, to manually configure VS Code, choose the
  appropriate JSON block from the examples below and add it to your host
  configuration:\\n\\n<table>\\n<tr><th>Using OAuth</th><th>Using a GitHub
  PAT</th></tr>\\n<tr><th align=left colspan=2>VS Code (version 1.101 or
  greater)</th></tr>\\n<tr
  valign=top>\\n<td>\\n  \\n```json\\n{\\n  \\\"servers\\\":
  {\\n    \\\"github\\\": {\\n      \\\"type\\\":
  \\\"http\\\",\\n      \\\"url\\\":
  \\\"https://api.githubcopilot.com/mcp/\\\"\\n    }\\n  }\\n}\\n```\\n\\n</td>\
  \\n<td>\\n\\n```json\\n{\\n  \\\"servers\\\": {\\n    \\\"github\\\":
  {\\n      \\\"type\\\": \\\"http\\\",\\n      \\\"url\\\":
  \\\"https://api.githubcopilot.com/mcp/\\\",\\n      \\\"headers\\\":
  {\\n        \\\"Authorization\\\": \\\"Bearer
  ${input:github_mcp_pat}\\\"\\n      }\\n    }\\n  },\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"github_mcp_pat\\\",\\n      \\\"description\\\": \\\"GitHub Personal
  Access Token\\\",\\n      \\\"password\\\":
  true\\n    }\\n  ]\\n}\\n```\\n\\n</td>\\n</tr>\\n</table>\\n\\n### Usage in
  other MCP Hosts\\n\\nFor MCP Hosts that are [Remote
  MCP-compatible](docs/host-integration.md), choose the appropriate JSON block
  from the examples below and add it to your host
  configuration:\\n\\n<table>\\n<tr><th>Using OAuth</th><th>Using a GitHub
  PAT</th></tr>\\n<tr
  valign=top>\\n<td>\\n  \\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"github\\\": {\\n      \\\"url\\\":
  \\\"https://api.githubcopilot.com/mcp/\\\"\\n    }\\n  }\\n}\\n```\\n\\n</td>\
  \\n<td>\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"github\\\":
  {\\n      \\\"url\\\":
  \\\"https://api.githubcopilot.com/mcp/\\\",\\n      \\\"authorization_token\\\
  \": \\\"Bearer <your GitHub
  PAT>\\\"\\n    }\\n  }\\n}\\n```\\n\\n</td>\\n</tr>\\n</table>\\n\\n>
  **Note:** The exact configuration format may vary by host. Refer to your
  host's documentation for the correct syntax and location for remote MCP server
  setup.\\n\\n### Configuration\\n\\nSee [Remote Server
  Documentation](docs/remote-server.md) on how to pass additional configuration
  settings to the remote GitHub MCP Server.\\n\\n---\\n\\n## Local GitHub MCP
  Server\\n\\n[![Install with Docker in VS
  Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-s\
  quare&logo=visualstudiocode&logoColor=white)](https://insiders.vscode.dev/red\
  irect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_token%22%2C%2\
  2type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Ac\
  cess%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22command%22%3A%22do\
  cker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22G\
  ITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5\
  D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agith\
  ub_token%7D%22%7D%7D) [![Install with Docker in VS Code
  Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5\
  ?style=flat-square&logo=visualstudiocode&logoColor=white)](https://insiders.v\
  scode.dev/redirect/mcp/install?name=github&inputs=%5B%7B%22id%22%3A%22github_\
  token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20\
  Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&config=%7B%22comma\
  nd%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%2\
  2-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mc\
  p-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7\
  Binput%3Agithub_token%7D%22%7D%7D&quality=insiders)\\n\\n##
  Prerequisites\\n\\n1. To run the server in a container, you will need to have
  [Docker](https://www.docker.com/) installed.\\n2. Once Docker is installed,
  you will also need to ensure Docker is running. The image is public; if you
  get errors on pull, you may have an expired token and need to `docker logout
  ghcr.io`.\\n3. Lastly you will need to [Create a GitHub Personal Access
  Token](https://github.com/settings/personal-access-tokens/new).\\nThe MCP
  server can use many of the GitHub APIs, so enable the permissions that you
  feel comfortable granting your AI tools (to learn more about access tokens,
  please check out the
  [documentation](https://docs.github.com/en/authentication/keeping-your-accoun\
  t-and-data-secure/managing-your-personal-access-tokens)).\\n\\n##
  Installation\\n\\n### Usage with VS Code\\n\\nFor quick installation, use one
  of the one-click install buttons. Once you complete that flow, toggle Agent
  mode (located by the Copilot Chat text input) and the server will
  start.\\n\\n### Usage in other MCP Hosts\\n\\nAdd the following JSON block to
  your IDE MCP settings.\\n\\n```json\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"inputs\\\": [\\n      {\\n        \\\"type\\\":
  \\\"promptString\\\",\\n        \\\"id\\\":
  \\\"github_token\\\",\\n        \\\"description\\\": \\\"GitHub Personal
  Access Token\\\",\\n        \\\"password\\\":
  true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"github\\\":
  {\\n        \\\"command\\\": \\\"docker\\\",\\n        \\\"args\\\":
  [\\n          \\\"run\\\",\\n          \\\"-i\\\",\\n          \\\"--rm\\\",\
  \\n          \\\"-e\\\",\\n          \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\",\\n          \
  \\\"ghcr.io/github/github-mcp-server\\\"\\n        ],\\n        \\\"env\\\":
  {\\n          \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\":
  \\\"${input:github_token}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\
  \\nOptionally, you can add a similar example (i.e. without the mcp key) to a
  file called `.vscode/mcp.json` in your workspace. This will allow you to share
  the configuration with others.\\n\\n\\n```json\\n{\\n  \\\"inputs\\\":
  [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\":
  \\\"github_token\\\",\\n      \\\"description\\\": \\\"GitHub Personal Access
  Token\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\":
  {\\n    \\\"github\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"-e\\\",\\n        \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\",\\n        \\\"ghc\
  r.io/github/github-mcp-server\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\":
  \\\"${input:github_token}\\\"\\n      }\\n    }\\n  }\\n}\\n\\n```\\n\\nMore
  about using MCP server tools in VS Code's [agent mode
  documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).\
  \\n\\n### Usage with Claude Desktop\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"github\\\": {\\n      \\\"command\\\":
  \\\"docker\\\",\\n      \\\"args\\\":
  [\\n        \\\"run\\\",\\n        \\\"-i\\\",\\n        \\\"--rm\\\",\\n        \
  \\\"-e\\\",\\n        \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\",\\n        \\\"ghc\
  r.io/github/github-mcp-server\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\":
  \\\"<YOUR_TOKEN>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Build from
  source\\n\\nIf you don't have Docker, you can use `go build` to build the
  binary in the\\n`cmd/github-mcp-server` directory, and use the
  `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN`
  environment variable set to your token. To specify the output location of the
  build, use the `-o` flag. You should configure your server to use the built
  executable as its `command`. For example:\\n\\n```JSON\\n{\\n  \\\"mcp\\\":
  {\\n    \\\"servers\\\": {\\n      \\\"github\\\":
  {\\n        \\\"command\\\":
  \\\"/path/to/github-mcp-server\\\",\\n        \\\"args\\\":
  [\\\"stdio\\\"],\\n        \\\"env\\\":
  {\\n          \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\":
  \\\"<YOUR_TOKEN>\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\n##
  Tool Configuration\\n\\nThe GitHub MCP Server supports enabling or disabling
  specific groups of functionalities via the `--toolsets` flag. This allows you
  to control which GitHub API capabilities are available to your AI tools.
  Enabling only the toolsets that you need can help the LLM with tool choice and
  reduce the context size.\\n\\n_Toolsets are not limited to Tools. Relevant MCP
  Resources and Prompts are also included where applicable._\\n\\n### Available
  Toolsets\\n\\nThe following sets of tools are available (all are on by
  default):\\n\\n<!-- START AUTOMATED TOOLSETS -->\\n| Toolset                 |
  Description                                                   |\\n|
  ----------------------- |
  ------------------------------------------------------------- |\\n|
  `context`               | **Strongly recommended**: Tools that provide context
  about the current user and GitHub context you are operating in |\\n| `actions`
  | GitHub Actions workflows and CI/CD operations |\\n| `code_security` | Code
  security related tools, such as GitHub Code Scanning |\\n| `discussions` |
  GitHub Discussions related tools |\\n| `experiments` | Experimental features
  that are not considered stable yet |\\n| `issues` | GitHub Issues related
  tools |\\n| `notifications` | GitHub Notifications related tools |\\n| `orgs`
  | GitHub Organization related tools |\\n| `pull_requests` | GitHub Pull
  Request related tools |\\n| `repos` | GitHub Repository related tools |\\n|
  `secret_protection` | Secret protection related tools, such as GitHub Secret
  Scanning |\\n| `users` | GitHub User related tools |\\n<!-- END AUTOMATED
  TOOLSETS -->\\n\\n#### Specifying Toolsets\\n\\nTo specify toolsets you want
  available to the LLM, you can pass an allow-list in two ways:\\n\\n1. **Using
  Command Line Argument**:\\n\\n   ```bash\\n   github-mcp-server --toolsets
  repos,issues,pull_requests,actions,code_security\\n   ```\\n\\n2. **Using
  Environment
  Variable**:\\n   ```bash\\n   GITHUB_TOOLSETS=\\\"repos,issues,pull_requests,\
  actions,code_security\\\" ./github-mcp-server\\n   ```\\n\\nThe environment
  variable `GITHUB_TOOLSETS` takes precedence over the command line argument if
  both are provided.\\n\\n### Using Toolsets With Docker\\n\\nWhen using Docker,
  you can pass the toolsets as environment variables:\\n\\n```bash\\ndocker run
  -i --rm \\\\\\n  -e GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\\\\n  -e
  GITHUB_TOOLSETS=\\\"repos,issues,pull_requests,actions,code_security,experime\
  nts\\\" \\\\\\n  ghcr.io/github/github-mcp-server\\n```\\n\\n### The
  \\\"all\\\" Toolset\\n\\nThe special toolset `all` can be provided to enable
  all available toolsets regardless of any other
  configuration:\\n\\n```bash\\n./github-mcp-server --toolsets all\\n```\\n\\nOr
  using the environment variable:\\n\\n```bash\\nGITHUB_TOOLSETS=\\\"all\\\"
  ./github-mcp-server\\n```\\n\\n## Dynamic Tool Discovery\\n\\n**Note**: This
  feature is currently in beta and may not be available in all environments.
  Please test it out and let us know if you encounter any issues.\\n\\nInstead
  of starting with all tools enabled, you can turn on dynamic toolset discovery.
  Dynamic toolsets allow the MCP host to list and enable toolsets in response to
  a user prompt. This should help to avoid situations where the model gets
  confused by the sheer number of tools available.\\n\\n### Using Dynamic Tool
  Discovery\\n\\nWhen using the binary, you can pass the `--dynamic-toolsets`
  flag.\\n\\n```bash\\n./github-mcp-server --dynamic-toolsets\\n```\\n\\nWhen
  using Docker, you can pass the toolsets as environment
  variables:\\n\\n```bash\\ndocker run -i --rm \\\\\\n  -e
  GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\\\\n  -e
  GITHUB_DYNAMIC_TOOLSETS=1
  \\\\\\n  ghcr.io/github/github-mcp-server\\n```\\n\\n## Read-Only Mode\\n\\nTo
  run the server in read-only mode, you can use the `--read-only` flag. This
  will only offer read-only tools, preventing any modifications to repositories,
  issues, pull requests, etc.\\n\\n```bash\\n./github-mcp-server
  --read-only\\n```\\n\\nWhen using Docker, you can pass the read-only mode as
  an environment variable:\\n\\n```bash\\ndocker run -i --rm \\\\\\n  -e
  GITHUB_PERSONAL_ACCESS_TOKEN=<your-token> \\\\\\n  -e GITHUB_READ_ONLY=1
  \\\\\\n  ghcr.io/github/github-mcp-server\\n```\\n\\n## GitHub Enterprise
  Server and Enterprise Cloud with data residency (ghe.com)\\n\\nThe flag
  `--gh-host` and the environment variable `GITHUB_HOST` can be used to
  set\\nthe hostname for GitHub Enterprise Server or GitHub Enterprise Cloud
  with data residency.\\n\\n- For GitHub Enterprise Server, prefix the hostname
  with the `https://` URI scheme, as it otherwise defaults to `http://`, which
  GitHub Enterprise Server does not support.\\n- For GitHub Enterprise Cloud
  with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the
  hostname.\\n``` json\\n\\\"github\\\": {\\n    \\\"command\\\":
  \\\"docker\\\",\\n    \\\"args\\\":
  [\\n    \\\"run\\\",\\n    \\\"-i\\\",\\n    \\\"--rm\\\",\\n    \\\"-e\\\",\
  \\n    \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\",\\n    \\\"-e\\\",\\n    \\\"GITH\
  UB_HOST\\\",\\n    \\\"ghcr.io/github/github-mcp-server\\\"\\n    ],\\n    \\\
  \"env\\\": {\\n        \\\"GITHUB_PERSONAL_ACCESS_TOKEN\\\":
  \\\"${input:github_token}\\\",\\n        \\\"GITHUB_HOST\\\":
  \\\"https://<your GHES or ghe.com domain name>\\\"\\n    }\\n}\\n```\\n\\n##
  i18n / Overriding Descriptions\\n\\nThe descriptions of the tools can be
  overridden by creating a\\n`github-mcp-server-config.json` file in the same
  directory as the binary.\\n\\nThe file should contain a JSON object with the
  tool names as keys and the new\\ndescriptions as values. For
  example:\\n\\n```json\\n{\\n  \\\"TOOL_ADD_ISSUE_COMMENT_DESCRIPTION\\\":
  \\\"an alternative
  description\\\",\\n  \\\"TOOL_CREATE_BRANCH_DESCRIPTION\\\": \\\"Create a new
  branch in a GitHub repository\\\"\\n}\\n```\\n\\nYou can create an export of
  the current translations by running the binary with\\nthe
  `--export-translations` flag.\\n\\nThis flag will preserve any
  translations/overrides you have made, while adding\\nany new translations that
  have been added to the binary since the last time
  you\\nexported.\\n\\n```sh\\n./github-mcp-server --export-translations\\ncat
  github-mcp-server-config.json\\n```\\n\\nYou can also use ENV vars to override
  the descriptions. The environment\\nvariable names are the same as the keys in
  the JSON file, prefixed with\\n`GITHUB_MCP_` and all uppercase.\\n\\nFor
  example, to override the `TOOL_ADD_ISSUE_COMMENT_DESCRIPTION` tool, you
  can\\nset the following environment variable:\\n\\n```sh\\nexport
  GITHUB_MCP_TOOL_ADD_ISSUE_COMMENT_DESCRIPTION=\\\"an alternative
  description\\\"\\n```\\n\\n## Tools\\n\\n\\n<!-- START AUTOMATED TOOLS
  -->\\n<details>\\n\\n<summary>Actions</summary>\\n\\n- **cancel_workflow_run**
  - Cancel workflow run\\n  - `owner`: Repository owner (string, required)\\n  -
  `repo`: Repository name (string, required)\\n  - `run_id`: The unique
  identifier of the workflow run (number, required)\\n\\n-
  **delete_workflow_run_logs** - Delete workflow logs\\n  - `owner`: Repository
  owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `run_id`: The unique identifier of the workflow run (number,
  required)\\n\\n- **download_workflow_run_artifact** - Download workflow
  artifact\\n  - `artifact_id`: The unique identifier of the artifact (number,
  required)\\n  - `owner`: Repository owner (string, required)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **get_job_logs** - Get job
  logs\\n  - `failed_only`: When true, gets logs for all failed jobs in run_id
  (boolean, optional)\\n  - `job_id`: The unique identifier of the workflow job
  (required for single job logs) (number, optional)\\n  - `owner`: Repository
  owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `return_content`: Returns actual log content instead of URLs
  (boolean, optional)\\n  - `run_id`: Workflow run ID (required when using
  failed_only) (number, optional)\\n  - `tail_lines`: Number of lines to return
  from the end of the log (number, optional)\\n\\n- **get_workflow_run** - Get
  workflow run\\n  - `owner`: Repository owner (string, required)\\n  - `repo`:
  Repository name (string, required)\\n  - `run_id`: The unique identifier of
  the workflow run (number, required)\\n\\n- **get_workflow_run_logs** - Get
  workflow run logs\\n  - `owner`: Repository owner (string, required)\\n  -
  `repo`: Repository name (string, required)\\n  - `run_id`: The unique
  identifier of the workflow run (number, required)\\n\\n-
  **get_workflow_run_usage** - Get workflow usage\\n  - `owner`: Repository
  owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `run_id`: The unique identifier of the workflow run (number,
  required)\\n\\n- **list_workflow_jobs** - List workflow jobs\\n  - `filter`:
  Filters jobs by their completed_at timestamp (string, optional)\\n  - `owner`:
  Repository owner (string, required)\\n  - `page`: The page number of the
  results to fetch (number, optional)\\n  - `per_page`: The number of results
  per page (max 100) (number, optional)\\n  - `repo`: Repository name (string,
  required)\\n  - `run_id`: The unique identifier of the workflow run (number,
  required)\\n\\n- **list_workflow_run_artifacts** - List workflow
  artifacts\\n  - `owner`: Repository owner (string, required)\\n  - `page`: The
  page number of the results to fetch (number, optional)\\n  - `per_page`: The
  number of results per page (max 100) (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n  - `run_id`: The unique identifier of
  the workflow run (number, required)\\n\\n- **list_workflow_runs** - List
  workflow runs\\n  - `actor`: Returns someone's workflow runs. Use the login
  for the user who created the workflow run. (string, optional)\\n  - `branch`:
  Returns workflow runs associated with a branch. Use the name of the branch.
  (string, optional)\\n  - `event`: Returns workflow runs for a specific event
  type (string, optional)\\n  - `owner`: Repository owner (string,
  required)\\n  - `page`: The page number of the results to fetch (number,
  optional)\\n  - `per_page`: The number of results per page (max 100) (number,
  optional)\\n  - `repo`: Repository name (string, required)\\n  - `status`:
  Returns workflow runs with the check run status (string, optional)\\n  -
  `workflow_id`: The workflow ID or workflow file name (string, required)\\n\\n-
  **list_workflows** - List workflows\\n  - `owner`: Repository owner (string,
  required)\\n  - `page`: The page number of the results to fetch (number,
  optional)\\n  - `per_page`: The number of results per page (max 100) (number,
  optional)\\n  - `repo`: Repository name (string, required)\\n\\n-
  **rerun_failed_jobs** - Rerun failed jobs\\n  - `owner`: Repository owner
  (string, required)\\n  - `repo`: Repository name (string, required)\\n  -
  `run_id`: The unique identifier of the workflow run (number, required)\\n\\n-
  **rerun_workflow_run** - Rerun workflow run\\n  - `owner`: Repository owner
  (string, required)\\n  - `repo`: Repository name (string, required)\\n  -
  `run_id`: The unique identifier of the workflow run (number, required)\\n\\n-
  **run_workflow** - Run workflow\\n  - `inputs`: Inputs the workflow accepts
  (object, optional)\\n  - `owner`: Repository owner (string, required)\\n  -
  `ref`: The git reference for the workflow. The reference can be a branch or
  tag name. (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `workflow_id`: The workflow ID (numeric) or workflow file name
  (e.g., main.yml, ci.yaml) (string,
  required)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Code
  Security</summary>\\n\\n- **get_code_scanning_alert** - Get code scanning
  alert\\n  - `alertNumber`: The number of the alert. (number, required)\\n  -
  `owner`: The owner of the repository. (string, required)\\n  - `repo`: The
  name of the repository. (string, required)\\n\\n-
  **list_code_scanning_alerts** - List code scanning alerts\\n  - `owner`: The
  owner of the repository. (string, required)\\n  - `ref`: The Git reference for
  the results you want to list. (string, optional)\\n  - `repo`: The name of the
  repository. (string, required)\\n  - `severity`: Filter code scanning alerts
  by severity (string, optional)\\n  - `state`: Filter code scanning alerts by
  state. Defaults to open (string, optional)\\n  - `tool_name`: The name of the
  tool used for code scanning. (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Context</summary>\\n\\\
  n- **get_me** - Get my user profile\\n  - `reason`: Optional: the reason for
  requesting the user information (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Discussions</summary>\
  \\n\\n- **get_discussion** - Get discussion\\n  - `discussionNumber`:
  Discussion Number (number, required)\\n  - `owner`: Repository owner (string,
  required)\\n  - `repo`: Repository name (string, required)\\n\\n-
  **get_discussion_comments** - Get discussion comments\\n  -
  `discussionNumber`: Discussion Number (number, required)\\n  - `owner`:
  Repository owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **list_discussion_categories** - List discussion
  categories\\n  - `after`: Cursor for pagination, use the 'after' field from
  the previous response (string, optional)\\n  - `before`: Cursor for
  pagination, use the 'before' field from the previous response (string,
  optional)\\n  - `first`: Number of categories to return per page (min 1, max
  100) (number, optional)\\n  - `last`: Number of categories to return from the
  end (min 1, max 100) (number, optional)\\n  - `owner`: Repository owner
  (string, required)\\n  - `repo`: Repository name (string, required)\\n\\n-
  **list_discussions** - List discussions\\n  - `category`: Optional filter by
  discussion category ID. If provided, only discussions with this category are
  listed. (string, optional)\\n  - `owner`: Repository owner (string,
  required)\\n  - `repo`: Repository name (string,
  required)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Issues</summary>\\n\\n-
  **add_issue_comment** - Add comment to issue\\n  - `body`: Comment content
  (string, required)\\n  - `issue_number`: Issue number to comment on (number,
  required)\\n  - `owner`: Repository owner (string, required)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **assign_copilot_to_issue** - Assign
  Copilot to issue\\n  - `issueNumber`: Issue number (number, required)\\n  -
  `owner`: Repository owner (string, required)\\n  - `repo`: Repository name
  (string, required)\\n\\n- **create_issue** - Open new issue\\n  - `assignees`:
  Usernames to assign to this issue (string[], optional)\\n  - `body`: Issue
  body content (string, optional)\\n  - `labels`: Labels to apply to this issue
  (string[], optional)\\n  - `milestone`: Milestone number (number,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  - `repo`:
  Repository name (string, required)\\n  - `title`: Issue title (string,
  required)\\n\\n- **get_issue** - Get issue details\\n  - `issue_number`: The
  number of the issue (number, required)\\n  - `owner`: The owner of the
  repository (string, required)\\n  - `repo`: The name of the repository
  (string, required)\\n\\n- **get_issue_comments** - Get issue comments\\n  -
  `issue_number`: Issue number (number, required)\\n  - `owner`: Repository
  owner (string, required)\\n  - `page`: Page number (number, optional)\\n  -
  `per_page`: Number of records per page (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **list_issues** - List issues\\n  -
  `direction`: Sort direction (string, optional)\\n  - `labels`: Filter by
  labels (string[], optional)\\n  - `owner`: Repository owner (string,
  required)\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `repo`: Repository name (string, required)\\n  -
  `since`: Filter by date (ISO 8601 timestamp) (string, optional)\\n  - `sort`:
  Sort order (string, optional)\\n  - `state`: Filter by state (string,
  optional)\\n\\n- **search_issues** - Search issues\\n  - `order`: Sort order
  (string, optional)\\n  - `owner`: Optional repository owner. If provided with
  repo, only notifications for this repository are listed. (string,
  optional)\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `query`: Search query using GitHub issues search
  syntax (string, required)\\n  - `repo`: Optional repository name. If provided
  with owner, only notifications for this repository are listed. (string,
  optional)\\n  - `sort`: Sort field by number of matches of categories,
  defaults to best match (string, optional)\\n\\n- **update_issue** - Edit
  issue\\n  - `assignees`: New assignees (string[], optional)\\n  - `body`: New
  description (string, optional)\\n  - `issue_number`: Issue number to update
  (number, required)\\n  - `labels`: New labels (string[], optional)\\n  -
  `milestone`: New milestone number (number, optional)\\n  - `owner`: Repository
  owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `state`: New state (string, optional)\\n  - `title`: New title
  (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Notifications</summary>\
  \\n\\n- **dismiss_notification** - Dismiss notification\\n  - `state`: The new
  state of the notification (read/done) (string, optional)\\n  - `threadID`: The
  ID of the notification thread (string, required)\\n\\n-
  **get_notification_details** - Get notification details\\n  -
  `notificationID`: The ID of the notification (string, required)\\n\\n-
  **list_notifications** - List notifications\\n  - `before`: Only show
  notifications updated before the given time (ISO 8601 format) (string,
  optional)\\n  - `filter`: Filter notifications to, use default unless
  specified. Read notifications are ones that have already been acknowledged by
  the user. Participating notifications are those that the user is directly
  involved in, such as issues or pull requests they have commented on or
  created. (string, optional)\\n  - `owner`: Optional repository owner. If
  provided with repo, only notifications for this repository are listed.
  (string, optional)\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `repo`: Optional repository name. If provided with
  owner, only notifications for this repository are listed. (string,
  optional)\\n  - `since`: Only show notifications updated after the given time
  (ISO 8601 format) (string, optional)\\n\\n-
  **manage_notification_subscription** - Manage notification subscription\\n  -
  `action`: Action to perform: ignore, watch, or delete the notification
  subscription. (string, required)\\n  - `notificationID`: The ID of the
  notification thread. (string, required)\\n\\n-
  **manage_repository_notification_subscription** - Manage repository
  notification subscription\\n  - `action`: Action to perform: ignore, watch, or
  delete the repository notification subscription. (string, required)\\n  -
  `owner`: The account owner of the repository. (string, required)\\n  - `repo`:
  The name of the repository. (string, required)\\n\\n-
  **mark_all_notifications_read** - Mark all notifications as read\\n  -
  `lastReadAt`: Describes the last point that notifications were checked
  (optional). Default: Now (string, optional)\\n  - `owner`: Optional repository
  owner. If provided with repo, only notifications for this repository are
  marked as read. (string, optional)\\n  - `repo`: Optional repository name. If
  provided with owner, only notifications for this repository are marked as
  read. (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Organizations</summary>\
  \\n\\n- **search_orgs** - Search organizations\\n  - `order`: Sort order
  (string, optional)\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `query`: Search query using GitHub organizations
  search syntax scoped to type:org (string, required)\\n  - `sort`: Sort field
  by category (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Pull
  Requests</summary>\\n\\n-
  **add_pull_request_review_comment_to_pending_review** - Add comment to the
  requester's latest pending pull request review\\n  - `body`: The text of the
  review comment (string, required)\\n  - `line`: The line of the blob in the
  pull request diff that the comment applies to. For multi-line comments, the
  last line of the range (number, optional)\\n  - `owner`: Repository owner
  (string, required)\\n  - `path`: The relative path to the file that
  necessitates a comment (string, required)\\n  - `pullNumber`: Pull request
  number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `side`: The side of the diff to comment on. LEFT indicates the
  previous state, RIGHT indicates the new state (string, optional)\\n  -
  `startLine`: For multi-line comments, the first line of the range that the
  comment applies to (number, optional)\\n  - `startSide`: For multi-line
  comments, the starting side of the diff that the comment applies to. LEFT
  indicates the previous state, RIGHT indicates the new state (string,
  optional)\\n  - `subjectType`: The level at which the comment is targeted
  (string, required)\\n\\n- **create_and_submit_pull_request_review** - Create
  and submit a pull request review without comments\\n  - `body`: Review comment
  text (string, required)\\n  - `commitID`: SHA of commit to review (string,
  optional)\\n  - `event`: Review action to perform (string, required)\\n  -
  `owner`: Repository owner (string, required)\\n  - `pullNumber`: Pull request
  number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **create_pending_pull_request_review** - Create pending pull
  request review\\n  - `commitID`: SHA of commit to review (string,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number (number, required)\\n  - `repo`: Repository
  name (string, required)\\n\\n- **create_pull_request** - Open new pull
  request\\n  - `base`: Branch to merge into (string, required)\\n  - `body`: PR
  description (string, optional)\\n  - `draft`: Create as draft PR (boolean,
  optional)\\n  - `head`: Branch containing changes (string, required)\\n  -
  `maintainer_can_modify`: Allow maintainer edits (boolean, optional)\\n  -
  `owner`: Repository owner (string, required)\\n  - `repo`: Repository name
  (string, required)\\n  - `title`: PR title (string, required)\\n\\n-
  **delete_pending_pull_request_review** - Delete the requester's latest pending
  pull request review\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number (number, required)\\n  - `repo`: Repository
  name (string, required)\\n\\n- **get_pull_request** - Get pull request
  details\\n  - `owner`: Repository owner (string, required)\\n  - `pullNumber`:
  Pull request number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **get_pull_request_comments** - Get pull request
  comments\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number (number, required)\\n  - `repo`: Repository
  name (string, required)\\n\\n- **get_pull_request_diff** - Get pull request
  diff\\n  - `owner`: Repository owner (string, required)\\n  - `pullNumber`:
  Pull request number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **get_pull_request_files** - Get pull request files\\n  -
  `owner`: Repository owner (string, required)\\n  - `page`: Page number for
  pagination (min 1) (number, optional)\\n  - `perPage`: Results per page for
  pagination (min 1, max 100) (number, optional)\\n  - `pullNumber`: Pull
  request number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **get_pull_request_reviews** - Get pull request reviews\\n  -
  `owner`: Repository owner (string, required)\\n  - `pullNumber`: Pull request
  number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **get_pull_request_status** - Get pull request status
  checks\\n  - `owner`: Repository owner (string, required)\\n  - `pullNumber`:
  Pull request number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **list_pull_requests** - List pull requests\\n  - `base`:
  Filter by base branch (string, optional)\\n  - `direction`: Sort direction
  (string, optional)\\n  - `head`: Filter by head user/org and branch (string,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  - `page`:
  Page number for pagination (min 1) (number, optional)\\n  - `perPage`: Results
  per page for pagination (min 1, max 100) (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n  - `sort`: Sort by (string,
  optional)\\n  - `state`: Filter by state (string, optional)\\n\\n-
  **merge_pull_request** - Merge pull request\\n  - `commit_message`: Extra
  detail for merge commit (string, optional)\\n  - `commit_title`: Title for
  merge commit (string, optional)\\n  - `merge_method`: Merge method (string,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number (number, required)\\n  - `repo`: Repository
  name (string, required)\\n\\n- **request_copilot_review** - Request Copilot
  review\\n  - `owner`: Repository owner (string, required)\\n  - `pullNumber`:
  Pull request number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **search_pull_requests** - Search pull requests\\n  -
  `order`: Sort order (string, optional)\\n  - `owner`: Optional repository
  owner. If provided with repo, only notifications for this repository are
  listed. (string, optional)\\n  - `page`: Page number for pagination (min 1)
  (number, optional)\\n  - `perPage`: Results per page for pagination (min 1,
  max 100) (number, optional)\\n  - `query`: Search query using GitHub pull
  request search syntax (string, required)\\n  - `repo`: Optional repository
  name. If provided with owner, only notifications for this repository are
  listed. (string, optional)\\n  - `sort`: Sort field by number of matches of
  categories, defaults to best match (string, optional)\\n\\n-
  **submit_pending_pull_request_review** - Submit the requester's latest pending
  pull request review\\n  - `body`: The text of the review comment (string,
  optional)\\n  - `event`: The event to perform (string, required)\\n  -
  `owner`: Repository owner (string, required)\\n  - `pullNumber`: Pull request
  number (number, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **update_pull_request** - Edit pull request\\n  - `base`: New
  base branch name (string, optional)\\n  - `body`: New description (string,
  optional)\\n  - `maintainer_can_modify`: Allow maintainer edits (boolean,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number to update (number, required)\\n  - `repo`:
  Repository name (string, required)\\n  - `state`: New state (string,
  optional)\\n  - `title`: New title (string, optional)\\n\\n-
  **update_pull_request_branch** - Update pull request branch\\n  -
  `expectedHeadSha`: The expected SHA of the pull request's HEAD ref (string,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  -
  `pullNumber`: Pull request number (number, required)\\n  - `repo`: Repository
  name (string,
  required)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Repositories</summary>\
  \\n\\n- **create_branch** - Create branch\\n  - `branch`: Name for new branch
  (string, required)\\n  - `from_branch`: Source branch (defaults to repo
  default) (string, optional)\\n  - `owner`: Repository owner (string,
  required)\\n  - `repo`: Repository name (string, required)\\n\\n-
  **create_or_update_file** - Create or update file\\n  - `branch`: Branch to
  create/update the file in (string, required)\\n  - `content`: Content of the
  file (string, required)\\n  - `message`: Commit message (string,
  required)\\n  - `owner`: Repository owner (username or organization) (string,
  required)\\n  - `path`: Path where to create/update the file (string,
  required)\\n  - `repo`: Repository name (string, required)\\n  - `sha`: SHA of
  file being replaced (for updates) (string, optional)\\n\\n-
  **create_repository** - Create repository\\n  - `autoInit`: Initialize with
  README (boolean, optional)\\n  - `description`: Repository description
  (string, optional)\\n  - `name`: Repository name (string, required)\\n  -
  `private`: Whether repo should be private (boolean, optional)\\n\\n-
  **delete_file** - Delete file\\n  - `branch`: Branch to delete the file from
  (string, required)\\n  - `message`: Commit message (string, required)\\n  -
  `owner`: Repository owner (username or organization) (string, required)\\n  -
  `path`: Path to the file to delete (string, required)\\n  - `repo`: Repository
  name (string, required)\\n\\n- **fork_repository** - Fork repository\\n  -
  `organization`: Organization to fork to (string, optional)\\n  - `owner`:
  Repository owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n\\n- **get_commit** - Get commit details\\n  - `owner`: Repository
  owner (string, required)\\n  - `page`: Page number for pagination (min 1)
  (number, optional)\\n  - `perPage`: Results per page for pagination (min 1,
  max 100) (number, optional)\\n  - `repo`: Repository name (string,
  required)\\n  - `sha`: Commit SHA, branch name, or tag name (string,
  required)\\n\\n- **get_file_contents** - Get file or directory contents\\n  -
  `owner`: Repository owner (username or organization) (string, required)\\n  -
  `path`: Path to file/directory (directories must end with a slash '/')
  (string, required)\\n  - `ref`: Accepts optional git refs such as
  `refs/tags/{tag}`, `refs/heads/{branch}` or `refs/pull/{pr_number}/head`
  (string, optional)\\n  - `repo`: Repository name (string, required)\\n  -
  `sha`: Accepts optional git sha, if sha is specified it will be used instead
  of ref (string, optional)\\n\\n- **get_tag** - Get tag details\\n  - `owner`:
  Repository owner (string, required)\\n  - `repo`: Repository name (string,
  required)\\n  - `tag`: Tag name (string, required)\\n\\n- **list_branches** -
  List branches\\n  - `owner`: Repository owner (string, required)\\n  - `page`:
  Page number for pagination (min 1) (number, optional)\\n  - `perPage`: Results
  per page for pagination (min 1, max 100) (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **list_commits** - List
  commits\\n  - `author`: Author username or email address (string,
  optional)\\n  - `owner`: Repository owner (string, required)\\n  - `page`:
  Page number for pagination (min 1) (number, optional)\\n  - `perPage`: Results
  per page for pagination (min 1, max 100) (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n  - `sha`: The commit SHA, branch name,
  or tag name to list commits from. If not specified, defaults to the
  repository's default branch. (string, optional)\\n\\n- **list_tags** - List
  tags\\n  - `owner`: Repository owner (string, required)\\n  - `page`: Page
  number for pagination (min 1) (number, optional)\\n  - `perPage`: Results per
  page for pagination (min 1, max 100) (number, optional)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **push_files** - Push files to
  repository\\n  - `branch`: Branch to push to (string, required)\\n  - `files`:
  Array of file objects to push, each object with path (string) and content
  (string) (object[], required)\\n  - `message`: Commit message (string,
  required)\\n  - `owner`: Repository owner (string, required)\\n  - `repo`:
  Repository name (string, required)\\n\\n- **search_code** - Search code\\n  -
  `order`: Sort order (string, optional)\\n  - `page`: Page number for
  pagination (min 1) (number, optional)\\n  - `perPage`: Results per page for
  pagination (min 1, max 100) (number, optional)\\n  - `q`: Search query using
  GitHub code search syntax (string, required)\\n  - `sort`: Sort field
  ('indexed' only) (string, optional)\\n\\n- **search_repositories** - Search
  repositories\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `query`: Search query (string,
  required)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Secret
  Protection</summary>\\n\\n- **get_secret_scanning_alert** - Get secret
  scanning alert\\n  - `alertNumber`: The number of the alert. (number,
  required)\\n  - `owner`: The owner of the repository. (string, required)\\n  -
  `repo`: The name of the repository. (string, required)\\n\\n-
  **list_secret_scanning_alerts** - List secret scanning alerts\\n  - `owner`:
  The owner of the repository. (string, required)\\n  - `repo`: The name of the
  repository. (string, required)\\n  - `resolution`: Filter by resolution
  (string, optional)\\n  - `secret_type`: A comma-separated list of secret types
  to return. All default secret patterns are returned. To return generic
  patterns, pass the token name(s) in the parameter. (string, optional)\\n  -
  `state`: Filter by state (string,
  optional)\\n\\n</details>\\n\\n<details>\\n\\n<summary>Users</summary>\\n\\n-
  **search_users** - Search users\\n  - `order`: Sort order (string,
  optional)\\n  - `page`: Page number for pagination (min 1) (number,
  optional)\\n  - `perPage`: Results per page for pagination (min 1, max 100)
  (number, optional)\\n  - `query`: Search query using GitHub users search
  syntax scoped to type:user (string, required)\\n  - `sort`: Sort field by
  category (string, optional)\\n\\n</details>\\n<!-- END AUTOMATED TOOLS
  -->\\n\\n## Library Usage\\n\\nThe exported Go API of this module should
  currently be considered unstable, and subject to breaking changes. In the
  future, we may offer stability; please file an issue if there is a use case
  where this would be valuable.\\n\\n## License\\n\\nThis project is licensed
  under the terms of the MIT open source license. Please refer to
  [MIT](./LICENSE) for the full
  terms.\\n\",\"isRecommended\":false,\"githubStars\":16750,\"downloadCount\":1\
  4956,\"createdAt\":\"2025-04-24T06:28:44.003471Z\",\"updatedAt\":\"2025-07-08\
  T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-03T09:07:39.738878Z\"},{\"mc\
  pId\":\"github.com/awslabs/mcp/tree/main/src/prometheus-mcp-server\",\"github\
  Url\":\"https://github.com/awslabs/mcp/tree/main/src/prometheus-mcp-server\",\
  \"name\":\"Prometheus Query\",\"author\":\"awslabs\",\"description\":\"Enables
  querying and monitoring with AWS Managed Prometheus, supporting PromQL
  queries, metric listing, and server information retrieval with AWS SigV4
  authentication.\",\"codiconIcon\":\"graph\",\"logoUrl\":\"https://storage.goo\
  gleapis.com/cline_public_images/aws.png\",\"category\":\"monitoring\",\"tags\
  \":[\"prometheus\",\"metrics\",\"aws\",\"monitoring\",\"promql\"],\"requiresA\
  piKey\":false,\"readmeContent\":\"# Prometheus MCP Server\\n\\nThe Prometheus
  MCP Server provides a robust interface for interacting with AWS Managed
  Prometheus, enabling users to execute PromQL queries, list metrics, and
  retrieve server information with AWS SigV4 authentication support.\\n\\nThis
  MCP server is designed to be fully compatible with Amazon Q developer CLI,
  allowing seamless integration of Prometheus monitoring capabilities into your
  Amazon Q workflows. You can load the server directly into Amazon Q to leverage
  its powerful querying and metric analysis features through the familiar Q
  interface.\\n\\n## Features\\n\\n- Execute instant PromQL queries against AWS
  Managed Prometheus\\n- Execute range queries with start time, end time, and
  step interval\\n- List all available metrics in your Prometheus instance\\n-
  Get server configuration information\\n- AWS SigV4 authentication for secure
  access\\n- Automatic retries with exponential backoff\\n\\n##
  Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs.prometheus-mcp-server&config=eyJjb21tYW5kIjoidXZ4I\
  GF3c2xhYnMucHJvbWV0aGV1cy1tY3Atc2VydmVyQGxhdGVzdCAtLXVybCBodHRwczovL2Fwcy13b3\
  Jrc3BhY2VzLnVzLWVhc3QtMS5hbWF6b25hd3MuY29tL3dvcmtzcGFjZXMvd3MtPFdvcmtzcGFjZSB\
  JRD4gLS1yZWdpb24gPFlvdXIgQVdTIFJlZ2lvbj4gLS1wcm9maWxlIDxZb3VyIENMSSBQcm9maWxl\
  IFtkZWZhdWx0XSBpZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIiwiZW52Ijp7IkZBU1RNQ1BfTE9HX0x\
  FVkVMIjoiREVCVUciLCJBV1NfUFJPRklMRSI6IjxZb3VyIENMSSBQcm9maWxlIFtkZWZhdWx0XSBp\
  ZiBubyBwcm9maWxlIGlzIHVzZWQ%2BIn19)\\n\\n### Prerequisites\\n\\n- Python 3.10
  or higher\\n- AWS credentials configured with appropriate permissions\\n- AWS
  Managed Prometheus workspace\\n\\n\\n\\n## Configuration\\n\\nThe server is
  configured through the Amazon Q MCP configuration file as shown in the Usage
  section below.\\n\\n## Usage with Amazon Q\\n\\nHere are some ways you can
  work with MCP across AWS, and we'll be adding support to more products
  including Amazon Q Developer CLI soon:\\n\\n1. Create a configuration
  file:\\n```bash\\nmkdir -p ~/.aws/amazonq/\\n```\\n\\n2. Add the following to
  `~/.aws/amazonq/mcp.json`:\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"awslabs.prometheus-mcp-server\\\": {\\n      \\\"command\\\":
  \\\"uvx\\\",\\n      \\\"args\\\":
  [\\n        \\\"awslabs.prometheus-mcp-server@latest\\\",\\n        \\\"--url\
  \\\",\\n        \\\"https://aps-workspaces.us-east-1.amazonaws.com/workspaces\
  /ws-<Workspace ID>\\\",\\n        \\\"--region\\\",\\n        \\\"<Your AWS
  Region>\\\",\\n        \\\"--profile\\\",\\n        \\\"<Your CLI Profile
  [default] if no profile is used>\\\"\\n      ],\\n      \\\"env\\\":
  {\\n        \\\"FASTMCP_LOG_LEVEL\\\":
  \\\"DEBUG\\\",\\n        \\\"AWS_PROFILE\\\": \\\"<Your CLI Profile [default]
  if no profile is used>\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n3. In Amazon
  Q, you can now use the Prometheus MCP server to query your metrics.\\n\\n##
  Available Tools\\n\\n1. **execute_query**\\n   - Execute instant PromQL
  queries against Prometheus\\n   - Parameters: query (required), time
  (optional)\\n\\n2. **execute_range_query**\\n   - Execute PromQL queries over
  a time range\\n   - Parameters: query, start time, end time, step
  interval\\n\\n3. **list_metrics**\\n   - Retrieve all available metric names
  from Prometheus\\n   - Returns: Sorted list of metric names\\n\\n4.
  **get_server_info**\\n   - Retrieve server configuration details\\n   -
  Returns: URL, region, profile, and service information\\n\\n## Example
  Queries\\n\\n```python\\n# Execute an instant query\\nresult = await
  execute_query(\\\"up\\\")\\n\\n# Execute a range query\\ndata = await
  execute_range_query(\\n    query=\\\"rate(node_cpu_seconds_total[5m])\\\",\\n    \
  start=\\\"2023-01-01T00:00:00Z\\\",\\n    end=\\\"2023-01-01T01:00:00Z\\\",\\\
  n    step=\\\"1m\\\"\\n)\\n\\n# List available metrics\\nmetrics = await
  list_metrics()\\n\\n# Get server information\\ninfo = await
  get_server_info()\\n```\\n\\n## Troubleshooting\\n\\nCommon issues and
  solutions:\\n\\n1. **AWS Credentials Not Found**\\n   - Check
  ~/.aws/credentials\\n   - Set AWS_PROFILE environment variable\\n   - Verify
  IAM permissions\\n\\n2. **Connection Errors**\\n   - Verify Prometheus URL is
  correct\\n   - Check network connectivity\\n   - Ensure AWS VPC access is
  configured correctly\\n\\n3. **Authentication Failures**\\n   - Verify AWS
  credentials are current\\n   - Check system clock synchronization\\n   -
  Ensure correct AWS region is specified\\n\\n## License\\n\\nThis project is
  licensed under the Apache License 2.0 - see the LICENSE file for
  details.\\n\",\"isRecommended\":false,\"githubStars\":4383,\"downloadCount\":\
  94,\"createdAt\":\"2025-06-21T02:02:37.097621Z\",\"updatedAt\":\"2025-07-08T0\
  1:10:48.398933Z\",\"lastGithubSync\":\"2025-07-05T13:29:08.495597Z\"},{\"mcpId\
  \":\"github.com/supermemoryai/supermemory-mcp\",\"githubUrl\":\"https://githu\
  b.com/supermemoryai/supermemory-mcp\",\"name\":\"Supermemory\",\"author\":\"s\
  upermemoryai\",\"description\":\"Universal memory system that makes personal
  context and memories available across different LLMs, enabling seamless memory
  transfer without logins or
  paywalls.\",\"codiconIcon\":\"database\",\"logoUrl\":\"https://storage.google\
  apis.com/cline_public_images/supermemory.png\",\"category\":\"knowledge-memory\
  \",\"tags\":[\"memory-management\",\"llm-integration\",\"context-sharing\",\"\
  persistence\",\"knowledge-base\"],\"requiresApiKey\":false,\"readmeContent\":\
  \"# Supermemory MCP - Universal Memory across LLMs\\n\\n[![Universal Memory
  MCP - Your memories, in every LLM you use. | Product
  Hunt](https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?p\
  ost_id=954861&theme=neutral&period=daily&t=1749339045428)](https://www.produc\
  thunt.com/products/supermemory?embed=true&utm_source=badge-top-post-badge&utm\
  _medium=badge&utm_source=badge-universal-memory-mcp)\\n\\nRead a detailed blog
  about it -
  https://supermemory.ai/blog/the-ux-and-technicalities-of-awesome-mcps
  \\n\\n**Your memories are in ChatGPT... But nowhere else. Universal Memory MCP
  makes your memories available to every single LLM. No logins or paywall. One
  command to set it up.**\\n\\nWhich means you can carry your memories to any
  MCP client. and it just works!\\n\\n## Demo (Click on the image for
  video!)\\n\\n[![Demo
  Video](./public/og-image.png)](https://youtu.be/ST6BR3vT5Xw)\\n\\n## Getting
  Started\\n\\nTo get started, just visit https://mcp.supermemory.ai, and follow
  the instructions on the page.\\n\\n## Features\\n\\n-  Built on top of the
  [Supermemory API](https://supermemory.ai), extremely fast and scalable.\\n- 
  No login required\\n-  Completely free to use\\n- Extremely simple
  setup.\\n\\n## Self-hosting\\n\\nTo self host, get an API key at
  https://console.supermemory.ai, and then simply add it in the `.env` file with
  `SUPERMEMORY_API_KEY=`\\n\",\"isRecommended\":false,\"githubStars\":1081,\"do\
  wnloadCount\":2653,\"createdAt\":\"2025-06-10T19:23:15.439727Z\",\"updatedAt\
  \":\"2025-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-07-01T20:20:48.8\
  53059Z\"},{\"mcpId\":\"github.com/Garoth/sendgrid-mcp\",\"githubUrl\":\"https\
  ://github.com/Garoth/sendgrid-mcp\",\"name\":\"SendGrid\",\"author\":\"Garoth\
  \",\"description\":\"Provides email marketing and contact management
  capabilities through SendGrid's Marketing API, enabling dynamic templates,
  contact list management, and bulk email
  sending.\",\"codiconIcon\":\"mail\",\"logoUrl\":\"https://storage.googleapis.\
  com/cline_public_images/sendgrid.png\",\"category\":\"marketing\",\"tags\":[\
  \"email-marketing\",\"contact-management\",\"templates\",\"bulk-email\",\"sen\
  dgrid-api\"],\"requiresApiKey\":false,\"readmeContent\":\"# SendGrid MCP
  Server\\n\\n<img src=\\\"assets/sendgrid-logo.png\\\" width=\\\"256\\\"
  height=\\\"256\\\" alt=\\\"SendGrid Logo\\\" />\\n\\nA Model Context Protocol
  (MCP) server that provides access to SendGrid's Marketing API for email
  marketing and contact management.
  https://docs.sendgrid.com/api-reference/how-to-use-the-sendgrid-v3-api\\n\\n##
  Demo\\n\\nIn this demo, we ask the Cline SendGrid agent to make a new contact
  list, add my emails to it, automatically generate a template for Lost Cities
  facts, and send the email to the list. In this process, Cline will
  automatically realize that it needs to know the verified senders we have, and
  which unsubscribe group to use. A pretty email is delivered to my inboxes,
  delighting me with Lost Cities!\\n\\n<img src=\\\"assets/1.png\\\"
  width=\\\"760\\\" alt=\\\"SendGrid MCP Demo 1\\\" />\\n<img
  src=\\\"assets/2.png\\\" width=\\\"760\\\" alt=\\\"SendGrid MCP Demo 2\\\"
  />\\n<img src=\\\"assets/3.png\\\" width=\\\"760\\\" alt=\\\"SendGrid MCP Demo
  3\\\" />\\n<img src=\\\"assets/4.png\\\" width=\\\"760\\\" alt=\\\"SendGrid
  MCP Demo 4\\\" />\\n<img src=\\\"assets/5.png\\\" width=\\\"760\\\"
  alt=\\\"SendGrid MCP Demo 5\\\" />\\n<img src=\\\"assets/6.png\\\"
  width=\\\"760\\\" alt=\\\"SendGrid MCP Demo 6\\\" />\\n<img
  src=\\\"assets/7.png\\\" width=\\\"760\\\" alt=\\\"SendGrid MCP Demo 7\\\"
  />\\n<img src=\\\"assets/8.png\\\" width=\\\"760\\\" alt=\\\"SendGrid MCP Demo
  8\\\" />\\n<img src=\\\"assets/9.png\\\" width=\\\"760\\\" alt=\\\"SendGrid
  MCP Demo 9\\\" />\\n\\n## Important Note on API Support\\n\\nThis server
  exclusively supports SendGrid's v3 APIs and does not provide support for
  legacy functionality. This includes:\\n\\n- Dynamic templates only - legacy
  templates are not supported\\n- Marketing API v3 for all contact & contact
  list operations\\n- Single Sends API for bulk email sending\\n\\n## Available
  Tools\\n\\n### Contact Management\\n\\n#### list_contacts\\nLists all contacts
  in your SendGrid account.\\n```typescript\\n// No parameters
  required\\n```\\n\\n#### add_contact\\nAdd a contact to your SendGrid
  marketing contacts.\\n```typescript\\n{\\n  email: string;           //
  Required: Contact email address\\n  first_name?: string;     // Optional:
  Contact first name\\n  last_name?: string;      // Optional: Contact last
  name\\n  custom_fields?: object;  // Optional: Custom field
  values\\n}\\n```\\n\\n#### delete_contacts\\nDelete contacts from your
  SendGrid account.\\n```typescript\\n{\\n  emails: string[];  // Required:
  Array of email addresses to delete\\n}\\n```\\n\\n####
  get_contacts_by_list\\nGet all contacts in a SendGrid
  list.\\n```typescript\\n{\\n  list_id: string;  // Required: ID of the contact
  list\\n}\\n```\\n\\n### List Management\\n\\n#### list_contact_lists\\nList
  all contact lists in your SendGrid account.\\n```typescript\\n// No parameters
  required\\n```\\n\\n#### create_contact_list\\nCreate a new contact list in
  SendGrid.\\n```typescript\\n{\\n  name: string;  // Required: Name of the
  contact list\\n}\\n```\\n\\n#### delete_list\\nDelete a contact list from
  SendGrid.\\n```typescript\\n{\\n  list_id: string;  // Required: ID of the
  contact list to delete\\n}\\n```\\n\\n#### add_contacts_to_list\\nAdd contacts
  to an existing SendGrid list.\\n```typescript\\n{\\n  list_id: string;    //
  Required: ID of the contact list\\n  emails: string[];   // Required: Array of
  email addresses to add\\n}\\n```\\n\\n#### remove_contacts_from_list\\nRemove
  contacts from a SendGrid list without deleting
  them.\\n```typescript\\n{\\n  list_id: string;    // Required: ID of the
  contact list\\n  emails: string[];   // Required: Array of email addresses to
  remove\\n}\\n```\\n\\n### Email Sending\\n\\n#### send_email\\nSend an email
  using SendGrid.\\n```typescript\\n{\\n  to:
  string;                             // Required: Recipient email
  address\\n  subject: string;                        // Required: Email subject
  line\\n  text: string;                          // Required: Plain text
  content\\n  from: string;                          // Required: Verified
  sender email address\\n  html?: string;                         // Optional:
  HTML content\\n  template_id?: string;                  // Optional: Dynamic
  template ID\\n  dynamic_template_data?: object;        // Optional: Template
  variables\\n}\\n```\\n\\n#### send_to_list\\nSend an email to a contact list
  using SendGrid Single Sends.\\n```typescript\\n{\\n  name:
  string;                          // Required: Name of the single
  send\\n  list_ids: string[];                    // Required: Array of list IDs
  to send to\\n  subject: string;                       // Required: Email
  subject line\\n  html_content: string;                  // Required: HTML
  content\\n  plain_content: string;                 // Required: Plain text
  content\\n  sender_id: number;                     // Required: ID of the
  verified sender\\n  suppression_group_id?: number;         // Required if
  custom_unsubscribe_url not provided\\n  custom_unsubscribe_url?:
  string;       // Required if suppression_group_id not
  provided\\n}\\n```\\n\\n### Template Management (Dynamic Templates
  Only)\\n\\n#### create_template\\nCreate a new dynamic email
  template.\\n```typescript\\n{\\n  name: string;           // Required: Name of
  the template\\n  subject: string;        // Required: Default subject
  line\\n  html_content: string;   // Required: HTML content with handlebars
  syntax\\n  plain_content: string;  // Required: Plain text content with
  handlebars syntax\\n}\\n```\\n\\n#### list_templates\\nList all dynamic email
  templates.\\n```typescript\\n// No parameters required\\n```\\n\\n####
  get_template\\nRetrieve a template by ID.\\n```typescript\\n{\\n  template_id:
  string;  // Required: ID of the template to retrieve\\n}\\n```\\n\\n####
  delete_template\\nDelete a dynamic
  template.\\n```typescript\\n{\\n  template_id: string;  // Required: ID of the
  template to delete\\n}\\n```\\n\\n### Analytics and Validation\\n\\n####
  get_stats\\nGet SendGrid email statistics.\\n```typescript\\n{\\n  start_date:
  string;                          // Required: Start date
  (YYYY-MM-DD)\\n  end_date?: string;                           // Optional: End
  date (YYYY-MM-DD)\\n  aggregated_by?: 'day' | 'week' | 'month';    //
  Optional: Aggregation period\\n}\\n```\\n\\n#### validate_email\\nValidate an
  email address using SendGrid.\\n```typescript\\n{\\n  email: string;  //
  Required: Email address to validate\\n}\\n```\\n\\n### Account
  Management\\n\\n#### list_verified_senders\\nList all verified sender
  identities.\\n```typescript\\n// No parameters required\\n```\\n\\n####
  list_suppression_groups\\nList all unsubscribe groups.\\n```typescript\\n// No
  parameters required\\n```\\n\\n## Installation\\n\\n```bash\\ngit clone
  https://github.com/Garoth/sendgrid-mcp.git\\ncd sendgrid-mcp\\nnpm
  install\\n```\\n\\n## Configuration\\n\\n1. Get your SendGrid API key:\\n   -
  Log in to your SendGrid account\\n   - Go to Settings > API Keys\\n   - Create
  a new API key with full access permissions\\n   - Save the API key securely as
  it won't be shown again\\n\\n2. Add it to your Cline MCP settings file inside
  VSCode's settings (ex.
  ~/.config/Code/User/globalStorage/saoudrizwan.claude-dev/settings/cline_mcp_s\
  ettings.json):\\n\\n```json\\n{\\n  \\\"mcpServers\\\":
  {\\n    \\\"sendgrid\\\": {\\n      \\\"command\\\":
  \\\"node\\\",\\n      \\\"args\\\":
  [\\\"/path/to/sendgrid-mcp/build/index.js\\\"],\\n      \\\"env\\\":
  {\\n        \\\"SENDGRID_API_KEY\\\":
  \\\"your-api-key-here\\\"\\n      },\\n      \\\"disabled\\\":
  false,\\n      \\\"autoApprove\\\":
  [\\n        \\\"list_contacts\\\",\\n        \\\"list_contact_lists\\\",\\n        \
  \\\"list_templates\\\",\\n        \\\"list_single_sends\\\",\\n        \\\"ge\
  t_single_send\\\",\\n        \\\"list_verified_senders\\\",\\n        \\\"lis\
  t_suppression_groups\\\",\\n        \\\"get_stats\\\",\\n        \\\"validate\
  _email\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nNote: Tools that modify data
  (like sending emails or deleting contacts) are intentionally excluded from
  autoApprove for safety.\\n\\n## Development\\n\\n### Setting Up Tests\\n\\nThe
  tests use real API calls to ensure accurate responses. To run the
  tests:\\n\\n1. Copy the example environment file:\\n   ```bash\\n   cp
  .env.example .env\\n   ```\\n\\n2. Edit `.env` and add your SendGrid API
  key:\\n   ```\\n   SENDGRID_API_KEY=your-api-key-here\\n   ```\\n   Note: The
  `.env` file is gitignored to prevent committing sensitive information.\\n\\n3.
  Run the tests:\\n   ```bash\\n   npm test\\n   ```\\n\\n###
  Building\\n\\n```bash\\nnpm run build\\n```\\n\\n## Important Notes\\n\\n-
  When sending emails to lists, you must provide either a suppression_group_id
  or custom_unsubscribe_url to comply with email regulations\\n- Sender email
  addresses must be verified with SendGrid before they can be used to send
  emails\\n- All templates are created as dynamic templates with support for
  handlebars syntax (e.g., {{variable_name}})\\n- The Single Sends API is used
  for all bulk email operations as it provides better tracking and management
  capabilities\\n- The SendGrid API is \\\"eventually consistent\\\" - data
  changes (like adding contacts or updating lists) may not appear immediately
  after being made\\n\\n## License\\n\\nMIT\\n\\nSendGrid logo copyright / owned
  by
  Twilio\\n\",\"isRecommended\":false,\"githubStars\":12,\"downloadCount\":421,\
  \"createdAt\":\"2025-02-23T01:48:41.737092Z\",\"updatedAt\":\"2025-07-08T01:1\
  0:48.398933Z\",\"lastGithubSync\":\"2025-07-01T13:32:24.035139Z\"},{\"mcpId\":\
  \"github.com/awslabs/mcp/tree/main/src/aws-support-mcp-server\",\"githubUrl\":\
  \"https://github.com/awslabs/mcp/tree/main/src/aws-support-mcp-server\",\"name\
  \":\"AWS Support\",\"author\":\"awslabs\",\"description\":\"Enables
  programmatic management of AWS support cases, including creation,
  communication, and resolution, with automatic determination of issue types and
  severity
  levels.\",\"codiconIcon\":\"question\",\"logoUrl\":\"https://storage.googleap\
  is.com/cline_public_images/aws.png\",\"category\":\"customer-support\",\"tags\
  \":[\"aws\",\"support-cases\",\"ticket-management\",\"cloud-support\",\"case-\
  resolution\"],\"requiresApiKey\":false,\"readmeContent\":\"# AWS Support MCP
  Server\\n\\nA Model Context Protocol (MCP) server implementation for
  interacting with the AWS Support API. This server enables AI assistants to
  create and manage AWS support cases programmatically.\\n\\n## Features\\n\\n-
  Create and manage AWS support cases\\n- Retrieve case information and
  communications\\n- Add communications to existing cases\\n- Resolve support
  cases\\n- Determine appropriate Issue Type, Service Code, and Category
  Code\\n- Determine appropriate Severity Level for a case\\n\\n\\n##
  Requirements\\n\\n- Python 3.7+\\n- AWS credentials with Support API
  access\\n- Business, Enterprise On-Ramp, or Enterprise Support plan\\n\\n##
  Prerequisites\\n\\n1. Install `uv` from
  [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the
  [GitHub README](https://github.com/astral-sh/uv#installation)\\n2. Install
  Python using `uv python install 3.10`\\n\\n## Installation\\n\\n[![Install MCP
  Server](https://cursor.com/deeplink/mcp-install-light.svg)](https://cursor.co\
  m/install-mcp?name=awslabs_support_mcp_server&config=eyJjb21tYW5kIjoidXZ4IC1t\
  IGF3c2xhYnMuYXdzLXN1cHBvcnQtbWNwLXNlcnZlckBsYXRlc3QgLS1kZWJ1ZyAtLWxvZy1maWxlI\
  C4vbG9ncy9tY3Bfc3VwcG9ydF9zZXJ2ZXIubG9nIiwiZW52Ijp7IkFXU19QUk9GSUxFIjoieW91ci\
  1hd3MtcHJvZmlsZSJ9fQ%3D%3D)\\n\\nConfigure the MCP server in your MCP client
  configuration (e.g., for Amazon Q Developer CLI, edit
  `~/.aws/amazonq/mcp.json`):\\n\\n```json\\n\\n{\\n   \\\"mcpServers\\\":
  {\\n      \\\"awslabs_support_mcp_server\\\": {\\n         \\\"command\\\":
  \\\"uvx\\\",\\n         \\\"args\\\": [\\n            \\\"-m\\\",
  \\\"awslabs.aws-support-mcp-server@latest\\\",\\n            \\\"--debug\\\",\
  \\n            \\\"--log-file\\\",\\n            \\\"./logs/mcp_support_serve\
  r.log\\\"\\n         ],\\n         \\\"env\\\":
  {\\n            \\\"AWS_PROFILE\\\":
  \\\"your-aws-profile\\\"\\n         }\\n      }\\n   }\\n}\\n```\\n\\nAlterna\
  tively:\\n```bash\\n\\n\\nuv pip install -e .\\nuv run
  awslabs/aws_support_mcp_server/server.py\\n```\\n\\n```json\\n{\\n   \\\"mcpS\
  ervers\\\": {\\n      \\\"awslabs_support_mcp_server\\\":
  {\\n         \\\"command\\\": \\\"path-to-python\\\",\\n         \\\"args\\\":
  [\\n            \\\"-m\\\",\\n            \\\"awslabs.aws_support_mcp_server.\
  server\\\",\\n            \\\"--debug\\\",\\n            \\\"--log-file\\\",\
  \\n            \\\"./logs/mcp_support_server.log\\\"\\n         ],\\n         \
  \\\"env\\\": {\\n            \\\"AWS_PROFILE\\\":
  \\\"manual_enterprise\\\"\\n         }\\n      }\\n   }\\n}\\n```\\n\\n##
  Usage\\n\\nStart the server:\\n\\n```bash\\npython -m
  awslabs.aws_support_mcp_server.server [options]\\n```\\n\\nOptions:\\n-
  `--port PORT`: Port to run the server on (default: 8888)\\n- `--debug`: Enable
  debug logging\\n- `--log-file`: Where to save the log file\\n\\n##
  Configuration\\n\\nThe server can be configured using environment
  variables:\\n\\n- `AWS_REGION`: AWS region (default: us-east-1)\\n-
  `AWS_PROFILE`: AWS credentials profile name\\n\\n## Documentation\\n\\nFor
  detailed documentation on available tools and resources, see the [API
  Documentation](docs/api.md).\\n\\n\\n\\n## License\\n\\nCopyright Amazon.com,
  Inc. or its affiliates. All Rights Reserved.\\n\\nLicensed under the Apache
  License, Version 2.0 (the
  \\\"License\\\").\\n\",\"isRecommended\":false,\"githubStars\":4254,\"downloa\
  dCount\":57,\"createdAt\":\"2025-06-21T01:51:41.534347Z\",\"updatedAt\":\"202\
  5-07-08T01:10:48.398933Z\",\"lastGithubSync\":\"2025-06-29T01:33:24.249162Z\"\
  }]},\"installId\":\"262bfe91-7c4e-4541-be09-aa6331fdca75\",\"welcomeViewCompl\
  eted\":false}"
VisualStudioExptTeam.intellicode-api-usage-examples: '{"VSCode.ABExp.FeatureData":{"features":["config.chat.editRequests","config.notebook.experimental.generate","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","portForwardingServiceEnabled-development","portForwardingServiceEnabled-production","portForwardingServiceEnabled-staging","shouldUseGrpcService","test-ai-12cf","validate_micf","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;vspor879:30202332;vspor708:30202333;vspor363:30204092;binariesv615:30325510;c4g48928:30535728;5fd0e150:31155592;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;usemarketplace:31343026;6abeh943:31336334;yijiwantestdri0626-t:31336930;ji9b5146:31342393;","configs":[{"Id":"vscode","Parameters":{"config.chat.editRequests":"hover","config.notebook.experimental.generate":true,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"portForwardingServiceEnabled-development":true,"portForwardingServiceEnabled-production":true,"portForwardingServiceEnabled-staging":true,"shouldUseGrpcService":true,"test-ai-12":false,"validate_mi":false,"workspace.embeddingIndex.automaticReindexingDelay":100000000}}]}}'
VisualStudioExptTeam.vscodeintellicode: '{"VSCode.ABExp.FeatureData":{"features":["config.chat.editRequests","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries","copilot_ci","extensions.gallery.useLatestApi","extensions.gallery.useResourceApi","intellicodeaa","livesharecontinuousaa","mindaroBinariesVersion","msEntraShowUpdateUserFlow","portForwardingServiceEnabled-development","portForwardingServiceEnabled-production","portForwardingServiceEnabled-staging","shouldUseGrpcService","test-ai-12cf","validate_micf","workspace.embeddingIndex.automaticReindexingDelay"],"assignmentContext":"vsliv368:30146709;vspor879:30202332;vspor708:30202333;vspor363:30204092;binariesv615:30325510;vsint734:30416762;c4g48928:30535728;6074i472:31201624;9064b325:31222308;copilot_t_ci:31333650;usemplatestapi:31297334;aj953862:31281341;usemarketplace:31343026;nes-diff-11:31337487;6abeh943:31336334;yijiwantestdri0626-t:31336930;ji9b5146:31342393;","configs":[{"Id":"vscode","Parameters":{"config.chat.editRequests":"hover","config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffMaxTokens":1000,"config.github.copilot.chat.advanced.inlineEdits.xtabProvider.diffNEntries":25,"copilot_ci":true,"extensions.gallery.useLatestApi":"marketplace","extensions.gallery.useResourceApi":"marketplace","intellicodeaa":true,"livesharecontinuousaa":true,"mindaroBinariesVersion":"1.0.20210615.1","msEntraShowUpdateUserFlow":true,"portForwardingServiceEnabled-development":true,"portForwardingServiceEnabled-production":true,"portForwardingServiceEnabled-staging":true,"shouldUseGrpcService":true,"test-ai-12":false,"validate_mi":false,"workspace.embeddingIndex.automaticReindexingDelay":100000000}}]}}'
workbench.activity.pinnedViewlets2: '[{"id":"workbench.view.explorer","pinned":true,"visible":false,"order":0},{"id":"workbench.view.search","pinned":true,"visible":false,"order":1},{"id":"workbench.view.scm","pinned":true,"visible":false,"order":2},{"id":"workbench.view.debug","pinned":true,"visible":false,"order":3},{"id":"workbench.view.remote","pinned":true,"visible":false,"order":4},{"id":"workbench.view.extensions","pinned":true,"visible":false,"order":4},{"id":"workbench.view.extension.test","pinned":true,"visible":false,"order":6},{"id":"workbench.view.extension.references-view","pinned":true,"visible":false,"order":7},{"id":"workbench.view.extension.openapi-explorer","pinned":true,"visible":false,"order":8},{"id":"workbench.view.extension.atlascode-rovo-dev","pinned":true,"visible":false,"order":12},{"id":"workbench.view.extension.sidebarDevToolsContainer","pinned":true,"visible":false,"order":16},{"id":"workbench.view.extension.sidebarDevToolsInspectorContainer","pinned":true,"visible":false,"order":17},{"id":"workbench.view.extension.sidebarDevToolsDeepLinksContainer","pinned":true,"visible":false,"order":18},{"id":"workbench.view.extension.sidebarDevTools","pinned":true,"visible":false,"order":23},{"id":"workbench.view.extension.copilot-chat","pinned":true,"visible":false,"order":44},{"id":"workbench.view.extension.42crunch-platform","pinned":true,"visible":false,"order":9},{"id":"workbench.view.extension.github-pull-requests","pinned":true,"visible":false,"order":25},{"id":"workbench.view.extension.aws-explorer","pinned":true,"visible":false,"order":10},{"id":"workbench.view.extension.github-pull-request","pinned":true,"visible":false,"order":26},{"id":"workbench.view.extension.atlascode-drawer","pinned":true,"visible":false,"order":11},{"id":"workbench.view.extension.postgres-explorer","pinned":true,"visible":false,"order":13},{"id":"workbench.view.extension.flutter","pinned":true,"visible":false,"order":14},{"id":"workbench.view.extension.flutterPropertyEditor","pinned":true,"visible":false,"order":15},{"id":"workbench.view.extension.gitlens","pinned":true,"visible":false,"order":19},{"id":"workbench.view.extension.gitlensInspect","pinned":true,"visible":false,"order":20},{"id":"workbench.view.extension.gitlensPatch","pinned":true,"visible":false,"order":21},{"id":"workbench.view.extension.figma","pinned":true,"visible":false,"order":22},{"id":"workbench.view.extension.github-actions","pinned":true,"visible":false,"order":24},{"id":"workbench.view.extension.todo-tree-container","pinned":true,"visible":false,"order":27},{"id":"workbench.view.extension.terraform","pinned":true,"visible":false,"order":28},{"id":"workbench.view.extension.terraform-cloud","pinned":true,"visible":false,"order":29},{"id":"workbench.view.extension.dbt_view","pinned":true,"visible":false,"order":30},{"id":"workbench.view.extension.datapilot_view","pinned":true,"visible":false,"order":31},{"id":"workbench.view.extension.ionide-fsharp","pinned":true,"visible":false,"order":32},{"id":"workbench.view.extension.malloy","pinned":true,"visible":false,"order":33},{"id":"workbench.view.extension.vscode-edge-devtools-view","pinned":true,"visible":false,"order":35},{"id":"workbench.view.extension.data-wrangler-primary","pinned":true,"visible":false,"order":36},{"id":"workbench.view.extension.jupyter","pinned":true,"visible":false,"order":37},{"id":"workbench.view.extension.PowerShell","pinned":true,"visible":false,"order":38},{"id":"workbench.view.extension.cortex-cloud-activity-bar","pinned":true,"visible":false,"order":40},{"id":"workbench.view.extension.prisma-cloud","pinned":true,"visible":false,"order":40},{"id":"workbench.view.extension.roo-cline-ActivityBar","pinned":true,"visible":false,"order":41},{"id":"workbench.view.extension.claude-dev-ActivityBar","pinned":true,"visible":false,"order":42},{"id":"workbench.view.extension.snowflakeActivityBarContainer","pinned":true,"visible":false,"order":44},{"id":"workbench.view.extension.nx-console","pinned":true,"visible":false,"order":39},{"id":"workbench.view.extension.containersView","pinned":true,"visible":false,"order":34},{"id":"workbench.view.extension.tinymist-activitybar","pinned":true,"visible":false,"order":45},{"id":"workbench.view.extension.wiz","pinned":true,"visible":false,"order":45},{"id":"workbench.view.sync","pinned":true,"visible":false},{"id":"workbench.view.editSessions","pinned":true,"visible":false}]'
workbench.activity.placeholderViewlets: "[{\"id\":\"workbench.view.explorer\",\
  \"themeIcon\":{\"id\":\"explorer-view-icon\"},\"name\":\"Explorer\",\"isBuilt\
  in\":true,\"views\":[{},{},{},{\"when\":\"timelineHasProvider\"},{\"when\":\"\
  npm:showScriptExplorer\"},{\"when\":\"isCloud9 && !aws.appBuilder.hide ||
  !aws.appBuilder.hide && !aws.isWebExtHost\"},{\"when\":\"config.dart.enablePub
  && dart-code:anyProjectLoaded\"},{\"when\":\"git.commit.selected &&
  git.commit.view.show &&
  !config.gitHistory.hideCommitViewExplorer\"},{\"when\":\"git.commit.compare.c\
  ompared && git.commit.compare.view.show &&
  !config.gitHistory.hideCompareCommitViewExplorer\"},{\"when\":\"go.showExplor\
  er\"},{\"when\":\"go.showPackageOutline\"},{\"when\":\"fsharp.project.any &&
  fsharp.showProjectExplorerInExplorerActivity\"},{\"when\":\"lean4.isLeanFeatu\
  reSetActive &&
  lean4.leanModuleHierarchy.visible\"},{\"when\":\"malloy.webviewPanelFocused ||
  resourceLangId == 'malloy' || resourceLangId == 'malloy-notebook' || resource
  =~
  /malloy-notebook$/\"},{\"when\":\"solutionExplorerVisible\"}]},{\"id\":\"work\
  bench.view.search\",\"themeIcon\":{\"id\":\"search-view-icon\"},\"name\":\"Se\
  arch\",\"isBuiltin\":true,\"views\":[{}]},{\"id\":\"workbench.view.scm\",\"th\
  emeIcon\":{\"id\":\"source-control-view-icon\"},\"name\":\"Source
  Control\",\"isBuiltin\":true,\"views\":[{\"when\":\"scm.providerCount &&
  scm.providerCount != '0'\"},{},{\"when\":\"scm.historyProviderCount &&
  scm.historyProviderCount !=
  '0'\"},{\"when\":\"!config.gitlens.views.scm.grouped.views.repositories &&
  !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:repositories\"},{\"when\":\"!config.gitlens.\
  views.scm.grouped.views.commits && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:commits\"},{\"when\":\"!config.gitlens.views\
  .scm.grouped.views.branches && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:branches\"},{\"when\":\"!config.gitlens.view\
  s.scm.grouped.views.remotes && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:remotes\"},{\"when\":\"!config.gitlens.views\
  .scm.grouped.views.stashes && !gitlens:disabled && !gitlens:hasVirtualFolders
  &&
  !gitlens:views:scm:grouped:views:stashes\"},{\"when\":\"!config.gitlens.views\
  .scm.grouped.views.tags && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:tags\"},{\"when\":\"!config.gitlens.views.sc\
  m.grouped.views.worktrees && !gitlens:disabled && !gitlens:hasVirtualFolders
  && !gitlens:plus:disabled &&
  !gitlens:views:scm:grouped:views:worktrees\"},{\"when\":\"!config.gitlens.vie\
  ws.scm.grouped.views.contributors && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:contributors\"},{\"when\":\"config.gitlens.v\
  iews.scm.grouped.views.branches && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.commits && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.contributors && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.launchpad && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.remotes && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.repositories && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.searchAndCompare && !gitlens:disabled
  || config.gitlens.views.scm.grouped.views.stashes && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.tags && !gitlens:disabled ||
  config.gitlens.views.scm.grouped.views.worktrees && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:branches && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:commits && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:contributors && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:launchpad && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:remotes && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:repositories && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:searchAndCompare && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:stashes && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:tags && !gitlens:disabled ||
  gitlens:views:scm:grouped:views:worktrees &&
  !gitlens:disabled\"}]},{\"id\":\"workbench.view.debug\",\"themeIcon\":{\"id\":\
  \"run-view-icon\"},\"name\":\"Run and
  Debug\",\"isBuiltin\":true,\"views\":[{\"when\":\"debugUx ==
  'simple'\"},{\"when\":\"debugUx == 'default'\"},{\"when\":\"debugUx ==
  'default'\"},{\"when\":\"debugUx ==
  'default'\"},{\"when\":\"loadedScriptsSupported && debugUx ==
  'default'\"},{\"when\":\"breakpointsExist || hasDebugged || debugUx ==
  'default'\"},{\"when\":\"debugType == 'pwa-chrome' || debugType ==
  'pwa-msedge'\"},{\"when\":\"jsDebugHasExcludedCallers && debugType ==
  'node-terminal' || jsDebugHasExcludedCallers && debugType == 'pwa-chrome' ||
  jsDebugHasExcludedCallers && debugType == 'pwa-extensionHost' ||
  jsDebugHasExcludedCallers && debugType == 'pwa-msedge' ||
  jsDebugHasExcludedCallers && debugType ==
  'pwa-node'\"},{\"when\":\"jsDebugNetworkAvailable\"}]},{\"id\":\"workbench.vi\
  ew.remote\",\"themeIcon\":{\"id\":\"remote-explorer-view-icon\"},\"name\":\"R\
  emote
  Explorer\",\"isBuiltin\":true,\"views\":[{},{\"when\":\"!hideConnectCommands\
  \"},{\"when\":\"remote-containers:showDetails &&
  !hideConnectCommands\"},{\"when\":\"!hideConnectCommands\"}]},{\"id\":\"workb\
  ench.view.extensions\",\"themeIcon\":{\"id\":\"extensions-view-icon\"},\"name\
  \":\"Extensions\",\"isBuiltin\":true,\"views\":[{\"when\":\"defaultExtensionV\
  iews\"},{\"when\":\"searchExtensionUpdates ||
  searchOutdatedExtensions\"},{\"when\":\"recommendedExtensions &&
  workbenchState != 'empty'\"},{\"when\":\"defaultExtensionViews && hasGallery
  && !hasInstalledExtensions\"},{\"when\":\"searchExtensionUpdates ||
  searchRecentlyUpdatedExtensions\"},{\"when\":\"recommendedExtensions\"},{\"wh\
  en\":\"defaultExtensionViews && hasGallery &&
  !config.extensions.showRecommendationsOnlyOnDemand &&
  !sortByUpdateDate\"},{\"when\":\"defaultExtensionViews &&
  hasInstalledExtensions\"},{\"when\":\"defaultExtensionViews &&
  hasInstalledMcpServers\"},{\"when\":\"defaultExtensionViews &&
  !chatSetupHidden &&
  !hasInstalledMcpServers\"},{\"when\":\"defaultExtensionViews &&
  hasInstalledExtensions\"},{\"when\":\"searchMarketplaceExtensions\"},{\"when\
  \":\"installedExtensions ||
  searchInstalledExtensions\"},{\"when\":\"searchEnabledExtensions\"},{\"when\":\
  \"searchDisabledExtensions\"},{\"when\":\"searchBuiltInExtensions\"},{\"when\
  \":\"searchWorkspaceUnsupportedExtensions\"},{\"when\":\"builtInExtensions\"}\
  ,{\"when\":\"builtInExtensions\"},{\"when\":\"builtInExtensions\"},{\"when\":\
  \"searchUnsupportedWorkspaceExtensions\"},{\"when\":\"searchUnsupportedWorksp\
  aceExtensions\"},{\"when\":\"searchUnsupportedWorkspaceExtensions &&
  virtualWorkspace\"},{\"when\":\"searchUnsupportedWorkspaceExtensions &&
  virtualWorkspace\"},{\"when\":\"searchDeprecatedExtensions\"},{\"when\":\"sea\
  rchMcpServers\"}]},{\"id\":\"workbench.view.extension.test\",\"themeIcon\":{\
  \"id\":\"test-view-icon\"},\"name\":\"Testing\",\"isBuiltin\":true,\"views\":\
  [{\"when\":\"testing.providerCount >
  0\"},{\"when\":\"testing.isTestCoverageOpen\"},{\"when\":\"go.hasProfiles\"}]\
  },{\"id\":\"workbench.view.extension.references-view\",\"themeIcon\":{\"id\":\
  \"references\"},\"name\":\"References\",\"isBuiltin\":false,\"views\":[{\"when\
  \":\"reference-list.isActive\"}]},{\"id\":\"workbench.view.extension.openapi-\
  explorer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/42crunc\
  h.vscode-openapi-4.37.2/resources/icons/icon_api.svg\",\"scheme\":\"file\"},\
  \"name\":\"OpenAPI\",\"isBuiltin\":false,\"views\":[{\"when\":\"openapiThreeE\
  nabled || openapiTwoEnabled\"},{\"when\":\"!openapiThreeEnabled &&
  !openapiTwoEnabled\"}]},{\"id\":\"workbench.view.extension.atlascode-rovo-dev\
  \",\"themeIcon\":{\"id\":\"rocket\"},\"name\":\"Rovo
  Dev\",\"isBuiltin\":false,\"views\":[{\"when\":\"atlascode:rovoDevEnabled\"}]\
  },{\"id\":\"workbench.view.extension.sidebarDevToolsContainer\",\"iconUrl\":{\
  \"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/dart-code.dart-code-3.114.2/med\
  ia/icons/sidebar/devtools.svg\",\"scheme\":\"file\"},\"name\":\"Flutter
  DevTools\",\"isBuiltin\":false,\"views\":[{\"when\":\"dart-code:anyFlutterPro\
  jectLoaded &&
  dart-code:devToolsSidebar.cpu-profiler\"},{\"when\":\"dart-code:anyFlutterPro\
  jectLoaded &&
  dart-code:devToolsSidebar.memory\"},{\"when\":\"dart-code:anyFlutterProjectLo\
  aded &&
  dart-code:devToolsSidebar.performance\"},{\"when\":\"dart-code:anyFlutterProj\
  ectLoaded &&
  dart-code:devToolsSidebar.network\"},{\"when\":\"dart-code:anyFlutterProjectL\
  oaded &&
  dart-code:devToolsSidebar.logging\"}]},{\"id\":\"workbench.view.extension.sid\
  ebarDevToolsInspectorContainer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSI\
  ON_DATA_PATH%%/dart-code.dart-code-3.114.2/media/icons/sidebar/inspector.svg\
  \",\"scheme\":\"file\"},\"name\":\"Flutter DevTools:
  Inspector\",\"isBuiltin\":false,\"views\":[{\"when\":\"dart-code:anyFlutterPr\
  ojectLoaded &&
  dart-code:devToolsSidebar.inspector\"}]},{\"id\":\"workbench.view.extension.s\
  idebarDevToolsDeepLinksContainer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTEN\
  SION_DATA_PATH%%/dart-code.dart-code-3.114.2/media/icons/sidebar/deep_links.s\
  vg\",\"scheme\":\"file\"},\"name\":\"Flutter DevTools: Deep
  Links\",\"isBuiltin\":false,\"views\":[{\"when\":\"dart-code:anyFlutterProjec\
  tLoaded &&
  dart-code:devToolsSidebar.deep-links\"}]},{\"id\":\"workbench.view.extension.\
  sidebarDevTools\",\"name\":\"Flutter
  DevTools\",\"isBuiltin\":false},{\"id\":\"workbench.view.extension.copilot-ch\
  at\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/github.copilo\
  t-chat-0.29.1/assets/debug-icon.svg\",\"scheme\":\"file\"},\"name\":\"Copilot
  Chat
  Debug\",\"isBuiltin\":false,\"views\":[{\"when\":\"github.copilot.chat.showLo\
  gView\"}]},{\"id\":\"workbench.view.extension.42crunch-platform\",\"iconUrl\"\
  :{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/42crunch.vscode-openapi-4.37.\
  2/resources/icon_42crunch_platform.svg\",\"scheme\":\"file\"},\"name\":\"42Cr\
  unch\",\"isBuiltin\":false,\"views\":[{\"when\":\"openapi.platform.credentials
  ==
  'present'\"}]},{\"id\":\"workbench.view.extension.github-pull-requests\",\"th\
  emeIcon\":{\"id\":\"github\"},\"name\":\"GitHub\",\"isBuiltin\":false,\"views\
  \":[{\"when\":\"ReposManagerStateContext ==
  'NeedsAuthentication'\"},{\"when\":\"!github:resolvingConflicts &&
  ReposManagerStateContext !=
  'NeedsAuthentication'\"},{\"when\":\"!github:resolvingConflicts &&
  ReposManagerStateContext !=
  'NeedsAuthentication'\"},{\"when\":\"!github:resolvingConflicts &&
  ReposManagerStateContext !=
  'NeedsAuthentication'\"},{\"when\":\"github:resolvingConflicts\"}]},{\"id\":\
  \"workbench.view.extension.aws-explorer\",\"iconUrl\":{\"$mid\":1,\"path\":\"\
  %%EXTENSION_DATA_PATH%%/amazonwebservices.aws-toolkit-vscode-3.69.0/resources\
  /aws-logo.svg\",\"scheme\":\"file\"},\"name\":\"AWS\",\"isBuiltin\":false,\"v\
  iews\":[{\"when\":\"aws.toolkit.notifications.show && !aws.isSageMaker &&
  !isCloud9\"},{\"when\":\"!aws.explorer.showAuthView && !aws.isSageMaker &&
  !aws.toolkit.amazonq.dismissed && !isCloud9\"},{\"when\":\"isCloud9 &&
  !aws.explorer.showAuthView || !aws.explorer.showAuthView &&
  !aws.isWebExtHost\"},{\"when\":\"!aws.explorer.showAuthView\"},{\"when\":\"is\
  Cloud9 && !aws.explorer.showAuthView || !aws.explorer.showAuthView &&
  !aws.isWebExtHost\"},{\"when\":\"isCloud9CodeCatalyst &&
  !aws.explorer.showAuthView || !aws.explorer.showAuthView && !aws.isSageMaker
  && !isCloud9\"},{\"when\":\"aws.explorer.showAuthView && !aws.isSageMaker &&
  !isCloud9\"}]},{\"id\":\"workbench.view.extension.github-pull-request\",\"the\
  meIcon\":{\"id\":\"git-pull-request\"},\"name\":\"GitHub Pull
  Request\",\"isBuiltin\":false,\"views\":[{\"when\":\"github:createPullRequest
  ||
  github:revertPullRequest\"},{\"when\":\"github:createPullRequest\"},{\"when\":\
  \"github:createPullRequest\"},{\"when\":\"github:inReviewMode &&
  !github:createPullRequest &&
  !github:revertPullRequest\"},{\"when\":\"github:focusedReview &&
  github:inReviewMode && !github:createPullRequest && !github:revertPullRequest
  && github:activePRCount <= 1\"},{\"when\":\"github:focusedReview &&
  !github:stateValidated\"}]},{\"id\":\"workbench.view.extension.atlascode-draw\
  er\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/atlassian.atl\
  ascode-3.8.6/resources/atlassian-icon.svg\",\"scheme\":\"file\"},\"name\":\"A\
  tlassian\",\"isBuiltin\":false,\"views\":[{\"when\":\"atlascode:assignedIssue\
  ExplorerEnabled &&
  config.atlascode.jira.enabled\"},{\"when\":\"atlascode:assignedIssueExplorerE\
  nabled && atlascode:customJQLExplorerEnabled && atlascode:isJiraAuthenticated
  &&
  config.atlascode.jira.enabled\"},{\"when\":\"atlascode:bitbucketExplorerEnabl\
  ed &&
  config.atlascode.bitbucket.enabled\"},{\"when\":\"atlascode:pipelineExplorerE\
  nabled &&
  config.atlascode.bitbucket.enabled\"},{\"when\":\"config.atlascode.helpExplor\
  erEnabled\"}]},{\"id\":\"workbench.view.extension.postgres-explorer\",\"iconU\
  rl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/ckolkman.vscode-postgres-\
  1.4.3/resources/postgres-explorer.svg\",\"scheme\":\"file\"},\"name\":\"Postg\
  reSQL
  Explorer\",\"isBuiltin\":false,\"views\":[{\"when\":\"config.vscode-postgres.\
  showExplorer\"}]},{\"id\":\"workbench.view.extension.flutter\",\"iconUrl\":{\
  \"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/dart-code.dart-code-3.114.2/med\
  ia/icons/sidebar/flutter.svg\",\"scheme\":\"file\"},\"name\":\"Flutter\",\"is\
  Builtin\":false,\"views\":[{\"when\":\"dart-code:anyFlutterProjectLoaded &&
  dart-code:flutterSidebarSupported\"},{\"when\":\"dart-code:anyFlutterProjectL\
  oaded\"}]},{\"id\":\"workbench.view.extension.flutterPropertyEditor\",\"iconU\
  rl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/dart-code.dart-code-3.114\
  .2/media/icons/sidebar/property_editor.svg\",\"scheme\":\"file\"},\"name\":\"\
  Flutter Property
  Editor\",\"isBuiltin\":false,\"views\":[{\"when\":\"dart-code:anyFlutterProje\
  ctLoaded &&
  dart-code:flutterPropertyEditorSupported\"}]},{\"id\":\"workbench.view.extens\
  ion.gitlens\",\"themeIcon\":{\"id\":\"gitlens-gitlens\"},\"name\":\"GitLens\",\
  \"isBuiltin\":false,\"views\":[{},{\"when\":\"!config.gitlens.views.scm.group\
  ed.views.launchpad &&
  !gitlens:views:scm:grouped:views:launchpad\"},{\"when\":\"config.gitlens.clou\
  dPatches.enabled && gitlens:gk:organization:drafts:enabled &&
  !gitlens:hasVirtualFolders &&
  !gitlens:untrusted\"},{\"when\":\"!gitlens:hasVirtualFolders &&
  !gitlens:untrusted\"}]},{\"id\":\"workbench.view.extension.gitlensInspect\",\
  \"themeIcon\":{\"id\":\"gitlens-gitlens-inspect\"},\"name\":\"GitLens
  Inspect\",\"isBuiltin\":false,\"views\":[{\"when\":\"!gitlens:disabled\"},{\"\
  when\":\"gitlens:views:pullRequest:visible &&
  !gitlens:disabled\"},{\"when\":\"!gitlens:disabled &&
  !gitlens:hasVirtualFolders\"},{\"when\":\"!config.gitlens.views.scm.grouped.v\
  iews.fileHistory && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:fileHistory\"},{\"when\":\"!gitlens:disabled
  &&
  !gitlens:plus:disabled\"},{\"when\":\"!config.gitlens.views.scm.grouped.views\
  .searchAndCompare && !gitlens:disabled &&
  !gitlens:views:scm:grouped:views:searchAndCompare\"}]},{\"id\":\"workbench.vi\
  ew.extension.gitlensPatch\",\"themeIcon\":{\"id\":\"gitlens-cloud-patch\"},\"\
  name\":\"GitLens
  Patch\",\"isBuiltin\":false,\"views\":[{\"when\":\"config.gitlens.cloudPatche\
  s.enabled && gitlens:views:patchDetails:mode &&
  !gitlens:untrusted\"}]},{\"id\":\"workbench.view.extension.figma\",\"iconUrl\
  \":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/figma.figma-vscode-extensio\
  n-0.4.1/resources/logo-sidebar.svg\",\"scheme\":\"file\"},\"name\":\"Figma\",\
  \"isBuiltin\":false,\"views\":[{\"when\":\"!figma.loggedIn\"},{\"when\":\"!fi\
  gma.loggedIn\"},{\"when\":\"figma.loggedIn\"},{\"when\":\"figma.loggedIn\"}]}\
  ,{\"id\":\"workbench.view.extension.github-actions\",\"iconUrl\":{\"$mid\":1,\
  \"path\":\"%%EXTENSION_DATA_PATH%%/github.vscode-github-actions-0.27.2/resour\
  ces/icons/light/explorer.svg\",\"scheme\":\"file\"},\"name\":\"GitHub
  Actions\",\"isBuiltin\":false,\"views\":[{\"when\":\"github-actions.has-repos
  && github-actions.internet-access &&
  github-actions.signed-in\"},{\"when\":\"github-actions.has-repos &&
  github-actions.internet-access &&
  github-actions.signed-in\"},{\"when\":\"github-actions.has-repos &&
  github-actions.internet-access &&
  github-actions.signed-in\"},{\"when\":\"!github-actions.has-repos ||
  !github-actions.internet-access ||
  !github-actions.signed-in\"}]},{\"id\":\"workbench.view.extension.todo-tree-c\
  ontainer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/gruntfu\
  ggly.todo-tree-0.0.226/resources/todo-tree-container.svg\",\"scheme\":\"file\
  \"},\"name\":\"TODOs\",\"isBuiltin\":false,\"views\":[{\"when\":\"!todo-tree-\
  is-empty\"}]},{\"id\":\"workbench.view.extension.terraform\",\"iconUrl\":{\"$\
  mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/hashicorp.terraform-2.34.5-darwin-\
  arm64/assets/icons/vs_code_terraform.svg\",\"scheme\":\"file\"},\"name\":\"Ha\
  shiCorp
  Terraform\",\"isBuiltin\":false,\"views\":[{},{}]},{\"id\":\"workbench.view.e\
  xtension.terraform-cloud\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DAT\
  A_PATH%%/hashicorp.terraform-2.34.5-darwin-arm64/assets/icons/vs_code_terrafo\
  rm_cloud.svg\",\"scheme\":\"file\"},\"name\":\"HCP
  Terraform\",\"isBuiltin\":false,\"views\":[{},{}]},{\"id\":\"workbench.view.e\
  xtension.dbt_view\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%\
  %/innoverio.vscode-dbt-power-user-0.58.7/media/images/dbt_icon.svg\",\"scheme\
  \":\"file\"},\"name\":\"dbt Power
  User\",\"isBuiltin\":false,\"views\":[{},{},{},{},{}]},{\"id\":\"workbench.vi\
  ew.extension.datapilot_view\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_\
  DATA_PATH%%/innoverio.vscode-dbt-power-user-0.58.7/media/images/altimate.svg\
  \",\"scheme\":\"file\"},\"name\":\"DataPilot
  Chat\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extension\
  .ionide-fsharp\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/i\
  onide.ionide-fsharp-7.26.4/images/activity-fsharp-logo.svg\",\"scheme\":\"file\
  \"},\"name\":\"F#\",\"isBuiltin\":false,\"views\":[{\"when\":\"fsharp.project\
  .any &&
  fsharp.showProjectExplorerInFsharpActivity\"}]},{\"id\":\"workbench.view.exte\
  nsion.malloy\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/mal\
  loydata.malloy-vscode-0.2.1744744834-darwin-arm64/img/logo.png\",\"scheme\":\
  \"file\"},\"name\":\"Malloy\",\"isBuiltin\":false,\"views\":[{\"when\":\"reso\
  urceLangId == 'malloy' || resourceLangId == 'malloy-notebook' || resource =~
  /malloy-notebook$/\"},{\"when\":\"resourceLangId == 'malloy' || resourceLangId
  == 'malloy-notebook' || resource =~
  /malloy-notebook$/\"}]},{\"id\":\"workbench.view.extension.vscode-edge-devtoo\
  ls-view\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/ms-edged\
  evtools.vscode-edge-devtools-2.1.9/resources/viewIcon.svg\",\"scheme\":\"file\
  \"},\"name\":\"Microsoft Edge
  Tools\",\"isBuiltin\":false,\"views\":[{},{}]},{\"id\":\"workbench.view.exten\
  sion.data-wrangler-primary\",\"themeIcon\":{\"id\":\"data-wrangler\"},\"name\
  \":\"Data
  Wrangler\",\"isBuiltin\":false,\"views\":[{\"when\":\"dataWrangler.dataWrangl\
  erActive && isWorkspaceTrusted\"},{\"when\":\"dataWrangler.dataViewerActive &&
  isWorkspaceTrusted || dataWrangler.dataWranglerActive &&
  isWorkspaceTrusted\"},{\"when\":\"dataWrangler.dataWranglerActive &&
  isWorkspaceTrusted\"},{\"when\":\"dataWrangler.dataViewerActive &&
  isWorkspaceTrusted\"},{\"when\":\"dataWrangler.dataViewerActive &&
  isWorkspaceTrusted\"}]},{\"id\":\"workbench.view.extension.jupyter\",\"themeI\
  con\":{\"id\":\"notebook\"},\"name\":\"Jupyter\",\"isBuiltin\":false,\"views\
  \":[]},{\"id\":\"workbench.view.extension.PowerShell\",\"themeIcon\":{\"id\":\
  \"terminal-powershell\"},\"name\":\"PowerShell\",\"isBuiltin\":false,\"views\
  \":[{\"when\":\"config.powershell.sideBar.CommandExplorerVisibility\"}]},{\"id\
  \":\"workbench.view.extension.cortex-cloud-activity-bar\",\"iconUrl\":{\"$mid\
  \":1,\"path\":\"%%EXTENSION_DATA_PATH%%/prismacloud.prisma-cloud-1.3.0/static\
  /icons/svg/cortex.svg\",\"scheme\":\"file\"},\"name\":\"Cortex
  Cloud\",\"isBuiltin\":false,\"views\":[{},{},{},{},{},{\"when\":\"weaknessesV\
  iewVisible\"},{\"when\":\"ossViewVisible\"},{\"when\":\"uncategorizedViewVisi\
  ble\"}]},{\"id\":\"workbench.view.extension.prisma-cloud\",\"name\":\"Prisma
  Cloud\",\"isBuiltin\":false},{\"id\":\"workbench.view.extension.roo-cline-Act\
  ivityBar\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/roovete\
  rinaryinc.roo-cline-3.23.16/assets/icons/icon.svg\",\"scheme\":\"file\"},\"na\
  me\":\"Roo
  Code\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extension\
  .claude-dev-ActivityBar\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA\
  _PATH%%/saoudrizwan.claude-dev-3.19.7/assets/icons/icon.svg\",\"scheme\":\"fi\
  le\"},\"name\":\"Cline
  (+')\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extensio\
  n.snowflakeActivityBarContainer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENS\
  ION_DATA_PATH%%/snowflake.snowflake-vsc-1.17.0/static/snowflake.svg\",\"scheme\
  \":\"file\"},\"name\":\"Snowflake\",\"isBuiltin\":false,\"views\":[{},{\"when\
  \":\"config.snowflake.enableNativeAppPanel\"},{\"when\":\"snowflake.isActiveA\
  ccountLoggedIn &&
  !config.snowflake.objectExplorer.search\"},{\"when\":\"config.snowflake.objec\
  tExplorer.search &&
  snowflake.isActiveAccountLoggedIn\"},{},{\"when\":\"config.snowflake.enableUn\
  releasedFeatures\"},{\"when\":\"config.snowflake.snowConvertMigrationAssistan\
  t.enabled\"},{\"when\":\"config.snowflake.snowparkCheckpoints.enabled\"}]},{\
  \"id\":\"workbench.view.extension.nx-console\",\"iconUrl\":{\"$mid\":1,\"path\
  \":\"%%EXTENSION_DATA_PATH%%/nrwl.angular-console-18.59.0/tree-view-icon.svg\
  \",\"scheme\":\"file\"},\"name\":\"Nx
  Console\",\"isBuiltin\":false,\"views\":[{\"when\":\"!isAngularWorkspace &&
  !isNxWorkspace\"},{\"when\":\"isAngularWorkspace &&
  !isNxWorkspace\"},{\"when\":\"isNxWorkspace\"},{\"when\":\"isNxWorkspace &&
  nxCloudView.visible.loading\"},{\"when\":\"isNxWorkspace &&
  nxCloudView.visible.onboarding\"},{\"when\":\"isNxWorkspace &&
  nxCloudView.visible.recent-cipe\"},{\"when\":\"isNxWorkspace\"},{},{\"when\":\
  \"isNxWorkspace\"}]},{\"id\":\"workbench.view.extension.containersView\",\"ic\
  onUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/ms-azuretools.vscode-c\
  ontainers-2.0.3/resources/ContainerTools.svg\",\"scheme\":\"file\"},\"name\":\
  \"Containers\",\"isBuiltin\":false,\"views\":[{},{},{},{},{},{},{}]},{\"id\":\
  \"workbench.view.extension.tinymist-activitybar\",\"iconUrl\":{\"$mid\":1,\"p\
  ath\":\"%%EXTENSION_DATA_PATH%%/myriad-dreamin.tinymist-0.13.14-darwin-arm64/\
  icons/ti.png\",\"scheme\":\"file\"},\"name\":\"Tinymist\",\"isBuiltin\":false,\
  \"views\":[]},{\"id\":\"workbench.view.extension.wiz\",\"iconUrl\":{\"$mid\":\
  1,\"path\":\"%%EXTENSION_DATA_PATH%%/wizcloud.wiz-vscode-2.5.3/resources/wiz_\
  star_logo_outline.svg\",\"scheme\":\"file\"},\"name\":\"Wiz\",\"isBuiltin\":f\
  alse,\"views\":[{\"when\":\"wiz.authenticated &&
  wiz.hasLicense\"},{\"when\":\"wiz.authenticated &&
  wiz.hasLicense\"},{\"when\":\"wiz.authenticated &&
  wiz.hasLicense\"},{\"when\":\"!wiz.authenticated\"},{\"when\":\"wiz.authentic\
  ated &&
  !wiz.hasLicense\"}]},{\"id\":\"workbench.view.sync\",\"themeIcon\":{\"id\":\"\
  settings-sync-view-icon\"},\"name\":\"Settings
  Sync\",\"isBuiltin\":true,\"views\":[{\"when\":\"enableSyncConflictsView &&
  hasConflicts\"},{\"when\":\"enableSyncActivityViews &&
  userDataSyncAccountStatus == 'available' && syncStatus !=
  'uninitialized'\"},{\"when\":\"enableSyncActivityViews &&
  userDataSyncAccountStatus == 'available' && syncStatus !=
  'uninitialized'\"},{\"when\":\"enableSyncActivityViews &&
  userDataSyncAccountStatus == 'available' && syncStatus !=
  'uninitialized'\"},{\"when\":\"enableSyncActivityViews\"},{\"when\":\"enableS\
  yncActivityViews\"}]},{\"id\":\"workbench.view.editSessions\",\"themeIcon\":{\
  \"id\":\"edit-sessions-view-icon\"},\"name\":\"Cloud
  Changes\",\"isBuiltin\":true,\"views\":[{\"when\":\"editSessionsShowView\"}]}\
  ]"
workbench.activityBar.location: default
workbench.auxiliaryBar.lastNonMaximizedSize: "300"
workbench.auxiliarybar.pinnedPanels: '[{"id":"workbench.panel.aichat","pinned":true,"visible":false,"order":1},{"id":"workbench.panel.composerViewPane2","pinned":true,"visible":false,"order":1},{"id":"workbench.panel.aipaneaaaiBugFinder","pinned":true,"visible":false,"order":3},{"id":"workbench.panel.chat","pinned":true,"visible":false,"order":100},{"id":"workbench.panel.chatEditing","pinned":true,"visible":false,"order":101}]'
workbench.auxiliarybar.placeholderPanels: '[{"id":"workbench.panel.aichat","name":"New
  Chat","isBuiltin":false},{"id":"workbench.panel.composerViewPane2","name":"Composer","isBuiltin":false},{"id":"workbench.panel.aipaneaaaiBugFinder","name":"Bug
  Finder","isBuiltin":false},{"id":"workbench.panel.chat","themeIcon":{"id":"comment-discussion"},"name":"Chat","isBuiltin":true,"views":[{"when":"chatExtensionInvalid
  || chatPanelParticipantRegistered || chatSetupInstalled && !chatSetupDisabled
  || !chatSetupDisabled &&
  !chatSetupHidden"}]},{"id":"workbench.panel.chatEditing","name":"Copilot
  Edits","isBuiltin":false}]'
workbench.auxiliaryBar.size: "433"
workbench.backgroundComposer.persistentData: '{"showControlPanel":false,"dataVersion":1,"lastOpenedBcIds":{},"archivedBcIds":[],"selectedTab":"personal","isBackgroundComposerEnabled":false}'
workbench.chat.hideWelcomeView: "true"
workbench.contrib.onboarding.browser.changeManagement.03122025.shown: "true"
workbench.contrib.onboarding.browser.changeManagement.05052025.shown: "true"
workbench.contrib.onboarding.browser.changeManagement.v1.shown: "true"
workbench.contrib.onboarding.browser.changeRemainingCmdBackspaceKeybindings.04012025.shown: "true"
workbench.contrib.onboarding.browser.gettingStarted.contribution.ts.firsttime: "false"
workbench.editor.languageDetectionOpenedLanguages.global: '[["javascript",true],["jsonc",true],["css",true],["scss",true],["typescriptreact",true],["jinja-sql",true],["python",true],["markdown",true],["toml",true],["xml",true],["csharp",true],["plaintext",true]]'
workbench.explorer.views.state.hidden: '[{"id":"notepad","isHidden":false},{"id":"outline","isHidden":false},{"id":"timeline","isHidden":false},{"id":"workbench.explorer.openEditorsView","isHidden":true},{"id":"workbench.explorer.emptyView","isHidden":false},{"id":"npm","isHidden":true},{"id":"workbench.explorer.fileView","isHidden":false},{"id":"aws.appBuilderForFileExplorer","isHidden":false},{"id":"dartDependencyTree","isHidden":false},{"id":"commitViewProvider","isHidden":false},{"id":"compareCommitViewProvider","isHidden":false},{"id":"go.explorer","isHidden":false},{"id":"ionide.projectExplorer","isHidden":false},{"id":"malloySchema","isHidden":false},{"id":"solutionExplorer","isHidden":false},{"id":"cell-tag","isHidden":false},{"id":"go.package.outline","isHidden":false},{"id":"backgroundComposerExplorer","isHidden":false},{"id":"leanModuleHierarchy","isHidden":false},{"id":"copilot-workspace-vscode.allSessions","isHidden":false},{"id":"copilot-workspace-vscode.task","isHidden":false},{"id":"copilot-workspace-vscode.plan","isHidden":false}]'
workbench.grid.size: '{"height":1521,"width":3830}'
workbench.panel.aipaneaaaiBugFinder.hidden: '[{"id":"workbench.panel.aipane.viewaaaiBugFinder","isHidden":false}]'
workbench.panel.alignment: center
workbench.panel.chat.hidden: '[{"id":"workbench.panel.chat.view.copilot","isHidden":false}]'
workbench.panel.chatEditing.hidden: '[{"id":"workbench.panel.chat.view.edits","isHidden":false}]'
workbench.panel.composerChatViewPane.hidden: '[{"id":"workbench.panel.aichat.view","isHidden":false},{"id":"workbench.panel.aichat.view.4c7f3bfa-c1bb-46ac-afed-f67b64936507","isHidden":false},{"id":"workbench.panel.aichat.view.6d2a425a-a684-4c46-8712-be9805e93745","isHidden":false},{"id":"workbench.panel.aichat.view.db079529-8863-460d-9a18-35a4e11f416e","isHidden":false},{"id":"workbench.panel.aichat.view.f80b3d20-e3a2-464c-a3cd-c2a08febb055","isHidden":false},{"id":"workbench.panel.aichat.view.aeeb21e6-df84-4187-a3e9-f8c8ffaf19f9","isHidden":false},{"id":"workbench.panel.aichat.view.86b04444-807f-436d-a8e3-e8069303f6da","isHidden":false},{"id":"workbench.panel.aichat.view.83d503a8-2daf-49aa-8a02-8eeb7c6995f7","isHidden":false},{"id":"workbench.panel.aichat.view.4fa12760-72f6-4f61-9440-5fed633eab33","isHidden":false},{"id":"workbench.panel.aichat.view.bc51e801-2524-4a64-a2eb-b5e870cc7fa3","isHidden":false},{"id":"workbench.panel.aichat.view.2e0cc017-966c-4c88-8f1e-bf57dac57411","isHidden":false},{"id":"workbench.panel.aichat.view.bc39d1b2-02dc-4adc-bba7-ad75fa7bf869","isHidden":false},{"id":"workbench.panel.aichat.view.75c0670c-9537-4e4b-b8fe-32ecbb161801","isHidden":false},{"id":"workbench.panel.aichat.view.eef73a53-20ec-413a-9f02-5b36857275ad","isHidden":false},{"id":"workbench.panel.aichat.view.8844c29f-6861-4cb7-a405-dd902e5d6d26","isHidden":false},{"id":"workbench.panel.aichat.view.68b07fa3-d193-48eb-b240-cacb8e24de68","isHidden":false},{"id":"workbench.panel.aichat.view.6d1dbc37-87e8-4d5d-a984-4090b16bf9ae","isHidden":false},{"id":"workbench.panel.aichat.view.8ca5186e-438d-4171-84eb-d6d56ab62f58","isHidden":false},{"id":"workbench.panel.aichat.view.03a32512-5e5b-4bbf-8165-db0542762969","isHidden":false},{"id":"workbench.panel.aichat.view.34586670-a10a-4c82-82c1-035a7854ee9e","isHidden":false},{"id":"workbench.panel.aichat.view.7549c983-78f2-4408-8ee9-2f9105324fae","isHidden":false},{"id":"workbench.panel.aichat.view.24c8dc15-bd90-4e75-9b7f-eea21412ff8d","isHidden":false},{"id":"workbench.panel.aichat.view.121833a1-ced0-48d7-9171-877de26dcac8","isHidden":false},{"id":"workbench.panel.aichat.view.99475a3d-b91f-468a-a54e-6b00b9197508","isHidden":false},{"id":"workbench.panel.aichat.view.c2532e10-339c-4ab1-9276-7f49a156c42a","isHidden":false},{"id":"workbench.panel.aichat.view.703b25f3-ea10-438d-a2a5-58f42e713156","isHidden":false},{"id":"workbench.panel.aichat.view.09eb8305-ba12-479c-91a4-46dc230c5138","isHidden":false},{"id":"workbench.panel.aichat.view.86fe8a76-95b6-4cd2-94a5-6b339a3bb40e","isHidden":false},{"id":"workbench.panel.aichat.view.d40454de-bd9f-40b6-9588-d3f262afcfea","isHidden":false},{"id":"workbench.panel.aichat.view.8a7309c8-0a02-42d0-8536-375b6241c821","isHidden":false},{"id":"workbench.panel.aichat.view.9d3ef8dc-bc85-4189-a58f-452d7d92ed63","isHidden":false},{"id":"workbench.panel.aichat.view.3872694d-54eb-4f6c-808c-2c3f984ede10","isHidden":false},{"id":"workbench.panel.aichat.view.73050f15-dddf-4686-9111-adeb082ebd21","isHidden":false},{"id":"workbench.panel.aichat.view.332f6155-8c20-42b8-9465-ecc8e98f4cad","isHidden":false},{"id":"workbench.panel.aichat.view.f8f5499c-bacd-4e33-b47a-90bff34f95f4","isHidden":false},{"id":"workbench.panel.aichat.view.2772133f-4dea-440d-a1cc-4fedc8418144","isHidden":false},{"id":"workbench.panel.aichat.view.fd76d3c1-2931-43bf-b015-f7bb11f2bd88","isHidden":false}]'
workbench.panel.composerViewPane2.hidden: '[{"id":"workbench.panel.composerViewPane2.view","isHidden":false}]'
workbench.panel.lastNonMaximizedHeight: "300"
workbench.panel.lastNonMaximizedWidth: "300"
workbench.panel.markers.hidden: '[{"id":"workbench.panel.markers.view","isHidden":false}]'
workbench.panel.output.hidden: '[{"id":"workbench.panel.output","isHidden":false}]'
workbench.panel.pinnedPanels: '[{"id":"workbench.panel.markers","pinned":true,"visible":false,"order":0},{"id":"workbench.panel.output","pinned":true,"visible":false,"order":1},{"id":"workbench.panel.repl","pinned":true,"visible":false,"order":2},{"id":"terminal","pinned":true,"visible":false,"order":3},{"id":"workbench.panel.testResults","pinned":true,"visible":false,"order":3},{"id":"~remote.forwardedPortsContainer","pinned":true,"visible":false,"order":5},{"id":"workbench.view.extension.gitlensPanel","pinned":true,"visible":false,"order":8},{"id":"workbench.view.extension.terraform-cloud-panel","pinned":true,"visible":false,"order":9},{"id":"workbench.view.extension.dbt_preview_results","pinned":true,"visible":false,"order":10},{"id":"workbench.view.extension.lineage_view","pinned":true,"visible":false,"order":11},{"id":"workbench.panel.comments","pinned":true,"visible":false,"order":10},{"id":"workbench.view.extension.docs_edit_view","pinned":true,"visible":false,"order":12},{"id":"workbench.view.extension.insights_view","pinned":true,"visible":false,"order":13},{"id":"workbench.view.extension.data-wrangler-secondary","pinned":true,"visible":false,"order":14},{"id":"workbench.view.extension.cortex-cloud-panel","pinned":true,"visible":false,"order":16},{"id":"workbench.view.extension.snowflakeResultsContainer","pinned":true,"visible":false,"order":17},{"id":"workbench.view.extension.snowflakeDetailsContainer","pinned":true,"visible":false,"order":18},{"id":"workbench.view.extension.jupyter-variables","pinned":true,"visible":false,"order":15},{"id":"workbench.view.extension.dbt-lineage","pinned":true,"visible":false,"order":6},{"id":"workbench.view.extension.query-results","pinned":true,"visible":false,"order":7},{"id":"refactorPreview","pinned":true,"visible":false}]'
workbench.panel.placeholderPanels: "[{\"id\":\"workbench.panel.markers\",\"them\
  eIcon\":{\"id\":\"markers-view-icon\"},\"name\":\"Problems\",\"isBuiltin\":tr\
  ue,\"views\":[{}]},{\"id\":\"workbench.panel.output\",\"themeIcon\":{\"id\":\
  \"output-view-icon\"},\"name\":\"Output\",\"isBuiltin\":true,\"views\":[{}]},{\
  \"id\":\"workbench.panel.repl\",\"themeIcon\":{\"id\":\"debug-console-view-ic\
  on\"},\"name\":\"Debug
  Console\",\"isBuiltin\":true,\"views\":[{\"when\":\"debuggersAvailable\"}]},{\
  \"id\":\"terminal\",\"themeIcon\":{\"id\":\"terminal-view-icon\"},\"name\":\"\
  Terminal\",\"isBuiltin\":true,\"views\":[{}]},{\"id\":\"workbench.panel.testR\
  esults\",\"themeIcon\":{\"id\":\"test-results-icon\"},\"name\":\"Test
  Results\",\"isBuiltin\":true,\"views\":[{\"when\":\"testing.hasAnyResults\"}]\
  },{\"id\":\"~remote.forwardedPortsContainer\",\"themeIcon\":{\"id\":\"ports-v\
  iew-icon\"},\"name\":\"Ports\",\"isBuiltin\":true,\"views\":[{}]},{\"id\":\"w\
  orkbench.view.extension.gitlensPanel\",\"themeIcon\":{\"id\":\"gitlens-graph\
  \"},\"name\":\"GitLens\",\"isBuiltin\":false,\"views\":[{\"when\":\"!gitlens:\
  disabled && !gitlens:plus:disabled\"},{\"when\":\"!gitlens:disabled &&
  !gitlens:plus:disabled\"}]},{\"id\":\"workbench.view.extension.terraform-clou\
  d-panel\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/hashicor\
  p.terraform-2.34.5-darwin-arm64/assets/icons/vs_code_terraform_cloud.svg\",\"\
  scheme\":\"file\"},\"name\":\"HCP
  Terraform\",\"isBuiltin\":false,\"views\":[{\"when\":\"terraform.cloud.run.vi\
  ewingPlan\"},{\"when\":\"terraform.cloud.run.viewingApply\"}]},{\"id\":\"work\
  bench.view.extension.dbt_preview_results\",\"iconUrl\":{\"$mid\":1,\"path\":\
  \"%%EXTENSION_DATA_PATH%%/innoverio.vscode-dbt-power-user-0.58.7/media/images\
  /dbt_icon.svg\",\"scheme\":\"file\"},\"name\":\"Query
  Results\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extens\
  ion.lineage_view\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%\
  /innoverio.vscode-dbt-power-user-0.58.7/media/images/dbt_icon.svg\",\"scheme\
  \":\"file\"},\"name\":\"Lineage\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\
  \"workbench.panel.comments\",\"name\":\"Comments\",\"isBuiltin\":false},{\"id\
  \":\"workbench.view.extension.docs_edit_view\",\"iconUrl\":{\"$mid\":1,\"path\
  \":\"%%EXTENSION_DATA_PATH%%/innoverio.vscode-dbt-power-user-0.58.7/media/ima\
  ges/dbt_icon.svg\",\"scheme\":\"file\"},\"name\":\"Documentation
  Editor\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extensi\
  on.insights_view\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%\
  /innoverio.vscode-dbt-power-user-0.58.7/media/images/dbt_icon.svg\",\"scheme\
  \":\"file\"},\"name\":\"Actions\",\"isBuiltin\":false,\"views\":[{}]},{\"id\":\
  \"workbench.view.extension.data-wrangler-secondary\",\"themeIcon\":{\"id\":\"\
  data-wrangler\"},\"name\":\"Data
  Wrangler\",\"isBuiltin\":false,\"views\":[{\"when\":\"dataWrangler.dataWrangl\
  erActive &&
  isWorkspaceTrusted\"}]},{\"id\":\"workbench.view.extension.cortex-cloud-panel\
  \",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/prismacloud.pri\
  sma-cloud-1.3.0/static/icons/svg/cortex.svg\",\"scheme\":\"file\"},\"name\":\
  \"Cortex Cloud Scan
  History\",\"isBuiltin\":false,\"views\":[{\"when\":\"workspaceFolderCount ==
  '1'\"}]},{\"id\":\"workbench.view.extension.snowflakeResultsContainer\",\"ico\
  nUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%%/snowflake.snowflake-vsc\
  -1.17.0/static/snowflake.svg\",\"scheme\":\"file\"},\"name\":\"Snowflake\",\"\
  isBuiltin\":false,\"views\":[{}]},{\"id\":\"workbench.view.extension.snowflak\
  eDetailsContainer\",\"iconUrl\":{\"$mid\":1,\"path\":\"%%EXTENSION_DATA_PATH%\
  %/snowflake.snowflake-vsc-1.17.0/static/snowflake.svg\",\"scheme\":\"file\"},\
  \"name\":\"Snowflake\",\"isBuiltin\":false,\"views\":[{\"when\":\"snowflake.i\
  sActiveAccountLoggedIn\"}]},{\"id\":\"workbench.view.extension.jupyter-variab\
  les\",\"themeIcon\":{\"id\":\"notebook\"},\"name\":\"Jupyter\",\"isBuiltin\":\
  false,\"views\":[{\"when\":\"jupyter.hasNativeNotebookOrInteractiveWindowOpen\
  \"},{\"when\":\"jupyter.hasNativeNotebookOrInteractiveWindowOpen &&
  jupyter:showTagsExplorer\"}]},{\"id\":\"workbench.view.extension.dbt-lineage\
  \",\"themeIcon\":{\"id\":\"type-hierarchy\"},\"name\":\"Lineage\",\"isBuiltin\
  \":false,\"views\":[{\"when\":\"showWebviewPanels\"}]},{\"id\":\"workbench.vi\
  ew.extension.query-results\",\"themeIcon\":{\"id\":\"table\"},\"name\":\"Query
  Results\",\"isBuiltin\":false,\"views\":[{\"when\":\"showWebviewPanels\"}]},{\
  \"id\":\"refactorPreview\",\"themeIcon\":{\"id\":\"refactor-preview-view-icon\
  \"},\"name\":\"Refactor
  Preview\",\"isBuiltin\":true,\"views\":[{\"when\":\"refactorPreview.enabled\"\
  }]}]"
workbench.panel.repl.hidden: '[{"id":"workbench.panel.repl.view","isHidden":false}]'
workbench.panel.size: "519"
workbench.scm.views.state.hidden: '[{"id":"workbench.scm.repositories","isHidden":true},{"id":"workbench.scm","isHidden":false},{"id":"workbench.scm.history","isHidden":false},{"id":"gitlens.views.repositories","isHidden":true},{"id":"gitlens.views.commits","isHidden":false},{"id":"gitlens.views.branches","isHidden":false},{"id":"gitlens.views.remotes","isHidden":false},{"id":"gitlens.views.stashes","isHidden":false},{"id":"gitlens.views.tags","isHidden":false},{"id":"gitlens.views.worktrees","isHidden":false},{"id":"gitlens.views.contributors","isHidden":false},{"id":"gitlens.views.scm.grouped","isHidden":false}]'
workbench.services.onFirstStartupService.isVeryFirstTime: "false"
workbench.sideBar.size: "539"
workbench.statusbar.hidden: '["GitHub.copilot.status"]'
workbench.telemetryOptOutShown: "true"
workbench.view.bugbot.hidden: '[{"id":"workbench.views.bugbot","isHidden":false}]'
workbench.view.debug.state.hidden: '[{"id":"workbench.debug.welcome","isHidden":false},{"id":"workbench.debug.variablesView","isHidden":false},{"id":"workbench.debug.watchExpressionsView","isHidden":false},{"id":"workbench.debug.callStackView","isHidden":false},{"id":"workbench.debug.loadedScriptsView","isHidden":false},{"id":"workbench.debug.breakPointsView","isHidden":false},{"id":"jsBrowserBreakpoints","isHidden":false},{"id":"jsExcludedCallers","isHidden":false},{"id":"jsDebugNetworkTree","isHidden":false}]'
workbench.view.extension.atlascode-drawer.state.hidden: '[{"id":"atlascode.views.jira.customJql","isHidden":false},{"id":"atlascode.views.bb.pullrequestsTreeView","isHidden":false},{"id":"atlascode.views.bb.pipelinesTreeView","isHidden":false},{"id":"atlascode.views.bb.issuesTreeView","isHidden":false},{"id":"atlascode.views.helpTreeView","isHidden":false},{"id":"atlascode.views.jira.assignedWorkItemsTreeView","isHidden":false},{"id":"atlascode.views.jira.customJqlTreeView","isHidden":false}]'
workbench.view.extension.aws-explorer.state.hidden: '[{"id":"aws.toolkit.notifications","isHidden":false},{"id":"aws.amazonq.codewhisperer","isHidden":false},{"id":"aws.explorer","isHidden":false},{"id":"aws.cdk","isHidden":false},{"id":"aws.appBuilder","isHidden":false},{"id":"aws.codecatalyst","isHidden":false},{"id":"aws.toolkit.AmazonCommonAuth","isHidden":false}]'
workbench.view.extension.claude-dev-ActivityBar.state.hidden: '[{"id":"claude-dev.SidebarProvider","isHidden":false}]'
workbench.view.extension.containersView.state.hidden: '[{"id":"vscode-containers.views.containers","isHidden":false},{"id":"vscode-containers.views.images","isHidden":false},{"id":"vscode-containers.views.registries","isHidden":false},{"id":"vscode-containers.views.networks","isHidden":false},{"id":"vscode-containers.views.volumes","isHidden":false},{"id":"vscode-containers.views.dockerContexts","isHidden":false},{"id":"vscode-containers.views.help","isHidden":false}]'
workbench.view.extension.cortex-cloud-activity-bar.state.hidden:
  '[{"id":"cortexCloud.landingPage","isHidden":false},{"id":"cortexCloud.resultTree.iac-misconfiguration","isHidden":false},{"id":"cortexCloud.resultTree.secrets","isHidden":false},{"id":"cortexCloud.resultTree.vulnerabilities","isHidden":false},{"id":"cortexCloud.resultTree.licenses","isHidden":false},{"id":"cortexCloud.resultTree.weaknesses","isHidden":false},{"id":"cortexCloud.resultTree.oss","isHidden":false},{"id":"cortexCloud.resultTree.uncategorized","isHidden":false}]'
workbench.view.extension.cortex-cloud-panel.state.hidden: '[{"id":"cortexCloud.scanHistory","isHidden":false}]'
workbench.view.extension.datapilot_view.state.hidden: '[{"id":"dbtPowerUser.datapilot-webview","isHidden":false}]'
workbench.view.extension.dbt-lineage.state.hidden: '[{"id":"dbt.dbtLineage","isHidden":false}]'
workbench.view.extension.dbt_preview_results.state.hidden: '[{"id":"dbtPowerUser.PreviewResults","isHidden":false}]'
workbench.view.extension.dbt_view.state.hidden: '[{"id":"model_test_treeview","isHidden":false},{"id":"parent_model_treeview","isHidden":false},{"id":"children_model_treeview","isHidden":false},{"id":"documentation_treeview","isHidden":false},{"id":"icon_actions_treeview","isHidden":false}]'
workbench.view.extension.dockerView.state.hidden: '[{"id":"dockerContainers","isHidden":false},{"id":"dockerImages","isHidden":false},{"id":"dockerRegistries","isHidden":false},{"id":"dockerNetworks","isHidden":false},{"id":"dockerVolumes","isHidden":false},{"id":"vscode-docker.views.dockerContexts","isHidden":false},{"id":"vscode-docker.views.help","isHidden":false}]'
workbench.view.extension.docs_edit_view.state.hidden: '[{"id":"dbtPowerUser.DocsEdit","isHidden":false}]'
workbench.view.extension.figma.state.hidden: '[{"id":"figma.views.login","isHidden":false},{"id":"figma.views.dummyLoginNotifications","isHidden":false},{"id":"figma.views.files","isHidden":false},{"id":"figma.views.notifications","isHidden":false}]'
workbench.view.extension.github-actions.state.hidden: '[{"id":"github-actions.current-branch","isHidden":false},{"id":"github-actions.workflows","isHidden":false},{"id":"github-actions.settings","isHidden":false},{"id":"github-actions.empty-view","isHidden":false}]'
workbench.view.extension.github-pull-request.state.hidden: '[{"id":"github:createPullRequestWebview","isHidden":false},{"id":"github:compareChangesFiles","isHidden":false},{"id":"github:compareChangesCommits","isHidden":false},{"id":"prStatus:github","isHidden":false},{"id":"github:activePullRequest","isHidden":false},{"id":"github:activePullRequest:welcome","isHidden":false}]'
workbench.view.extension.github-pull-requests.state.hidden: '[{"id":"github:login","isHidden":false},{"id":"pr:github","isHidden":false},{"id":"issues:github","isHidden":false},{"id":"notifications:github","isHidden":false},{"id":"github:conflictResolution","isHidden":false}]'
workbench.view.extension.gitlens.state.hidden: '[{"id":"gitlens.views.home","isHidden":false},{"id":"gitlens.views.launchpad","isHidden":false},{"id":"gitlens.views.drafts","isHidden":false},{"id":"gitlens.views.workspaces","isHidden":false}]'
workbench.view.extension.gitlensInspect.state.hidden: '[{"id":"gitlens.views.commitDetails","isHidden":false},{"id":"gitlens.views.pullRequest","isHidden":false},{"id":"gitlens.views.lineHistory","isHidden":false},{"id":"gitlens.views.fileHistory","isHidden":false},{"id":"gitlens.views.timeline","isHidden":false},{"id":"gitlens.views.searchAndCompare","isHidden":false}]'
workbench.view.extension.gitlensPanel.state.hidden: '[{"id":"gitlens.views.graph","isHidden":false},{"id":"gitlens.views.graphDetails","isHidden":false}]'
workbench.view.extension.insights_view.state.hidden: '[{"id":"dbtPowerUser.Insights","isHidden":false}]'
workbench.view.extension.ionide-fsharp.state.hidden: '[{"id":"ionide.projectExplorerInActivity","isHidden":false}]'
workbench.view.extension.lineage_view.state.hidden: '[{"id":"dbtPowerUser.Lineage","isHidden":false}]'
workbench.view.extension.nx-console.state.hidden: '[{"id":"nxConsole.views.welcome","isHidden":false},{"id":"nxConsole.views.angular-welcome","isHidden":false},{"id":"nxProjects","isHidden":false},{"id":"nxCloudLoading","isHidden":false},{"id":"nxCloudOnboarding","isHidden":false},{"id":"nxCloudRecentCIPE","isHidden":false},{"id":"nxCommands","isHidden":false},{"id":"nxHelpAndFeedback","isHidden":false},{"id":"nxMigrate","isHidden":false}]'
workbench.view.extension.openapi-explorer.state.hidden: '[{"id":"openapiOutline","isHidden":false},{"id":"openapiNotSelectedOutline","isHidden":false}]'
workbench.view.extension.postgres-explorer.state.hidden: '[{"id":"postgres","isHidden":false}]'
workbench.view.extension.prisma-cloud.state.hidden: '[{"id":"general","isHidden":false},{"id":"iac-misconfiguration","isHidden":false},{"id":"secrets","isHidden":false},{"id":"vulnerabilities","isHidden":false},{"id":"licenses","isHidden":false},{"id":"weaknesses","isHidden":false},{"id":"oss","isHidden":false},{"id":"uncategorized","isHidden":false}]'
workbench.view.extension.query-results.state.hidden: '[{"id":"dbt.queryResults","isHidden":false}]'
workbench.view.extension.roo-cline-ActivityBar.state.hidden: '[{"id":"roo-cline.SidebarProvider","isHidden":false}]'
workbench.view.extension.snowflakeActivityBarContainer.state.hidden:
  '[{"id":"snowflakeAccount","isHidden":false},{"id":"snowflakeNativeApp","isHidden":false},{"id":"snowflakeObjectExplorer","isHidden":false},{"id":"snowflakeSearchableObjectExplorer","isHidden":false},{"id":"snowflakeQueryHistoryTree","isHidden":false},{"id":"snowparkCheckpoints","isHidden":false},{"id":"snowflakeSnowConvertEwiList","isHidden":false},{"id":"snowflakeSmaEwiList","isHidden":false}]'
workbench.view.extension.snowflakeResultsContainer.state.hidden: '[{"id":"snowflakeQueryResults","isHidden":false}]'
workbench.view.extension.terraform-cloud.state.hidden: '[{"id":"terraform.cloud.workspaces","isHidden":false},{"id":"terraform.cloud.runs","isHidden":false}]'
workbench.view.extension.terraform.state.hidden: '[{"id":"terraform.providers","isHidden":false},{"id":"terraform.modules","isHidden":false}]'
workbench.view.extension.test.state.hidden: '[{"id":"workbench.view.testing","isHidden":false},{"id":"workbench.view.testCoverage","isHidden":false},{"id":"go.test.profile","isHidden":false}]'
workbench.view.extension.todo-tree-container.state.hidden: '[{"id":"todo-tree-view","isHidden":false}]'
workbench.view.extension.vscode-copilot-workspace.state.hidden:
  '[{"id":"copilot-workspace-vscode.allSessions","isHidden":false},{"id":"copilot-workspace-vscode.task","isHidden":false},{"id":"copilot-workspace-vscode.plan","isHidden":false}]'
workbench.view.extension.vscode-edge-devtools-view.state.hidden:
  '[{"id":"vscode-edge-devtools-view.targets","isHidden":false},{"id":"vscode-edge-devtools-view.help-links","isHidden":false}]'
workbench.view.extension.wiz.state.hidden: '[{"id":"wiz.codeFindingsView","isHidden":false},{"id":"wiz.imageFindingsView","isHidden":false},{"id":"wiz.helpview","isHidden":false},{"id":"wiz.loginView","isHidden":false},{"id":"wiz.missingLicenseView","isHidden":false}]'
workbench.view.extensions.state.hidden: '[{"id":"workbench.views.extensions.installed","isHidden":false},{"id":"workbench.views.extensions.searchOutdated","isHidden":false},{"id":"workbench.views.extensions.workspaceRecommendations","isHidden":false},{"id":"workbench.views.extensions.popular","isHidden":false},{"id":"workbench.views.extensions.searchRecentlyUpdated","isHidden":false},{"id":"workbench.views.extensions.otherRecommendations","isHidden":false},{"id":"extensions.recommendedList","isHidden":false},{"id":"workbench.views.extensions.enabled","isHidden":true},{"id":"workbench.views.extensions.disabled","isHidden":true},{"id":"workbench.views.extensions.marketplace","isHidden":false},{"id":"workbench.views.extensions.searchInstalled","isHidden":false},{"id":"workbench.views.extensions.searchEnabled","isHidden":false},{"id":"workbench.views.extensions.searchDisabled","isHidden":false},{"id":"workbench.views.extensions.searchBuiltin","isHidden":false},{"id":"workbench.views.extensions.searchWorkspaceUnsupported","isHidden":false},{"id":"workbench.views.extensions.builtinFeatureExtensions","isHidden":false},{"id":"workbench.views.extensions.builtinThemeExtensions","isHidden":false},{"id":"workbench.views.extensions.builtinProgrammingLanguageExtensions","isHidden":false},{"id":"workbench.views.extensions.untrustedUnsupportedExtensions","isHidden":false},{"id":"workbench.views.extensions.untrustedPartiallySupportedExtensions","isHidden":false},{"id":"workbench.views.extensions.virtualUnsupportedExtensions","isHidden":false},{"id":"workbench.views.extensions.virtualPartiallySupportedExtensions","isHidden":false},{"id":"workbench.views.extensions.deprecatedExtensions","isHidden":false},{"id":"workbench.views.mcp.installed","isHidden":false},{"id":"workbench.views.mcp.default.marketplace","isHidden":false},{"id":"workbench.views.mcp.marketplace","isHidden":false}]'
workbench.view.remote.state.hidden: '[{"id":"targetsContainers","isHidden":false},{"id":"detailsContainers","isHidden":false},{"id":"devVolumes","isHidden":false},{"id":"remoteTargets","isHidden":false}]'
workbench.view.search.state.hidden: '[{"id":"workbench.view.search","isHidden":false}]'
workbench.views.extensions.installed.size: "95"
workbench.welcomePage.hiddenCategories: '["GitHub.copilot-chat#copilotWelcome"]'
workbench.welcomePage.walkthroughMetadata: '[["GitHub.copilot-chat#copilotWelcome",{"firstSeen":1740226929092,"stepIDs":["copilot.setup.signIn","copilot.setup.signInNoAction","copilot.setup.signUp","copilot.setup.signUpNoAction","copilot.panelChat","copilot.edits","copilot.firstSuggest","copilot.inlineChatNotMac","copilot.inlineChatMac","copilot.sparkle"],"manaullyOpened":false}],["amazonwebservices.aws-toolkit-vscode#aws.toolkit.lambda.walkthrough",{"firstSeen":1740743239454,"stepIDs":["toolInstall","chooseTemplate","step1","step2"],"manaullyOpened":false}],["eamodio.gitlens#welcome",{"firstSeen":1740743239454,"stepIDs":["get-started-community","welcome-in-trial","welcome-in-trial-expired","welcome-in-trial-expired-eligible","welcome-paid","visualize-code-history","accelerate-pr-reviews","streamline-collaboration","improve-workflows-with-integrations"],"manaullyOpened":false}],["innoverio.vscode-dbt-power-user#initialSetup",{"firstSeen":1740743239454,"stepIDs":["open","initialSupport","updateExtension","selectInterpreter","installDbtCore","installDbtCloud","associateFileExts","pickProject","installDeps","validateProjectCore","validateProjectCloud","finish"],"manaullyOpened":false}],["innoverio.vscode-dbt-power-user#tutorials",{"firstSeen":1740743239454,"stepIDs":["generate_models","autocompletion","previews","dependants","documentation","lineage","healthcheck"],"manaullyOpened":false}],["malloydata.malloy-vscode#malloy-quickstart",{"firstSeen":1740743239454,"stepIDs":["configure-connections","download-samples","check-out-samples"],"manaullyOpened":false}],["ms-azuretools.vscode-docker#dockerStart",{"firstSeen":1740743239454,"stepIDs":["openFolder","openFolderMac","scaffold","buildImage","runContainer","dockerExplorer","pushImage","azDeploy","learn"],"manaullyOpened":false}],["ms-dotnettools.csdevkit#csdevkit.gettingStarted",{"firstSeen":1740743239454,"stepIDs":["csdevkit.signInStep","csdevkit.setupEnvironmentStep","csdevkit.openWorkspaceStep","csdevkit.createNewProjectStep","csdevkit.launchDebugAndTestStep","csdevkit.learnMoreStep"],"manaullyOpened":false}],["ms-python.python#pythonWelcome",{"firstSeen":1740743239454,"stepIDs":["python.createPythonFolder","python.createPythonFile","python.installPythonWin8","python.installPythonMac","python.installPythonLinux","python.createEnvironment","python.runAndDebug","python.learnMoreWithDS"],"manaullyOpened":false}],["ms-python.python#pythonDataScienceWelcome",{"firstSeen":1740743239454,"stepIDs":["python.installJupyterExt","python.createNewNotebook","python.openInteractiveWindow","python.dataScienceLearnMore"],"manaullyOpened":false}],["ms-toolsai.datawrangler#dataWranglerWelcome",{"firstSeen":1740743239454,"stepIDs":["openDataWrangler","openDataWrangler-web-variant","cleanDataUsingOperations","applyYourChanges","exportYourCode","openTitanicCSV"],"manaullyOpened":false}],["ms-toolsai.jupyter#jupyterWelcome",{"firstSeen":1740743239454,"stepIDs":["ipynb.newUntitledIpynb","jupyter.selectKernel","jupyter.exploreAndDebug","jupyter.dataScienceLearnMore"],"manaullyOpened":false}],["ms-vscode.powershell#PowerShell",{"firstSeen":1740743239454,"stepIDs":["install-windows","install-mac","install-linux","file","sessions","ise","terminal","explore"],"manaullyOpened":false}],["snowflake.snowflake-vsc#snowflake.intro",{"firstSeen":1740743239454,"stepIDs":["authenticate","execute-sql-mac","execute-sql","db-explorer","autocomplete"],"manaullyOpened":false}],["nrwl.angular-console#nxConsole",{"firstSeen":1740744159336,"stepIDs":["nxConsole.generate","nxConsole.run","nxConsole.commonNxCommands","nxConsole.projects","nxConsole.streamlining"],"manaullyOpened":false}]]'
zokugun.cron-tasks: '{"version":"0.2.1"}'
